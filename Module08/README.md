# Module 08: Hands on With Microsoft Foundry Local - Complete Developer Toolkit

## Overview

Microsoft Foundry Local represents the next generation of edge AI development, providing developers with powerful tools to build, deploy, and scale AI applications locally while maintaining seamless integration with Azure AI Foundry. This module provides comprehensive coverage of Foundry Local from installation to advanced agent development.

**Key Technologies:**
- Microsoft Foundry Local CLI and SDK
- Azure AI Foundry integration
- On-device model inference
- Local model caching and optimization
- Agent-based architectures

## Module Learning Objectives

By completing this module, you will:

- **Master Foundry Local Setup**: Install, configure, and optimize Foundry Local for Windows 11 development
- **Deploy Diverse Models**: Run phi, qwen, deepseek, and GPT-OSS-20B models locally with CLI commands
- **Build Production Solutions**: Create AI applications with advanced prompt engineering and data integration
- **Leverage Open-Source Ecosystem**: Integrate Hugging Face models and community-driven additions
- **Compare AI Architectures**: Understand LLMs vs SLMs trade-offs and deployment strategies
- **Develop AI Agents**: Build intelligent agents using Foundry Local's architecture and grounding capabilities
- **Implement Models as Tools**: Create modular, customizable AI solutions for enterprise applications

## Session Structure

### [1: Getting Started with Foundry Local](./01.FoundryLocalSetup.md)
**Focus**: Installation, CLI setup, model caching, and hardware acceleration

**What You'll Learn:**
- Complete Foundry Local installation on Windows 11
- CLI configuration and command structure
- Model caching strategies for optimal performance
- Hardware acceleration setup and optimization
- Hands-on deployment of phi, qwen, deepseek, and GPT-OSS-20B models

**Duration**: 2-3 hours  
**Prerequisites**: Windows 11, basic command line knowledge

---

### [2: Build AI Solutions with Azure AI Foundry](./02.AzureAIFoundryIntegration.md)
**Focus**: Advanced prompt engineering, data integration, and actionable tasks

**What You'll Learn:**
- Advanced prompt engineering techniques
- Data integration patterns and best practices
- Building actionable AI tasks with Foundry Local
- Seamless Azure AI Foundry integration workflows
- Performance optimization and monitoring

**Duration**: 2-3 hours  
**Prerequisites**: Session 1 completion, Azure account (optional)

---

### [3: Open-Source Models Foundry Local](./03.OpenSourceModels.md)
**Focus**: Hugging Face integration, model selection strategies, and community-driven additions

**What You'll Learn:**
- Hugging Face model integration with Foundry Local
- Bring-your-own-model (BYOM) strategies and implementation
- Model Mondays series insights and community contributions
- Custom model deployment and optimization
- Community model evaluation and selection criteria

**Duration**: 2-3 hours  
**Prerequisites**: Session 1-2 completion, Hugging Face account

---

### [4: Explore Cutting-Edge Models - LLMs, SLMs, and On-Device Inference](./04.CuttingEdgeModels.md)
**Focus**: Model comparison, EdgeAI with Phi and ONNX Runtime, advanced demos

**What You'll Learn:**
- Comprehensive LLMs vs SLMs comparison and use cases
- Local vs cloud inference trade-offs and decision frameworks
- EdgeAI implementation with Phi and ONNX Runtime
- Chainlit RAG Chat App development and deployment
- WebGPU inference optimization techniques
- AI PC SDK integration and capabilities

**Duration**: 3-4 hours  
**Prerequisites**: Session 1-3 completion, understanding of inference concepts

---

### [5: Build AI-Powered Agents Fast with Foundry Local](./05.AIPoweredAgents.md)
**Focus**: Rapid GenAI app development, system prompts, grounding, and agent architectures

**What You'll Learn:**
- Foundry Local agent architecture and design patterns
- System prompt engineering for agent behavior
- Grounding techniques for reliable agent responses
- Rapid GenAI application development workflows
- Agent orchestration and multi-agent systems
- Production deployment strategies for AI agents

**Duration**: 3-4 hours  
**Prerequisites**: Session 1-4 completion, basic understanding of AI agents

---

### [6: Foundry Local - Models as Tools](./06.ModelsAsTools.md)
**Focus**: Modular AI solutions, on-device deployment, and enterprise scaling

**What You'll Learn:**
- Treating AI models as modular, customizable tools
- On-device deployment without cloud dependency
- Low-latency, cost-efficient, and privacy-preserving inference
- SDK, API, and CLI integration patterns
- Model customization for specific use cases
- Scaling strategies from local to Azure AI Foundry
- Enterprise-ready AI application architectures

**Duration**: 3-4 hours  
**Prerequisites**: All previous sessions, enterprise development experience helpful

## Prerequisites

### System Requirements
- **Operating System**: Windows 11 (22H2 or later)
- **Memory**: 16GB RAM (32GB recommended for larger models)
- **Storage**: 50GB free space for model caching
- **Hardware**: NPU-enabled device recommended (Copilot+ PC), GPU optional
- **Network**: High-speed internet for initial model downloads

### Development Environment
- Visual Studio Code with AI Toolkit extension
- Python 3.10+ and pip
- Git for version control
- PowerShell or Command Prompt
- Azure CLI (optional for cloud integration)

### Knowledge Prerequisites
- Basic understanding of AI/ML concepts
- Command line familiarity
- Python programming basics
- REST API concepts
- Basic knowledge of prompting and model inference

## Module Timeline

**Total Estimated Time**: 15-20 hours

| Session | Focus Area | Time | Complexity |
|---------|------------|------|------------|
|  1 | Setup & Basics | 2-3 hours | Beginner |
|  2 | AI Solutions | 2-3 hours | Intermediate |
|  3 | Open Source | 2-3 hours | Intermediate |
|  4 | Advanced Models | 3-4 hours | Advanced |
|  5 | AI Agents | 3-4 hours | Advanced |
|  6 | Enterprise Tools | 3-4 hours | Expert |

## Key Resources

### Primary Documentation
- [Microsoft Foundry Local GitHub](https://github.com/microsoft/Foundry-Local)
- [Azure AI Foundry Local Documentation](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/)
- [Model Mondays Series](https://aka.ms/model-mondays)

### Community Resources
- [Foundry Local Community Discussions](https://github.com/microsoft/Foundry-Local/discussions)
- [Azure AI Foundry Samples](https://github.com/Azure-Samples/ai-foundry)
- [Microsoft AI Developer Community](https://techcommunity.microsoft.com/category/artificialintelligence)

## Learning Outcomes

Upon completing this module, you will be equipped to:

### Technical Mastery
- **Deploy and Manage**: Foundry Local installations across development and production environments
- **Integrate Models**: Seamlessly work with diverse model families from Microsoft, Hugging Face, and community sources
- **Build Applications**: Create production-ready AI applications with advanced features and optimizations
- **Develop Agents**: Implement sophisticated AI agents with grounding, reasoning, and tool integration

### Strategic Understanding
- **Architecture Decisions**: Make informed choices between local vs cloud deployment
- **Performance Optimization**: Optimize inference performance across different hardware configurations
- **Enterprise Scaling**: Design applications that scale from local prototypes to enterprise deployments
- **Privacy and Security**: Implement privacy-preserving AI solutions with local inference

### Innovation Capabilities
- **Rapid Prototyping**: Quickly build and test AI application concepts
- **Community Integration**: Leverage open-source models and contribute to the ecosystem
- **Advanced Patterns**: Implement cutting-edge AI patterns including RAG, agents, and tool integration
- **Future-Ready Development**: Build applications ready for emerging AI technologies and patterns

## Getting Started

1. **Prepare Your Environment**: Ensure Windows 11 with recommended hardware specifications
2. **Install Prerequisites**: Set up development tools and dependencies
3. **Begin with Session 1**: Start with Foundry Local installation and basic setup
4. **Progress Sequentially**: Complete sessions in order for optimal learning progression
5. **Practice Continuously**: Apply concepts through hands-on exercises and projects

## Success Metrics

Track your progress through the module:

- [ ] Successfully install and configure Foundry Local
- [ ] Deploy and run at least 4 different model families
- [ ] Build a complete AI solution with data integration
- [ ] Integrate at least 2 open-source models
- [ ] Create a functional RAG chat application
- [ ] Develop and deploy an AI agent
- [ ] Implement a models-as-tools architecture

## Quick Start for Samples

### 1) Environment setup (Windows cmd.exe)
```cmd
cd Module08
py -m venv .venv
.\.venv\Scripts\activate
pip install -r requirements.txt
```

### 2) Start a local model (new terminal)
```cmd
foundry model list
foundry model run phi-4-mini
```

### 3) Run the Chainlit demo (Session 4)
```cmd
cd Module08
.\.venv\Scripts\activate
chainlit run samples\04\app.py -w
```

### 4) Run the multi-agent coordinator (Session 5)
```cmd
cd Module08
.\.venv\Scripts\activate
python -m samples.05.agents.coordinator
```

If you see connection errors, validate Foundry Local:
```cmd
curl http://localhost:8000/v1/models
```

### Router configuration (Session 6)
The router performs a quick health check and supports env-based config:
```cmd
set BASE_URL=http://localhost:8000
set GENERAL_MODEL=phi-4-mini
set REASONING_MODEL=deepseek-r1-distill-qwen-7b
set CODE_MODEL=qwen2.5-7b-instruct
REM Or provide a full JSON registry
set TOOL_REGISTRY={"general":{"model":"phi-4-mini"}}
python samples\06\router.py "Pick the best model for code refactoring"
```

This module represents the cutting edge of edge AI development, combining Microsoft's enterprise-grade tools with the flexibility and innovation of the open-source ecosystem. By mastering Foundry Local, you'll be positioned at the forefront of AI application development.

For Azure OpenAI (Session 2), see the sample README for required environment variables and API version settings.

## Samples Overview

- `samples/01`: Quick REST chat to Foundry Local (`chat_quickstart.py`).
- `samples/02`: OpenAI SDK integration (`sdk_quickstart.py`).
- `samples/03`: Model discovery + quick bench (`list_and_bench.cmd`).
- `samples/04`: Chainlit RAG demo (`app.py`).
- `samples/05`: Multi-agent orchestration (`python -m samples.05.agents.coordinator`).
- `samples/06`: Models-as-Tools router (`python samples\06\router.py`).