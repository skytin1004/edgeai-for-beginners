#############################################
# Workshop Environment Variables (.env.example)
#
# Copy this file to .env and adjust values for your setup:
#   cp .env.example .env
#
# SDK Reference:
#   https://github.com/microsoft/Foundry-Local
#   https://github.com/microsoft/Foundry-Local/tree/main/sdk/python/foundry_local
#############################################

# Python search path for helper utilities
PYTHONPATH=${workspaceFolder}/Workshop/samples;${workspaceFolder}/Module08

# Core Model Aliases
FOUNDRY_LOCAL_ALIAS=phi-4-mini
SLM_ALIAS=phi-4-mini
LLM_ALIAS=qwen2.5-7b

# Endpoint override (leave blank for auto-detection)
FOUNDRY_LOCAL_ENDPOINT=

# Benchmark Configuration
BENCH_MODELS=phi-4-mini,qwen2.5-0.5b,gemma-2-2b
BENCH_ROUNDS=3
BENCH_PROMPT=Explain retrieval augmented generation briefly.
BENCH_STREAM=0
COMPARE_RETRIES=2

# RAG Configuration
EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2
RAG_QUESTION=Why use RAG with local inference?

# Multi-Agent Configuration
AGENT_QUESTION=Explain why edge AI matters for compliance.
AGENT_MODEL_PRIMARY=phi-4-mini
AGENT_MODEL_EDITOR=phi-4-mini

# Model Comparison
COMPARE_PROMPT=List 5 benefits of local AI inference.

# Reliability / Telemetry
SHOW_USAGE=1
RETRY_ON_FAIL=1
RETRY_BACKOFF=1.0

# Azure OpenAI (Optional)
# AZURE_OPENAI_ENDPOINT=
# AZURE_OPENAI_API_KEY=
# AZURE_OPENAI_API_VERSION=2024-08-01-preview
