<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20892f7994d9e5d2473ad19dfa93cf6d",
  "translation_date": "2025-09-18T22:44:59+00:00",
  "source_file": "Module02/01.PhiFamily.md",
  "language_code": "hr"
}
-->
# Odjeljak 1: Osnove obitelji Microsoft Phi modela

Obitelj Microsoft Phi modela predstavlja promjenu paradigme u umjetnoj inteligenciji, pokazujuÄ‡i da kompaktni, uÄinkoviti modeli mogu postiÄ‡i izvanredne rezultate uz znatno manju potroÅ¡nju resursa u usporedbi s tradicionalnim velikim jeziÄnim modelima. VaÅ¾no je razumjeti kako obitelj Phi omoguÄ‡uje snaÅ¾ne AI moguÄ‡nosti uz smanjene raÄunalne zahtjeve, istovremeno odrÅ¾avajuÄ‡i visoke performanse u raznim zadacima.

## Resursi za programere

### Azure AI Foundry Model Catalog
Obitelj Phi modela (osim Phi-silica) dostupna je putem [Azure AI Foundry Model Catalog](https://ai.azure.com/explore/models?q=phi), Å¡to programerima olakÅ¡ava pristup, prilagodbu i implementaciju ovih modela u njihovim aplikacijama. Katalog pruÅ¾a jednostavan naÄin za eksperimentiranje s razliÄitim varijantama Phi modela i njihovu integraciju u projekte.

### Azure AI Foundry
MoÅ¾ete implementirati i eksperimentirati s Phi modelima koristeÄ‡i [Azure AI Foundry](https://ai.azure.com), koji pruÅ¾a sveobuhvatno okruÅ¾enje za izgradnju, testiranje i implementaciju AI rjeÅ¡enja uz minimalnu pripremu.

### Foundry Local
Za lokalni razvoj i implementaciju, pogledajte [Microsoft Foundry Local](https://github.com/microsoft/foundry-local), koji omoguÄ‡uje pokretanje Phi modela na vaÅ¡em razvojnom raÄunalu uz optimizirane konfiguracije.

### Dokumentacijski resursi
- [Microsoft Research: Phi Model Technical Reports](https://ai.azure.com/labs/projects/phi-4)
- [Phi Cookbook](https://aka.ms/phicookbook)

## Uvod

U ovoj lekciji istraÅ¾it Ä‡emo obitelj Microsoftovih Phi modela i njezine osnovne koncepte. Pokrit Ä‡emo evoluciju obitelji Phi, inovativne metodologije treniranja koje Äine Phi modele uÄinkovitim, kljuÄne varijante u obitelji i praktiÄne primjene u razliÄitim scenarijima.

## Ciljevi uÄenja

Na kraju ove lekcije moÄ‡i Ä‡ete:

- Razumjeti filozofiju dizajna i evoluciju obitelji Microsoftovih Phi modela.
- Identificirati kljuÄne inovacije koje omoguÄ‡uju Phi modelima postizanje visokih performansi s manje parametara.
- Prepoznati prednosti i ograniÄenja razliÄitih varijanti Phi modela.
- Primijeniti znanje o Phi modelima za odabir odgovarajuÄ‡ih varijanti za stvarne scenarije.

## Razumijevanje tradicionalne paradigme AI modela

Tradicionalno, postizanje visokih performansi u obradi prirodnog jezika zahtijevalo je masivne jeziÄne modele s milijardama ili stotinama milijardi parametara. Organizacije obiÄno implementiraju ove modele na moÄ‡nim GPU klasterima, pristupajuÄ‡i njihovim moguÄ‡nostima putem API suÄelja ili specijalizirane hardverske infrastrukture.

Ovaj pristup dobro funkcionira za mnoge aplikacije, ali ima inherentna ograniÄenja kada je rijeÄ o praktiÄnim scenarijima implementacije. Konvencionalna metoda ukljuÄuje koriÅ¡tenje modela koji zahtijevaju znaÄajne raÄunalne resurse, velike koliÄine memorije i znaÄajnu potroÅ¡nju energije. Iako ovaj pristup pruÅ¾a pristup najnaprednijim moguÄ‡nostima, stvara ovisnost o skupom hardveru, uvodi visoke operativne troÅ¡kove i ograniÄava fleksibilnost implementacije.

## Izazov uÄinkovite implementacije AI-a

Potreba za uÄinkovitijim AI-jem postala je sve vaÅ¾nija u raznim scenarijima. Razmotrite aplikacije koje zahtijevaju lokalnu implementaciju zbog razloga privatnosti, osjetljive implementacije gdje troÅ¡kovi API-ja u oblaku postaju prohibitivni, scenarije rubnog raÄunalstva s ograniÄenim hardverskim resursima ili aplikacije u stvarnom vremenu gdje je kaÅ¡njenje kritiÄno.

### KljuÄna ograniÄenja implementacije

Tradicionalne implementacije velikih modela suoÄavaju se s nekoliko temeljnih ograniÄenja koja ograniÄavaju njihovu praktiÄnu primjenjivost:

- **OgraniÄenja troÅ¡kova**: Visoki raÄunalni troÅ¡kovi Äine kontinuiranu implementaciju skupom za mnoge organizacije.
- **OgraniÄenja resursa**: OgraniÄen pristup vrhunskoj GPU infrastrukturi ograniÄava moguÄ‡nosti implementacije.
- **Zahtjevi privatnosti**: Osjetljive aplikacije zahtijevaju lokalnu obradu kako bi se odrÅ¾ala privatnost podataka.
- **Osjetljivost na kaÅ¡njenje**: Aplikacije u stvarnom vremenu trebaju trenutne odgovore bez kaÅ¡njenja zbog povratnog putovanja u oblak.

## Filozofija Microsoftovih Phi modela

Obitelj Microsoftovih Phi modela predstavlja temeljnu promjenu u filozofiji dizajna AI modela, dajuÄ‡i prednost uÄinkovitosti i praktiÄnoj implementaciji uz odrÅ¾avanje snaÅ¾nih performansi. Phi modeli to postiÅ¾u inovativnim arhitekturama, visokokvalitetnim metodologijama treniranja i specijaliziranim tehnikama optimizacije.

Obitelj Phi obuhvaÄ‡a razliÄite pristupe dizajnirane za maksimiziranje performansi po parametru, omoguÄ‡ujuÄ‡i implementaciju na standardnom hardveru uz pruÅ¾anje znaÄajnih AI moguÄ‡nosti. Cilj je odrÅ¾ati konkurentne performanse uz dramatiÄno smanjenje raÄunalnih zahtjeva, potroÅ¡nje memorije i operativnih troÅ¡kova.

### Temeljna naÄela dizajna Phi modela

Phi modeli temelje se na nekoliko osnovnih naÄela koja ih razlikuju od tradicionalnih velikih jeziÄnih modela:

- **UÄinkovitost na prvom mjestu**: Optimizirani za maksimalne performanse po parametru, a ne za apsolutnu veliÄinu.
- **Kvalitetno treniranje**: Fokus na visokokvalitetnim, kuriranim podacima za treniranje umjesto masivnih skupova podataka.
- **Fleksibilnost implementacije**: Dizajnirani za uÄinkovito funkcioniranje na raznim hardverskim konfiguracijama.
- **Specijalizirane moguÄ‡nosti**: ÄŒesto optimizirani za specifiÄne zadatke ili domene kako bi se maksimizirala uÄinkovitost.

## KljuÄne tehnologije koje omoguÄ‡uju obitelj Phi modela

### Pristup "udÅ¾beniÄkog" treniranja

Jedan od najrevolucionarnijih aspekata obitelji Phi je metodologija treniranja "kvalitete udÅ¾benika". Umjesto treniranja na ogromnim koliÄinama nefiltriranih podataka s interneta, Phi modeli koriste paÅ¾ljivo kurirane, visokokvalitetne edukativne sadrÅ¾aje dizajnirane za uÄinkovito poduÄavanje razmiÅ¡ljanja, matematike, kodiranja i opÄ‡eg znanja.

Ovaj pristup funkcionira stvaranjem sintetiÄkih edukativnih sadrÅ¾aja koji oponaÅ¡aju visokokvalitetne udÅ¾benike i akademske materijale. Podaci za treniranje posebno su dizajnirani da budu pedagoÅ¡ki zvuÄni, fokusirajuÄ‡i se na jasna objaÅ¡njenja, korak-po-korak razmiÅ¡ljanje i strukturirano predstavljanje znanja.

### Napredno treniranje razmiÅ¡ljanja

Nedavni Phi modeli ukljuÄuju sofisticirane metodologije treniranja razmiÅ¡ljanja koje omoguÄ‡uju sloÅ¾eno viÅ¡ekorakovno rjeÅ¡avanje problema. Te tehnike ukljuÄuju:

**Treniranje lanca razmiÅ¡ljanja**: Modeli uÄe razbijati sloÅ¾ene probleme na meÄ‘ukorake razmiÅ¡ljanja, ÄineÄ‡i proces rjeÅ¡avanja problema transparentnijim i pouzdanijim.

**Skaliranje tijekom generiranja odgovora**: Modeli generiraju detaljne lance razmiÅ¡ljanja koji koriste dodatne raÄunalne resurse tijekom generiranja odgovora za poboljÅ¡anu toÄnost.

**Treniranje na granici sposobnosti**: Podaci za treniranje paÅ¾ljivo su odabrani kako bi izazvali model na granici njegovih trenutnih sposobnosti, potiÄuÄ‡i uÄenje sloÅ¾enih obrazaca razmiÅ¡ljanja.

### Inovacije u arhitekturi

Obitelj Phi ukljuÄuje nekoliko arhitektonskih optimizacija dizajniranih posebno za uÄinkovitost:

**UÄinkovitost parametara**: PaÅ¾ljivi arhitektonski izbori koji maksimiziraju utjecaj svakog parametra u modelu.

**Multimodalna integracija**: UÄinkovita integracija obrade teksta, vizije i govora unutar kompaktnih arhitektura.

**Optimizacija hardvera**: Specijalizirane varijante optimizirane za specifiÄne hardverske platforme i scenarije implementacije.

## Optimizacija hardvera za Phi modele

Moderni okruÅ¾enja implementacije imaju koristi od uÄinkovitosti Phi modela na raznim hardverskim konfiguracijama:

### Implementacija optimizirana za CPU

Phi modeli dizajnirani su za uÄinkovito funkcioniranje na hardveru koji koristi samo CPU, ÄineÄ‡i ih dostupnima za implementaciju na standardnoj raÄunalnoj infrastrukturi bez potrebe za specijaliziranim AI akceleratorima.

### GPU ubrzanje

Iako ne zahtijevaju moÄ‡ne GPU-ove, Phi modeli mogu koristiti dostupne GPU resurse za poboljÅ¡ane performanse, pruÅ¾ajuÄ‡i fleksibilnost u konfiguracijama implementacije.

### Integracija na rubnim ureÄ‘ajima

Specijalizirane varijante poput Phi-3-Silica optimizirane su za specifiÄne platforme rubnog raÄunalstva, postiÅ¾uÄ‡i izvanredne metrike uÄinkovitosti poput 650 tokena u sekundi uz samo 1,5W potroÅ¡nje energije.

## Prednosti obitelji Phi modela

### UÄinkovitost troÅ¡kova

Phi modeli dramatiÄno smanjuju operativne troÅ¡kove zahtijevajuÄ‡i znatno manje raÄunalne infrastrukture uz odrÅ¾avanje konkurentnih performansi. To Äini AI dostupnim organizacijama s ograniÄenim proraÄunima ili aplikacijama velikog obujma gdje je troÅ¡ak po upitu vaÅ¾an.

### Fleksibilnost implementacije

UÄinkovitost Phi modela omoguÄ‡uje implementaciju na Å¡irokom rasponu hardverskih konfiguracija, od osobnih prijenosnih raÄunala do poslovnih servera, pruÅ¾ajuÄ‡i organizacijama veÄ‡u fleksibilnost u odabiru AI infrastrukture.

### Privatnost i sigurnost

UÄinkovitost Phi modela omoguÄ‡uje lokalnu implementaciju za aplikacije osjetljive na privatnost, osiguravajuÄ‡i da osjetljivi podaci nikada ne napuÅ¡taju kontrolu organizacije, a istovremeno pruÅ¾aju snaÅ¾ne AI moguÄ‡nosti.

### Performanse u stvarnom vremenu

Smanjeni raÄunalni zahtjevi omoguÄ‡uju brÅ¾e vrijeme obrade, omoguÄ‡ujuÄ‡i aplikacije u stvarnom vremenu koje zahtijevaju trenutne odgovore bez kompromisa u kvaliteti AI moguÄ‡nosti.

### Dostupnost AI-a

Smanjenjem prepreka za implementaciju AI-a, Phi modeli Äine napredne AI moguÄ‡nosti dostupnima organizacijama s ograniÄenim resursima, omoguÄ‡ujuÄ‡i manjim timovima i pojedinaÄnim programerima koriÅ¡tenje sofisticiranog razumijevanja jezika.

## PraktiÄni primjeri i sluÄajevi upotrebe

Prije nego Å¡to se upustimo u tehniÄku evoluciju, istraÅ¾imo neke konkretne primjere onoga Å¡to Phi modeli mogu postiÄ‡i:

### Primjer matematiÄkog razmiÅ¡ljanja

Phi-4-mini-reasoning izvrsno rjeÅ¡ava matematiÄke probleme korak po korak. Na primjer, kada se postavi pitanje "Kako rijeÅ¡iti 3*x^2+4*x+5=1?", model pruÅ¾a detaljne korake razmiÅ¡ljanja:

```
<|system|>Your name is Phi, an AI math expert developed by Microsoft.<|end|>
<|user|>How to solve 3*x^2+4*x+5=1?<|end|>
<|assistant|>
I need to solve the quadratic equation 3xÂ² + 4x + 5 = 1.

First, let me rearrange this to standard form:
3xÂ² + 4x + 5 = 1
3xÂ² + 4x + 5 - 1 = 0  
3xÂ² + 4x + 4 = 0

Now I can use the quadratic formula: x = (-b Â± âˆš(bÂ² - 4ac)) / (2a)
Where a = 3, b = 4, c = 4

Let me calculate the discriminant:
bÂ² - 4ac = 4Â² - 4(3)(4) = 16 - 48 = -32

Since the discriminant is negative (-32), this equation has no real solutions.
The solutions are complex: x = (-4 Â± âˆš(-32)) / 6 = (-4 Â± 4iâˆš2) / 6 = (-2 Â± 2iâˆš2) / 3
```

### Primjer podrÅ¡ke za viÅ¡e jezika

Phi-3.5-mini-instruct pokazuje snaÅ¾ne moguÄ‡nosti za viÅ¡e jezika u raznim jezicima. Evo primjera formata upita:

```
<|system|>You are a helpful assistant.<|end|>
<|user|>How to explain Internet for a medieval knight?<|end|>
<|assistant|>
Imagine, good sir knight, a vast network of invisible roads that span the entire realm and beyond. The Internet is like a magical system of messenger birds that can carry any message - be it text, images, or even moving pictures - instantly to any castle, village, or hamlet in the world.

Think of it as if every scribe's work could be copied and shared with thousands of people simultaneously, as if you could visit any library in any kingdom without leaving your chambers, or as if you could hold council with knights from distant lands as if they were sitting at your very table.

This "Internet" allows people to:
- Send messages faster than the swiftest horse
- Access knowledge from scholars across all kingdoms
- Trade goods without traveling to distant markets
- Share stories and news from lands you've never seen

'Tis like having a thousand scribes, merchants, and storytellers all working for you at once, good knight!
```

### Primjer multimodalnih moguÄ‡nosti

Phi-4-multimodal moÅ¾e istovremeno obraÄ‘ivati tekst, slike i govor. Evo nekoliko praktiÄnih primjena:

**Planiranje putovanja uz unos zvuka:**
Phi-4 Multimodal analizira govor kako bi pomogao u planiranju putovanja u Seattle, pokazujuÄ‡i svoje napredne moguÄ‡nosti obrade zvuka i preporuka.

**RjeÅ¡avanje matematiÄkih problema iz slika:**
Phi-4 Multimodal rjeÅ¡ava sloÅ¾ene matematiÄke probleme putem vizualnih unosa, pokazujuÄ‡i svoju sposobnost obrade i rjeÅ¡avanja jednadÅ¾bi prikazanih na slikama.

**Primjer pozivanja funkcija:**
Uz pozivanje funkcija, Phi-4-mini i Phi-4-multimodal mogu proÅ¡iriti svoje moguÄ‡nosti obrade teksta integracijom traÅ¾ilica, povezivanjem raznih alata i viÅ¡e. Kao Å¡to je prikazano, model moÅ¾e dohvatiti informacije o utakmicama Premier lige putem Phi-4-mini, pokazujuÄ‡i svoju sposobnost besprijekorne interakcije s vanjskim izvorima podataka.

### Primjer generiranja koda

Phi-4-multimodal moÅ¾e generirati strukturirani projektni kod na temelju sadrÅ¾aja slike i danih upita, kao Å¡to je prikazano u ovom praktiÄnom tijeku rada:

1. Prenesite sliku Å¾iÄanog okvira ili dizajna
2. PruÅ¾ite kontekst o zahtjevima projekta
3. Model generira kompletne, funkcionalne strukture koda
4. Kod se moÅ¾e prilagoditi na temelju specifiÄnih okvira ili jezika

### Primjer implementacije na rubnim ureÄ‘ajima

MoÅ¾emo implementirati kvantizirani model na rubnim ureÄ‘ajima. Kombinacijom Microsoft Olive i ONNX GenAI Runtimea, moÅ¾emo implementirati Phi-4-mini na Windows, iPhone, Android i drugim ureÄ‘ajima. Ovo je primjer pokretanja na iPhoneu 12 Pro.

Proces implementacije ukljuÄuje:
- Kvantizaciju modela za mobilnu optimizaciju
- Integraciju ONNX runtimea za kompatibilnost na viÅ¡e platformi
- Lokalnu obradu bez internetske povezanosti
- Performanse u stvarnom vremenu uz minimalnu potroÅ¡nju energije

## Evolucija obitelji Phi modela

### Phi-1 i Phi-2: Temeljni modeli

Rani Phi modeli uspostavili su temeljna naÄela visokokvalitetnih podataka za treniranje i uÄinkovitih arhitektura:

- **Phi-1 (1.3B parametara)**: Uveo koncept kuriranih podataka za treniranje za osnovno razumijevanje jezika i generiranje koda.
- **Phi-2 (2.7B parametara)**: PoboljÅ¡ao sposobnosti razmiÅ¡ljanja putem sintetiÄkih NLP podataka i paÅ¾ljivo filtriranog web sadrÅ¾aja.

### Obitelj Phi-3: Glavna primjena

Serija Phi-3 oznaÄila je proboj u SLM moguÄ‡nostima s viÅ¡e specijaliziranih varijanti:

- **Phi-3-mini (3.8B parametara)**: OpÄ‡i jeziÄni zadaci s iznimnom uÄinkovitoÅ¡Ä‡u, nadmaÅ¡ujuÄ‡i modele dvostruko veÄ‡e veliÄine.
- **Phi-3-small (7B parametara)**: Napredne performanse koje nadmaÅ¡uju GPT-3.5 Turbo na raznim mjerilima.
- **Phi-3-medium (14B parametara)**: Performanse na razini poduzeÄ‡a koje nadmaÅ¡uju Gemini 1.0 Pro.
- **Phi-3-vision (4.2B parametara)**: Multimodalne moguÄ‡nosti za obradu slika i teksta.
- **Phi-3-Silica (3.3B parametara)**: Specijalizirana optimizacija za ugraÄ‘enu implementaciju u Windows 11.

### Obitelj Phi-4: Napredno razmiÅ¡ljanje

Najnovija generacija pomiÄe granice sposobnosti razmiÅ¡ljanja:

- **Phi-4 (14B parametara)**: Specijalizacija za sloÅ¾eno razmiÅ¡ljanje, posebno u matematici.
- **Phi-4-mini (3.8B parametara)**: PoboljÅ¡ano razmiÅ¡ljanje uz pozivanje funkcija i podrÅ¡ku za dugi kontekst.
- **Phi-4-multimodal**: Istovremena obrada govora, vizije i teksta.
- **Phi-4-reasoning (14B parametara)**: Specijaliziran za sloÅ¾ene viÅ¡ekorakovne zadatke razmiÅ¡ljanja.
- **Phi-4-reasoning-plus (14B parametara)**: PoboljÅ¡ana toÄnost putem dodatnog uÄenja pojaÄanjem.
- **Phi-4-mini-reasoning (3.8B parametara)**: MatematiÄko razmiÅ¡ljanje optimizirano za ograniÄena okruÅ¾enja.

## Primjene Phi modela

### Poslovne aplikacije

Organizacije koriste Phi modele za analizu dokumenata, automatizaciju korisniÄke podrÅ¡ke, pomoÄ‡ pri generiranju koda i aplikacije poslovne inteligencije koje zahtijevaju lokalnu implementaciju radi usklaÄ‘enosti i sigurnosti.

### Mobilno i rubno raÄunalstvo

Mobilne aplikacije koriste Phi modele za prijevod u stvarnom vremenu, inteligentne asistente, generiranje sadrÅ¾aja i personalizirane preporuke bez potrebe za stalnom internetskom povezanoÅ¡Ä‡u.

### Edukacijska tehnologija

Edukacijske platforme koriste Phi modele za personalizirano poduÄavanje, automatizirano ocjenjivanje, generiranje sadrÅ¾aja i interaktivna iskustva uÄenja koja mogu funkcionirati offline ili u okruÅ¾enjima s niskom povezanoÅ¡Ä‡u.

### Zdravstvo i usklaÄ‘enost

Aplikacije u zdravstvu imaju koristi od sposobnosti Phi modela da lokalno obraÄ‘uju osjetljive medicinske podatke, istovremeno pruÅ¾ajuÄ‡i AI-podrÅ¾anu dijagnostiÄku pomoÄ‡, pra
Obitelj Phi pokazuje da buduÄ‡nost primjene umjetne inteligencije ne leÅ¾i samo u izgradnji veÄ‡ih modela, veÄ‡ u razvoju pametnijih, uÄinkovitijih modela koji mogu uÄinkovito raditi na raznovrsnim hardverskim okruÅ¾enjima uz odrÅ¾avanje visokih standarda performansi.

## Primjeri razvoja i integracije

### Brzi poÄetak s Transformers knjiÅ¾nicom

Evo kako zapoÄeti s Phi modelima koristeÄ‡i Hugging Face Transformers knjiÅ¾nicu:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load Phi-4-mini-instruct
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    attn_implementation="flash_attention_2"  # For optimized performance
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")

# Format your prompt using the chat template
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Explain quantum computing in simple terms."}
]

# Apply chat template
input_text = tokenizer.apply_chat_template(messages, tokenize=False)
inputs = tokenizer(input_text, return_tensors="pt")

# Generate response
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)
    
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### Primjer fino podeÅ¡avanja

SljedeÄ‡i primjer pokazuje kako fino podesiti Phi-4-mini-instruct za specifiÄne zadatke:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig
from trl import SFTTrainer
from datasets import load_dataset

# Configuration for LoRA fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules="all-linear"
)

# Training configuration optimized for efficiency
training_config = TrainingArguments(
    output_dir="./phi-4-mini-finetuned",
    learning_rate=5.0e-06,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=1,
    num_train_epochs=1,
    bf16=True,
    gradient_checkpointing=True,
    warmup_ratio=0.2,
    save_steps=100
)

# Load model and tokenizer
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")
tokenizer.pad_token = tokenizer.unk_token
tokenizer.padding_side = 'right'

# Load and process dataset
train_dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_config,
    peft_config=peft_config,
    train_dataset=train_dataset,
    max_seq_length=2048,
    tokenizer=tokenizer,
    packing=True
)

# Start fine-tuning
trainer.train()
```

### Specijalizirani formati upita

**Za zadatke zakljuÄivanja (Phi-4-reasoning-plus):**
```
<|im_start|>system<|im_sep|>
You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions.

Please structure your response into two main sections:
<think>
{Thought section}
</think>
{Solution section}
<|im_end|>
<|im_start|>user<|im_sep|>
What is the derivative of x^2?
<|im_end|>
<|im_start|>assistant<|im_sep|>
```

**Za matematiÄke zadatke (Phi-4-mini-reasoning):**
```
<|system|>
Your name is Phi, an AI math expert developed by Microsoft.
<|end|>
<|user|>
Solve this calculus problem: Find the integral of 2x + 3
<|end|>
<|assistant|>
```

### Mobilna primjena s ONNX-om

```python
import onnxruntime as ort
import numpy as np

# Load ONNX model for mobile deployment
session = ort.InferenceSession("phi-4-mini-quantized.onnx")

# Prepare input
input_ids = tokenizer.encode("Hello, how are you?", return_tensors="np")

# Run inference
outputs = session.run(None, {"input_ids": input_ids})
predicted_ids = outputs[0]

# Decode response
response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)
```

## Mjerila performansi i postignuÄ‡a

Obitelj Phi modela postigla je izvanredne rezultate na raznim mjerilima, Äesto nadmaÅ¡ujuÄ‡i mnogo veÄ‡e modele:

### KljuÄni naglasci performansi

**Izvrsnost u matematiÄkom zakljuÄivanju:**
- Phi-4 postiÅ¾e 82,5% toÄnosti na AIME 2025 (kvalifikacije za matematiÄku olimpijadu)
- Phi-4-reasoning (14B) nadmaÅ¡uje DeepSeek-R1-Distill-70B (5x veÄ‡i) na mjerilima zakljuÄivanja
- Phi-4-mini-reasoning (3.8B) usporediv je s modelima dvostruko veÄ‡im u zadacima matematiÄkog zakljuÄivanja

**PostignuÄ‡a u uÄinkovitosti:**
- Phi-3-Silica postiÅ¾e 650 tokena u sekundi uz potroÅ¡nju od samo 1.5W
- Phi-4-mini (3.8B) postiÅ¾e sliÄne performanse kao mnogo veÄ‡i modeli

**Performanse na mjerilima:**
- **MMLU (Masivno viÅ¡ezadaÄ‡no razumijevanje jezika)**: Konkurentne performanse u 57 akademskih predmeta
- **HumanEval**: SnaÅ¾ne sposobnosti generiranja koda, posebno u Pythonu
- **MGSM**: ViÅ¡ejeziÄno rjeÅ¡avanje matematiÄkih problema osnovne Å¡kole
- **DROP**: SloÅ¾eni zadaci razumijevanja i zakljuÄivanja
- **SimpleQA**: ToÄnost odgovora na ÄinjeniÄna pitanja

### ğŸ“Š Matrica usporedbe modela

| Model | Parametri | Duljina konteksta | KljuÄne prednosti | Najbolje primjene |
|-------|-----------|-------------------|-------------------|-------------------|
| **Phi-3-mini** | 3.8B | 4K/128K | OpÄ‡a uÄinkovitost | Mobilne aplikacije, osnovni chatbotovi |
| **Phi-3.5-mini** | 3.8B | 128K | ViÅ¡ejeziÄna podrÅ¡ka | MeÄ‘unarodne aplikacije |
| **Phi-4-mini** | 3.8B | 128K | PoboljÅ¡ano zakljuÄivanje, pozivanje funkcija | Automatizacija poslovanja |
| **Phi-4-mini-reasoning** | 3.8B | 128K | MatematiÄko zakljuÄivanje | Obrazovne platforme |
| **Phi-4** | 14B | 32K | SloÅ¾eno zakljuÄivanje | IstraÅ¾ivanje, napredna analiza |
| **Phi-4-reasoning** | 14B | 32K/64K | ViÅ¡ekorak zakljuÄivanje | Znanstveno raÄunalstvo |
| **Phi-4-reasoning-plus** | 14B | 32K | Maksimalna toÄnost zakljuÄivanja | KritiÄno donoÅ¡enje odluka |
| **Phi-4-multimodal** | 5.6B | Varijabilno | Govor, vizija, tekst | Multimedijske aplikacije |

## VodiÄ za odabir modela

### Za osnovne aplikacije
- **Phi-3-mini**: Jednostavno generiranje teksta, osnovna pitanja i odgovori, brzi odgovori
- **Phi-4-mini**: PoboljÅ¡ano zakljuÄivanje s moguÄ‡nostima pozivanja funkcija

### Za matematiÄke i zadatke zakljuÄivanja
- **Phi-4**: SloÅ¾eno rjeÅ¡avanje matematiÄkih problema i zakljuÄivanje
- **Phi-4-reasoning**: ViÅ¡ekorak zakljuÄivanje s detaljnim objaÅ¡njenjima
- **Phi-4-reasoning-plus**: Maksimalna toÄnost za kritiÄne aplikacije zakljuÄivanja
- **Phi-4-mini-reasoning**: UÄinkovito matematiÄko zakljuÄivanje za okruÅ¾enja s ograniÄenim resursima

### Za multimodalne aplikacije
- **Phi-3-vision**: Kombinacije obrade slike i teksta
- **Phi-4-multimodal**: Sveobuhvatne moguÄ‡nosti govora, vizije i teksta

### Za poslovnu primjenu
- **Phi-3-medium**: Napredno razumijevanje jezika za poslovne aplikacije
- **Phi-3-Silica**: Optimizirano za specifiÄne hardverske platforme

## Platforme za primjenu i dostupnost

### Cloud platforme
- **Azure AI Foundry**: Potpuna primjena s poslovnim alatima
- **Hugging Face**: Repozitorij otvorenog koda i resursi zajednice
- **NVIDIA API Catalog**: Opcije za primjenu mikroservisa

### Okviri za lokalni razvoj
- **Ollama**: Lagani okvir za lokalnu primjenu modela
- **ONNX Runtime**: Optimizirano za razne hardverske konfiguracije  
- **DirectML**: Optimizirane performanse za Windows
- **llama.cpp**: Mehanizam za inferenciju na viÅ¡e platformi

### Resursi za uÄenje
- **Phi Portal**: SluÅ¾beni Microsoft Phi dokumentacijski centar
- **Phi Cookbook**: Sveobuhvatni primjeri i vodiÄi
- **TehniÄka izvjeÅ¡Ä‡a**: Detaljni istraÅ¾ivaÄki radovi na arxivu
- **Prostori zajednice**: Interaktivni demo sadrÅ¾aji na Hugging Faceu

### PoÄetak rada s Phi modelima

#### Platforme za razvoj
1. **Azure AI Foundry**: Jednostavan lokalni CLI i upravljanje modelima.
2. **Hugging Face Transformers**: Brza lokalna eksperimentacija
3. **Ollama**: Jednostavna lokalna primjena za testiranje

#### Put uÄenja
1. **Razumijevanje osnovnih pojmova**: ProuÄite temeljne principe dizajna
2. **Eksperimentiranje s varijantama**: Isprobajte razliÄite Phi modele kako biste razumjeli njihove moguÄ‡nosti
3. **Praksa implementacije**: Primijenite modele u testnim okruÅ¾enjima
4. **Å irenje primjene**: Postupno proÅ¡irite upotrebu na temelju uspjeÅ¡nih pilot projekata

#### Najbolje prakse
- **ZapoÄnite s manjim modelima**: PoÄnite s Phi-mini modelima za poÄetni razvoj
- **Optimizirajte upite**: Koristite pravilno formatiranje razgovora za najbolje rezultate
- **Pratite performanse**: Pratite brzinu inferencije i metrike toÄnosti
- **Razmotrite hardver**: Prilagodite veliÄinu modela dostupnim raÄunalnim resursima

## ZakljuÄak

Obitelj Microsoft Phi modela predstavlja revolucionarni pristup dizajnu AI modela, pokazujuÄ‡i da manji, uÄinkovitiji modeli mogu postiÄ‡i izvanredne rezultate u raznim zadacima. FokusirajuÄ‡i se na visokokvalitetne podatke za treniranje i optimizacije arhitekture, obitelj Phi pruÅ¾a iznimne moguÄ‡nosti uz znaÄajno smanjene raÄunalne zahtjeve u usporedbi s tradicionalnim velikim jeziÄnim modelima.

## KljuÄni ciljevi uÄenja

1. Razumjeti filozofiju dizajna i evoluciju obitelji Microsoft Phi modela od Phi-1 do Phi-4
2. Identificirati kljuÄne inovacije, ukljuÄujuÄ‡i "kvalitetu udÅ¾benika" u treniranju i optimizacije arhitekture
3. Prepoznati prednosti i ograniÄenja razliÄitih Phi varijanti u razliÄitim scenarijima primjene
4. Primijeniti znanje za odabir odgovarajuÄ‡ih Phi modela za specifiÄne sluÄajeve upotrebe i hardverska ograniÄenja
5. Implementirati tehnike optimizacije za primjenu Phi modela na ureÄ‘ajima s ograniÄenim resursima
6. Objasniti arhitektonske prednosti obitelji Phi modela u odnosu na tradicionalne velike jeziÄne modele
7. Odabrati odgovarajuÄ‡u Phi varijantu na temelju specifiÄnih zahtjeva aplikacije i hardverskih ograniÄenja
8. Primijeniti Phi modele u scenarijima primjene na oblaku i rubnim ureÄ‘ajima s optimiziranim konfiguracijama
9. Primijeniti tehnike kvantizacije i optimizacije za poboljÅ¡anje performansi Phi modela na ciljnim ureÄ‘ajima
10. Procijeniti kompromise izmeÄ‘u veliÄine modela, performansi i moguÄ‡nosti unutar obitelji Phi modela

## Å to slijedi

- [02: Osnove obitelji Qwen](02.QwenFamily.md)

---

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden pomoÄ‡u AI usluge za prevoÄ‘enje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati toÄnost, imajte na umu da automatski prijevodi mogu sadrÅ¾avati pogreÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za kljuÄne informacije preporuÄuje se profesionalni prijevod od strane ljudskog prevoditelja. Ne preuzimamo odgovornost za bilo kakve nesporazume ili pogreÅ¡ne interpretacije koje proizlaze iz koriÅ¡tenja ovog prijevoda.