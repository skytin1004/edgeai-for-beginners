<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ad0c054ebd3de404d997d1707a513c70",
  "translation_date": "2025-09-19T01:20:00+00:00",
  "source_file": "Module05/04.SLMOps.Deployment.md",
  "language_code": "hr"
}
-->
# Odjeljak 4: Implementacija modela spremnog za produkciju

## Pregled

Ovaj detaljni vodiÄ provest Ä‡e vas kroz cijeli proces implementacije fino podeÅ¡enih kvantiziranih modela koristeÄ‡i Foundry Local. Pokrit Ä‡emo konverziju modela, optimizaciju kvantizacije i konfiguraciju implementacije od poÄetka do kraja.

## Preduvjeti

Prije nego Å¡to zapoÄnete, osigurajte sljedeÄ‡e:

- âœ… Fino podeÅ¡en onnx model spreman za implementaciju
- âœ… Windows ili Mac raÄunalo
- âœ… Python 3.10 ili noviji
- âœ… Najmanje 8GB dostupne RAM memorije
- âœ… Foundry Local instaliran na vaÅ¡em sustavu

## Dio 1: Postavljanje okruÅ¾enja

### Instalacija potrebnih alata

Otvorite svoj terminal (Command Prompt na Windowsu, Terminal na Macu) i pokrenite sljedeÄ‡e naredbe redoslijedom:

```bash
# Update transformers library to the latest version
pip install transformers -U

# Install Microsoft Olive (model conversion tool)
pip install git+https://github.com/microsoft/Olive.git

# Install ONNX Runtime GenAI
git clone https://github.com/microsoft/onnxruntime-genai
cd onnxruntime-genai && python build.py --config Release
pip install {Your build release path}/onnxruntime_genai-0.9.0.dev0-cp311-cp311-linux_x86_64.whl

# Install additional dependencies
pip install onnx onnxruntime numpy
```

âš ï¸ **VaÅ¾na napomena**: TakoÄ‘er Ä‡e vam trebati CMake verzija 3.31 ili novija, koju moÅ¾ete preuzeti s [cmake.org](https://cmake.org/download/).

## Dio 2: Konverzija modela i kvantizacija

### Odabir pravog formata

Za fino podeÅ¡ene male jeziÄne modele preporuÄujemo koriÅ¡tenje **ONNX formata** jer nudi:

- ğŸš€ Bolju optimizaciju performansi
- ğŸ”§ Hardverski neovisnu implementaciju
- ğŸ­ MoguÄ‡nosti spremne za produkciju
- ğŸ“± Kompatibilnost na viÅ¡e platformi

### Metoda 1: Konverzija jednom naredbom (preporuÄeno)

Koristite sljedeÄ‡u naredbu za direktnu konverziju vaÅ¡eg fino podeÅ¡enog modela:

```bash
olive auto-opt \
    --model_name_or_path /path/to/your/finetuned/model \
    --device cpu \
    --provider CPUExecutionProvider \
    --use_model_builder \
    --precision int4 \
    --output_path models/your-model-name/onnx \
    --log_level 1
```

**ObjaÅ¡njenje parametara:**
- `--model_name_or_path`: Putanja do vaÅ¡eg fino podeÅ¡enog modela
- `--device cpu`: Koristite CPU za optimizaciju
- `--precision int4`: Koristite INT4 kvantizaciju (otprilike 75% smanjenje veliÄine)
- `--output_path`: Putanja za izlazni model

### Metoda 2: Pristup putem konfiguracijske datoteke (za napredne korisnike)

Kreirajte konfiguracijsku datoteku nazvanu `finetuned_conversion_config.json`:

```json
{
    "input_model": {
        "type": "HfModel",
        "model_path": "/path/to/your/finetuned/model",
        "task": "text-generation"
    },
    "systems": {
        "local_system": {
            "type": "LocalSystem",
            "accelerators": [
                {
                    "execution_providers": [
                        "CPUExecutionProvider"
                    ]
                }
            ]
        }
    },
    "passes": {
        "builder": {
            "type": "ModelBuilder",
            "config": {
                "precision": "int4",
                "quantization_config": {
                    "block_size": 128,
                    "is_symmetric": false
                }
            }
        }
    },
    "host": "local_system",
    "target": "local_system",
    "cache_dir": "cache",
    "output_dir": "models/output/your-finetuned-model-onnx"
}
```

Zatim pokrenite:

```bash
olive run --config ./finetuned_conversion_config.json
```

### Usporedba opcija kvantizacije

| Preciznost | VeliÄina datoteke | Brzina inferencije | Kvaliteta modela | PreporuÄena upotreba |
|------------|-------------------|--------------------|------------------|----------------------|
| FP16       | Osnovna Ã— 0.5     | Brza               | Najbolja         | Hardver visokih performansi |
| INT8       | Osnovna Ã— 0.25    | Vrlo brza          | Dobra            | UravnoteÅ¾en izbor |
| INT4       | Osnovna Ã— 0.125   | NajbrÅ¾a            | Prihvatljiva     | OgraniÄeni resursi |

ğŸ’¡ **Preporuka**: ZapoÄnite s INT4 kvantizacijom za vaÅ¡u prvu implementaciju. Ako kvaliteta nije zadovoljavajuÄ‡a, pokuÅ¡ajte s INT8 ili FP16.

## Dio 3: Konfiguracija implementacije u Foundry Local

### Kreiranje konfiguracije modela

Navigirajte do direktorija modela u Foundry Local:

```bash
foundry cache cd ./models/
```

Kreirajte strukturu direktorija za vaÅ¡ model:

```bash
mkdir -p ./models/custom/your-finetuned-model
```

Kreirajte konfiguracijsku datoteku `inference_model.json` u direktoriju vaÅ¡eg modela:

```json
{
  "Name": "your-finetuned-model-int4",
  "Description": "Fine-tuned quantized model",
  "Version": "1.0",
  "PromptTemplate": {
    "system": "<|im_start|>system\n{Content}<|im_end|>",
    "user": "<|im_start|>user\n{Content}<|im_end|>",
    "assistant": "<|im_start|>assistant\n{Content}<|im_end|>",
    "prompt": "<|im_start|>user\n{Content}<|im_end|>\n<|im_start|>assistant"
  },
  "ModelConfig": {
    "max_length": 2048,
    "temperature": 0.7,
    "top_p": 0.9,
    "repetition_penalty": 1.1
  }
}
```

### PredloÅ¡ci konfiguracija specifiÄnih za model

#### Za modele serije Qwen:

```json
{
  "Name": "qwen-finetuned-int4",
  "PromptTemplate": {
    "system": "<|im_start|>system\n{Content}<|im_end|>",
    "user": "<|im_start|>user\n{Content}<|im_end|>",
    "assistant": "<|im_start|>assistant\n{Content}<|im_end|>",
    "prompt": "<|im_start|>user\n{Content}<|im_end|>\n<|im_start|>assistant"
  }
}
```

## Dio 4: Testiranje i optimizacija modela

### Provjera instalacije modela

Provjerite moÅ¾e li Foundry Local prepoznati vaÅ¡ model:

```bash
foundry cache ls
```

Trebali biste vidjeti `your-finetuned-model-int4` na popisu.

### Pokretanje testiranja modela

```bash
foundry model run your-finetuned-model-int4
```

### Benchmarking performansi

Pratite kljuÄne metrike tijekom testiranja:

1. **Vrijeme odgovora**: Mjerite prosjeÄno vrijeme po odgovoru
2. **PotroÅ¡nja memorije**: Pratite koriÅ¡tenje RAM-a
3. **IskoriÅ¡tenost CPU-a**: Provjerite optereÄ‡enje procesora
4. **Kvaliteta izlaza**: Procijenite relevantnost i koherentnost odgovora

### Lista za provjeru kvalitete

- âœ… Model odgovara prikladno na upite iz fino podeÅ¡enog domena
- âœ… Format odgovora odgovara oÄekivanoj strukturi izlaza
- âœ… Nema curenja memorije tijekom duljeg koriÅ¡tenja
- âœ… Dosljedne performanse za razliÄite duljine ulaza
- âœ… Ispravno rukovanje rubnim sluÄajevima i nevaÅ¾eÄ‡im unosima

## SaÅ¾etak

ÄŒestitamo! UspjeÅ¡no ste zavrÅ¡ili:

- âœ… Konverziju formata fino podeÅ¡enog modela
- âœ… Optimizaciju kvantizacije modela
- âœ… Konfiguraciju implementacije u Foundry Local
- âœ… PodeÅ¡avanje performansi i otklanjanje poteÅ¡koÄ‡a

---

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden pomoÄ‡u AI usluge za prevoÄ‘enje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati toÄnost, imajte na umu da automatski prijevodi mogu sadrÅ¾avati pogreÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za kljuÄne informacije preporuÄuje se profesionalni prijevod od strane Äovjeka. Ne preuzimamo odgovornost za bilo kakva nesporazuma ili pogreÅ¡na tumaÄenja koja proizlaze iz koriÅ¡tenja ovog prijevoda.