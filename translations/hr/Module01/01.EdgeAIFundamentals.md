<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a35d3b47e6ae98ad9b3e89fb73917e90",
  "translation_date": "2025-09-19T00:10:26+00:00",
  "source_file": "Module01/01.EdgeAIFundamentals.md",
  "language_code": "hr"
}
-->
# Sekcija 1: Osnove EdgeAI-a

EdgeAI predstavlja promjenu paradigme u primjeni umjetne inteligencije, donoseÄ‡i AI moguÄ‡nosti izravno na rubne ureÄ‘aje umjesto da se oslanja iskljuÄivo na obradu u oblaku. VaÅ¾no je razumjeti kako EdgeAI omoguÄ‡uje lokalnu obradu AI-a na ureÄ‘ajima s ograniÄenim resursima, dok istovremeno odrÅ¾ava razumnu izvedbu i rjeÅ¡ava izazove poput privatnosti, kaÅ¡njenja i offline funkcionalnosti.

## Uvod

U ovoj lekciji istraÅ¾it Ä‡emo EdgeAI i njegove osnovne koncepte. Pokrit Ä‡emo tradicionalnu paradigmu raÄunalne obrade AI-a, izazove rubnog raÄunalstva, kljuÄne tehnologije koje omoguÄ‡uju EdgeAI te praktiÄne primjene u raznim industrijama.

## Ciljevi uÄenja

Na kraju ove lekcije moÄ‡i Ä‡ete:

- Razumjeti razliku izmeÄ‘u tradicionalnog pristupa AI-u temeljenog na oblaku i EdgeAI-a.
- Identificirati kljuÄne tehnologije koje omoguÄ‡uju obradu AI-a na rubnim ureÄ‘ajima.
- Prepoznati prednosti i ograniÄenja implementacija EdgeAI-a.
- Primijeniti znanje o EdgeAI-u na stvarne scenarije i primjere upotrebe.

## Razumijevanje tradicionalne paradigme raÄunalne obrade AI-a

Tradicionalno, generativne AI aplikacije oslanjaju se na infrastrukturu visokih performansi za uÄinkovito pokretanje velikih jeziÄnih modela (LLM-ova). Organizacije obiÄno implementiraju ove modele na GPU klasterima u oblaku, pristupajuÄ‡i njihovim moguÄ‡nostima putem API suÄelja.

Ovaj centralizirani model dobro funkcionira za mnoge aplikacije, ali ima inherentna ograniÄenja u scenarijima rubnog raÄunalstva. Tradicionalni pristup ukljuÄuje slanje korisniÄkih upita na udaljene servere, obradu pomoÄ‡u moÄ‡nog hardvera i vraÄ‡anje rezultata putem interneta. Iako ova metoda omoguÄ‡uje pristup najnaprednijim modelima, stvara ovisnost o internetskoj povezanosti, uvodi probleme s kaÅ¡njenjem i postavlja pitanja privatnosti kada se osjetljivi podaci moraju prenijeti na vanjske servere.

Postoji nekoliko osnovnih koncepata koje trebamo razumjeti kada radimo s tradicionalnim paradigmama raÄunalne obrade AI-a, a to su:

- **â˜ï¸ Obrada u oblaku**: AI modeli pokreÄ‡u se na moÄ‡noj server infrastrukturi s visokim raÄunalnim resursima.
- **ğŸ”Œ Pristup putem API-ja**: Aplikacije pristupaju AI moguÄ‡nostima putem udaljenih API poziva umjesto lokalne obrade.
- **ğŸ›ï¸ Centralizirano upravljanje modelima**: Modeli se odrÅ¾avaju i aÅ¾uriraju centralno, osiguravajuÄ‡i dosljednost, ali zahtijevajuÄ‡i mreÅ¾nu povezanost.
- **ğŸ“ˆ Skalabilnost resursa**: Infrastruktura u oblaku moÅ¾e dinamiÄki skalirati kako bi se nosila s promjenjivim zahtjevima za raÄunalnim resursima.

## Izazovi rubnog raÄunalstva

Rubni ureÄ‘aji poput prijenosnih raÄunala, mobilnih telefona i ureÄ‘aja Interneta stvari (IoT) poput Raspberry Pi-a i NVIDIA Orin Nano-a predstavljaju jedinstvena ograniÄenja u raÄunalnim resursima. Ovi ureÄ‘aji obiÄno imaju ograniÄenu procesorsku snagu, memoriju i energetske resurse u usporedbi s infrastrukturom podatkovnih centara.

Pokretanje tradicionalnih LLM-ova na takvim ureÄ‘ajima povijesno je bilo izazovno zbog ovih hardverskih ograniÄenja. MeÄ‘utim, potreba za obradom AI-a na rubu postaje sve vaÅ¾nija u raznim scenarijima. Razmotrite situacije u kojima je internetska povezanost nepouzdana ili nedostupna, poput udaljenih industrijskih lokacija, vozila u tranzitu ili podruÄja s loÅ¡om mreÅ¾nom pokrivenoÅ¡Ä‡u. Osim toga, aplikacije koje zahtijevaju visoke sigurnosne standarde, poput medicinskih ureÄ‘aja, financijskih sustava ili vladinih aplikacija, moÅ¾da trebaju lokalno obraÄ‘ivati osjetljive podatke kako bi odrÅ¾ale privatnost i usklaÄ‘enost.

### KljuÄna ograniÄenja rubnog raÄunalstva

OkruÅ¾enja rubnog raÄunalstva suoÄavaju se s nekoliko temeljnih ograniÄenja koja tradicionalna AI rjeÅ¡enja temeljena na oblaku ne susreÄ‡u:

- **OgraniÄena procesorska snaga**: Rubni ureÄ‘aji obiÄno imaju manje CPU jezgri i niÅ¾e brzine takta u usporedbi s hardverom za servere.
- **OgraniÄenja memorije**: Dostupna RAM memorija i kapacitet pohrane znaÄajno su smanjeni na rubnim ureÄ‘ajima.
- **OgraniÄenja energije**: UreÄ‘aji na baterijski pogon moraju balansirati performanse s potroÅ¡njom energije za produÅ¾eni rad.
- **Upravljanje toplinom**: Kompaktni oblici ureÄ‘aja ograniÄavaju moguÄ‡nosti hlaÄ‘enja, Å¡to utjeÄe na odrÅ¾ive performanse pod optereÄ‡enjem.

## Å to je EdgeAI?

### Koncept: Definicija EdgeAI-a

EdgeAI odnosi se na implementaciju i izvrÅ¡avanje algoritama umjetne inteligencije izravno na rubnim ureÄ‘ajimaâ€”fiziÄkom hardveru koji postoji na "rubu" mreÅ¾e, blizu mjesta gdje se podaci generiraju i prikupljaju. Ti ureÄ‘aji ukljuÄuju pametne telefone, IoT senzore, pametne kamere, autonomna vozila, nosive ureÄ‘aje i industrijsku opremu. Za razliku od tradicionalnih AI sustava koji se oslanjaju na servere u oblaku za obradu, EdgeAI donosi inteligenciju izravno na izvor podataka.

U svojoj srÅ¾i, EdgeAI se odnosi na decentralizaciju obrade AI-a, premjeÅ¡tajuÄ‡i je iz centraliziranih podatkovnih centara i distribuirajuÄ‡i je preko Å¡iroke mreÅ¾e ureÄ‘aja koji Äine naÅ¡ digitalni ekosustav. Ovo predstavlja temeljnu promjenu u arhitekturi naÄina na koji se AI sustavi dizajniraju i implementiraju.

KljuÄni konceptualni stupovi EdgeAI-a ukljuÄuju:

- **Obrada u blizini**: Obrada se odvija fiziÄki blizu mjesta gdje podaci nastaju.
- **Decentralizirana inteligencija**: Sposobnosti donoÅ¡enja odluka distribuiraju se na viÅ¡e ureÄ‘aja.
- **Suverenitet podataka**: Informacije ostaju pod lokalnom kontrolom, Äesto nikada ne napuÅ¡tajuÄ‡i ureÄ‘aj.
- **Autonomno djelovanje**: UreÄ‘aji mogu inteligentno funkcionirati bez stalne povezanosti.
- **UgraÄ‘eni AI**: Inteligencija postaje intrinziÄna sposobnost svakodnevnih ureÄ‘aja.

### Vizualizacija arhitekture EdgeAI-a

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         TRADITIONAL AI ARCHITECTURE                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   Data Transfer  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   API Response   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Edge Devices â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚ Cloud Servers â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ End Users â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     Data                         Model Inference                     Results
   Collection                     High Latency
                                  High Bandwidth
                                  Privacy Concerns
                               
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            EDGE AI ARCHITECTURE                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   Direct Response   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Edge Devices with Embedded AI        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚ End Users â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â”‚ Sensors â”‚â”€>â”‚ SLM Inference â”‚â”€>â”‚ Local Action â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     Data         Low Latency       Immediate
   Collection     Processing        Response
                  No Data Transfer
                  Enhanced Privacy
```

EdgeAI predstavlja promjenu paradigme u primjeni umjetne inteligencije, donoseÄ‡i AI moguÄ‡nosti izravno na rubne ureÄ‘aje umjesto da se oslanja iskljuÄivo na obradu u oblaku. Ovaj pristup omoguÄ‡uje pokretanje AI modela lokalno na ureÄ‘ajima s ograniÄenim raÄunalnim resursima, pruÅ¾ajuÄ‡i moguÄ‡nosti inferencije u stvarnom vremenu bez potrebe za stalnom internetskom povezanoÅ¡Ä‡u.

EdgeAI obuhvaÄ‡a razne tehnologije i tehnike osmiÅ¡ljene za uÄiniti AI modele uÄinkovitijima i prikladnijima za implementaciju na ureÄ‘ajima s ograniÄenim resursima. Cilj je odrÅ¾ati razumnu izvedbu uz znaÄajno smanjenje zahtjeva za raÄunalnim i memorijskim resursima modela.

Pogledajmo osnovne pristupe koji omoguÄ‡uju implementacije EdgeAI-a na razliÄitim vrstama ureÄ‘aja i primjenama.

### Osnovni principi EdgeAI-a

EdgeAI se temelji na nekoliko temeljnih principa koji ga razlikuju od tradicionalnog AI-a temeljenog na oblaku:

- **Lokalna obrada**: Inferencija AI-a odvija se izravno na rubnom ureÄ‘aju bez potrebe za vanjskom povezanoÅ¡Ä‡u.
- **Optimizacija resursa**: Modeli su posebno optimizirani za hardverska ograniÄenja ciljanih ureÄ‘aja.
- **Performanse u stvarnom vremenu**: Obrada se odvija s minimalnim kaÅ¡njenjem za aplikacije osjetljive na vrijeme.
- **Privatnost po dizajnu**: Osjetljivi podaci ostaju na ureÄ‘aju, poboljÅ¡avajuÄ‡i sigurnost i usklaÄ‘enost.

## KljuÄne tehnologije koje omoguÄ‡uju EdgeAI

### Kvantizacija modela

Jedna od najvaÅ¾nijih tehnika u EdgeAI-u je kvantizacija modela. Ovaj proces ukljuÄuje smanjenje preciznosti parametara modela, obiÄno s 32-bitnih brojeva s pomiÄnim zarezom na 8-bitne cijele brojeve ili Äak niÅ¾e precizne formate. Iako ovo smanjenje preciznosti moÅ¾e izgledati zabrinjavajuÄ‡e, istraÅ¾ivanja su pokazala da mnogi AI modeli mogu odrÅ¾ati svoju izvedbu Äak i uz znaÄajno smanjenu preciznost.

Kvantizacija funkcionira mapiranjem raspona vrijednosti s pomiÄnim zarezom na manji skup diskretnih vrijednosti. Na primjer, umjesto koriÅ¡tenja 32 bita za predstavljanje svakog parametra, kvantizacija moÅ¾e koristiti samo 8 bita, Å¡to rezultira 4x smanjenjem zahtjeva za memorijom i Äesto dovodi do brÅ¾ih vremena inferencije.

```python
# Example: PyTorch model quantization 
import torch

# Load a pre-trained model
model = torch.load('large_model.pth')

# Quantize the model to INT8
quantized_model = torch.quantization.quantize_dynamic(
    model,  # model to quantize
    {torch.nn.Linear, torch.nn.Conv2d},  # layers to quantize
    dtype=torch.qint8  # quantization data type
)

# Save the quantized model
torch.save(quantized_model, 'quantized_model.pth')

# Memory usage comparison
original_size = model.size()
quantized_size = quantized_model.size()
print(f"Memory reduction: {original_size / quantized_size:.2f}x")
```

RazliÄite tehnike kvantizacije ukljuÄuju:

- **Post-trening kvantizacija (PTQ)**: Primjenjuje se nakon treninga modela bez potrebe za ponovnim treniranjem.
- **Kvantizacija svjesna treninga (QAT)**: UkljuÄuje uÄinke kvantizacije tijekom treninga za bolju toÄnost.
- **DinamiÄka kvantizacija**: Kvantizira teÅ¾ine na int8, ali aktivacije izraÄunava dinamiÄki.
- **StatistiÄka kvantizacija**: PredraÄunava sve parametre kvantizacije za teÅ¾ine i aktivacije.

Za implementacije EdgeAI-a, odabir odgovarajuÄ‡e strategije kvantizacije ovisi o specifiÄnoj arhitekturi modela, zahtjevima izvedbe i hardverskim moguÄ‡nostima ciljanog ureÄ‘aja.

### Kompresija i optimizacija modela

Osim kvantizacije, razne tehnike kompresije pomaÅ¾u smanjiti veliÄinu modela i zahtjeve za raÄunalnim resursima. To ukljuÄuje:

**Pruning**: Ova tehnika uklanja nepotrebne veze ili neurone iz neuronskih mreÅ¾a. Identificiranjem i eliminacijom parametara koji malo doprinose izvedbi modela, pruning moÅ¾e znaÄajno smanjiti veliÄinu modela uz odrÅ¾avanje toÄnosti.

```python
# Example: Neural network pruning in TensorFlow
import tensorflow as tf
import tensorflow_model_optimization as tfmot

# Define the model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Apply pruning during training
pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(
    initial_sparsity=0.0,
    final_sparsity=0.5,  # 50% of connections will be pruned
    begin_step=0,
    end_step=10000
)

pruned_model = tfmot.sparsity.keras.prune_low_magnitude(
    model, pruning_schedule=pruning_schedule
)

# Compile the pruned model
pruned_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model while pruning
pruned_model.fit(x_train, y_train, epochs=10)

# Convert to a smaller model for deployment
final_model = tfmot.sparsity.keras.strip_pruning(pruned_model)
```

**Destilacija znanja**: Ovaj pristup ukljuÄuje treniranje manjeg "studentskog" modela da oponaÅ¡a ponaÅ¡anje veÄ‡eg "uÄiteljskog" modela. Studentski model uÄi pribliÅ¾iti izlaze uÄitelja, Äesto postiÅ¾uÄ‡i sliÄnu izvedbu s znaÄajno manje parametara.

**Optimizacija arhitekture modela**: IstraÅ¾ivaÄi su razvili specijalizirane arhitekture dizajnirane posebno za implementaciju na rubu, poput MobileNets, EfficientNets i drugih laganih arhitektura koje balansiraju izvedbu s raÄunalnom uÄinkovitoÅ¡Ä‡u.

### Mali jeziÄni modeli (SLM-ovi)

RastuÄ‡i trend u EdgeAI-u je razvoj malih jeziÄnih modela (SLM-ova). Ovi modeli su dizajnirani od temelja da budu kompaktni i uÄinkoviti, dok i dalje pruÅ¾aju znaÄajne moguÄ‡nosti obrade prirodnog jezika. SLM-ovi to postiÅ¾u paÅ¾ljivim odabirom arhitekture, uÄinkovitim tehnikama treninga i fokusiranim treningom na specifiÄne domene ili zadatke.

Za razliku od tradicionalnih pristupa koji ukljuÄuju kompresiju velikih modela, SLM-ovi se Äesto treniraju s manjim skupovima podataka i optimiziranim arhitekturama posebno dizajniranim za implementaciju na rubu. Ovaj pristup moÅ¾e rezultirati modelima koji su ne samo manji, veÄ‡ i uÄinkovitiji za specifiÄne primjene.

## Hardverska akceleracija za EdgeAI

Moderni rubni ureÄ‘aji sve viÅ¡e ukljuÄuju specijalizirani hardver dizajniran za ubrzanje AI radnih optereÄ‡enja:

### Neuronske procesorske jedinice (NPUs)

NPUs su specijalizirani procesori dizajnirani posebno za neuronske mreÅ¾ne izraÄune. Ovi Äipovi mogu obavljati zadatke inferencije AI-a mnogo uÄinkovitije od tradicionalnih CPU-a, Äesto uz niÅ¾u potroÅ¡nju energije. Mnogi moderni pametni telefoni, prijenosna raÄunala i IoT ureÄ‘aji sada ukljuÄuju NPUs kako bi omoguÄ‡ili obradu AI-a na ureÄ‘aju.

```csharp
// Example: Using Windows ML to target NPU acceleration in C#
using Microsoft.ML.OnnxRuntime;

// Create session options with NPU provider
var sessionOptions = new SessionOptions();
sessionOptions.AppendExecutionProvider_DmlExecutionProvider();  // DirectML for NPU

// Load the ONNX model
using var session = new InferenceSession("model.onnx", sessionOptions);

// Create input tensor
var inputTensor = new DenseTensor<float>(new[] { 1, 3, 224, 224 });  // Example input shape
var inputs = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor("input", inputTensor) };

// Run inference with NPU acceleration
using var results = session.Run(inputs);
var output = results.First().AsTensor<float>();

// Process output
Console.WriteLine($"Inference result: {output[0]}");
```

UreÄ‘aji s NPUs ukljuÄuju:

- **Apple**: A-serija i M-serija Äipova s Neural Engine-om
- **Qualcomm**: Snapdragon procesori s Hexagon DSP/NPU
- **Samsung**: Exynos procesori s NPU
- **Intel**: Movidius VPUs i Habana Labs akceleratori
- **Microsoft**: Windows Copilot+ PC-ovi s NPUs

### ğŸ® GPU akceleracija

Iako rubni ureÄ‘aji moÅ¾da nemaju moÄ‡ne GPU-ove koji se nalaze u podatkovnim centrima, mnogi ipak ukljuÄuju integrirane ili diskretne GPU-ove koji mogu ubrzati AI radne optereÄ‡enja. Moderni mobilni GPU-ovi i integrirani grafiÄki procesori mogu pruÅ¾iti znaÄajna poboljÅ¡anja performansi za zadatke inferencije AI-a.

```python
# Example: Using TensorRT for GPU acceleration on edge devices
import tensorrt as trt
import numpy as np

# Create TensorRT logger and builder
TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
builder = trt.Builder(TRT_LOGGER)
network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
parser = trt.OnnxParser(network, TRT_LOGGER)

# Parse ONNX model
with open('model.onnx', 'rb') as model:
    parser.parse(model.read())

# Configure builder
config = builder.create_builder_config()
config.max_workspace_size = 1 << 28  # 256 MiB
config.set_flag(trt.BuilderFlag.FP16)  # Use FP16 precision for edge GPU

# Build and serialize engine
engine = builder.build_engine(network, config)
with open('model.trt', 'wb') as f:
    f.write(engine.serialize())
```

### Optimizacija CPU-a

ÄŒak i ureÄ‘aji koji koriste samo CPU mogu imati koristi od EdgeAI-a putem optimiziranih implementacija. Moderni CPU-ovi ukljuÄuju specijalizirane instrukcije za AI radne optereÄ‡enja, a softverski okviri razvijeni su za maksimiziranje performansi CPU-a za inferenciju AI-a.

```bash
# Example: Using XNNPACK with TFLite for optimized CPU inference
# Compilation command with XNNPACK acceleration enabled

bazel build -c opt --copt=-O3 --copt=-march=native \
  tensorflow/lite/delegates/xnnpack:libxnnpack_delegate.so

# Convert TensorFlow model to TFLite with optimization
tflite_convert \
  --keras_model_file=model.h5 \
  --output_file=model.tflite \
  --inference_type=FLOAT \
  --experimental_new_converter \
  --experimental_new_quantizer
```

Za softverske inÅ¾enjere koji rade s EdgeAI-om, razumijevanje kako iskoristiti ove opcije hardverske akceleracije kljuÄno je za optimizaciju performansi inferencije i energetske uÄinkovitosti na ciljanom ureÄ‘aju.

## Prednosti EdgeAI-a

### Privatnost i sigurnost

Jedna od najznaÄajnijih prednosti EdgeAI-a je poboljÅ¡ana privatnost i sigurnost. Obradom podataka lokalno na ureÄ‘aju, osjetljive informacije nikada ne napuÅ¡taju kontrolu korisnika. Ovo je posebno vaÅ¾no za aplikacije koje obraÄ‘uju osobne podatke, medicinske informacije ili povjerljive poslovne podatke.

### Smanjeno kaÅ¡njenje

EdgeAI eliminira potrebu za slanjem podataka na udaljene servere za obradu, znaÄajno smanjujuÄ‡i kaÅ¡njenje. Ovo je kljuÄno za aplikacije u stvarnom vremenu poput autonomnih vozila, industrijske automatizacije ili interaktivnih aplikacija gdje su potrebni trenutni odgovori.

### Offline funkcionalnost

EdgeAI omoguÄ‡uje funkcionalnost AI-a Äak i kada internetska povezanost nije dostupna. Ovo je vrijedno za aplikacije u udaljenim lokacijama, tijekom putovanja ili u situacijama gdje je pouzdanost mreÅ¾e upitna.

### TroÅ¡kovna uÄinkovitost

Smanjenjem oslanjanja na AI usluge temeljene na oblaku, EdgeAI moÅ¾e pomoÄ‡i u smanjenju operativnih troÅ¡kova, posebno za aplikacije s velikim volumenom koriÅ¡tenja. Organizacije mogu izbjeÄ‡i stalne troÅ¡kove API-ja i smanjiti zahtjeve za propusnoÅ¡Ä‡u.

### Skalabilnost

EdgeAI distribuira raÄunalno optereÄ‡enje preko rubnih ureÄ‘aja umjesto da ga centralizira u podatkovnim centrima. Ovo moÅ¾e pomoÄ‡i u smanjenju troÅ¡kova infrastrukture i poboljÅ¡anju ukupne skalabilnosti sustava.

## Primjene EdgeAI-a

### Pametni ureÄ‘aji i IoT

EdgeAI pokreÄ‡e mnoge znaÄajke pametnih ureÄ‘aja, od glasovnih asistenata koji mogu lokalno obraÄ‘ivati naredbe do pametnih kamera koje mogu identificirati objekte i ljude bez slanja videozapisa u oblak. IoT ureÄ‘aji koriste EdgeAI za prediktivno odrÅ¾avanje, praÄ‡enje okoliÅ¡a i automatizirano donoÅ¡enje odluka.

### Mobilne aplikacije

Pametni telefoni i tableti koriste EdgeAI za razne znaÄajke, ukljuÄujuÄ‡i poboljÅ¡anje fotografija, prijevod u stvarnom vremenu, proÅ¡irenu stvarnost i personalizirane preporuke. Ove aplikacije imaju koristi od niskog kaÅ¡njenja i prednosti privatnosti lokalne obrade.

### Industrijske primjene

Proizvodni i industrijski sektori koriste EdgeAI za kontrolu kvalitete, prediktivno odrÅ¾avanje i optimizaciju procesa. Ove aplikacije Äesto zahtijevaju obradu u stvarnom vremenu i mogu raditi u okruÅ¾enjima s ograniÄenom povezanoÅ¡Ä‡u.

### Zdravstvo

Medicinski ureÄ‘aji i zdravstvene aplikacije koriste EdgeAI za praÄ‡enje pacijenata, pomoÄ‡ u dijagnostici i preporuke za lijeÄenje. Prednosti privatnosti i sigurnosti lokalne obrade posebno su vaÅ¾ne u zdravstvenim aplikacijama.

## Izazovi i ograniÄenja

### Kompromisi u izvedbi

EdgeAI obiÄno ukljuÄuje kompromise izmeÄ‘u veliÄine modela, raÄunalne uÄinkovitosti i performansi. Iako tehnike poput kvant
## â¡ï¸ Å to slijedi

- [02: EdgeAI aplikacije](02.RealWorldCaseStudies.md)

---

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden pomoÄ‡u AI usluge za prevoÄ‘enje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati toÄnost, imajte na umu da automatski prijevodi mogu sadrÅ¾avati pogreÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za kljuÄne informacije preporuÄuje se profesionalni prijevod od strane ljudskog prevoditelja. Ne preuzimamo odgovornost za bilo kakva nesporazuma ili pogreÅ¡na tumaÄenja koja proizlaze iz koriÅ¡tenja ovog prijevoda.