<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2f1754a482b6a84e07287a5b775e65b6",
  "translation_date": "2025-09-30T23:38:29+00:00",
  "source_file": "Module08/samples/04/README.md",
  "language_code": "ko"
}
-->
# ìƒ˜í”Œ 04: Chainlitì„ í™œìš©í•œ í”„ë¡œë•ì…˜ ì±„íŒ… ì• í”Œë¦¬ì¼€ì´ì…˜

Microsoft Foundry Localì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡œë•ì…˜ ì¤€ë¹„ê°€ ì™„ë£Œëœ ì±„íŒ… ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•˜ëŠ” ë‹¤ì–‘í•œ ì ‘ê·¼ ë°©ì‹ì„ ë³´ì—¬ì£¼ëŠ” í¬ê´„ì ì¸ ìƒ˜í”Œì…ë‹ˆë‹¤. í˜„ëŒ€ì ì¸ ì›¹ ì¸í„°í˜ì´ìŠ¤, ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ, ìµœì²¨ë‹¨ ë¸Œë¼ìš°ì € ê¸°ìˆ ì„ í¬í•¨í•©ë‹ˆë‹¤.

## í¬í•¨ëœ ë‚´ìš©

- **ğŸš€ Chainlit ì±„íŒ… ì•±** (`app.py`): ìŠ¤íŠ¸ë¦¬ë° ê¸°ëŠ¥ì„ ê°–ì¶˜ í”„ë¡œë•ì…˜ ì¤€ë¹„ ì±„íŒ… ì• í”Œë¦¬ì¼€ì´ì…˜
- **ğŸŒ WebGPU ë°ëª¨** (`webgpu-demo/`): í•˜ë“œì›¨ì–´ ê°€ì†ì„ í™œìš©í•œ ë¸Œë¼ìš°ì € ê¸°ë°˜ AI ì¶”ë¡ 
- **ğŸ¨ Open WebUI í†µí•©** (`open-webui-guide.md`): ì „ë¬¸ì ì¸ ChatGPT ìŠ¤íƒ€ì¼ ì¸í„°í˜ì´ìŠ¤
- **ğŸ“š êµìœ¡ìš© ë…¸íŠ¸ë¶** (`chainlit_app.ipynb`): ëŒ€í™”í˜• í•™ìŠµ ìë£Œ

## ë¹ ë¥¸ ì‹œì‘

### 1. Chainlit ì±„íŒ… ì• í”Œë¦¬ì¼€ì´ì…˜

```cmd
# Navigate to Module08 directory
cd Module08

# Start your model
foundry model run phi-4-mini

# Run Chainlit app (using port 8080 to avoid conflicts)
chainlit run samples\04\app.py -w --port 8080
```

ì—´ë¦¬ëŠ” ìœ„ì¹˜: `http://localhost:8080`

### 2. WebGPU ë¸Œë¼ìš°ì € ë°ëª¨

```cmd
# Navigate to WebGPU demo
cd Module08\samples\04\webgpu-demo

# Serve the demo
python -m http.server 5173
```

ì—´ë¦¬ëŠ” ìœ„ì¹˜: `http://localhost:5173`

### 3. Open WebUI ì„¤ì •

```cmd
# Run Open WebUI with Docker
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

ì—´ë¦¬ëŠ” ìœ„ì¹˜: `http://localhost:3000`

## ì•„í‚¤í…ì²˜ íŒ¨í„´

### ë¡œì»¬ vs í´ë¼ìš°ë“œ ê²°ì • ë§¤íŠ¸ë¦­ìŠ¤

| ì‹œë‚˜ë¦¬ì˜¤ | ì¶”ì²œ | ì´ìœ  |
|----------|------|------|
| **ë¯¼ê°í•œ ë°ì´í„°** | ğŸ  ë¡œì»¬ (Foundry) | ë°ì´í„°ê°€ ê¸°ê¸°ë¥¼ ë²—ì–´ë‚˜ì§€ ì•ŠìŒ |
| **ë³µì¡í•œ ì¶”ë¡ ** | â˜ï¸ í´ë¼ìš°ë“œ (Azure OpenAI) | ë” í° ëª¨ë¸ì— ì ‘ê·¼ ê°€ëŠ¥ |
| **ì‹¤ì‹œê°„ ì±„íŒ…** | ğŸ  ë¡œì»¬ (Foundry) | ë‚®ì€ ì§€ì—° ì‹œê°„, ë¹ ë¥¸ ì‘ë‹µ |
| **ë¬¸ì„œ ë¶„ì„** | ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ | ì¶”ì¶œì€ ë¡œì»¬, ë¶„ì„ì€ í´ë¼ìš°ë“œ |
| **ì½”ë“œ ìƒì„±** | ğŸ  ë¡œì»¬ (Foundry) | ê°œì¸ì •ë³´ ë³´í˜¸ + íŠ¹í™”ëœ ëª¨ë¸ |
| **ì—°êµ¬ ì‘ì—…** | â˜ï¸ í´ë¼ìš°ë“œ (Azure OpenAI) | ê´‘ë²”ìœ„í•œ ì§€ì‹ ê¸°ë°˜ í•„ìš” |

### ê¸°ìˆ  ë¹„êµ

| ê¸°ìˆ  | ì‚¬ìš© ì‚¬ë¡€ | ì¥ì  | ë‹¨ì  |
|------|----------|------|------|
| **Chainlit** | Python ê°œë°œì, ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ | ì‰¬ìš´ ì„¤ì •, ìŠ¤íŠ¸ë¦¬ë° ì§€ì› | Python ì „ìš© |
| **WebGPU** | ìµœëŒ€ ê°œì¸ì •ë³´ ë³´í˜¸, ì˜¤í”„ë¼ì¸ ì‹œë‚˜ë¦¬ì˜¤ | ë¸Œë¼ìš°ì € ë„¤ì´í‹°ë¸Œ, ì„œë²„ ë¶ˆí•„ìš” | ì œí•œëœ ëª¨ë¸ í¬ê¸° |
| **Open WebUI** | í”„ë¡œë•ì…˜ ë°°í¬, íŒ€ | ì „ë¬¸ UI, ì‚¬ìš©ì ê´€ë¦¬ | Docker í•„ìš” |

## ì‚¬ì „ ìš”êµ¬ ì‚¬í•­

- **Foundry Local**: ì„¤ì¹˜ ë° ì‹¤í–‰ ì¤‘ ([ë‹¤ìš´ë¡œë“œ](https://aka.ms/foundry-local-installer))
- **Python**: 3.10+ ë° ê°€ìƒ í™˜ê²½
- **ëª¨ë¸**: ìµœì†Œ í•˜ë‚˜ ë¡œë“œë¨ (`foundry model run phi-4-mini`)
- **ë¸Œë¼ìš°ì €**: WebGPU ì§€ì› Chrome/Edge
- **Docker**: Open WebUIìš© (ì„ íƒ ì‚¬í•­)

## ì„¤ì¹˜ ë° ì„¤ì •

### 1. Python í™˜ê²½ ì„¤ì •

```cmd
# Navigate to Module08 directory
cd Module08

# Create and activate virtual environment
py -m venv .venv
.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Foundry Local ì„¤ì •

```cmd
# Verify Foundry Local installation
foundry --version

# Start the service
foundry service start

# Load a model
foundry model run phi-4-mini

# Verify model is running
foundry service ps
```

## ìƒ˜í”Œ ì• í”Œë¦¬ì¼€ì´ì…˜

### Chainlit ì±„íŒ… ì• í”Œë¦¬ì¼€ì´ì…˜

**íŠ¹ì§•:**
- ğŸš€ **ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°**: í† í°ì´ ìƒì„±ë˜ëŠ” ì¦‰ì‹œ í‘œì‹œ
- ğŸ›¡ï¸ **ê°•ë ¥í•œ ì˜¤ë¥˜ ì²˜ë¦¬**: ìš°ì•„í•œ ë³µêµ¬ ë° ì„±ëŠ¥ ì €í•˜ ë°©ì§€
- ğŸ¨ **í˜„ëŒ€ì ì¸ UI**: ê¸°ë³¸ ì œê³µ ì „ë¬¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
- ğŸ”§ **ìœ ì—°í•œ êµ¬ì„±**: í™˜ê²½ ë³€ìˆ˜ ë° ìë™ ê°ì§€
- ğŸ“± **ë°˜ì‘í˜• ë””ìì¸**: ë°ìŠ¤í¬í†± ë° ëª¨ë°”ì¼ì—ì„œ ì‘ë™

**ë¹ ë¥¸ ì‹œì‘:**
```cmd
# Run with default settings (recommended)
chainlit run samples\04\app.py -w --port 8080

# Use specific model
set MODEL=qwen2.5-7b
chainlit run samples\04\app.py -w --port 8080

# Manual endpoint configuration
set BASE_URL=http://localhost:51211
set API_KEY=your-api-key
chainlit run samples\04\app.py -w --port 8080
```

### WebGPU ë¸Œë¼ìš°ì € ë°ëª¨

**íŠ¹ì§•:**
- ğŸŒ **ë¸Œë¼ìš°ì € ë„¤ì´í‹°ë¸Œ AI**: ì„œë²„ ë¶ˆí•„ìš”, ë¸Œë¼ìš°ì €ì—ì„œë§Œ ì‹¤í–‰
- âš¡ **WebGPU ê°€ì†**: í•˜ë“œì›¨ì–´ ê°€ì† ì§€ì›
- ğŸ”’ **ìµœëŒ€ ê°œì¸ì •ë³´ ë³´í˜¸**: ë°ì´í„°ê°€ ê¸°ê¸°ë¥¼ ë²—ì–´ë‚˜ì§€ ì•ŠìŒ
- ğŸ¯ **ì„¤ì¹˜ ë¶ˆí•„ìš”**: í˜¸í™˜ ë¸Œë¼ìš°ì €ì—ì„œ ë°”ë¡œ ì‘ë™
- ğŸ”„ **ìš°ì•„í•œ ëŒ€ì²´**: WebGPUê°€ ì—†ì„ ê²½ìš° CPUë¡œ ìë™ ì „í™˜

**ì‹¤í–‰:**
```cmd
cd samples\04\webgpu-demo
python -m http.server 5173
# Open http://localhost:5173
```

### Open WebUI í†µí•©

**íŠ¹ì§•:**
- ğŸ¨ **ChatGPT ìŠ¤íƒ€ì¼ ì¸í„°í˜ì´ìŠ¤**: ì „ë¬¸ì ì´ê³  ìµìˆ™í•œ UI
- ğŸ‘¥ **ë‹¤ì¤‘ ì‚¬ìš©ì ì§€ì›**: ì‚¬ìš©ì ê³„ì • ë° ëŒ€í™” ê¸°ë¡
- ğŸ“ **íŒŒì¼ ì²˜ë¦¬**: ë¬¸ì„œ ì—…ë¡œë“œ ë° ë¶„ì„
- ğŸ”„ **ëª¨ë¸ ì „í™˜**: ë‹¤ì–‘í•œ ëª¨ë¸ ê°„ ì†ì‰¬ìš´ ì „í™˜
- ğŸ³ **Docker ë°°í¬**: í”„ë¡œë•ì…˜ ì¤€ë¹„ ì™„ë£Œ ì»¨í…Œì´ë„ˆ ì„¤ì •

**ë¹ ë¥¸ ì„¤ì •:**
```cmd
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

## êµ¬ì„± ì°¸ì¡°

### í™˜ê²½ ë³€ìˆ˜

| ë³€ìˆ˜ | ì„¤ëª… | ê¸°ë³¸ê°’ | ì˜ˆì‹œ |
|------|------|--------|------|
| `MODEL` | ì‚¬ìš©í•  ëª¨ë¸ ë³„ì¹­ | `phi-4-mini` | `qwen2.5-7b` |
| `BASE_URL` | Foundry Local ì—”ë“œí¬ì¸íŠ¸ | ìë™ ê°ì§€ | `http://localhost:51211` |
| `API_KEY` | API í‚¤ (ë¡œì»¬ì—ì„œëŠ” ì„ íƒ ì‚¬í•­) | `""` | `your-api-key` |

## ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œ

**Chainlit ì• í”Œë¦¬ì¼€ì´ì…˜:**

1. **ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ:**
   ```cmd
   # Check Foundry Local status
   foundry service status
   foundry service ps
   
   # Validate API endpoint (note: port 51211)
   curl http://localhost:51211/v1/models
   ```

2. **í¬íŠ¸ ì¶©ëŒ:**
   ```cmd
   # Check what's using port 8080
   netstat -ano | findstr :8080
   
   # Use different port if needed
   chainlit run samples\04\app.py -w --port 3000
   ```

3. **Python í™˜ê²½ ë¬¸ì œ:**
   ```cmd
   # Verify correct interpreter in VS Code
   # Ctrl+Shift+P â†’ Python: Select Interpreter
   # Choose: Module08/.venv/Scripts/python.exe
   
   # Reinstall dependencies
   pip install -r requirements.txt
   ```

**WebGPU ë°ëª¨:**

1. **WebGPUê°€ ì§€ì›ë˜ì§€ ì•ŠìŒ:**
   - Chrome/Edge 113+ë¡œ ì—…ë°ì´íŠ¸
   - WebGPU í™œì„±í™”: `chrome://flags/#enable-unsafe-webgpu`
   - GPU ìƒíƒœ í™•ì¸: `chrome://gpu`
   - ë°ëª¨ëŠ” CPUë¡œ ìë™ ì „í™˜ë¨

2. **ëª¨ë¸ ë¡œë”© ì˜¤ë¥˜:**
   - ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¥¼ ìœ„í•œ ì¸í„°ë„· ì—°ê²° í™•ì¸
   - ë¸Œë¼ìš°ì € ì½˜ì†”ì—ì„œ CORS ì˜¤ë¥˜ í™•ì¸
   - HTTPë¡œ ì œê³µ ì¤‘ì¸ì§€ í™•ì¸ (file:// ì•„ë‹˜)

**Open WebUI:**

1. **ì—°ê²° ê±°ë¶€ë¨:**
   ```cmd
   # Check Docker is running
   docker --version
   
   # Check container status
   docker ps | findstr open-webui
   
   # View container logs
   docker logs open-webui
   ```

2. **ëª¨ë¸ì´ ë‚˜íƒ€ë‚˜ì§€ ì•ŠìŒ:**
   ```cmd
   # Verify Foundry Local endpoint
   curl http://localhost:51211/v1/models
   
   # Restart Open WebUI
   docker restart open-webui
   ```

### ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

```cmd
# âœ… 1. Foundry Local Setup
foundry --version                    # Should show version
foundry service status               # Should show "running"
foundry model list                   # Should show loaded models
curl http://localhost:51211/v1/models  # Should return JSON

# âœ… 2. Python Environment  
python --version                     # Should be 3.10+
pip list | findstr chainlit         # Should show chainlit package
pip list | findstr openai           # Should show openai package

# âœ… 3. Application Testing
chainlit run samples\04\app.py -w --port 8080  # Should open browser
# Test WebGPU demo at localhost:5173
# Test Open WebUI at localhost:3000
```

## ê³ ê¸‰ ì‚¬ìš©ë²•

### ì„±ëŠ¥ ìµœì í™”

**Chainlit:**
- ìŠ¤íŠ¸ë¦¬ë°ì„ ì‚¬ìš©í•˜ì—¬ ë” ë‚˜ì€ ì„±ëŠ¥ ì œê³µ
- ë†’ì€ ë™ì‹œì„±ì„ ìœ„í•´ ì—°ê²° í’€ë§ êµ¬í˜„
- ë°˜ë³µ ì¿¼ë¦¬ì— ëŒ€í•´ ëª¨ë¸ ì‘ë‹µ ìºì‹±
- ëŒ€í™” ê¸°ë¡ì´ í° ê²½ìš° ë©”ëª¨ë¦¬ ì‚¬ìš© ëª¨ë‹ˆí„°ë§

**WebGPU:**
- ìµœëŒ€ ê°œì¸ì •ë³´ ë³´í˜¸ ë° ì†ë„ë¥¼ ìœ„í•´ WebGPU ì‚¬ìš©
- ì‘ì€ ëª¨ë¸ì„ ìœ„í•œ ëª¨ë¸ ì–‘ìí™” êµ¬í˜„
- ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ë¥¼ ìœ„í•œ Web Workers ì‚¬ìš©
- ë¸Œë¼ìš°ì € ì €ì¥ì†Œì— ì»´íŒŒì¼ëœ ëª¨ë¸ ìºì‹±

**Open WebUI:**
- ëŒ€í™” ê¸°ë¡ì„ ìœ„í•œ ì§€ì† ë³¼ë¥¨ ì‚¬ìš©
- Docker ì»¨í…Œì´ë„ˆì˜ ë¦¬ì†ŒìŠ¤ ì œí•œ êµ¬ì„±
- ì‚¬ìš©ì ë°ì´í„°ë¥¼ ìœ„í•œ ë°±ì—… ì „ëµ êµ¬í˜„
- SSL ì¢…ë£Œë¥¼ ìœ„í•œ ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ ì„¤ì •

### í†µí•© íŒ¨í„´

**ë¡œì»¬/í´ë¼ìš°ë“œ í•˜ì´ë¸Œë¦¬ë“œ:**
```python
# Route based on complexity and privacy requirements
async def intelligent_routing(prompt: str, metadata: dict):
    if metadata.get("contains_pii"):
        return await foundry_local_completion(prompt)  # Privacy-sensitive
    elif len(prompt.split()) > 200:
        return await azure_openai_completion(prompt)   # Complex reasoning
    else:
        return await foundry_local_completion(prompt)  # Default local
```

**ë©€í‹°ëª¨ë‹¬ íŒŒì´í”„ë¼ì¸:**
```python
# Combine different AI capabilities
async def analyze_document(file_path: str):
    # 1. OCR with WebGPU (browser-based)
    text = await webgpu_ocr(file_path)
    
    # 2. Analysis with Foundry Local (private)
    summary = await foundry_local_analyze(text)
    
    # 3. Enhancement with cloud (if needed)
    if summary.confidence < 0.8:
        summary = await azure_openai_enhance(summary)
    
    return summary
```

## í”„ë¡œë•ì…˜ ë°°í¬

### ë³´ì•ˆ ê³ ë ¤ ì‚¬í•­

- **API í‚¤**: í™˜ê²½ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê³  í•˜ë“œì½”ë”©í•˜ì§€ ì•Šê¸°
- **ë„¤íŠ¸ì›Œí¬**: í”„ë¡œë•ì…˜ì—ì„œ HTTPS ì‚¬ìš©, íŒ€ ì•¡ì„¸ìŠ¤ë¥¼ ìœ„í•œ VPN ê³ ë ¤
- **ì•¡ì„¸ìŠ¤ ì œì–´**: Open WebUIì— ëŒ€í•œ ì¸ì¦ êµ¬í˜„
- **ë°ì´í„° ê°œì¸ì •ë³´ ë³´í˜¸**: ë¡œì»¬ì— ë‚¨ëŠ” ë°ì´í„°ì™€ í´ë¼ìš°ë“œë¡œ ì „ì†¡ë˜ëŠ” ë°ì´í„° ê°ì‚¬
- **ì—…ë°ì´íŠ¸**: Foundry Local ë° ì»¨í…Œì´ë„ˆë¥¼ ìµœì‹  ìƒíƒœë¡œ ìœ ì§€

### ëª¨ë‹ˆí„°ë§ ë° ìœ ì§€ ê´€ë¦¬

- **ìƒíƒœ í™•ì¸**: ì—”ë“œí¬ì¸íŠ¸ ëª¨ë‹ˆí„°ë§ êµ¬í˜„
- **ë¡œê·¸**: ëª¨ë“  êµ¬ì„± ìš”ì†Œì—ì„œ ë¡œê·¸ ì¤‘ì•™í™”
- **ë©”íŠ¸ë¦­**: ì‘ë‹µ ì‹œê°„, ì˜¤ë¥˜ìœ¨, ë¦¬ì†ŒìŠ¤ ì‚¬ìš© ì¶”ì 
- **ë°±ì—…**: ëŒ€í™” ë°ì´í„° ë° êµ¬ì„±ì˜ ì •ê¸° ë°±ì—…

## ì°¸ê³  ìë£Œ ë° ë¦¬ì†ŒìŠ¤

### ë¬¸ì„œ
- [Chainlit ë¬¸ì„œ](https://docs.chainlit.io/) - í”„ë ˆì„ì›Œí¬ ê°€ì´ë“œ
- [Foundry Local ë¬¸ì„œ](https://learn.microsoft.com/azure/ai-foundry/foundry-local/) - Microsoft ê³µì‹ ë¬¸ì„œ
- [ONNX Runtime Web](https://onnxruntime.ai/docs/get-started/with-javascript/web.html) - WebGPU í†µí•©
- [Open WebUI ë¬¸ì„œ](https://docs.openwebui.com/) - ê³ ê¸‰ êµ¬ì„±

### ìƒ˜í”Œ íŒŒì¼
- [`app.py`](../../../../../Module08/samples/04/app.py) - í”„ë¡œë•ì…˜ Chainlit ì• í”Œë¦¬ì¼€ì´ì…˜
- [`chainlit_app.ipynb`](./chainlit_app.ipynb) - êµìœ¡ìš© ë…¸íŠ¸ë¶
- [`webgpu-demo/`](../../../../../Module08/samples/04/webgpu-demo) - ë¸Œë¼ìš°ì € ê¸°ë°˜ AI ì¶”ë¡ 
- [`open-webui-guide.md`](./open-webui-guide.md) - Open WebUI ì„¤ì • ì™„ì „ ê°€ì´ë“œ

### ê´€ë ¨ ìƒ˜í”Œ
- [ì„¸ì…˜ 4 ë¬¸ì„œ](../../04.CuttingEdgeModels.md) - ì „ì²´ ì„¸ì…˜ ê°€ì´ë“œ
- [Foundry Local ìƒ˜í”Œ](https://github.com/microsoft/foundry-local/tree/main/samples) - ê³µì‹ ìƒ˜í”Œ

---

**ë©´ì±… ì¡°í•­**:  
ì´ ë¬¸ì„œëŠ” AI ë²ˆì—­ ì„œë¹„ìŠ¤ [Co-op Translator](https://github.com/Azure/co-op-translator)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë²ˆì—­ë˜ì—ˆìŠµë‹ˆë‹¤. ì •í™•ì„±ì„ ìœ„í•´ ìµœì„ ì„ ë‹¤í•˜ê³  ìˆìœ¼ë‚˜, ìë™ ë²ˆì—­ì—ëŠ” ì˜¤ë¥˜ë‚˜ ë¶€ì •í™•í•œ ë‚´ìš©ì´ í¬í•¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì›ë³¸ ë¬¸ì„œì˜ ì›ì–´ ë²„ì „ì„ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê¶Œìœ„ ìˆëŠ” ìë£Œë¡œ ê°„ì£¼í•´ì•¼ í•©ë‹ˆë‹¤. ì¤‘ìš”í•œ ì •ë³´ì˜ ê²½ìš°, ì „ë¬¸ì ì¸ ì¸ê°„ ë²ˆì—­ì„ ê¶Œì¥í•©ë‹ˆë‹¤. ì´ ë²ˆì—­ ì‚¬ìš©ìœ¼ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ” ì˜¤í•´ë‚˜ ì˜ëª»ëœ í•´ì„ì— ëŒ€í•´ ë‹¹ì‚¬ëŠ” ì±…ì„ì„ ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤.