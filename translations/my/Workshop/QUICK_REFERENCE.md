<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a887b7e85782dadd3fd1216cd63b6c23",
  "translation_date": "2025-10-08T12:18:34+00:00",
  "source_file": "Workshop/QUICK_REFERENCE.md",
  "language_code": "my"
}
-->
# Workshop Samples - á€¡á€™á€¼á€”á€ºá€€á€­á€¯á€¸á€€á€¬á€¸á€€á€’á€º

**á€”á€±á€¬á€€á€ºá€†á€¯á€¶á€¸á€¡á€•á€ºá€’á€­á€á€º**: á€¡á€±á€¬á€€á€ºá€á€­á€¯á€˜á€¬ áˆáŠ á‚á€á‚á…

---

## ğŸš€ á€¡á€™á€¼á€”á€ºá€…á€á€„á€ºá€›á€”á€º

```bash
# 1. Ensure Foundry Local is running
foundry service status
foundry model run phi-4-mini

# 2. Install dependencies
pip install -r Workshop/requirements.txt

# 3. Run a sample
cd Workshop/samples/session01
python chat_bootstrap.py "What is edge AI?"
```

---

## ğŸ“‚ á€”á€™á€°á€”á€¬á€¡á€€á€»á€‰á€ºá€¸á€á€»á€¯á€•á€º

| á€¡á€…á€Šá€ºá€¸á€¡á€á€±á€¸ | á€”á€™á€°á€”á€¬ | á€›á€Šá€ºá€›á€½á€šá€ºá€á€»á€€á€º | á€¡á€á€»á€­á€”á€º |
|------------|--------|-------------|--------|
| 01 | `chat_bootstrap.py` | á€¡á€á€¼á€±á€á€¶ chat + streaming | ~30 á€…á€€á€¹á€€á€”á€·á€º |
| 02 | `rag_pipeline.py` | RAG á€”á€¾á€„á€·á€º embeddings | ~45 á€…á€€á€¹á€€á€”á€·á€º |
| 02 | `rag_eval_ragas.py` | RAG á€¡á€€á€²á€–á€¼á€á€ºá€á€¼á€„á€ºá€¸ | ~60 á€…á€€á€¹á€€á€”á€·á€º |
| 03 | `benchmark_oss_models.py` | á€™á€±á€¬á€ºá€’á€šá€º benchmarking | ~2 á€™á€­á€”á€…á€º |
| 04 | `model_compare.py` | SLM á€”á€¾á€„á€·á€º LLM | ~45 á€…á€€á€¹á€€á€”á€·á€º |
| 05 | `agents_orchestrator.py` | Multi-agent á€…á€”á€…á€º | ~60 á€…á€€á€¹á€€á€”á€·á€º |
| 06 | `models_router.py` | á€›á€Šá€ºá€›á€½á€šá€ºá€á€»á€€á€º routing | ~45 á€…á€€á€¹á€€á€”á€·á€º |
| 06 | `models_pipeline.py` | Multi-step pipeline | ~60 á€…á€€á€¹á€€á€”á€·á€º |

---

## ğŸ› ï¸ á€•á€á€ºá€á€”á€ºá€¸á€€á€»á€„á€º Variables

### á€¡á€›á€±á€¸á€€á€¼á€®á€¸á€á€±á€¬
```bash
# Choose model
set FOUNDRY_LOCAL_ALIAS=phi-4-mini

# Override endpoint (optional)
set FOUNDRY_LOCAL_ENDPOINT=http://localhost:8000

# Show token usage
set SHOW_USAGE=1
```

### á€¡á€…á€Šá€ºá€¸á€¡á€á€±á€¸á€¡á€œá€­á€¯á€€á€º
```bash
# Session 02: RAG
set RAG_QUESTION="What is local inference?"
set EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Session 03: Benchmarking
set BENCH_MODELS=phi-4-mini,qwen2.5-0.5b
set BENCH_ROUNDS=3
set BENCH_STREAM=1

# Session 04: Comparison
set SLM_ALIAS=phi-4-mini
set LLM_ALIAS=qwen2.5-7b

# Session 05: Agents
set AGENT_MODEL_PRIMARY=phi-4-mini
set AGENT_QUESTION="Why use edge AI?"

# Session 06: Pipeline
set PIPELINE_TASK="Your task here"
```

---

## âœ… á€¡á€á€Šá€ºá€•á€¼á€¯á€á€¼á€„á€ºá€¸á€”á€¾á€„á€·á€º á€…á€™á€ºá€¸á€á€•á€ºá€á€¼á€„á€ºá€¸

```bash
# Validate syntax and imports
python scripts/validate_samples.py

# Validate specific session
python scripts/validate_samples.py --session 01

# Run smoke tests
python scripts/test_samples.py --quick

# Verbose testing
python scripts/test_samples.py --verbose
```

---

## ğŸ› á€•á€¼á€¿á€”á€¬á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€á€¼á€„á€ºá€¸

### á€á€»á€­á€á€ºá€†á€€á€ºá€™á€¾á€¯á€¡á€™á€¾á€¬á€¸
```bash
# Check Foundry Local
foundry service status

# Start if needed
foundry service start
foundry model run phi-4-mini
```

### Import á€¡á€™á€¾á€¬á€¸
```bash
# Install missing dependencies
pip install sentence-transformers ragas datasets

# Or install all
pip install -r Workshop/requirements.txt
```

### á€™á€±á€¬á€ºá€’á€šá€ºá€™á€á€½á€±á€·á€›á€¾á€­
```bash
# List available models
foundry model ls

# Download model
foundry model download phi-4-mini
```

### á€¡á€œá€¯á€•á€ºá€”á€¾á€±á€¸á€á€¼á€„á€ºá€¸
```bash
# Use smaller model
set FOUNDRY_LOCAL_ALIAS=qwen2.5-0.5b

# Reduce benchmark rounds
set BENCH_ROUNDS=1
```

---

## ğŸ“– á€¡á€™á€»á€¬á€¸á€†á€¯á€¶á€¸á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€á€±á€¬ á€•á€¯á€¶á€…á€¶á€™á€»á€¬á€¸

### á€¡á€á€¼á€±á€á€¶ Chat
```python
from workshop_utils import chat_once

text, usage = chat_once(
    'phi-4-mini',
    messages=[{"role": "user", "content": "Hello"}],
    max_tokens=100,
    temperature=0.7
)
```

### Client á€›á€šá€°á€á€¼á€„á€ºá€¸
```python
from workshop_utils import get_client

manager, client, model_id = get_client(
    alias='phi-4-mini',
    endpoint=None  # Auto-detect
)
```

### á€¡á€™á€¾á€¬á€¸á€€á€­á€¯á€„á€ºá€á€½á€šá€ºá€á€¼á€„á€ºá€¸
```python
try:
    manager, client, model_id = get_client(alias)
except Exception as e:
    print(f"[ERROR] Failed: {e}")
    print("[INFO] Check: foundry service status")
    sys.exit(1)
```

### Streaming
```python
stream = client.chat.completions.create(
    model=model_id,
    messages=messages,
    stream=True
)

for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
```

---

## ğŸ“Š á€™á€±á€¬á€ºá€’á€šá€ºá€›á€½á€±á€¸á€á€»á€šá€ºá€™á€¾á€¯

| á€™á€±á€¬á€ºá€’á€šá€º | á€¡á€›á€½á€šá€ºá€¡á€…á€¬á€¸ | á€¡á€€á€±á€¬á€„á€ºá€¸á€†á€¯á€¶á€¸á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€™á€¾á€¯ | á€¡á€™á€¼á€”á€ºá€”á€¾á€¯á€”á€ºá€¸ |
|---------|------------|------------------------|-------------|
| `qwen2.5-0.5b` | 0.5B | á€¡á€™á€¼á€”á€ºá€¡á€á€­á€¡á€€á€»á€á€½á€²á€á€¼á€¬á€¸á€™á€¾á€¯ | âš¡âš¡âš¡ |
| `qwen2.5-coder-0.5b` | 0.5B | á€¡á€™á€¼á€”á€º code á€–á€”á€ºá€á€®á€¸á€™á€¾á€¯ | âš¡âš¡âš¡ |
| `gemma-2-2b` | 2B | á€–á€”á€ºá€á€®á€¸á€™á€¾á€¯á€›á€±á€¸á€á€¬á€¸á€á€¼á€„á€ºá€¸ | âš¡âš¡ |
| `phi-3.5-mini` | 3.5B | Code, refactoring | âš¡âš¡ |
| `phi-4-mini` | 4B | á€¡á€‘á€½á€±á€‘á€½á€±, á€¡á€€á€»á€‰á€ºá€¸á€á€»á€¯á€•á€º | âš¡âš¡ |
| `qwen2.5-7b` | 7B | á€›á€¾á€¯á€•á€ºá€‘á€½á€±á€¸á€á€±á€¬ reasoning | âš¡ |

---

## ğŸ”— á€¡á€›á€„á€ºá€¸á€¡á€™á€¼á€…á€ºá€™á€»á€¬á€¸

- **SDK Docs**: https://github.com/microsoft/Foundry-Local/tree/main/sdk/python
- **á€¡á€™á€¼á€”á€ºá€€á€­á€¯á€¸á€€á€¬á€¸**: `Workshop/FOUNDRY_SDK_QUICKREF.md`
- **á€¡á€•á€ºá€’á€­á€á€ºá€¡á€€á€»á€‰á€ºá€¸á€á€»á€¯á€•á€º**: `Workshop/SAMPLES_UPDATE_SUMMARY.md`
- **á€•á€¼á€±á€¬á€„á€ºá€¸á€›á€½á€¾á€±á€·á€™á€¾á€á€ºá€…á€¯á€™á€»á€¬á€¸**: `Workshop/SDK_MIGRATION_NOTES.md`

---

## ğŸ’¡ á€¡á€€á€¼á€¶á€•á€±á€¸á€á€»á€€á€ºá€™á€»á€¬á€¸

1. **Client á€™á€»á€¬á€¸ cache á€œá€¯á€•á€ºá€•á€«**: `workshop_utils` á€á€„á€·á€ºá€¡á€á€½á€€á€º cache á€œá€¯á€•á€ºá€•á€±á€¸á€á€Šá€º
2. **á€™á€±á€¬á€ºá€’á€šá€ºá€¡á€á€±á€¸á€™á€»á€¬á€¸á€€á€­á€¯ á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€•á€«**: á€…á€™á€ºá€¸á€á€•á€ºá€›á€”á€º `qwen2.5-0.5b` á€–á€¼á€„á€·á€º á€…á€á€„á€ºá€•á€«
3. **á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€™á€¾á€¯á€…á€¬á€›á€„á€ºá€¸á€–á€½á€„á€·á€ºá€•á€«**: `SHOW_USAGE=1` á€á€á€ºá€™á€¾á€á€ºá€•á€¼á€®á€¸ token á€™á€»á€¬á€¸á€€á€­á€¯ á€…á€±á€¬á€„á€·á€ºá€€á€¼á€Šá€·á€ºá€•á€«
4. **Batch á€…á€”á€…á€º**: prompt á€™á€»á€¬á€¸á€€á€­á€¯ á€¡á€†á€€á€ºá€™á€•á€¼á€á€ºá€œá€¯á€•á€ºá€†á€±á€¬á€„á€ºá€•á€«
5. **max_tokens á€€á€­á€¯ á€œá€»á€¾á€±á€¬á€·á€á€»á€•á€«**: á€¡á€™á€¼á€”á€ºá€á€¯á€¶á€·á€•á€¼á€”á€ºá€™á€¾á€¯á€¡á€á€½á€€á€º latency á€œá€»á€¾á€±á€¬á€·á€á€»á€á€Šá€º

---

## ğŸ¯ á€”á€™á€°á€”á€¬ Workflow á€™á€»á€¬á€¸

### á€¡á€¬á€¸á€œá€¯á€¶á€¸á€€á€­á€¯ á€…á€™á€ºá€¸á€á€•á€ºá€•á€«
```bash
python scripts/validate_samples.py
python scripts/test_samples.py --quick
```

### á€™á€±á€¬á€ºá€’á€šá€º Benchmark
```bash
cd samples/session03
set BENCH_MODELS=phi-4-mini,qwen2.5-0.5b,gemma-2-2b
set BENCH_ROUNDS=3
python benchmark_oss_models.py
```

### RAG Pipeline
```bash
cd samples/session02
set RAG_QUESTION="What is RAG?"
python rag_pipeline.py
```

### Multi-Agent á€…á€”á€…á€º
```bash
cd samples/session05
set AGENT_QUESTION="Why edge AI for healthcare?"
python agents_orchestrator.py
```

---

**á€¡á€™á€¼á€”á€ºá€¡á€€á€°á€¡á€Šá€®**: á€”á€™á€°á€”á€¬á€á€…á€ºá€á€¯á€…á€®á€€á€­á€¯ `--help` á€–á€¼á€„á€·á€º á€¡á€œá€¯á€•á€ºá€œá€Šá€ºá€…á€±á€•á€«áŠ á€á€­á€¯á€·á€™á€Ÿá€¯á€á€º docstring á€€á€­á€¯ á€€á€¼á€Šá€·á€ºá€•á€«:
```bash
python chat_bootstrap.py --help
# or
python -c "import chat_bootstrap; help(chat_bootstrap)"
```

---

**á€”á€™á€°á€”á€¬á€¡á€¬á€¸á€œá€¯á€¶á€¸á€€á€­á€¯ Foundry Local SDK á€¡á€€á€±á€¬á€„á€ºá€¸á€†á€¯á€¶á€¸á€¡á€œá€±á€·á€¡á€€á€»á€„á€·á€ºá€™á€»á€¬á€¸á€–á€¼á€„á€·á€º á‚á€á‚á… á€¡á€±á€¬á€€á€ºá€á€­á€¯á€˜á€¬á€á€½á€„á€º á€¡á€•á€ºá€’á€­á€á€ºá€œá€¯á€•á€ºá€•á€¼á€®á€¸á€–á€¼á€…á€ºá€á€Šá€º** âœ¨

---

**á€á€”á€ºá€á€¶á€á€»á€€á€º**:  
á€¤á€…á€¬á€›á€½á€€á€ºá€…á€¬á€á€™á€ºá€¸á€€á€­á€¯ AI á€˜á€¬á€á€¬á€•á€¼á€”á€ºá€á€”á€ºá€†á€±á€¬á€„á€ºá€™á€¾á€¯ [Co-op Translator](https://github.com/Azure/co-op-translator) á€€á€­á€¯ á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á á€˜á€¬á€á€¬á€•á€¼á€”á€ºá€‘á€¬á€¸á€•á€«á€á€Šá€ºá‹ á€€á€»á€½á€”á€ºá€¯á€•á€ºá€á€­á€¯á€·á€á€Šá€º á€á€­á€€á€»á€™á€¾á€”á€ºá€€á€”á€ºá€™á€¾á€¯á€¡á€á€½á€€á€º á€€á€¼á€­á€¯á€¸á€…á€¬á€¸á€”á€±á€á€±á€¬á€ºá€œá€Šá€ºá€¸ á€¡á€œá€­á€¯á€¡á€œá€»á€±á€¬á€€á€ºá€˜á€¬á€á€¬á€•á€¼á€”á€ºá€á€¼á€„á€ºá€¸á€á€½á€„á€º á€¡á€™á€¾á€¬á€¸á€™á€»á€¬á€¸ á€á€­á€¯á€·á€™á€Ÿá€¯á€á€º á€™á€™á€¾á€”á€ºá€€á€”á€ºá€™á€¾á€¯á€™á€»á€¬á€¸ á€•á€«á€á€„á€ºá€”á€­á€¯á€„á€ºá€á€Šá€ºá€€á€­á€¯ á€á€á€­á€•á€¼á€¯á€•á€«á‹ á€™á€°á€œá€˜á€¬á€á€¬á€…á€€á€¬á€¸á€–á€¼á€„á€·á€º á€›á€±á€¸á€á€¬á€¸á€‘á€¬á€¸á€á€±á€¬ á€…á€¬á€›á€½á€€á€ºá€…á€¬á€á€™á€ºá€¸á€€á€­á€¯ á€¡á€¬á€á€¬á€á€Šá€ºá€á€±á€¬á€›á€„á€ºá€¸á€™á€¼á€…á€ºá€¡á€–á€¼á€…á€º á€á€á€ºá€™á€¾á€á€ºá€á€„á€·á€ºá€•á€«á€á€Šá€ºá‹ á€¡á€›á€±á€¸á€€á€¼á€®á€¸á€á€±á€¬ á€¡á€á€»á€€á€ºá€¡á€œá€€á€ºá€™á€»á€¬á€¸á€¡á€á€½á€€á€º á€œá€°á€·á€˜á€¬á€á€¬á€•á€¼á€”á€ºá€•á€Šá€¬á€›á€¾á€„á€ºá€™á€»á€¬á€¸á€€á€­á€¯ á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€›á€”á€º á€¡á€€á€¼á€¶á€•á€¼á€¯á€•á€«á€á€Šá€ºá‹ á€¤á€˜á€¬á€á€¬á€•á€¼á€”á€ºá€€á€­á€¯ á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€á€¼á€„á€ºá€¸á€™á€¾ á€–á€¼á€…á€ºá€•á€±á€«á€ºá€œá€¬á€á€±á€¬ á€”á€¬á€¸á€œá€Šá€ºá€™á€¾á€¯á€™á€¾á€¬á€¸á€™á€»á€¬á€¸ á€á€­á€¯á€·á€™á€Ÿá€¯á€á€º á€¡á€“á€­á€•á€¹á€•á€«á€šá€ºá€™á€¾á€¬á€¸á€™á€»á€¬á€¸á€¡á€á€½á€€á€º á€€á€»á€½á€”á€ºá€¯á€•á€ºá€á€­á€¯á€·á€á€Šá€º á€á€¬á€á€”á€ºá€™á€šá€°á€•á€«á‹