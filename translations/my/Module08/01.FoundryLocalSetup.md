<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6503a980cb3bf2b2de2d2bc4ac6acc4c",
  "translation_date": "2025-09-25T02:21:57+00:00",
  "source_file": "Module08/01.FoundryLocalSetup.md",
  "language_code": "my"
}
-->
# á€¡á€…á€Šá€ºá€¸á€¡á€á€±á€¸ á: Foundry Local á€€á€­á€¯ á€…á€á€„á€ºá€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€á€¼á€„á€ºá€¸

## á€¡á€€á€»á€‰á€ºá€¸á€á€»á€¯á€•á€º

Microsoft Foundry Local á€á€Šá€º Azure AI Foundry áá€…á€½á€™á€ºá€¸á€›á€Šá€ºá€™á€»á€¬á€¸á€€á€­á€¯ Windows 11 á€–á€½á€¶á€·á€–á€¼á€­á€¯á€¸á€›á€±á€¸á€•á€á€ºá€á€”á€ºá€¸á€€á€»á€„á€ºá€á€½á€„á€º á€á€­á€¯á€€á€ºá€›á€­á€¯á€€á€ºá€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€”á€­á€¯á€„á€ºá€…á€±á€•á€¼á€®á€¸ á€á€®á€¸á€á€”á€·á€ºá€œá€¯á€¶á€á€¼á€¯á€¶á€™á€¾á€¯á€›á€¾á€­á€á€±á€¬áŠ á€¡á€”á€­á€™á€·á€ºá€†á€¯á€¶á€¸á€€á€¼á€¬á€á€»á€­á€”á€ºá€”á€¾á€„á€·á€º AI á€–á€½á€¶á€·á€–á€¼á€­á€¯á€¸á€›á€±á€¸á€€á€­á€¯ á€…á€®á€¸á€•á€½á€¬á€¸á€›á€±á€¸á€¡á€†á€„á€·á€ºá€€á€­á€›á€­á€šá€¬á€™á€»á€¬á€¸á€–á€¼á€„á€·á€º á€•á€¶á€·á€•á€­á€¯á€¸á€•á€±á€¸á€á€Šá€ºá‹ á€’á€®á€¡á€…á€Šá€ºá€¸á€¡á€á€±á€¸á€á€½á€„á€º phi, qwen, deepseek, á€”á€¾á€„á€·á€º GPT-OSS-20B á€…á€á€Šá€ºá€á€­á€¯á€·á€¡á€•á€«á€¡á€á€„á€º á€œá€°á€€á€¼á€­á€¯á€€á€ºá€™á€»á€¬á€¸á€á€±á€¬ á€™á€±á€¬á€ºá€’á€šá€ºá€™á€»á€¬á€¸á€€á€­á€¯ á€á€•á€ºá€†á€„á€ºá€á€¼á€„á€ºá€¸áŠ á€–á€½á€²á€·á€…á€Šá€ºá€¸á€á€¼á€„á€ºá€¸á€”á€¾á€„á€·á€º á€œá€€á€ºá€á€½á€±á€·á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€á€¼á€„á€ºá€¸á€€á€­á€¯ á€œá€¯á€¶á€¸á€á€–á€±á€¬á€ºá€•á€¼á€‘á€¬á€¸á€á€Šá€ºá‹

## á€á€„á€ºá€šá€°á€›á€™á€Šá€·á€ºá€¡á€›á€¬á€™á€»á€¬á€¸

á€’á€®á€¡á€…á€Šá€ºá€¸á€¡á€á€±á€¸á€¡á€†á€¯á€¶á€¸á€á€½á€„á€º á€á€„á€ºá€á€Šá€º:
- Windows 11 á€á€½á€„á€º Foundry Local á€€á€­á€¯ á€á€•á€ºá€†á€„á€ºá€•á€¼á€®á€¸ á€–á€½á€²á€·á€…á€Šá€ºá€¸á€”á€­á€¯á€„á€ºá€™á€Šá€º
- CLI á€¡á€™á€­á€”á€·á€ºá€™á€»á€¬á€¸á€”á€¾á€„á€·á€º á€–á€½á€²á€·á€…á€Šá€ºá€¸á€™á€¾á€¯á€›á€½á€±á€¸á€á€»á€šá€ºá€™á€¾á€¯á€™á€»á€¬á€¸á€€á€­á€¯ á€€á€»á€½á€™á€ºá€¸á€€á€»á€„á€ºá€…á€½á€¬ á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€”á€­á€¯á€„á€ºá€™á€Šá€º
- á€¡á€€á€±á€¬á€„á€ºá€¸á€†á€¯á€¶á€¸á€…á€½á€™á€ºá€¸á€†á€±á€¬á€„á€ºá€›á€Šá€ºá€¡á€á€½á€€á€º á€™á€±á€¬á€ºá€’á€šá€º caching á€™á€Ÿá€¬á€—á€»á€°á€Ÿá€¬á€™á€»á€¬á€¸á€€á€­á€¯ á€”á€¬á€¸á€œá€Šá€ºá€™á€Šá€º
- phi, qwen, deepseek, á€”á€¾á€„á€·á€º GPT-OSS-20B á€™á€±á€¬á€ºá€’á€šá€ºá€™á€»á€¬á€¸á€€á€­á€¯ á€¡á€±á€¬á€„á€ºá€™á€¼á€„á€ºá€…á€½á€¬ á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€”á€­á€¯á€„á€ºá€™á€Šá€º
- Foundry Local á€€á€­á€¯ á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á á€á€„á€·á€ºá€›á€²á€· á€•á€‘á€™á€†á€¯á€¶á€¸ AI á€¡á€€á€ºá€•á€œá€®á€€á€±á€¸á€›á€¾á€„á€ºá€¸á€€á€­á€¯ á€–á€”á€ºá€á€®á€¸á€”á€­á€¯á€„á€ºá€™á€Šá€º

## á€€á€¼á€­á€¯á€á€„á€ºá€œá€­á€¯á€¡á€•á€ºá€á€»á€€á€ºá€™á€»á€¬á€¸

### á€…á€”á€…á€ºá€œá€­á€¯á€¡á€•á€ºá€á€»á€€á€ºá€™á€»á€¬á€¸
- **Windows 11**: Version 22H2 á€á€­á€¯á€·á€™á€Ÿá€¯á€á€º á€¡á€‘á€€á€º
- **RAM**: á€¡á€”á€Šá€ºá€¸á€†á€¯á€¶á€¸ 16GBáŠ á€¡á€€á€¼á€¶á€•á€¼á€¯ 32GB
- **Storage**: á€™á€±á€¬á€ºá€’á€šá€ºá€™á€»á€¬á€¸á€”á€¾á€„á€·á€º cache á€¡á€á€½á€€á€º 50GB á€¡á€á€™á€²á€·á€”á€±á€›á€¬
- **Hardware**: NPU- á€á€­á€¯á€·á€™á€Ÿá€¯á€á€º GPU-enabled device (Copilot+ PC á€á€­á€¯á€·á€™á€Ÿá€¯á€á€º NVIDIA GPU) á€¡á€€á€¼á€¶á€•á€¼á€¯
- **Network**: á€™á€±á€¬á€ºá€’á€šá€ºá€™á€»á€¬á€¸á€€á€­á€¯ á€’á€±á€«á€„á€ºá€¸á€œá€¯á€’á€ºá€œá€¯á€•á€ºá€›á€”á€º á€¡á€™á€¼á€”á€ºá€”á€¾á€¯á€”á€ºá€¸á€›á€¾á€­á€á€±á€¬ á€¡á€„á€ºá€á€¬á€”á€€á€º

### á€–á€½á€¶á€·á€–á€¼á€­á€¯á€¸á€›á€±á€¸á€•á€á€ºá€á€”á€ºá€¸á€€á€»á€„á€º
```powershell
# Verify Windows version
winver

# Check available memory
Get-ComputerInfo | Select-Object TotalPhysicalMemory

# Verify PowerShell version (5.1+ required)
$PSVersionTable.PSVersion

# Set up Python environment (recommended)
py -m venv .venv
.venv\Scripts\activate

# Install required dependencies
pip install openai foundry-local-sdk
```

## á€¡á€•á€­á€¯á€„á€ºá€¸ á: á€á€•á€ºá€†á€„á€ºá€á€¼á€„á€ºá€¸á€”á€¾á€„á€·á€º á€…á€á€„á€ºá€–á€½á€²á€·á€…á€Šá€ºá€¸á€á€¼á€„á€ºá€¸

### á€¡á€†á€„á€·á€º á: Foundry Local á€€á€­á€¯ á€á€•á€ºá€†á€„á€ºá€•á€«

Winget á€€á€­á€¯ á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á Foundry Local á€€á€­á€¯ á€á€•á€ºá€†á€„á€ºá€•á€« á€á€­á€¯á€·á€™á€Ÿá€¯á€á€º GitHub á€™á€¾ installer á€€á€­á€¯ á€’á€±á€«á€„á€ºá€¸á€œá€¯á€’á€ºá€œá€¯á€•á€ºá€•á€«:

```powershell
# Winget (Windows)
winget install --id Microsoft.FoundryLocal --source winget

# Alternatively: download installer from the official repo
# https://aka.ms/foundry-local-installer
```

### á€¡á€†á€„á€·á€º á‚: á€á€•á€ºá€†á€„á€ºá€™á€¾á€¯á€€á€­á€¯ á€¡á€á€Šá€ºá€•á€¼á€¯á€•á€«

```powershell
# Check Foundry Local version
foundry --version

# Verify CLI accessibility and categories
foundry --help
foundry model --help
foundry cache --help
foundry service --help
```

## á€¡á€•á€­á€¯á€„á€ºá€¸ á‚: CLI á€€á€­á€¯ á€”á€¬á€¸á€œá€Šá€ºá€á€¼á€„á€ºá€¸

### á€¡á€“á€­á€€ Command á€–á€½á€²á€·á€…á€Šá€ºá€¸á€™á€¾á€¯

```powershell
# General command structure
foundry [category] [command] [options]

# Main categories
foundry model   # manage and run models
foundry service # manage the local service
foundry cache   # manage local model cache

# Common commands
foundry model list              # list available models
foundry model run phi-4-mini  # run a model (downloads as needed)
foundry cache ls                # list cached models
```


## á€¡á€•á€­á€¯á€„á€ºá€¸ áƒ: á€™á€±á€¬á€ºá€’á€šá€º caching á€”á€¾á€„á€·á€º á€…á€®á€™á€¶á€á€”á€·á€ºá€á€½á€²á€™á€¾á€¯

Foundry Local á€á€Šá€º á€…á€½á€™á€ºá€¸á€†á€±á€¬á€„á€ºá€›á€Šá€ºá€”á€¾á€„á€·á€º storage á€€á€­á€¯ á€¡á€€á€±á€¬á€„á€ºá€¸á€†á€¯á€¶á€¸á€–á€¼á€…á€ºá€…á€±á€›á€”á€º á€¡á€¬á€›á€¯á€¶á€…á€­á€¯á€€á€ºá€‘á€¬á€¸á€á€±á€¬ á€™á€±á€¬á€ºá€’á€šá€º caching á€€á€­á€¯ á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€á€Šá€º:

```powershell
# Show cache contents
foundry cache ls

# Optional: change cache directory (advanced)
foundry cache cd "C:\\FoundryLocal\\Cache"
foundry cache ls
```

## á€¡á€•á€­á€¯á€„á€ºá€¸ á„: á€œá€€á€ºá€á€½á€±á€· á€™á€±á€¬á€ºá€’á€šá€ºá€™á€»á€¬á€¸á€€á€­á€¯ á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€á€¼á€„á€ºá€¸

### Microsoft Phi á€™á€±á€¬á€ºá€’á€šá€ºá€™á€»á€¬á€¸á€€á€­á€¯ á€¡á€œá€¯á€•á€ºá€œá€¯á€•á€ºá€…á€±á€á€¼á€„á€ºá€¸

```powershell
# List catalog and run Phi (auto-downloads best variant for your hardware)
foundry model list
foundry model run phi-4-mini
```

### Qwen á€™á€±á€¬á€ºá€’á€šá€ºá€™á€»á€¬á€¸á€”á€¾á€„á€·á€º á€¡á€œá€¯á€•á€ºá€œá€¯á€•á€ºá€á€¼á€„á€ºá€¸

```powershell
# Run Qwen2.5 models (downloads on first run)
foundry model run qwen2.5-7b-instruct
foundry model run qwen2.5-14b-instruct
```

### DeepSeek á€™á€±á€¬á€ºá€’á€šá€ºá€™á€»á€¬á€¸á€€á€­á€¯ á€¡á€œá€¯á€•á€ºá€œá€¯á€•á€ºá€…á€±á€á€¼á€„á€ºá€¸

```powershell
# Run DeepSeek model
foundry model run deepseek-r1-distill-qwen-7b
```

### GPT-OSS-20B á€€á€­á€¯ á€¡á€œá€¯á€•á€ºá€œá€¯á€•á€ºá€…á€±á€á€¼á€„á€ºá€¸

```powershell
# Run the latest OpenAI open-source model (requires recent Foundry Local and sufficient GPU VRAM)
foundry model run gpt-oss-20b

# Check version if you encounter errors (requires 0.6.87+ per docs)
foundry --version
```

## á€¡á€•á€­á€¯á€„á€ºá€¸ á…: á€á€„á€·á€ºá€›á€²á€· á€•á€‘á€™á€†á€¯á€¶á€¸ á€¡á€€á€ºá€•á€œá€®á€€á€±á€¸á€›á€¾á€„á€ºá€¸á€€á€­á€¯ á€–á€”á€ºá€á€®á€¸á€á€¼á€„á€ºá€¸

### á€á€±á€á€ºá€™á€® Chat á€¡á€€á€ºá€•á€œá€®á€€á€±á€¸á€›á€¾á€„á€ºá€¸ (OpenAI SDK + Foundry Local)

OpenAI SDK á€”á€¾á€„á€·á€º Foundry Local á€€á€­á€¯ á€•á€±á€«á€„á€ºá€¸á€…á€•á€ºá€¡á€á€¯á€¶á€¸á€•á€¼á€¯á á€‘á€¯á€á€ºá€œá€¯á€•á€ºá€™á€¾á€¯á€¡á€†á€„á€·á€º chat á€¡á€€á€ºá€•á€œá€®á€€á€±á€¸á€›á€¾á€„á€ºá€¸á€€á€­á€¯ á€–á€”á€ºá€á€®á€¸á€•á€«áŠ Sample 01 á€™á€¾ pattern á€™á€»á€¬á€¸á€€á€­á€¯ á€œá€­á€¯á€€á€ºá€”á€¬á€•á€«á‹

```python
# chat_quickstart.py (Sample 01 pattern)
import os
import sys
from openai import OpenAI

try:
    from foundry_local import FoundryLocalManager
    FOUNDRY_SDK_AVAILABLE = True
except ImportError:
    FOUNDRY_SDK_AVAILABLE = False
    print("âš ï¸ Install foundry-local-sdk: pip install foundry-local-sdk")

def create_client():
    """Create OpenAI client with Foundry Local or Azure OpenAI."""
    # Check for Azure OpenAI configuration
    azure_endpoint = os.environ.get("AZURE_OPENAI_ENDPOINT")
    azure_api_key = os.environ.get("AZURE_OPENAI_API_KEY")
    
    if azure_endpoint and azure_api_key:
        # Azure OpenAI path
        model = os.environ.get("MODEL", "your-deployment-name")
        client = OpenAI(
            base_url=f"{azure_endpoint}/openai",
            api_key=azure_api_key,
            default_query={"api-version": "2024-08-01-preview"},
        )
        print(f"ğŸŒ Using Azure OpenAI with model: {model}")
        return client, model
    
    # Foundry Local path with SDK management
    alias = os.environ.get("MODEL", "phi-4-mini")
    if FOUNDRY_SDK_AVAILABLE:
        try:
            # Use FoundryLocalManager for proper service management
            manager = FoundryLocalManager(alias)
            model_info = manager.get_model_info(alias)
            
            client = OpenAI(
                base_url=manager.endpoint,
                api_key=manager.api_key
            )
            model = model_info.id
            print(f"ğŸ  Using Foundry Local SDK with model: {model}")
            return client, model
        except Exception as e:
            print(f"âš ï¸ Foundry SDK failed ({e}), using manual configuration")
    
    # Fallback to manual configuration
    base_url = os.environ.get("BASE_URL", "http://localhost:8000")
    api_key = os.environ.get("API_KEY", "")
    model = alias
    
    client = OpenAI(
        base_url=f"{base_url}/v1",
        api_key=api_key
    )
    print(f"ğŸ”§ Manual configuration with model: {model}")
    return client, model

def main():
    """Main chat function."""
    client, model = create_client()
    
    print("Foundry Local Chat Interface (type 'quit' to exit)\n")
    conversation_history = []
    
    while True:
        user_input = input("You: ")
        if user_input.lower() == 'quit':
            break
        
        try:
            # Add user message to history
            conversation_history.append({"role": "user", "content": user_input})
            
            # Create chat completion
            response = client.chat.completions.create(
                model=model,
                messages=conversation_history,
                max_tokens=500,
                temperature=0.7
            )
            
            assistant_message = response.choices[0].message.content
            conversation_history.append({"role": "assistant", "content": assistant_message})
            
            print(f"Assistant: {assistant_message}\n")
            
        except Exception as e:
            print(f"Error: {e}\n")

if __name__ == "__main__":
    main()
```

### Chat á€¡á€€á€ºá€•á€œá€®á€€á€±á€¸á€›á€¾á€„á€ºá€¸á€€á€­á€¯ á€¡á€œá€¯á€•á€ºá€œá€¯á€•á€ºá€…á€±á€•á€«

```powershell
# Ensure the model is running in another terminal
foundry model run phi-4-mini

# Option 1: Using FoundryLocalManager (recommended)
python chat_quickstart.py "Explain what Foundry Local is"

# Option 2: Manual configuration with environment variables
set BASE_URL=http://localhost:8000
set MODEL=phi-4-mini
set API_KEY=
python chat_quickstart.py "Write a welcome message"

# Option 3: Azure OpenAI configuration
set AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
set AZURE_OPENAI_API_KEY=your-api-key
set AZURE_OPENAI_API_VERSION=2024-08-01-preview
set MODEL=your-deployment-name
python chat_quickstart.py "Hello from Azure OpenAI"
```

## á€¡á€•á€­á€¯á€„á€ºá€¸ á†: á€•á€¼á€¿á€”á€¬á€™á€»á€¬á€¸á€€á€­á€¯ á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€á€¼á€„á€ºá€¸á€”á€¾á€„á€·á€º á€¡á€€á€±á€¬á€„á€ºá€¸á€†á€¯á€¶á€¸á€¡á€œá€±á€·á€¡á€€á€»á€„á€·á€ºá€™á€»á€¬á€¸

### á€¡á€™á€»á€¬á€¸á€†á€¯á€¶á€¸á€–á€¼á€…á€ºá€á€±á€¬ á€•á€¼á€¿á€”á€¬á€™á€»á€¬á€¸á€”á€¾á€„á€·á€º á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€”á€Šá€ºá€¸á€™á€»á€¬á€¸

```powershell
# Issue: "Could not use Foundry SDK" warning
pip install foundry-local-sdk
# Or set environment variables for manual configuration

# Issue: Connection refused
foundry service status
foundry service ps  # Check loaded models

# Issue: Model not found
foundry model list
foundry model run phi-4-mini

# Issue: Cache problems or low disk space
foundry cache ls
foundry cache clean

# Issue: GPT-OSS-20B not supported on your version
foundry --version
winget upgrade --id Microsoft.FoundryLocal

# Test API endpoint
curl http://localhost:8000/v1/models
```

### á€…á€”á€…á€ºá€¡á€›á€„á€ºá€¸á€¡á€™á€¼á€…á€ºá€™á€»á€¬á€¸á€€á€­á€¯ á€…á€±á€¬á€„á€·á€ºá€€á€¼á€Šá€·á€ºá€á€¼á€„á€ºá€¸ (Windows)

```powershell
# Quick CPU and process view
Get-Process | Sort-Object -Property CPU -Descending | Select-Object -First 10
Get-Counter '\\Processor(_Total)\\% Processor Time' -SampleInterval 1 -MaxSamples 10
```

### á€•á€á€ºá€á€”á€ºá€¸á€€á€»á€„á€º Variable á€™á€»á€¬á€¸

| Variable | á€–á€±á€¬á€ºá€•á€¼á€á€»á€€á€º | Default | á€œá€­á€¯á€¡á€•á€ºá€á€»á€€á€º |
|----------|-------------|---------|----------|
| `MODEL` | á€™á€±á€¬á€ºá€’á€šá€º alias á€á€­á€¯á€·á€™á€Ÿá€¯á€á€º á€¡á€™á€Šá€º | `phi-4-mini` | No |
| `BASE_URL` | Foundry Local base URL | `http://localhost:8000` | No |
| `API_KEY` | API key (á€¡á€™á€»á€¬á€¸á€¡á€¬á€¸á€–á€¼á€„á€·á€º local á€¡á€á€½á€€á€º á€™á€œá€­á€¯á€¡á€•á€º) | `""` | No |
| `AZURE_OPENAI_ENDPOINT` | Azure OpenAI endpoint | - | Azure á€¡á€á€½á€€á€º |
| `AZURE_OPENAI_API_KEY` | Azure OpenAI API key | - | Azure á€¡á€á€½á€€á€º |
| `AZURE_OPENAI_API_VERSION` | Azure API version | `2024-08-01-preview` | No |

### á€¡á€€á€±á€¬á€„á€ºá€¸á€†á€¯á€¶á€¸á€¡á€œá€±á€·á€¡á€€á€»á€„á€·á€ºá€™á€»á€¬á€¸

- **OpenAI SDK á€€á€­á€¯ á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€•á€«**: raw HTTP requests á€‘á€€á€º OpenAI SDK á€€á€­á€¯ á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€•á€«áŠ á€‘á€­á€”á€ºá€¸á€á€­á€™á€ºá€¸á€™á€¾á€¯á€•á€­á€¯á€™á€­á€¯á€€á€±á€¬á€„á€ºá€¸á€™á€½á€”á€ºá€…á€±á€á€Šá€º
- **FoundryLocalManager**: service management á€¡á€á€½á€€á€º á€›á€›á€¾á€­á€”á€­á€¯á€„á€ºá€á€±á€¬ á€á€›á€¬á€¸á€á€„á€º SDK á€€á€­á€¯ á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€•á€«
- **Error Handling**: á€‘á€¯á€á€ºá€œá€¯á€•á€ºá€™á€¾á€¯á€¡á€€á€ºá€•á€œá€®á€€á€±á€¸á€›á€¾á€„á€ºá€¸á€™á€»á€¬á€¸á€¡á€á€½á€€á€º fallback strategies á€™á€»á€¬á€¸á€€á€­á€¯ á€á€„á€·á€ºá€á€±á€¬á€ºá€…á€½á€¬ á€¡á€€á€±á€¬á€„á€ºá€¡á€‘á€Šá€ºá€–á€±á€¬á€ºá€•á€«
- **Regular Upgrade**: Foundry Local á€€á€­á€¯ á€¡á€™á€¼á€² update á€œá€¯á€•á€ºá€‘á€¬á€¸á€•á€«áŠ á€™á€±á€¬á€ºá€’á€šá€ºá€¡á€á€…á€ºá€™á€»á€¬á€¸á€”á€¾á€„á€·á€º á€•á€¼á€„á€ºá€†á€„á€ºá€™á€¾á€¯á€™á€»á€¬á€¸á€€á€­á€¯ á€›á€šá€°á€”á€­á€¯á€„á€ºá€›á€”á€º
- **Start Small**: á€™á€±á€¬á€ºá€’á€šá€ºá€¡á€á€±á€¸á€™á€»á€¬á€¸ (Phi mini, Qwen 7B) á€–á€¼á€„á€·á€º á€…á€á€„á€ºá€•á€¼á€®á€¸ á€á€–á€¼á€Šá€ºá€¸á€–á€¼á€Šá€ºá€¸ á€á€­á€¯á€¸á€á€»á€²á€·á€•á€«
- **Monitor Resources**: prompt á€”á€¾á€„á€·á€º setting á€™á€»á€¬á€¸á€€á€­á€¯ tune á€œá€¯á€•á€ºá€…á€‰á€º CPU/GPU/memory á€€á€­á€¯ á€…á€±á€¬á€„á€·á€ºá€€á€¼á€Šá€·á€ºá€•á€«

## á€¡á€•á€­á€¯á€„á€ºá€¸ á‡: á€œá€€á€ºá€á€½á€±á€·á€œá€±á€·á€€á€»á€„á€·á€ºá€™á€¾á€¯á€™á€»á€¬á€¸

### á€œá€±á€·á€€á€»á€„á€·á€ºá€™á€¾á€¯ á: Multi-Model Test á€€á€­á€¯ á€¡á€™á€¼á€”á€ºá€…á€™á€ºá€¸á€á€•á€ºá€á€¼á€„á€ºá€¸

```powershell
# deploy-models.ps1
$models = @(
    "phi-4-mini",
    "qwen2.5-7b-instruct"
)
foreach ($model in $models) {
    Write-Host "Running $model..."
    foundry model run $model --verbose
}
```

### á€œá€±á€·á€€á€»á€„á€·á€ºá€™á€¾á€¯ á‚: OpenAI SDK Integration Test

```python
# sdk_integration_test.py (matching Sample 01 pattern)
import os
from openai import OpenAI
from foundry_local import FoundryLocalManager

def test_model_integration(model_alias):
    """Test OpenAI SDK integration with different models."""
    try:
        # Use FoundryLocalManager for proper setup
        manager = FoundryLocalManager(model_alias)
        model_info = manager.get_model_info(model_alias)
        
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key
        )
        
        # Test basic completion
        response = client.chat.completions.create(
            model=model_info.id,
            messages=[{"role": "user", "content": "Say hello and state your model name."}],
            max_tokens=50
        )
        
        print(f"âœ… {model_alias}: {response.choices[0].message.content}")
        return True
    except Exception as e:
        print(f"âŒ {model_alias}: {e}")
        return False

# Test multiple models
models_to_test = ["phi-4-mini", "qwen2.5-7b-instruct"]
for model in models_to_test:
    test_model_integration(model)
```

### á€œá€±á€·á€€á€»á€„á€·á€ºá€™á€¾á€¯ áƒ: Comprehensive Service Health Check

```python
# health_check.py
from openai import OpenAI
from foundry_local import FoundryLocalManager

def comprehensive_health_check():
    """Perform comprehensive health check of Foundry Local service."""
    try:
        # Initialize with a common model
        manager = FoundryLocalManager("phi-4-mini")
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key
        )
        
        # 1. Check service connectivity
        models_response = client.models.list()
        available_models = [model.id for model in models_response.data]
        print(f"âœ… Service healthy - {len(available_models)} models available")
        
        # 2. Test each available model
        for model_id in available_models:
            try:
                response = client.chat.completions.create(
                    model=model_id,
                    messages=[{"role": "user", "content": "Test"}],
                    max_tokens=10
                )
                print(f"âœ… {model_id}: Working")
            except Exception as e:
                print(f"âŒ {model_id}: {e}")
        
        return True
    except Exception as e:
        print(f"âŒ Service check failed: {e}")
        return False

comprehensive_health_check()
```

## á€›á€„á€ºá€¸á€™á€¼á€…á€ºá€™á€»á€¬á€¸

- **Foundry Local á€€á€­á€¯ á€…á€á€„á€ºá€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€•á€«**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
- **CLI reference á€”á€¾á€„á€·á€º commands overview**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
- **OpenAI SDK integration**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
- **Compile Hugging Face models**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- **Microsoft Foundry Local GitHub**: https://github.com/microsoft/Foundry-Local
- **OpenAI Python SDK**: https://github.com/openai/openai-python
- **Sample 01: Quick Chat via OpenAI SDK**: samples/01/README.md
- **Sample 02: Advanced SDK Integration**: samples/02/README.md

---

