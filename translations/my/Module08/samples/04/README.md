<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "562ac0eae12d808c9f45fbb77eb5c84f",
  "translation_date": "2025-09-25T02:24:05+00:00",
  "source_file": "Module08/samples/04/README.md",
  "language_code": "my"
}
-->
# á€”á€™á€°á€”á€¬ 04: Chainlit á€–á€¼á€„á€·á€º Chat Application á€™á€»á€¬á€¸á€€á€­á€¯ á€‘á€¯á€á€ºá€œá€¯á€•á€ºá€á€¼á€„á€ºá€¸

Microsoft Foundry Local á€€á€­á€¯ á€¡á€žá€¯á€¶á€¸á€•á€¼á€¯á á€‘á€¯á€á€ºá€œá€¯á€•á€ºá€™á€¾á€¯á€¡á€†á€„á€·á€º chat application á€™á€»á€¬á€¸á€€á€­á€¯ á€á€Šá€ºá€†á€±á€¬á€€á€ºá€›á€”á€º á€¡á€™á€»á€­á€¯á€¸á€™á€»á€­á€¯á€¸á€žá€±á€¬á€”á€Šá€ºá€¸á€œá€™á€ºá€¸á€™á€»á€¬á€¸á€€á€­á€¯ á€•á€¼á€žá€‘á€¬á€¸á€žá€±á€¬ á€”á€™á€°á€”á€¬á€á€…á€ºá€á€¯á€–á€¼á€…á€ºá€•á€¼á€®á€¸áŠ á€á€±á€á€ºá€™á€® web interface á€™á€»á€¬á€¸áŠ streaming response á€™á€»á€¬á€¸á€”á€¾á€„á€·á€º á€”á€±á€¬á€€á€ºá€†á€¯á€¶á€¸á€•á€±á€«á€º browser á€”á€Šá€ºá€¸á€•á€Šá€¬á€™á€»á€¬á€¸á€•á€«á€á€„á€ºá€žá€Šá€ºá‹

## á€•á€«á€á€„á€ºá€žá€±á€¬á€¡á€›á€¬á€™á€»á€¬á€¸

- **ðŸš€ Chainlit Chat App** (`app.py`): Streaming á€•á€«á€á€„á€ºá€žá€±á€¬ á€‘á€¯á€á€ºá€œá€¯á€•á€ºá€™á€¾á€¯á€¡á€†á€„á€·á€º chat application
- **ðŸŒ WebGPU Demo** (`webgpu-demo/`): Hardware acceleration á€–á€¼á€„á€·á€º browser-based AI inference
- **ðŸŽ¨ Open WebUI Integration** (`open-webui-guide.md`): ChatGPT á€”á€¾á€„á€·á€ºá€á€°á€žá€±á€¬ professional interface
- **ðŸ“š Educational Notebook** (`chainlit_app.ipynb`): Interactive learning materials

## á€¡á€™á€¼á€”á€ºá€…á€á€„á€ºá€›á€”á€º

### 1. Chainlit Chat Application

```cmd
# Navigate to Module08 directory
cd Module08

# Start your model
foundry model run phi-4-mini

# Run Chainlit app (using port 8080 to avoid conflicts)
chainlit run samples\04\app.py -w --port 8080
```

á€–á€½á€„á€·á€ºá€›á€”á€º: `http://localhost:8080`

### 2. WebGPU Browser Demo

```cmd
# Navigate to WebGPU demo
cd Module08\samples\04\webgpu-demo

# Serve the demo
python -m http.server 5173
```

á€–á€½á€„á€·á€ºá€›á€”á€º: `http://localhost:5173`

### 3. Open WebUI Setup

```cmd
# Run Open WebUI with Docker
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

á€–á€½á€„á€·á€ºá€›á€”á€º: `http://localhost:3000`

## Architecture Patterns

### Local vs Cloud á€†á€¯á€¶á€¸á€–á€¼á€á€ºá€á€»á€€á€º Matrix

| á€¡á€á€¼á€±á€¡á€”á€± | á€¡á€€á€¼á€¶á€•á€¼á€¯á€á€»á€€á€º | á€¡á€€á€¼á€±á€¬á€„á€ºá€¸á€›á€„á€ºá€¸ |
|----------|----------------|--------|
| **Privacy-Sensitive Data** | ðŸ  Local (Foundry) | Data á€žá€Šá€º device á€™á€¾ á€™á€‘á€½á€€á€ºá€žá€½á€¬á€¸á€•á€« |
| **Complex Reasoning** | â˜ï¸ Cloud (Azure OpenAI) | Model á€¡á€€á€¼á€®á€¸á€™á€»á€¬á€¸á€€á€­á€¯ á€¡á€žá€¯á€¶á€¸á€•á€¼á€¯á€”á€­á€¯á€„á€ºá€žá€Šá€º |
| **Real-time Chat** | ðŸ  Local (Foundry) | Latency á€”á€Šá€ºá€¸á€•á€¼á€®á€¸ response á€™á€¼á€”á€ºá€žá€Šá€º |
| **Document Analysis** | ðŸ”„ Hybrid | Extraction á€¡á€á€½á€€á€º LocaláŠ Analysis á€¡á€á€½á€€á€º Cloud |
| **Code Generation** | ðŸ  Local (Foundry) | Privacy + Specialized models |
| **Research Tasks** | â˜ï¸ Cloud (Azure OpenAI) | á€€á€»á€šá€ºá€•á€¼á€”á€·á€ºá€žá€±á€¬ knowledge base á€œá€­á€¯á€¡á€•á€ºá€žá€Šá€º |

### á€”á€Šá€ºá€¸á€•á€Šá€¬á€”á€¾á€­á€¯á€„á€ºá€¸á€šá€¾á€‰á€ºá€™á€¾á€¯

| á€”á€Šá€ºá€¸á€•á€Šá€¬ | á€¡á€žá€¯á€¶á€¸á€•á€¼á€¯á€™á€¾á€¯ | á€¡á€€á€»á€­á€¯á€¸á€€á€»á€±á€¸á€‡á€°á€¸ | á€¡á€¬á€¸á€”á€Šá€ºá€¸á€á€»á€€á€º |
|------------|----------|------|------|
| **Chainlit** | Python developer á€™á€»á€¬á€¸áŠ rapid prototyping | Setup á€œá€½á€šá€ºáŠ streaming support | Python-only |
| **WebGPU** | Privacy á€¡á€™á€»á€¬á€¸á€†á€¯á€¶á€¸áŠ offline scenarios | Browser-nativeáŠ server á€™á€œá€­á€¯á€¡á€•á€º | Model size á€€á€”á€Šá€ºá€¸ |
| **Open WebUI** | Production deploymentáŠ teams | Professional UIáŠ user management | Docker á€œá€­á€¯á€¡á€•á€º |

## á€œá€­á€¯á€¡á€•á€ºá€á€»á€€á€ºá€™á€»á€¬á€¸

- **Foundry Local**: Install á€œá€¯á€•á€ºá€•á€¼á€®á€¸ run á€œá€¯á€•á€ºá€‘á€¬á€¸ ([Download](https://aka.ms/foundry-local-installer))
- **Python**: 3.10+ á€”á€¾á€„á€·á€º virtual environment
- **Model**: á€¡á€”á€Šá€ºá€¸á€†á€¯á€¶á€¸ model á€á€…á€ºá€á€¯ load á€œá€¯á€•á€ºá€‘á€¬á€¸ (`foundry model run phi-4-mini`)
- **Browser**: WebGPU support á€›á€¾á€­á€žá€±á€¬ Chrome/Edge
- **Docker**: Open WebUI á€¡á€á€½á€€á€º (optional)

## Installation & Setup

### 1. Python Environment Setup

```cmd
# Navigate to Module08 directory
cd Module08

# Create and activate virtual environment
py -m venv .venv
.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Foundry Local Setup

```cmd
# Verify Foundry Local installation
foundry --version

# Start the service
foundry service start

# Load a model
foundry model run phi-4-mini

# Verify model is running
foundry service ps
```

## á€”á€™á€°á€”á€¬ Applications

### Chainlit Chat Application

**Features:**
- ðŸš€ **Real-time Streaming**: Token á€™á€»á€¬á€¸á€€á€­á€¯ generate á€œá€¯á€•á€ºá€žá€Šá€·á€ºá€¡á€á€«á€™á€¾á€¬á€•á€² á€•á€¼á€žá€žá€Šá€º
- ðŸ›¡ï¸ **Robust Error Handling**: Error á€–á€¼á€…á€ºá€•á€«á€€ recovery á€œá€½á€šá€ºá€€á€°
- ðŸŽ¨ **Modern UI**: Professional chat interface
- ðŸ”§ **Flexible Configuration**: Environment variables á€”á€¾á€„á€·á€º auto-detection
- ðŸ“± **Responsive Design**: Desktop á€”á€¾á€„á€·á€º mobile device á€™á€»á€¬á€¸á€á€½á€„á€º á€¡á€œá€¯á€•á€ºá€œá€¯á€•á€ºá€žá€Šá€º

**Quick Start:**
```cmd
# Run with default settings (recommended)
chainlit run samples\04\app.py -w --port 8080

# Use specific model
set MODEL=qwen2.5-7b-instruct
chainlit run samples\04\app.py -w --port 8080

# Manual endpoint configuration
set BASE_URL=http://localhost:51211
set API_KEY=your-api-key
chainlit run samples\04\app.py -w --port 8080
```

### WebGPU Browser Demo

**Features:**
- ðŸŒ **Browser-native AI**: Server á€™á€œá€­á€¯á€¡á€•á€ºáŠ browser á€¡á€á€½á€„á€ºá€¸ run á€œá€¯á€•á€ºá€žá€Šá€º
- âš¡ **WebGPU Acceleration**: Hardware acceleration á€›á€›á€¾á€­á€”á€­á€¯á€„á€ºá€žá€Šá€º
- ðŸ”’ **Maximum Privacy**: Data á€žá€Šá€º device á€™á€¾ á€™á€‘á€½á€€á€ºá€žá€½á€¬á€¸á€•á€«
- ðŸŽ¯ **Zero Install**: Compatible browser á€™á€»á€¬á€¸á€á€½á€„á€º á€¡á€œá€¯á€•á€ºá€œá€¯á€•á€ºá€žá€Šá€º
- ðŸ”„ **Graceful Fallback**: WebGPU á€™á€›á€›á€¾á€­á€•á€«á€€ CPU á€žá€­á€¯á€· fallback

**Running:**
```cmd
cd samples\04\webgpu-demo
python -m http.server 5173
# Open http://localhost:5173
```

### Open WebUI Integration

**Features:**
- ðŸŽ¨ **ChatGPT-like Interface**: ProfessionaláŠ á€›á€­á€¯á€¸á€›á€¾á€„á€ºá€¸á€žá€±á€¬ UI
- ðŸ‘¥ **Multi-user Support**: User account á€™á€»á€¬á€¸á€”á€¾á€„á€·á€º conversation history
- ðŸ“ **File Processing**: Document á€™á€»á€¬á€¸á€€á€­á€¯ upload á€œá€¯á€•á€ºá€•á€¼á€®á€¸ analysis
- ðŸ”„ **Model Switching**: Model á€™á€»á€¬á€¸á€€á€­á€¯ á€œá€½á€šá€ºá€€á€°á€…á€½á€¬ á€•á€¼á€±á€¬á€„á€ºá€¸á€”á€­á€¯á€„á€ºá€žá€Šá€º
- ðŸ³ **Docker Deployment**: Containerized setup

**Quick Setup:**
```cmd
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

## Configuration Reference

### Environment Variables

| Variable | Description | Default | Example |
|----------|-------------|---------|----------|
| `MODEL` | á€¡á€žá€¯á€¶á€¸á€•á€¼á€¯á€™á€Šá€·á€º model alias | `phi-4-mini` | `qwen2.5-7b-instruct` |
| `BASE_URL` | Foundry Local endpoint | Auto-detected | `http://localhost:51211` |
| `API_KEY` | API key (optional for local) | `""` | `your-api-key` |

## Troubleshooting

### Common Issues

**Chainlit Application:**

1. **Service not available:**
   ```cmd
   # Check Foundry Local status
   foundry service status
   foundry service ps
   
   # Validate API endpoint (note: port 51211)
   curl http://localhost:51211/v1/models
   ```

2. **Port conflicts:**
   ```cmd
   # Check what's using port 8080
   netstat -ano | findstr :8080
   
   # Use different port if needed
   chainlit run samples\04\app.py -w --port 3000
   ```

3. **Python environment issues:**
   ```cmd
   # Verify correct interpreter in VS Code
   # Ctrl+Shift+P â†’ Python: Select Interpreter
   # Choose: Module08/.venv/Scripts/python.exe
   
   # Reinstall dependencies
   pip install -r requirements.txt
   ```

**WebGPU Demo:**

1. **WebGPU not supported:**
   - Chrome/Edge 113+ á€žá€­á€¯á€· update á€œá€¯á€•á€ºá€•á€«
   - WebGPU á€€á€­á€¯ enable á€œá€¯á€•á€ºá€•á€«: `chrome://flags/#enable-unsafe-webgpu`
   - GPU status á€€á€­á€¯á€…á€…á€ºá€•á€«: `chrome://gpu`
   - Demo á€žá€Šá€º CPU á€žá€­á€¯á€· automatic fallback á€œá€¯á€•á€ºá€•á€«á€™á€Šá€º

2. **Model loading errors:**
   - Model download á€¡á€á€½á€€á€º internet connection á€›á€¾á€­á€€á€¼á€±á€¬á€„á€ºá€¸á€žá€±á€á€»á€¬á€•á€«
   - Browser console á€á€½á€„á€º CORS error á€™á€»á€¬á€¸á€€á€­á€¯á€…á€…á€ºá€•á€«
   - HTTP á€–á€¼á€„á€·á€º serve á€œá€¯á€•á€ºá€”á€±á€€á€¼á€±á€¬á€„á€ºá€¸ verify á€œá€¯á€•á€ºá€•á€« (file:// á€™á€Ÿá€¯á€á€º)

**Open WebUI:**

1. **Connection refused:**
   ```cmd
   # Check Docker is running
   docker --version
   
   # Check container status
   docker ps | findstr open-webui
   
   # View container logs
   docker logs open-webui
   ```

2. **Models not appearing:**
   ```cmd
   # Verify Foundry Local endpoint
   curl http://localhost:51211/v1/models
   
   # Restart Open WebUI
   docker restart open-webui
   ```

### Validation Checklist

```cmd
# âœ… 1. Foundry Local Setup
foundry --version                    # Should show version
foundry service status               # Should show "running"
foundry model list                   # Should show loaded models
curl http://localhost:51211/v1/models  # Should return JSON

# âœ… 2. Python Environment  
python --version                     # Should be 3.10+
pip list | findstr chainlit         # Should show chainlit package
pip list | findstr openai           # Should show openai package

# âœ… 3. Application Testing
chainlit run samples\04\app.py -w --port 8080  # Should open browser
# Test WebGPU demo at localhost:5173
# Test Open WebUI at localhost:3000
```

## Advanced Usage

### Performance Optimization

**Chainlit:**
- Streaming á€€á€­á€¯á€¡á€žá€¯á€¶á€¸á€•á€¼á€¯á performance á€€á€­á€¯á€á€­á€¯á€¸á€á€€á€ºá€…á€±á€•á€«
- High concurrency á€¡á€á€½á€€á€º connection pooling á€€á€­á€¯ implement á€œá€¯á€•á€ºá€•á€«
- Model response á€™á€»á€¬á€¸á€€á€­á€¯ cache á€œá€¯á€•á€ºá€•á€«
- Conversation history á€™á€»á€¬á€¸á€€á€¼á€®á€¸á€œá€¬á€•á€«á€€ memory usage á€€á€­á€¯ monitor á€œá€¯á€•á€ºá€•á€«

**WebGPU:**
- Privacy á€”á€¾á€„á€·á€º speed á€¡á€á€½á€€á€º WebGPU á€€á€­á€¯á€¡á€žá€¯á€¶á€¸á€•á€¼á€¯á€•á€«
- Model size á€€á€­á€¯á€žá€±á€¸á€…á€±á€›á€”á€º quantization á€€á€­á€¯ implement á€œá€¯á€•á€ºá€•á€«
- Background processing á€¡á€á€½á€€á€º Web Workers á€€á€­á€¯á€¡á€žá€¯á€¶á€¸á€•á€¼á€¯á€•á€«
- Browser storage á€á€½á€„á€º compiled models á€™á€»á€¬á€¸á€€á€­á€¯ cache á€œá€¯á€•á€ºá€•á€«

**Open WebUI:**
- Conversation history á€¡á€á€½á€€á€º persistent volumes á€€á€­á€¯á€¡á€žá€¯á€¶á€¸á€•á€¼á€¯á€•á€«
- Docker container á€¡á€á€½á€€á€º resource limits á€€á€­á€¯ configure á€œá€¯á€•á€ºá€•á€«
- User data á€¡á€á€½á€€á€º backup strategy á€™á€»á€¬á€¸á€€á€­á€¯ implement á€œá€¯á€•á€ºá€•á€«
- SSL termination á€¡á€á€½á€€á€º reverse proxy á€€á€­á€¯ setup á€œá€¯á€•á€ºá€•á€«

### Integration Patterns

**Hybrid Local/Cloud:**
```python
# Route based on complexity and privacy requirements
async def intelligent_routing(prompt: str, metadata: dict):
    if metadata.get("contains_pii"):
        return await foundry_local_completion(prompt)  # Privacy-sensitive
    elif len(prompt.split()) > 200:
        return await azure_openai_completion(prompt)   # Complex reasoning
    else:
        return await foundry_local_completion(prompt)  # Default local
```

**Multi-Modal Pipeline:**
```python
# Combine different AI capabilities
async def analyze_document(file_path: str):
    # 1. OCR with WebGPU (browser-based)
    text = await webgpu_ocr(file_path)
    
    # 2. Analysis with Foundry Local (private)
    summary = await foundry_local_analyze(text)
    
    # 3. Enhancement with cloud (if needed)
    if summary.confidence < 0.8:
        summary = await azure_openai_enhance(summary)
    
    return summary
```

## Production Deployment

### Security Considerations

- **API Keys**: Environment variables á€€á€­á€¯á€¡á€žá€¯á€¶á€¸á€•á€¼á€¯á€•á€«áŠ hardcode á€™á€œá€¯á€•á€ºá€•á€«á€”á€¾á€„á€·á€º
- **Network**: Production á€á€½á€„á€º HTTPS á€€á€­á€¯á€¡á€žá€¯á€¶á€¸á€•á€¼á€¯á€•á€«áŠ team access á€¡á€á€½á€€á€º VPN á€€á€­á€¯á€…á€‰á€ºá€¸á€…á€¬á€¸á€•á€«
- **Access Control**: Open WebUI á€¡á€á€½á€€á€º authentication á€€á€­á€¯ implement á€œá€¯á€•á€ºá€•á€«
- **Data Privacy**: Local á€”á€¾á€„á€·á€º cloud á€žá€­á€¯á€· data á€žá€½á€¬á€¸á€œá€¬á€™á€¾á€¯á€€á€­á€¯ audit á€œá€¯á€•á€ºá€•á€«
- **Updates**: Foundry Local á€”á€¾á€„á€·á€º containers á€™á€»á€¬á€¸á€€á€­á€¯ update á€œá€¯á€•á€ºá€‘á€¬á€¸á€•á€«

### Monitoring and Maintenance

- **Health Checks**: Endpoint monitoring á€€á€­á€¯ implement á€œá€¯á€•á€ºá€•á€«
- **Logging**: Component á€™á€»á€¬á€¸á€™á€¾ logs á€™á€»á€¬á€¸á€€á€­á€¯ centralize á€œá€¯á€•á€ºá€•á€«
- **Metrics**: Response timeáŠ error rateáŠ resource usage á€™á€»á€¬á€¸á€€á€­á€¯ track á€œá€¯á€•á€ºá€•á€«
- **Backup**: Conversation data á€”á€¾á€„á€·á€º configuration á€™á€»á€¬á€¸á€€á€­á€¯ regular backup á€œá€¯á€•á€ºá€•á€«

## References and Resources

### Documentation
- [Chainlit Documentation](https://docs.chainlit.io/) - Framework guide á€¡á€•á€¼á€Šá€·á€ºá€¡á€…á€¯á€¶
- [Foundry Local Documentation](https://learn.microsoft.com/azure/ai-foundry/foundry-local/) - Microsoft á€›á€²á€· official docs
- [ONNX Runtime Web](https://onnxruntime.ai/docs/get-started/with-javascript/web.html) - WebGPU integration
- [Open WebUI Documentation](https://docs.openwebui.com/) - Advanced configuration

### Sample Files
- [`app.py`](../../../../../Module08/samples/04/app.py) - Production Chainlit application
- [`chainlit_app.ipynb`](./chainlit_app.ipynb) - Educational notebook
- [`webgpu-demo/`](../../../../../Module08/samples/04/webgpu-demo) - Browser-based AI inference
- [`open-webui-guide.md`](./open-webui-guide.md) - Complete Open WebUI setup

### Related Samples
- [Session 4 Documentation](../../04.CuttingEdgeModels.md) - Session guide á€¡á€•á€¼á€Šá€·á€ºá€¡á€…á€¯á€¶
- [Foundry Local Samples](https://github.com/microsoft/foundry-local/tree/main/samples) - Official samples

---

