<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20892f7994d9e5d2473ad19dfa93cf6d",
  "translation_date": "2025-10-11T12:24:20+00:00",
  "source_file": "Module02/01.PhiFamily.md",
  "language_code": "et"
}
-->
# Section 1: Microsoft Phi mudelite perekonna p√µhialused

Microsofti Phi mudelite perekond esindab tehisintellekti paradigmas muutust, n√§idates, et kompaktsed ja t√µhusad mudelid suudavad saavutada silmapaistvaid tulemusi, olles samal ajal oluliselt ressursis√§√§stlikumad kui traditsioonilised suured keelemudelid. Oluline on m√µista, kuidas Phi perekond v√µimaldab v√µimsaid AI-v√µimeid v√§iksemate arvutusn√µuetega, s√§ilitades samas k√µrge j√µudluse erinevates √ºlesannetes.

## Ressursid arendajatele

### Azure AI Foundry mudelikataloog
Phi mudelite perekond (v√§lja arvatud Phi-silica) on saadaval [Azure AI Foundry mudelikataloogi](https://ai.azure.com/explore/models?q=phi) kaudu, mis teeb arendajatele lihtsaks nende mudelite kasutamise, peenh√§√§lestamise ja rakendustes juurutamise. Kataloog pakub sujuvat viisi erinevate Phi variantide katsetamiseks ja nende integreerimiseks oma projektidesse.

### Azure AI Foundry
Phi mudeleid saab juurutada ja katsetada [Azure AI Foundry](https://ai.azure.com) keskkonnas, mis pakub terviklikku platvormi AI lahenduste loomiseks, testimiseks ja juurutamiseks minimaalse seadistusega.

### Foundry Local
Kohalikuks arenduseks ja juurutamiseks tutvu [Microsoft Foundry Local](https://github.com/microsoft/foundry-local) lahendusega, mis v√µimaldab Phi mudeleid k√§ivitada arendusmasinas optimeeritud konfiguratsioonidega.

### Dokumentatsiooni ressursid
- [Microsoft Research: Phi mudelite tehnilised aruanded](https://ai.azure.com/labs/projects/phi-4)
- [Phi Kokkaraamat](https://aka.ms/phicookbook)

## Sissejuhatus

Selles √µppet√ºkis uurime Microsofti Phi mudelite perekonda ja selle p√µhikontseptsioone. K√§sitleme Phi perekonna arengut, uuenduslikke treeningmetoodikaid, mis muudavad Phi mudelid t√µhusaks, perekonna peamisi variante ja praktilisi rakendusi erinevates olukordades.

## √ïppe-eesm√§rgid

Selle √µppet√ºki l√µpuks suudad:

- M√µista Microsofti Phi mudelite perekonna disainifilosoofiat ja arengut.
- Tuvastada peamised uuendused, mis v√µimaldavad Phi mudelitel saavutada k√µrge j√µudluse v√§iksema parameetrite arvuga.
- Tunnustada erinevate Phi mudelite variantide eeliseid ja piiranguid.
- Rakendada teadmisi Phi mudelitest, et valida sobivaid variante reaalses maailmas kasutamiseks.

## Traditsioonilise AI mudeli paradigma m√µistmine

Traditsiooniliselt n√µudis k√µrge j√µudluse saavutamine loomuliku keele t√∂√∂tlemises massiivseid keelemudeleid, millel on miljardeid v√µi sadu miljardeid parameetreid. Organisatsioonid juurutavad tavaliselt neid mudeleid v√µimsates GPU klastrites, kasutades nende v√µimeid API-liideste v√µi spetsiaalse riistvara kaudu.

Kuigi see l√§henemine t√∂√∂tab paljude rakenduste puhul h√§sti, on sellel praktilise juurutamise osas olulisi piiranguid. Traditsiooniline meetod h√µlmab mudeleid, mis vajavad m√§rkimisv√§√§rseid arvutusressursse, suurt m√§lumahtu ja suurt energiatarbimist. Kuigi see l√§henemine pakub tipptasemel v√µimeid, tekitab see s√µltuvusi kallistest riistvaradest, suurendab tegevuskulusid ja piirab juurutamise paindlikkust.

## T√µhusa AI juurutamise v√§ljakutse

T√µhusama AI vajadus on muutunud √ºha olulisemaks erinevates olukordades. M√µtle rakendustele, mis vajavad kohalikku juurutamist privaatsuse huvides, kulutundlikele lahendustele, kus pilve API kulud muutuvad takistuseks, serva arvutamise stsenaariumidele piiratud riistvararesurssidega v√µi reaalajas rakendustele, kus latentsus on kriitiline.

### Peamised juurutamise piirangud

Traditsiooniliste suurte mudelite juurutamine seisab silmitsi mitmete p√µhiliste piirangutega, mis piiravad nende praktilist rakendatavust:

- **Kulupiirangud**: Suured arvutuskulud muudavad pideva juurutamise paljudele organisatsioonidele kalliks.
- **Ressursipiirangud**: Piiratud juurdep√§√§s tipptasemel GPU infrastruktuurile piirab juurutamisv√µimalusi.
- **Privaatsusn√µuded**: Tundlikud rakendused vajavad kohalikku t√∂√∂tlemist, et s√§ilitada andmete privaatsus.
- **Latentsustundlikkus**: Reaalajas rakendused vajavad viivitamatuid vastuseid ilma pilvega seotud viivitusteta.

## Microsofti Phi mudelite filosoofia

Microsofti Phi mudelite perekond esindab AI mudelite disainifilosoofia fundamentaalset muutust, keskendudes t√µhususele ja praktilisele juurutamisele, s√§ilitades samas tugeva j√µudluse. Phi mudelid saavutavad selle uuenduslike arhitektuuride, kvaliteetsete treeningmetoodikate ja spetsiaalsete optimeerimistehnikate abil.

Phi perekond h√µlmab erinevaid l√§henemisviise, mis on loodud maksimeerima j√µudlust parameetri kohta, v√µimaldades juurutamist tavap√§rasel riistvaral ja pakkudes samal ajal olulisi AI-v√µimeid. Eesm√§rk on s√§ilitada konkurentsiv√µimeline j√µudlus, v√§hendades oluliselt arvutusn√µudeid, m√§lukasutust ja tegevuskulusid.

### Phi disaini p√µhialused

Phi mudelid p√µhinevad mitmel p√µhim√µttel, mis eristavad neid traditsioonilistest suurtest keelemudelitest:

- **T√µhusus esikohal**: Optimeeritud maksimaalse j√µudluse saavutamiseks parameetri kohta, mitte absoluutse mastaabi j√§rgi.
- **Kvaliteetne treening**: Keskendutakse kvaliteetsele, kureeritud treeningandmestikule, mitte massiivsetele andmehulkadele.
- **Juurutamise paindlikkus**: Loodud t√∂√∂tama t√µhusalt erinevatel riistvarakonfiguratsioonidel.
- **Spetsialiseeritud v√µimed**: Sageli optimeeritud konkreetsete √ºlesannete v√µi valdkondade jaoks, et maksimeerida t√µhusust.

## Tehnoloogiad, mis v√µimaldavad Phi perekonda

### "√ïpiku" treeningmeetod

√úks Phi perekonna k√µige revolutsioonilisemaid aspekte on "√µpiku kvaliteediga" treeningmetoodika. Selle asemel, et treenida massiivsete filtreerimata internetiandmete peal, kasutavad Phi mudelid hoolikalt kureeritud, kvaliteetset hariduslikku sisu, mis on loodud t√µhusalt √µpetama loogikat, matemaatikat, kodeerimist ja √ºldteadmisi.

See l√§henemine t√∂√∂tab, luues s√ºnteetilist hariduslikku sisu, mis peegeldab kvaliteetseid √µpikuid ja akadeemilisi materjale. Treeningandmed on spetsiaalselt loodud pedagoogiliselt m√µistlikuks, keskendudes selgetele selgitustele, samm-sammulisele loogikale ja struktureeritud teadmiste esitamisele.

### T√§iustatud loogikatreening

Viimased Phi mudelid sisaldavad keerukaid loogikatreeningu metoodikaid, mis v√µimaldavad lahendada keerulisi mitmeastmelisi probleeme. Need tehnikad h√µlmavad:

**Chain-of-Thought treening**: Mudelid √µpivad jagama keerulisi probleeme vahepealseteks loogikaetappideks, muutes nende probleemilahendusprotsessi l√§bipaistvamaks ja usaldusv√§√§rsemaks.

**Inference-Time Scaling**: Mudelid genereerivad √ºksikasjalikke loogikaahelaid, mis kasutavad vastuse genereerimise ajal t√§iendavaid arvutusressursse, et parandada t√§psust.

**Edge-of-Capability treening**: Treeningandmed valitakse spetsiaalselt mudeli praeguste v√µimete piiril, et edendada keeruliste loogikamustrite √µppimist.

### Arhitektuurilised uuendused

Phi perekond sisaldab mitmeid arhitektuurilisi optimeerimisi, mis on loodud spetsiaalselt t√µhususe jaoks:

**Parameetrite t√µhusus**: Hoolikalt valitud arhitektuurilised lahendused, mis maksimeerivad iga mudeli parameetri m√µju.

**Multimodaalne integreerimine**: T√µhus tekst-, visuaal- ja k√µnet√∂√∂tluse integreerimine kompaktsetes arhitektuurides.

**Riistvara optimeerimine**: Spetsiaalsed variandid, mis on optimeeritud konkreetsete riistvaraplatvormide ja juurutamisstsenaariumide jaoks.

## Riistvara optimeerimine Phi mudelite jaoks

Kaasaegsed juurutamiskeskkonnad saavad kasu Phi mudelite t√µhususest erinevates riistvarakonfiguratsioonides:

### CPU-optimeeritud juurutamine

Phi mudelid on loodud t√µhusalt t√∂√∂tama ainult CPU-riistvaral, muutes need juurutatavaks tavap√§rasel arvutustaristul ilma spetsiaalsete AI kiirenditeta.

### GPU kiirendus

Kuigi Phi mudelid ei vaja v√µimsaid GPU-sid, saavad nad kasutada olemasolevaid GPU ressursse j√µudluse parandamiseks, pakkudes paindlikkust juurutamiskonfiguratsioonides.

### Servaseadmete integreerimine

Spetsiaalsed variandid, nagu Phi-3-Silica, on optimeeritud konkreetsete serva arvutamise platvormide jaoks, saavutades m√§rkimisv√§√§rseid t√µhususn√§itajaid, n√§iteks 650 tokenit sekundis vaid 1,5W energiatarbimisega.

## Phi mudelite perekonna eelised

### Kulut√µhusus

Phi mudelid v√§hendavad oluliselt tegevuskulusid, n√µudes oluliselt v√§hem arvutustaristut, s√§ilitades samas konkurentsiv√µimelise j√µudluse. See muudab AI k√§ttesaadavaks organisatsioonidele, kellel on piiratud eelarve v√µi suuremahulised rakendused, kus iga p√§ringu maksumus on oluline.

### Juurutamise paindlikkus

Phi mudelite t√µhusus v√µimaldab juurutamist laias valikus riistvarakonfiguratsioonides, alates isiklikest s√ºlearvutitest kuni ettev√µtte serveriteni, pakkudes organisatsioonidele suuremat paindlikkust AI taristu valikutes.

### Privaatsus ja turvalisus

Phi mudelite t√µhusus v√µimaldab kohalikku juurutamist privaatsustundlikes rakendustes, tagades, et tundlikud andmed ei lahku organisatsiooni kontrolli alt, pakkudes samal ajal v√µimsaid AI-v√µimeid.

### Reaalajas j√µudlus

V√§hendatud arvutusn√µuded t√§hendavad kiiremaid p√§ringuaegu, v√µimaldades reaalajas rakendusi, mis vajavad viivitamatuid vastuseid, ilma et see kahjustaks AI v√µimete kvaliteeti.

### K√§ttesaadav AI

V√§hendades AI juurutamise takistusi, muudavad Phi mudelid arenenud AI-v√µimed k√§ttesaadavaks organisatsioonidele, kellel on piiratud ressursid, v√µimaldades v√§iksematel meeskondadel ja √ºksikarendajatel kasutada keerukaid keelem√µistmise v√µimeid.

## Praktilised n√§ited ja kasutusjuhtumid

Enne tehnilise arengu s√ºvenemist uurime m√µningaid konkreetseid n√§iteid, mida Phi mudelid suudavad saavutada:

### Matemaatilise loogika n√§ide

Phi-4-mini-reasoning paistab silma samm-sammulise matemaatilise probleemilahenduse osas. N√§iteks, kui k√ºsida "Kuidas lahendada 3*x^2+4*x+5=1?", pakub mudel √ºksikasjalikke loogikaetappe:

```
<|system|>Your name is Phi, an AI math expert developed by Microsoft.<|end|>
<|user|>How to solve 3*x^2+4*x+5=1?<|end|>
<|assistant|>
I need to solve the quadratic equation 3x¬≤ + 4x + 5 = 1.

First, let me rearrange this to standard form:
3x¬≤ + 4x + 5 = 1
3x¬≤ + 4x + 5 - 1 = 0  
3x¬≤ + 4x + 4 = 0

Now I can use the quadratic formula: x = (-b ¬± ‚àö(b¬≤ - 4ac)) / (2a)
Where a = 3, b = 4, c = 4

Let me calculate the discriminant:
b¬≤ - 4ac = 4¬≤ - 4(3)(4) = 16 - 48 = -32

Since the discriminant is negative (-32), this equation has no real solutions.
The solutions are complex: x = (-4 ¬± ‚àö(-32)) / 6 = (-4 ¬± 4i‚àö2) / 6 = (-2 ¬± 2i‚àö2) / 3
```

### Mitmekeelne tugi n√§ide

Phi-3.5-mini-instruct demonstreerib tugevat mitmekeelset v√µimekust erinevates keeltes. Siin on n√§ide k√ºsimuse vormingust:

```
<|system|>You are a helpful assistant.<|end|>
<|user|>How to explain Internet for a medieval knight?<|end|>
<|assistant|>
Imagine, good sir knight, a vast network of invisible roads that span the entire realm and beyond. The Internet is like a magical system of messenger birds that can carry any message - be it text, images, or even moving pictures - instantly to any castle, village, or hamlet in the world.

Think of it as if every scribe's work could be copied and shared with thousands of people simultaneously, as if you could visit any library in any kingdom without leaving your chambers, or as if you could hold council with knights from distant lands as if they were sitting at your very table.

This "Internet" allows people to:
- Send messages faster than the swiftest horse
- Access knowledge from scholars across all kingdoms
- Trade goods without traveling to distant markets
- Share stories and news from lands you've never seen

'Tis like having a thousand scribes, merchants, and storytellers all working for you at once, good knight!
```

### Multimodaalsed v√µimed n√§ide

Phi-4-multimodal suudab samaaegselt t√∂√∂delda teksti, pilte ja k√µnet. Siin on m√µned praktilised rakendused:

**Reisiplaneerimine k√µne sisendi abil:**
Vaata, kuidas Phi-4 Multimodal anal√º√ºsib k√µnekeelt, et aidata planeerida reisi Seattle'isse, demonstreerides selle arenenud k√µnet√∂√∂tluse ja soovituste v√µimeid.

**Matemaatiliste probleemide lahendamine piltidest:**
Vaata, kuidas Phi-4 Multimodal lahendab keerulisi matemaatilisi probleeme visuaalsete sisendite kaudu, demonstreerides selle v√µimet t√∂√∂delda ja lahendada pilte sisaldavaid v√µrrandeid.

**Funktsioonikutsumise n√§ide:**
Funktsioonikutsumise abil saavad Phi-4-mini ja Phi-4-multimodal laiendada oma tekstit√∂√∂tluse v√µimeid, integreerides otsingumootoreid, √ºhendades erinevaid t√∂√∂riistu ja palju muud. N√§iteks mudel suudab Phi-4-mini abil hankida Premier League'i m√§nguinfot, n√§idates selle v√µimet sujuvalt suhelda v√§liste andmeallikatega.

### Koodi genereerimise n√§ide

Phi-4-multimodal suudab genereerida struktureeritud projektikoodi nii pildisisu kui ka antud k√ºsimuste p√µhjal, nagu n√§idatud praktilises t√∂√∂voos:

1. Laadi √ºles pildi kujundus v√µi disain.
2. Anna kontekst projekti n√µuete kohta.
3. Mudel genereerib t√§ielikud, funktsionaalsed koodistruktuurid.
4. Koodi saab kohandada konkreetsete raamistikute v√µi keelte j√§rgi.

### Serva juurutamise n√§ide

Saame juurutada kvantiseeritud mudeli servaseadmetes. Kombineerides Microsoft Olive'i ja ONNX GenAI Runtime'i, saame juurutada Phi-4-mini Windowsis, iPhone'is, Androidis ja teistel seadmetel. See on n√§ide, mis t√∂√∂tab iPhone 12 Pro peal.

Juurutamisprotsess h√µlmab:
- Mudeli kvantiseerimist mobiili optimeerimiseks.
- ONNX runtime'i integreerimist platvormidevaheliseks √ºhilduvuseks.
- Kohalikku p√§ringut ilma interneti√ºhenduseta.
- Reaalajas j√µudlust minimaalse energiatarbimisega.

## Phi perekonna areng

### Phi-1 ja Phi-2: Alusmudelid

Varased Phi mudelid kehtestasid kvaliteetsete treeningandmete ja t√µhusate arhitektuuride p√µhim√µtted:

- **Phi-1 (1.3B parameetrit)**: Tutvustas kureeritud treeningandmete kontseptsiooni p√µhilise keelem√µistmise ja koodi genereerimise jaoks.
- **Phi-2 (2.7B parameetrit)**: Parandas loogikav√µimeid s√ºnteetiliste NLP andmete ja hoolikalt filtreeritud veebisisu abil.

### Phi-3 perekond: Peavoolu kasutuselev√µtt

Phi-3 seeria t√§histas l√§bimurret SLM v√µimekuses mitme spetsialiseeritud variandiga:

- **Phi-3-mini (3.8B parameetrit)**: √úldised keele√ºlesanded erakordse t√µhususega, √ºletades kaks korda suuremaid mudeleid.
- **Phi-3-small (7B parameetrit)**: T√§iustatud j√µudlus, mis √ºletab GPT-3.5 Turbo mitmel v√µrdlusn√§itajal.
- **Phi-3-medium (14B parameetrit)**: Ettev√µtte tasemel j√µudlus, mis √ºletab Gemini 1.0 Pro.
- **Phi-3-vision (4.2B parameetrit)**: Multimodaalsed v√µimed piltide ja teksti t√∂√∂tlemiseks.
- **Phi-3-Silica (3.3B parameetrit)**: Spetsiaalne optimeerimine Windows 11 sisseehitatud juurutamiseks.

### Phi-4 perekond: T√§iustatud loogika

Viimane p√µlvkond nihutab loogikav√µimekuse piire:

- **Phi-4 (14B parameetrit)**: Keerulise loogika spetsialiseerumine, eriti matemaatikas.
- **Phi-4-mini (3.8B parameetrit)**: T√§iustatud loogika funktsioonikutsumise ja pika konteksti toega.
- **Phi-4-multimodal**: Samaaegne k√µne-, visuaal- ja tekstit√∂√∂tluse v√µimekus.
- **Phi-4-reasoning (14B parameetrit)**: Spetsialiseeritud keeruliste mitmeastmeliste loogika√ºlesannete jaoks.
- **Phi-4-reasoning-plus (14B parameetrit)**: T√§iustatud t√§psus t√§iendava tugevdatud √µppe kaudu.
- **Phi-4-mini-reasoning (3
Phi perekond n√§itab, et AI tuleviku rakendamine ei seisne ainult suuremate mudelite loomises, vaid targemate ja t√µhusamate mudelite arendamises, mis suudavad edukalt t√∂√∂tada erinevates riistvarakeskkondades, s√§ilitades samal ajal k√µrged j√µudlusstandardid.

## Arenduse ja integreerimise n√§ited

### Kiire alustamine Transformeritega

Siin on juhend, kuidas alustada Phi mudelite kasutamist Hugging Face Transformers raamatukoguga:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load Phi-4-mini-instruct
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    attn_implementation="flash_attention_2"  # For optimized performance
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")

# Format your prompt using the chat template
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Explain quantum computing in simple terms."}
]

# Apply chat template
input_text = tokenizer.apply_chat_template(messages, tokenize=False)
inputs = tokenizer(input_text, return_tensors="pt")

# Generate response
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)
    
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### Peenh√§√§lestamise n√§ide

J√§rgmine n√§ide n√§itab, kuidas peenh√§√§lestada Phi-4-mini-instruct konkreetsete √ºlesannete jaoks:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig
from trl import SFTTrainer
from datasets import load_dataset

# Configuration for LoRA fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules="all-linear"
)

# Training configuration optimized for efficiency
training_config = TrainingArguments(
    output_dir="./phi-4-mini-finetuned",
    learning_rate=5.0e-06,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=1,
    num_train_epochs=1,
    bf16=True,
    gradient_checkpointing=True,
    warmup_ratio=0.2,
    save_steps=100
)

# Load model and tokenizer
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")
tokenizer.pad_token = tokenizer.unk_token
tokenizer.padding_side = 'right'

# Load and process dataset
train_dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_config,
    peft_config=peft_config,
    train_dataset=train_dataset,
    max_seq_length=2048,
    tokenizer=tokenizer,
    packing=True
)

# Start fine-tuning
trainer.train()
```

### Spetsialiseeritud viipade vormingud

**Loogika√ºlesannete jaoks (Phi-4-reasoning-plus):**
```
<|im_start|>system<|im_sep|>
You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions.

Please structure your response into two main sections:
<think>
{Thought section}
</think>
{Solution section}
<|im_end|>
<|im_start|>user<|im_sep|>
What is the derivative of x^2?
<|im_end|>
<|im_start|>assistant<|im_sep|>
```

**Matemaatiliste √ºlesannete jaoks (Phi-4-mini-reasoning):**
```
<|system|>
Your name is Phi, an AI math expert developed by Microsoft.
<|end|>
<|user|>
Solve this calculus problem: Find the integral of 2x + 3
<|end|>
<|assistant|>
```

### Mobiilirakendused ONNX-iga

```python
import onnxruntime as ort
import numpy as np

# Load ONNX model for mobile deployment
session = ort.InferenceSession("phi-4-mini-quantized.onnx")

# Prepare input
input_ids = tokenizer.encode("Hello, how are you?", return_tensors="np")

# Run inference
outputs = session.run(None, {"input_ids": input_ids})
predicted_ids = outputs[0]

# Decode response
response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)
```

## J√µudluse v√µrdlused ja saavutused

Phi mudelite perekond on saavutanud m√§rkimisv√§√§rseid tulemusi erinevates v√µrdlustes, sageli √ºletades palju suuremaid mudeleid:

### Olulised j√µudluse saavutused

**Matemaatilise loogika tipptase:**
- Phi-4 saavutab 82,5% t√§psuse AIME 2025 (matemaatikaol√ºmpiaadi kvalifikatsioon)
- Phi-4-reasoning (14B) √ºletab DeepSeek-R1-Distill-70B (5x suurem) loogika√ºlesannete v√µrdlustes
- Phi-4-mini-reasoning (3.8B) konkureerib matemaatilise loogika √ºlesannetes mudelitega, mis on kaks korda suuremad

**T√µhususe saavutused:**
- Phi-3-Silica t√∂√∂tleb 650 tokenit sekundis, tarbides vaid 1,5W energiat
- Phi-4-mini (3.8B) saavutab sarnase j√µudluse palju suuremate mudelitega

**V√µrdluste tulemused:**
- **MMLU (Massiivne Multiteemaline Keeleline M√µistmine)**: Konkurentsiv√µimeline j√µudlus 57 akadeemilises valdkonnas
- **HumanEval**: Tugevad koodi genereerimise v√µimed, eriti Pythonis
- **MGSM**: Mitmekeelne algkooli matemaatika probleemide lahendamine
- **DROP**: Keerukad m√µistmise ja loogika√ºlesanded
- **SimpleQA**: Faktip√µhiste vastuste t√§psus

### üìä Mudelite v√µrdlustabel

| Mudel | Parameetrid | Konteksti pikkus | Peamised tugevused | Parimad kasutusjuhtumid |
|-------|------------|----------------|---------------|----------------|
| **Phi-3-mini** | 3.8B | 4K/128K | √úldine t√µhusus | Mobiilirakendused, lihtsad vestlusrobotid |
| **Phi-3.5-mini** | 3.8B | 128K | Mitmekeelne tugi | Rahvusvahelised rakendused |
| **Phi-4-mini** | 3.8B | 128K | T√§iustatud loogika, funktsioonide kutsumine | √Ñriautomaatika |
| **Phi-4-mini-reasoning** | 3.8B | 128K | Matemaatiline loogika | Haridusplatvormid |
| **Phi-4** | 14B | 32K | Keerukas loogika | Uurimist√∂√∂, arenenud anal√º√ºs |
| **Phi-4-reasoning** | 14B | 32K/64K | Mitmeastmeline loogika | Teaduslik arvutus |
| **Phi-4-reasoning-plus** | 14B | 32K | Maksimaalne t√§psus loogika√ºlesannetes | Kriitiliste otsuste tegemine |
| **Phi-4-multimodal** | 5.6B | Muutuv | K√µne, visuaal, tekst | Multimeedia rakendused |

## Mudeli valiku juhend

### P√µhirakenduste jaoks
- **Phi-3-mini**: Lihtne teksti genereerimine, p√µhiline k√ºsimuste-vastuste s√ºsteem, kiired vastused
- **Phi-4-mini**: T√§iustatud loogika funktsioonide kutsumise v√µimekusega

### Matemaatiliste ja loogika√ºlesannete jaoks
- **Phi-4**: Keerukate matemaatiliste probleemide lahendamine ja loogika
- **Phi-4-reasoning**: Mitmeastmeline loogika koos detailsete selgitustega
- **Phi-4-reasoning-plus**: Maksimaalne t√§psus kriitiliste loogika√ºlesannete jaoks
- **Phi-4-mini-reasoning**: T√µhus matemaatiline loogika ressursipiirangutega keskkondades

### Multimodaalsete rakenduste jaoks
- **Phi-3-vision**: Pildi ja teksti t√∂√∂tlemise kombinatsioonid
- **Phi-4-multimodal**: K√µikeh√µlmavad k√µne-, visuaal- ja tekstiv√µimed

### Ettev√µtte rakenduste jaoks
- **Phi-3-medium**: T√§iustatud keeleline m√µistmine √§rirakenduste jaoks
- **Phi-3-Silica**: Optimeeritud konkreetsete riistvaraplatvormide jaoks

## Rakendusplatvormid ja juurdep√§√§setavus

### Pilveplatvormid
- **Azure AI Foundry**: T√§isfunktsionaalne rakendus koos ettev√µtte t√∂√∂riistadega
- **Hugging Face**: Avatud l√§htekoodiga mudelite hoidla ja kogukonna ressursid
- **NVIDIA API kataloog**: Mikroteenuste rakendamise v√µimalused

### Kohalikud arendusraamistikud
- **Ollama**: Kerge raamistik kohalike mudelite rakendamiseks
- **ONNX Runtime**: Optimeeritud erinevate riistvarakonfiguratsioonide jaoks  
- **DirectML**: Windowsi optimeeritud j√µudlus
- **llama.cpp**: Platvormidevaheline j√§reldusmootor

### √ïppematerjalid
- **Phi portaal**: Microsofti ametlik Phi dokumentatsiooni keskus
- **Phi kokaraamat**: P√µhjalikud n√§ited ja juhendid
- **Tehnilised aruanded**: S√ºvitsi uurimust√∂√∂d arxivis
- **Kogukonna ruumid**: Hugging Face interaktiivsed demod

### Phi mudelitega alustamine

#### Arendusplatvormid
1. **Azure AI Foundry**: Lihtne kohalik CLI ja mudelite haldamine.
2. **Hugging Face Transformers**: Kiire kohalik katsetamine
3. **Ollama**: Lihtne kohalik rakendus testimiseks

#### √ïppimise tee
1. **M√µista p√µhikontseptsioone**: Uuri p√µhjalikult disainiprintsiipe
2. **Katseta variante**: Proovi erinevaid Phi mudeleid, et m√µista nende v√µimekust
3. **Harjuta rakendamist**: Rakenda mudeleid testkeskkondades
4. **Laienda rakendust**: Suurenda kasutust j√§rk-j√§rgult eduka piloodi p√µhjal

#### Parimad tavad
- **Alusta v√§ikselt**: Alusta Phi-mini mudelitega esialgseks arenduseks
- **Optimeeri viipeid**: Kasuta korrektset vestlusvormingut parimate tulemuste saavutamiseks
- **J√§lgi j√µudlust**: J√§lgi j√§relduskiirust ja t√§psusm√µ√µdikuid
- **Arvesta riistvaraga**: Sobita mudeli suurus olemasolevate arvutusressurssidega

## Kokkuv√µte

Microsofti Phi mudelite perekond esindab revolutsioonilist l√§henemist AI mudelite disainile, n√§idates, et v√§iksemad ja t√µhusamad mudelid v√µivad saavutada m√§rkimisv√§√§rseid tulemusi erinevates √ºlesannetes. Keskendudes kvaliteetsele treeningandmestikule ja arhitektuurilistele optimeerimistele, pakub Phi perekond erakordseid v√µimeid oluliselt v√§iksemate arvutusn√µuetega v√µrreldes traditsiooniliste suurte keelemudelitega.

## Olulised √µpieesm√§rgid

1. M√µista Microsofti Phi mudelite perekonna disainifilosoofiat ja arengut Phi-1-st Phi-4-ni
2. Tuvasta peamised uuendused, sealhulgas "√µpiku kvaliteediga" treening ja arhitektuurilised optimeerimised
3. Tunnista erinevate Phi variantide eeliseid ja piiranguid erinevates rakendussituatsioonides
4. Rakenda teadmisi, et valida sobivad Phi mudelid konkreetsete kasutusjuhtumite ja riistvarapiirangute jaoks
5. Rakenda optimeerimistehnikaid Phi mudelite rakendamiseks ressursipiirangutega seadmetel
6. Selgita Phi mudelite perekonna arhitektuurilisi eeliseid v√µrreldes traditsiooniliste suurte keelemudelitega
7. Vali sobiv Phi variant konkreetsete rakenduste n√µuete ja riistvarapiirangute p√µhjal
8. Rakenda Phi mudeleid nii pilve- kui ka servarakendustes optimeeritud konfiguratsioonidega
9. Rakenda kvantiseerimis- ja optimeerimistehnikaid, et parandada Phi mudelite j√µudlust sihtseadmetel
10. Hinda kompromisse mudeli suuruse, j√µudluse ja v√µimekuse vahel Phi perekonnas

## Mis edasi

- [02: Qwen perekonna p√µhialused](02.QwenFamily.md)

---

**Lahti√ºtlus**:  
See dokument on t√µlgitud, kasutades AI t√µlketeenust [Co-op Translator](https://github.com/Azure/co-op-translator). Kuigi p√º√ºame tagada t√§psust, palun arvestage, et automaatsed t√µlked v√µivad sisaldada vigu v√µi ebat√§psusi. Algne dokument selle algkeeles tuleks lugeda autoriteetseks allikaks. Olulise teabe puhul on soovitatav kasutada professionaalset inimt√µlget. Me ei vastuta selle t√µlke kasutamisest tulenevate arusaamatuste v√µi valede t√µlgenduste eest.