<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "562ac0eae12d808c9f45fbb77eb5c84f",
  "translation_date": "2025-09-24T21:20:01+00:00",
  "source_file": "Module08/samples/04/README.md",
  "language_code": "br"
}
-->
# Exemplo 04: Aplicativos de Chat para ProduÃ§Ã£o com Chainlit

Um exemplo abrangente demonstrando vÃ¡rias abordagens para construir aplicativos de chat prontos para produÃ§Ã£o usando o Microsoft Foundry Local, com interfaces web modernas, respostas em streaming e tecnologias avanÃ§adas de navegador.

## O que estÃ¡ incluÃ­do

- **ðŸš€ Aplicativo de Chat Chainlit** (`app.py`): Aplicativo de chat pronto para produÃ§Ã£o com streaming
- **ðŸŒ DemonstraÃ§Ã£o WebGPU** (`webgpu-demo/`): InferÃªncia de IA baseada em navegador com aceleraÃ§Ã£o de hardware
- **ðŸŽ¨ IntegraÃ§Ã£o com Open WebUI** (`open-webui-guide.md`): Interface profissional semelhante ao ChatGPT
- **ðŸ“š Notebook Educacional** (`chainlit_app.ipynb`): Materiais interativos de aprendizado

## InÃ­cio RÃ¡pido

### 1. Aplicativo de Chat Chainlit

```cmd
# Navigate to Module08 directory
cd Module08

# Start your model
foundry model run phi-4-mini

# Run Chainlit app (using port 8080 to avoid conflicts)
chainlit run samples\04\app.py -w --port 8080
```
  
Abre em: `http://localhost:8080`

### 2. DemonstraÃ§Ã£o WebGPU no Navegador

```cmd
# Navigate to WebGPU demo
cd Module08\samples\04\webgpu-demo

# Serve the demo
python -m http.server 5173
```
  
Abre em: `http://localhost:5173`

### 3. ConfiguraÃ§Ã£o do Open WebUI

```cmd
# Run Open WebUI with Docker
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```
  
Abre em: `http://localhost:3000`

## PadrÃµes de Arquitetura

### Matriz de DecisÃ£o Local vs Nuvem

| CenÃ¡rio                  | RecomendaÃ§Ã£o         | Motivo                          |
|--------------------------|----------------------|---------------------------------|
| **Dados SensÃ­veis**      | ðŸ  Local (Foundry)   | Os dados nunca saem do dispositivo |
| **RaciocÃ­nio Complexo**  | â˜ï¸ Nuvem (Azure OpenAI) | Acesso a modelos maiores       |
| **Chat em Tempo Real**   | ðŸ  Local (Foundry)   | Menor latÃªncia, respostas mais rÃ¡pidas |
| **AnÃ¡lise de Documentos**| ðŸ”„ HÃ­brido           | Local para extraÃ§Ã£o, nuvem para anÃ¡lise |
| **GeraÃ§Ã£o de CÃ³digo**    | ðŸ  Local (Foundry)   | Privacidade + modelos especializados |
| **Tarefas de Pesquisa**  | â˜ï¸ Nuvem (Azure OpenAI) | Necessidade de base de conhecimento ampla |

### ComparaÃ§Ã£o de Tecnologias

| Tecnologia   | Caso de Uso                  | Vantagens                     | Desvantagens                |
|--------------|------------------------------|-------------------------------|-----------------------------|
| **Chainlit** | Desenvolvedores Python, prototipagem rÃ¡pida | ConfiguraÃ§Ã£o fÃ¡cil, suporte a streaming | Apenas Python              |
| **WebGPU**   | MÃ¡xima privacidade, cenÃ¡rios offline | Nativo do navegador, sem necessidade de servidor | Tamanho limitado de modelo |
| **Open WebUI** | ImplantaÃ§Ã£o em produÃ§Ã£o, equipes | Interface profissional, gerenciamento de usuÃ¡rios | Requer Docker              |

## PrÃ©-requisitos

- **Foundry Local**: Instalado e em execuÃ§Ã£o ([Download](https://aka.ms/foundry-local-installer))
- **Python**: VersÃ£o 3.10+ com ambiente virtual
- **Modelo**: Pelo menos um carregado (`foundry model run phi-4-mini`)
- **Navegador**: Chrome/Edge com suporte a WebGPU para demonstraÃ§Ãµes
- **Docker**: Para Open WebUI (opcional)

## InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. ConfiguraÃ§Ã£o do Ambiente Python

```cmd
# Navigate to Module08 directory
cd Module08

# Create and activate virtual environment
py -m venv .venv
.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```
  
### 2. ConfiguraÃ§Ã£o do Foundry Local

```cmd
# Verify Foundry Local installation
foundry --version

# Start the service
foundry service start

# Load a model
foundry model run phi-4-mini

# Verify model is running
foundry service ps
```
  

## Aplicativos de Exemplo

### Aplicativo de Chat Chainlit

**Recursos:**
- ðŸš€ **Streaming em Tempo Real**: Os tokens aparecem conforme sÃ£o gerados
- ðŸ›¡ï¸ **Tratamento de Erros Robusto**: DegradaÃ§Ã£o e recuperaÃ§Ã£o elegantes
- ðŸŽ¨ **Interface Moderna**: Interface de chat profissional pronta para uso
- ðŸ”§ **ConfiguraÃ§Ã£o FlexÃ­vel**: VariÃ¡veis de ambiente e detecÃ§Ã£o automÃ¡tica
- ðŸ“± **Design Responsivo**: Funciona em dispositivos desktop e mÃ³veis

**InÃ­cio RÃ¡pido:**  
```cmd
# Run with default settings (recommended)
chainlit run samples\04\app.py -w --port 8080

# Use specific model
set MODEL=qwen2.5-7b-instruct
chainlit run samples\04\app.py -w --port 8080

# Manual endpoint configuration
set BASE_URL=http://localhost:51211
set API_KEY=your-api-key
chainlit run samples\04\app.py -w --port 8080
```
  

### DemonstraÃ§Ã£o WebGPU no Navegador

**Recursos:**
- ðŸŒ **IA Nativa do Navegador**: Sem necessidade de servidor, executa inteiramente no navegador
- âš¡ **AceleraÃ§Ã£o WebGPU**: AceleraÃ§Ã£o de hardware quando disponÃ­vel
- ðŸ”’ **MÃ¡xima Privacidade**: Nenhum dado sai do seu dispositivo
- ðŸŽ¯ **InstalaÃ§Ã£o Zero**: Funciona em qualquer navegador compatÃ­vel
- ðŸ”„ **Fallback Elegante**: Reverte para CPU se WebGPU nÃ£o estiver disponÃ­vel

**ExecuÃ§Ã£o:**  
```cmd
cd samples\04\webgpu-demo
python -m http.server 5173
# Open http://localhost:5173
```
  

### IntegraÃ§Ã£o com Open WebUI

**Recursos:**
- ðŸŽ¨ **Interface Semelhante ao ChatGPT**: UI profissional e familiar
- ðŸ‘¥ **Suporte MultiusuÃ¡rio**: Contas de usuÃ¡rio e histÃ³rico de conversas
- ðŸ“ **Processamento de Arquivos**: Upload e anÃ¡lise de documentos
- ðŸ”„ **Troca de Modelos**: Troca fÃ¡cil entre diferentes modelos
- ðŸ³ **ImplantaÃ§Ã£o com Docker**: ConfiguraÃ§Ã£o pronta para produÃ§Ã£o em contÃªiner

**ConfiguraÃ§Ã£o RÃ¡pida:**  
```cmd
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```
  

## ReferÃªncia de ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

| VariÃ¡vel    | DescriÃ§Ã£o                  | PadrÃ£o         | Exemplo               |
|-------------|----------------------------|----------------|-----------------------|
| `MODEL`     | Alias do modelo a ser usado | `phi-4-mini`   | `qwen2.5-7b-instruct` |
| `BASE_URL`  | Endpoint do Foundry Local  | Detectado automaticamente | `http://localhost:51211` |
| `API_KEY`   | Chave de API (opcional para local) | `""`          | `sua-chave-de-api`    |

## SoluÃ§Ã£o de Problemas

### Problemas Comuns

**Aplicativo Chainlit:**

1. **ServiÃ§o nÃ£o disponÃ­vel:**  
   ```cmd
   # Check Foundry Local status
   foundry service status
   foundry service ps
   
   # Validate API endpoint (note: port 51211)
   curl http://localhost:51211/v1/models
   ```
  
2. **Conflitos de porta:**  
   ```cmd
   # Check what's using port 8080
   netstat -ano | findstr :8080
   
   # Use different port if needed
   chainlit run samples\04\app.py -w --port 3000
   ```
  
3. **Problemas no ambiente Python:**  
   ```cmd
   # Verify correct interpreter in VS Code
   # Ctrl+Shift+P â†’ Python: Select Interpreter
   # Choose: Module08/.venv/Scripts/python.exe
   
   # Reinstall dependencies
   pip install -r requirements.txt
   ```
  

**DemonstraÃ§Ã£o WebGPU:**

1. **WebGPU nÃ£o suportado:**
   - Atualize para Chrome/Edge 113+
   - Habilite WebGPU: `chrome://flags/#enable-unsafe-webgpu`
   - Verifique o status da GPU: `chrome://gpu`
   - A demonstraÃ§Ã£o reverterÃ¡ automaticamente para CPU

2. **Erros de carregamento de modelo:**
   - Certifique-se de que hÃ¡ conexÃ£o com a internet para download do modelo
   - Verifique o console do navegador para erros de CORS
   - Confirme que estÃ¡ servindo via HTTP (nÃ£o file://)

**Open WebUI:**

1. **ConexÃ£o recusada:**  
   ```cmd
   # Check Docker is running
   docker --version
   
   # Check container status
   docker ps | findstr open-webui
   
   # View container logs
   docker logs open-webui
   ```
  
2. **Modelos nÃ£o aparecem:**  
   ```cmd
   # Verify Foundry Local endpoint
   curl http://localhost:51211/v1/models
   
   # Restart Open WebUI
   docker restart open-webui
   ```
  

### Lista de ValidaÃ§Ã£o

```cmd
# âœ… 1. Foundry Local Setup
foundry --version                    # Should show version
foundry service status               # Should show "running"
foundry model list                   # Should show loaded models
curl http://localhost:51211/v1/models  # Should return JSON

# âœ… 2. Python Environment  
python --version                     # Should be 3.10+
pip list | findstr chainlit         # Should show chainlit package
pip list | findstr openai           # Should show openai package

# âœ… 3. Application Testing
chainlit run samples\04\app.py -w --port 8080  # Should open browser
# Test WebGPU demo at localhost:5173
# Test Open WebUI at localhost:3000
```
  

## Uso AvanÃ§ado

### OtimizaÃ§Ã£o de Desempenho

**Chainlit:**
- Use streaming para melhor percepÃ§Ã£o de desempenho
- Implemente pooling de conexÃµes para alta concorrÃªncia
- Cache de respostas de modelo para consultas repetidas
- Monitore o uso de memÃ³ria com histÃ³ricos de conversas grandes

**WebGPU:**
- Use WebGPU para mÃ¡xima privacidade e velocidade
- Implemente quantizaÃ§Ã£o de modelo para modelos menores
- Use Web Workers para processamento em segundo plano
- Cache modelos compilados no armazenamento do navegador

**Open WebUI:**
- Use volumes persistentes para histÃ³rico de conversas
- Configure limites de recursos para o contÃªiner Docker
- Implemente estratÃ©gias de backup para dados de usuÃ¡rios
- Configure proxy reverso para terminaÃ§Ã£o SSL

### PadrÃµes de IntegraÃ§Ã£o

**HÃ­brido Local/Nuvem:**  
```python
# Route based on complexity and privacy requirements
async def intelligent_routing(prompt: str, metadata: dict):
    if metadata.get("contains_pii"):
        return await foundry_local_completion(prompt)  # Privacy-sensitive
    elif len(prompt.split()) > 200:
        return await azure_openai_completion(prompt)   # Complex reasoning
    else:
        return await foundry_local_completion(prompt)  # Default local
```
  
**Pipeline Multi-Modal:**  
```python
# Combine different AI capabilities
async def analyze_document(file_path: str):
    # 1. OCR with WebGPU (browser-based)
    text = await webgpu_ocr(file_path)
    
    # 2. Analysis with Foundry Local (private)
    summary = await foundry_local_analyze(text)
    
    # 3. Enhancement with cloud (if needed)
    if summary.confidence < 0.8:
        summary = await azure_openai_enhance(summary)
    
    return summary
```
  

## ImplantaÃ§Ã£o em ProduÃ§Ã£o

### ConsideraÃ§Ãµes de SeguranÃ§a

- **Chaves de API**: Use variÃ¡veis de ambiente, nunca codifique diretamente
- **Rede**: Use HTTPS em produÃ§Ã£o, considere VPN para acesso da equipe
- **Controle de Acesso**: Implemente autenticaÃ§Ã£o para Open WebUI
- **Privacidade de Dados**: Audite quais dados permanecem locais e quais vÃ£o para a nuvem
- **AtualizaÃ§Ãµes**: Mantenha o Foundry Local e os contÃªineres atualizados

### Monitoramento e ManutenÃ§Ã£o

- **VerificaÃ§Ãµes de SaÃºde**: Implemente monitoramento de endpoints
- **Logs**: Centralize os logs de todos os componentes
- **MÃ©tricas**: Acompanhe tempos de resposta, taxas de erro e uso de recursos
- **Backup**: Backup regular dos dados de conversas e configuraÃ§Ãµes

## ReferÃªncias e Recursos

### DocumentaÃ§Ã£o
- [DocumentaÃ§Ã£o Chainlit](https://docs.chainlit.io/) - Guia completo do framework
- [DocumentaÃ§Ã£o Foundry Local](https://learn.microsoft.com/azure/ai-foundry/foundry-local/) - DocumentaÃ§Ã£o oficial da Microsoft
- [ONNX Runtime Web](https://onnxruntime.ai/docs/get-started/with-javascript/web.html) - IntegraÃ§Ã£o com WebGPU
- [DocumentaÃ§Ã£o Open WebUI](https://docs.openwebui.com/) - ConfiguraÃ§Ã£o avanÃ§ada

### Arquivos de Exemplo
- [`app.py`](../../../../../Module08/samples/04/app.py) - Aplicativo Chainlit para produÃ§Ã£o
- [`chainlit_app.ipynb`](./chainlit_app.ipynb) - Notebook educacional
- [`webgpu-demo/`](../../../../../Module08/samples/04/webgpu-demo) - InferÃªncia de IA baseada em navegador
- [`open-webui-guide.md`](./open-webui-guide.md) - ConfiguraÃ§Ã£o completa do Open WebUI

### Exemplos Relacionados
- [DocumentaÃ§Ã£o da SessÃ£o 4](../../04.CuttingEdgeModels.md) - Guia completo da sessÃ£o
- [Exemplos do Foundry Local](https://github.com/microsoft/foundry-local/tree/main/samples) - Exemplos oficiais

---

