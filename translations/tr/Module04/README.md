<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c0cb9f7bcff2bc170532d8870a891f38",
  "translation_date": "2025-09-17T23:29:58+00:00",
  "source_file": "Module04/README.md",
  "language_code": "tr"
}
-->
# BÃ¶lÃ¼m 04: Model Format DÃ¶nÃ¼ÅŸÃ¼mÃ¼ ve Kuantizasyon - BÃ¶lÃ¼m Genel BakÄ±ÅŸ

EdgeAI'nin ortaya Ã§Ä±kÄ±ÅŸÄ±, kaynaklarÄ± sÄ±nÄ±rlÄ± cihazlarda geliÅŸmiÅŸ makine Ã¶ÄŸrenimi yeteneklerini kullanabilmek iÃ§in model format dÃ¶nÃ¼ÅŸÃ¼mÃ¼ ve kuantizasyonu Ã¶nemli teknolojiler haline getirdi. Bu kapsamlÄ± bÃ¶lÃ¼m, edge senaryolarÄ±nda modelleri anlamak, uygulamak ve optimize etmek iÃ§in eksiksiz bir rehber sunar.

## ğŸ“š BÃ¶lÃ¼m YapÄ±sÄ± ve Ã–ÄŸrenme Yolu

Bu bÃ¶lÃ¼m, edge biliÅŸim iÃ§in model optimizasyonunu anlamak ve uygulamak adÄ±na birbirini tamamlayan altÄ± ilerleyici bÃ¶lÃ¼mden oluÅŸmaktadÄ±r:

---

## [BÃ¶lÃ¼m 1: Model Format DÃ¶nÃ¼ÅŸÃ¼mÃ¼ ve Kuantizasyon Temelleri](./01.Introduce.md)

### ğŸ¯ Genel BakÄ±ÅŸ
Bu temel bÃ¶lÃ¼m, edge biliÅŸim ortamlarÄ±nda model optimizasyonu iÃ§in teorik Ã§erÃ§eveyi oluÅŸturur. 1-bit ile 8-bit hassasiyet seviyeleri arasÄ±ndaki kuantizasyon sÄ±nÄ±rlarÄ±nÄ± ve Ã¶nemli format dÃ¶nÃ¼ÅŸÃ¼m stratejilerini kapsar.

**Ana Konular:**
- Hassasiyet sÄ±nÄ±flandÄ±rma Ã§erÃ§evesi (ultra dÃ¼ÅŸÃ¼k, dÃ¼ÅŸÃ¼k, orta hassasiyet)
- GGUF ve ONNX formatlarÄ±nÄ±n avantajlarÄ± ve kullanÄ±m alanlarÄ±
- Operasyonel verimlilik ve daÄŸÄ±tÄ±m esnekliÄŸi iÃ§in kuantizasyonun faydalarÄ±
- Performans karÅŸÄ±laÅŸtÄ±rmalarÄ± ve bellek kullanÄ±m analizleri

**Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ±:**
- Kuantizasyon sÄ±nÄ±rlarÄ±nÄ± ve sÄ±nÄ±flandÄ±rmalarÄ±nÄ± anlamak
- Uygun format dÃ¶nÃ¼ÅŸÃ¼m tekniklerini belirlemek
- Edge daÄŸÄ±tÄ±mÄ± iÃ§in ileri dÃ¼zey optimizasyon stratejilerini Ã¶ÄŸrenmek

---

## [BÃ¶lÃ¼m 2: Llama.cpp Uygulama Rehberi](./02.Llamacpp.md)

### ğŸ¯ Genel BakÄ±ÅŸ
Llama.cpp'nin uygulanmasÄ± iÃ§in kapsamlÄ± bir rehber. Bu gÃ¼Ã§lÃ¼ C++ Ã§erÃ§evesi, Ã§eÅŸitli donanÄ±m yapÄ±landÄ±rmalarÄ±nda minimum kurulumla verimli BÃ¼yÃ¼k Dil Modeli Ã§Ä±karÄ±mÄ± saÄŸlar.

**Ana Konular:**
- Windows, macOS ve Linux platformlarÄ±nda kurulum
- GGUF format dÃ¶nÃ¼ÅŸÃ¼mÃ¼ ve Ã§eÅŸitli kuantizasyon seviyeleri (Q2_K'den Q8_0'a)
- CUDA, Metal, OpenCL ve Vulkan ile donanÄ±m hÄ±zlandÄ±rma
- Python entegrasyonu ve Ã¼retim daÄŸÄ±tÄ±m stratejileri

**Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ±:**
- Platformlar arasÄ± kurulum ve kaynak koddan derlemeyi Ã¶ÄŸrenmek
- Model kuantizasyonu ve optimizasyon tekniklerini uygulamak
- REST API entegrasyonu ile sunucu modunda modelleri daÄŸÄ±tmak

---

## [BÃ¶lÃ¼m 3: Microsoft Olive Optimizasyon Paketi](./03.MicrosoftOlive.md)

### ğŸ¯ Genel BakÄ±ÅŸ
Microsoft Olive'nin keÅŸfi, Ã§eÅŸitli donanÄ±m platformlarÄ±nda kurumsal dÃ¼zeyde model daÄŸÄ±tÄ±mÄ± iÃ§in tasarlanmÄ±ÅŸ, 40'tan fazla yerleÅŸik optimizasyon bileÅŸenine sahip donanÄ±m odaklÄ± bir model optimizasyon araÃ§ seti.

**Ana Konular:**
- Dinamik ve statik kuantizasyon ile otomatik optimizasyon Ã¶zellikleri
- CPU, GPU ve NPU daÄŸÄ±tÄ±mÄ± iÃ§in donanÄ±m odaklÄ± zeka
- PopÃ¼ler model desteÄŸi (Llama, Phi, Qwen, Gemma) kutudan Ã§Ä±ktÄ±ÄŸÄ± gibi
- Azure ML ile entegrasyon ve Ã¼retim iÅŸ akÄ±ÅŸlarÄ±

**Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ±:**
- Ã‡eÅŸitli model mimarileri iÃ§in otomatik optimizasyonu kullanmak
- Platformlar arasÄ± daÄŸÄ±tÄ±m stratejilerini uygulamak
- Kurumsal dÃ¼zeyde optimizasyon iÅŸ akÄ±ÅŸlarÄ± oluÅŸturmak

---

## [BÃ¶lÃ¼m 4: OpenVINO AraÃ§ Seti Optimizasyon Paketi](./04.openvino.md)

### ğŸ¯ Genel BakÄ±ÅŸ
Intel'in OpenVINO araÃ§ setinin kapsamlÄ± bir incelemesi. Bu aÃ§Ä±k kaynaklÄ± platform, bulut, ÅŸirket iÃ§i ve edge ortamlarÄ±nda geliÅŸmiÅŸ Sinir AÄŸÄ± SÄ±kÄ±ÅŸtÄ±rma Ã‡erÃ§evesi (NNCF) yetenekleriyle performanslÄ± AI Ã§Ã¶zÃ¼mleri sunar.

**Ana Konular:**
- DonanÄ±m hÄ±zlandÄ±rma ile platformlar arasÄ± daÄŸÄ±tÄ±m (CPU, GPU, VPU, AI hÄ±zlandÄ±rÄ±cÄ±lar)
- GeliÅŸmiÅŸ kuantizasyon ve budama iÃ§in Sinir AÄŸÄ± SÄ±kÄ±ÅŸtÄ±rma Ã‡erÃ§evesi (NNCF)
- BÃ¼yÃ¼k dil modeli optimizasyonu ve daÄŸÄ±tÄ±mÄ± iÃ§in OpenVINO GenAI
- Kurumsal dÃ¼zeyde model sunucu yetenekleri ve Ã¶lÃ§eklenebilir daÄŸÄ±tÄ±m stratejileri

**Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ±:**
- OpenVINO model dÃ¶nÃ¼ÅŸÃ¼m ve optimizasyon iÅŸ akÄ±ÅŸlarÄ±nÄ± Ã¶ÄŸrenmek
- NNCF ile geliÅŸmiÅŸ kuantizasyon tekniklerini uygulamak
- Ã‡eÅŸitli donanÄ±m platformlarÄ±nda optimize edilmiÅŸ modelleri Model Sunucu ile daÄŸÄ±tmak

---

## [BÃ¶lÃ¼m 5: Apple MLX Ã‡erÃ§evesi Derinlemesine Ä°nceleme](./05.AppleMLX.md)

### ğŸ¯ Genel BakÄ±ÅŸ
Apple MLX'in kapsamlÄ± bir incelemesi. Bu devrim niteliÄŸindeki Ã§erÃ§eve, Apple Silicon Ã¼zerinde verimli makine Ã¶ÄŸrenimi iÃ§in Ã¶zel olarak tasarlanmÄ±ÅŸtÄ±r ve BÃ¼yÃ¼k Dil Modeli yetenekleri ile yerel daÄŸÄ±tÄ±ma odaklanÄ±r.

**Ana Konular:**
- BirleÅŸik bellek mimarisi avantajlarÄ± ve Metal Performans Shader'larÄ±
- LLaMA, Mistral, Phi-3, Qwen ve Code Llama modelleri iÃ§in destek
- Verimli model Ã¶zelleÅŸtirme iÃ§in LoRA ince ayarÄ±
- Hugging Face entegrasyonu ve kuantizasyon desteÄŸi (4-bit ve 8-bit)

**Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ±:**
- Apple Silicon optimizasyonunu LLM daÄŸÄ±tÄ±mÄ± iÃ§in Ã¶ÄŸrenmek
- Ä°nce ayar ve model Ã¶zelleÅŸtirme tekniklerini uygulamak
- GeliÅŸmiÅŸ gizlilik Ã¶zellikleriyle kurumsal AI uygulamalarÄ± oluÅŸturmak

---

## [BÃ¶lÃ¼m 6: Edge AI GeliÅŸtirme Ä°ÅŸ AkÄ±ÅŸÄ± Sentezi](./06.workflow-synthesis.md)

### ğŸ¯ Genel BakÄ±ÅŸ
TÃ¼m optimizasyon Ã§erÃ§evelerinin birleÅŸik iÅŸ akÄ±ÅŸlarÄ±na, karar matrislerine ve Ã§eÅŸitli platformlar ve kullanÄ±m senaryolarÄ± iÃ§in Ã¼retime hazÄ±r en iyi uygulamalara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesinin kapsamlÄ± bir sentezi.

**Ana Konular:**
- Birden fazla optimizasyon Ã§erÃ§evesini entegre eden birleÅŸik iÅŸ akÄ±ÅŸÄ± mimarisi
- Ã‡erÃ§eve seÃ§imi karar aÄŸaÃ§larÄ± ve performans Ã¶dÃ¼nleÅŸim analizi
- Ãœretim hazÄ±r olma doÄŸrulamasÄ± ve kapsamlÄ± daÄŸÄ±tÄ±m stratejileri
- GeliÅŸen donanÄ±m ve model mimarileri iÃ§in geleceÄŸe yÃ¶nelik stratejiler

**Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ±:**
- Gereksinimlere ve kÄ±sÄ±tlamalara dayalÄ± sistematik Ã§erÃ§eve seÃ§imini Ã¶ÄŸrenmek
- KapsamlÄ± izleme ile Ã¼retim dÃ¼zeyinde Edge AI iÅŸ akÄ±ÅŸlarÄ± uygulamak
- GeliÅŸen teknolojiler ve gereksinimlerle uyumlu iÅŸ akÄ±ÅŸlarÄ± tasarlamak

---

## ğŸ¯ BÃ¶lÃ¼m Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ±

Bu kapsamlÄ± bÃ¶lÃ¼mÃ¼ tamamladÄ±ktan sonra okuyucular ÅŸunlarÄ± baÅŸaracaktÄ±r:

### **Teknik UzmanlÄ±k**
- Kuantizasyon sÄ±nÄ±rlarÄ±nÄ± ve pratik uygulamalarÄ±nÄ± derinlemesine anlamak
- Birden fazla optimizasyon Ã§erÃ§evesiyle uygulamalÄ± deneyim
- Edge biliÅŸim ortamlarÄ± iÃ§in Ã¼retim daÄŸÄ±tÄ±m becerileri

### **Stratejik AnlayÄ±ÅŸ**
- DonanÄ±m odaklÄ± optimizasyon seÃ§imi yetenekleri
- Performans Ã¶dÃ¼nleÅŸimleri hakkÄ±nda bilinÃ§li karar verme
- Kurumsal dÃ¼zeyde daÄŸÄ±tÄ±m ve izleme stratejileri

### **Performans KarÅŸÄ±laÅŸtÄ±rmalarÄ±**

| Ã‡erÃ§eve     | Kuantizasyon | Bellek KullanÄ±mÄ± | HÄ±z ArtÄ±ÅŸÄ±       | KullanÄ±m AlanÄ±               |
|-------------|--------------|------------------|------------------|------------------------------|
| Llama.cpp   | Q4_K_M       | ~4GB            | 2-3x            | Platformlar arasÄ± daÄŸÄ±tÄ±m    |
| Olive       | INT4         | %60-75 azalma   | 2-6x            | Kurumsal iÅŸ akÄ±ÅŸlarÄ±         |
| OpenVINO    | INT8/INT4    | %50-75 azalma   | 2-5x            | Intel donanÄ±m optimizasyonu  |
| MLX         | 4-bit        | ~4GB            | 2-4x            | Apple Silicon optimizasyonu  |

## ğŸš€ Sonraki AdÄ±mlar ve Ä°leri Uygulamalar

Bu bÃ¶lÃ¼m ÅŸunlar iÃ§in eksiksiz bir temel saÄŸlar:
- Belirli alanlar iÃ§in Ã¶zel model geliÅŸtirme
- Edge AI optimizasyonunda araÅŸtÄ±rma
- Ticari AI uygulama geliÅŸtirme
- BÃ¼yÃ¼k Ã¶lÃ§ekli kurumsal Edge AI daÄŸÄ±tÄ±mlarÄ±

Bu altÄ± bÃ¶lÃ¼mden elde edilen bilgiler, hÄ±zla geliÅŸen edge AI model optimizasyonu ve daÄŸÄ±tÄ±mÄ± alanÄ±nda gezinmek iÃ§in kapsamlÄ± bir araÃ§ seti sunar.

---

**Feragatname**:  
Bu belge, AI Ã§eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±k iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan kaynaklanan yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalar iÃ§in sorumluluk kabul etmiyoruz.