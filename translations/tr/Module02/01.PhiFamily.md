<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20892f7994d9e5d2473ad19dfa93cf6d",
  "translation_date": "2025-09-17T22:43:19+00:00",
  "source_file": "Module02/01.PhiFamily.md",
  "language_code": "tr"
}
-->
# BÃ¶lÃ¼m 1: Microsoft Phi Model Ailesi Temelleri

Microsoft Phi model ailesi, yapay zekada bir paradigma deÄŸiÅŸimini temsil eder ve kompakt, verimli modellerin, geleneksel bÃ¼yÃ¼k dil modellerine kÄ±yasla Ã§ok daha az kaynak tÃ¼ketirken olaÄŸanÃ¼stÃ¼ performans elde edebileceÄŸini gÃ¶sterir. Phi ailesinin, Ã§eÅŸitli gÃ¶revlerde yÃ¼ksek performansÄ± korurken azaltÄ±lmÄ±ÅŸ hesaplama gereksinimleriyle gÃ¼Ã§lÃ¼ yapay zeka yeteneklerini nasÄ±l saÄŸladÄ±ÄŸÄ±nÄ± anlamak Ã¶nemlidir.

## GeliÅŸtiriciler iÃ§in Kaynaklar

### Azure AI Foundry Model KataloÄŸu
Phi model ailesi (Phi-silica hariÃ§), [Azure AI Foundry Model KataloÄŸu](https://ai.azure.com/explore/models?q=phi) Ã¼zerinden eriÅŸilebilir. Bu katalog, geliÅŸtiricilerin bu modelleri kolayca eriÅŸim, ince ayar ve uygulamalarÄ±nda daÄŸÄ±tÄ±m yapmalarÄ±nÄ± saÄŸlar. Katalog, farklÄ± Phi varyantlarÄ±nÄ± denemek ve projelerinize entegre etmek iÃ§in pratik bir yol sunar.

### Azure AI Foundry
Phi modellerini [Azure AI Foundry](https://ai.azure.com) kullanarak daÄŸÄ±tabilir ve deneyebilirsiniz. Bu platform, minimum kurulumla yapay zeka Ã§Ã¶zÃ¼mleri oluÅŸturmak, test etmek ve daÄŸÄ±tmak iÃ§in kapsamlÄ± bir ortam saÄŸlar.

### Foundry Local
Yerel geliÅŸtirme ve daÄŸÄ±tÄ±m iÃ§in [Microsoft Foundry Local](https://github.com/microsoft/foundry-local) platformunu inceleyebilirsiniz. Bu araÃ§, Phi modellerini optimize edilmiÅŸ yapÄ±landÄ±rmalarla geliÅŸtirme makinenizde Ã§alÄ±ÅŸtÄ±rmanÄ±za olanak tanÄ±r.

### DokÃ¼mantasyon KaynaklarÄ±
- [Microsoft Research: Phi Model Teknik RaporlarÄ±](https://ai.azure.com/labs/projects/phi-4)
- [Phi Cookbook](https://aka.ms/phicookbook)

## GiriÅŸ

Bu derste, Microsoft'un Phi model ailesini ve temel kavramlarÄ±nÄ± inceleyeceÄŸiz. Phi ailesinin evrimini, Phi modellerini verimli kÄ±lan yenilikÃ§i eÄŸitim yÃ¶ntemlerini, ailedeki ana varyantlarÄ± ve farklÄ± senaryolardaki pratik uygulamalarÄ± ele alacaÄŸÄ±z.

## Ã–ÄŸrenme Hedefleri

Bu dersin sonunda ÅŸunlarÄ± yapabileceksiniz:

- Microsoft'un Phi model ailesinin tasarÄ±m felsefesini ve evrimini anlayÄ±n.
- Phi modellerinin daha az parametreyle yÃ¼ksek performans elde etmesini saÄŸlayan temel yenilikleri tanÄ±mlayÄ±n.
- FarklÄ± Phi model varyantlarÄ±nÄ±n avantajlarÄ±nÄ± ve sÄ±nÄ±rlamalarÄ±nÄ± tanÄ±yÄ±n.
- GerÃ§ek dÃ¼nya senaryolarÄ± iÃ§in uygun varyantlarÄ± seÃ§mek Ã¼zere Phi modelleri hakkÄ±ndaki bilgilerinizi uygulayÄ±n.

## Geleneksel Yapay Zeka Model ParadigmasÄ±nÄ± Anlamak

Geleneksel olarak, doÄŸal dil iÅŸleme alanÄ±nda yÃ¼ksek performans elde etmek, milyarlarca veya yÃ¼z milyarlarca parametreye sahip devasa dil modelleri gerektiriyordu. KuruluÅŸlar genellikle bu modelleri gÃ¼Ã§lÃ¼ GPU kÃ¼melerinde Ã§alÄ±ÅŸtÄ±rÄ±r ve yeteneklerine API arayÃ¼zleri veya Ã¶zel donanÄ±m altyapÄ±sÄ± aracÄ±lÄ±ÄŸÄ±yla eriÅŸir.

Bu yaklaÅŸÄ±m birÃ§ok uygulama iÃ§in iyi Ã§alÄ±ÅŸsa da, pratik daÄŸÄ±tÄ±m senaryolarÄ±nda doÄŸal sÄ±nÄ±rlamalarÄ± vardÄ±r. Geleneksel yÃ¶ntem, bÃ¼yÃ¼k hesaplama kaynaklarÄ±, bÃ¼yÃ¼k miktarda bellek ve Ã¶nemli enerji tÃ¼ketimi gerektiren modellerin kullanÄ±lmasÄ±nÄ± iÃ§erir. Bu yaklaÅŸÄ±m, en son teknolojilere eriÅŸim saÄŸlasa da pahalÄ± donanÄ±ma baÄŸÄ±mlÄ±lÄ±k yaratÄ±r, yÃ¼ksek operasyonel maliyetler getirir ve daÄŸÄ±tÄ±m esnekliÄŸini sÄ±nÄ±rlar.

## Verimli Yapay Zeka DaÄŸÄ±tÄ±mÄ±nÄ±n ZorluklarÄ±

Daha verimli yapay zeka ihtiyacÄ±, Ã§eÅŸitli senaryolarda giderek daha Ã¶nemli hale gelmiÅŸtir. Ã–rneÄŸin, gizlilik nedenleriyle yerel daÄŸÄ±tÄ±m gerektiren uygulamalar, bulut API maliyetlerinin engelleyici olduÄŸu maliyet duyarlÄ± uygulamalar, sÄ±nÄ±rlÄ± donanÄ±m kaynaklarÄ±na sahip uÃ§ biliÅŸim senaryolarÄ± veya gecikmenin kritik olduÄŸu gerÃ§ek zamanlÄ± uygulamalar.

### Temel DaÄŸÄ±tÄ±m KÄ±sÄ±tlamalarÄ±

Geleneksel bÃ¼yÃ¼k model daÄŸÄ±tÄ±mlarÄ±, pratik uygulanabilirliklerini sÄ±nÄ±rlayan birkaÃ§ temel kÄ±sÄ±tlamayla karÅŸÄ± karÅŸÄ±yadÄ±r:

- **Maliyet SÄ±nÄ±rlamalarÄ±**: YÃ¼ksek hesaplama maliyetleri, sÃ¼rekli daÄŸÄ±tÄ±mÄ± birÃ§ok kuruluÅŸ iÃ§in pahalÄ± hale getirir.
- **Kaynak KÄ±sÄ±tlamalarÄ±**: YÃ¼ksek kaliteli GPU altyapÄ±sÄ±na sÄ±nÄ±rlÄ± eriÅŸim, daÄŸÄ±tÄ±m seÃ§eneklerini sÄ±nÄ±rlar.
- **Gizlilik Gereksinimleri**: Hassas uygulamalar, veri gizliliÄŸini korumak iÃ§in yerel iÅŸlem gerektirir.
- **Gecikme Hassasiyeti**: GerÃ§ek zamanlÄ± uygulamalar, bulut Ã¼zerinden veri alÄ±ÅŸveriÅŸi gecikmeleri olmadan anÄ±nda yanÄ±tlar gerektirir.

## Microsoft Phi Model Felsefesi

Microsoft Phi model ailesi, verimlilik ve pratik daÄŸÄ±tÄ±mÄ± Ã¶nceliklendirirken gÃ¼Ã§lÃ¼ performans Ã¶zelliklerini koruyan bir yapay zeka model tasarÄ±m felsefesinde temel bir deÄŸiÅŸimi temsil eder. Phi modelleri, yenilikÃ§i mimariler, yÃ¼ksek kaliteli eÄŸitim yÃ¶ntemleri ve Ã¶zel optimizasyon teknikleri sayesinde bu hedefe ulaÅŸÄ±r.

Phi ailesi, standart donanÄ±mda anlamlÄ± yapay zeka yetenekleri saÄŸlarken, parametre baÅŸÄ±na performansÄ± en Ã¼st dÃ¼zeye Ã§Ä±karmak iÃ§in tasarlanmÄ±ÅŸ Ã§eÅŸitli yaklaÅŸÄ±mlarÄ± kapsar. AmaÃ§, rekabetÃ§i performansÄ± korurken hesaplama gereksinimlerini, bellek kullanÄ±mÄ±nÄ± ve operasyonel maliyetleri Ã¶nemli Ã¶lÃ§Ã¼de azaltmaktÄ±r.

### Temel Phi TasarÄ±m Ä°lkeleri

Phi modelleri, geleneksel bÃ¼yÃ¼k dil modellerinden farklÄ± kÄ±lan birkaÃ§ temel ilkeye dayanÄ±r:

- **Ã–ncelik Verimlilik**: Mutlak Ã¶lÃ§ek yerine parametre baÅŸÄ±na maksimum performans iÃ§in optimize edilmiÅŸtir.
- **Kaliteli EÄŸitim**: BÃ¼yÃ¼k veri setleri yerine yÃ¼ksek kaliteli, Ã¶zenle seÃ§ilmiÅŸ eÄŸitim verilerine odaklanÄ±r.
- **DaÄŸÄ±tÄ±m EsnekliÄŸi**: Ã‡eÅŸitli donanÄ±m yapÄ±landÄ±rmalarÄ±nda etkili bir ÅŸekilde Ã§alÄ±ÅŸacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r.
- **Ã–zel Yetkinlikler**: Belirli gÃ¶revler veya alanlar iÃ§in optimize edilerek etkinliÄŸi en Ã¼st dÃ¼zeye Ã§Ä±karÄ±r.

## Phi Ailesini EtkinleÅŸtiren Temel Teknolojiler

### "Ders KitabÄ±" EÄŸitim YaklaÅŸÄ±mÄ±

Phi ailesinin en devrimci yÃ¶nlerinden biri, "ders kitabÄ± kalitesinde" eÄŸitim metodolojisidir. Phi modelleri, bÃ¼yÃ¼k miktarda filtrelenmemiÅŸ internet verisi yerine, akÄ±l yÃ¼rÃ¼tme, matematik, kodlama ve genel bilgiyi etkili bir ÅŸekilde Ã¶ÄŸretmek iÃ§in tasarlanmÄ±ÅŸ Ã¶zenle seÃ§ilmiÅŸ, yÃ¼ksek kaliteli eÄŸitim iÃ§eriÄŸi kullanÄ±r.

Bu yaklaÅŸÄ±m, yÃ¼ksek kaliteli ders kitaplarÄ± ve akademik materyalleri yansÄ±tan sentetik eÄŸitim iÃ§eriÄŸi oluÅŸturarak Ã§alÄ±ÅŸÄ±r. EÄŸitim verileri, pedagojik olarak saÄŸlam olacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r ve aÃ§Ä±k aÃ§Ä±klamalar, adÄ±m adÄ±m akÄ±l yÃ¼rÃ¼tme ve yapÄ±landÄ±rÄ±lmÄ±ÅŸ bilgi sunumuna odaklanÄ±r.

### GeliÅŸmiÅŸ AkÄ±l YÃ¼rÃ¼tme EÄŸitimi

Son Phi modelleri, karmaÅŸÄ±k Ã§ok adÄ±mlÄ± problem Ã§Ã¶zmeyi mÃ¼mkÃ¼n kÄ±lan sofistike akÄ±l yÃ¼rÃ¼tme eÄŸitim metodolojilerini iÃ§erir. Bu teknikler ÅŸunlarÄ± iÃ§erir:

**DÃ¼ÅŸÃ¼nce Zinciri EÄŸitimi**: Modeller, karmaÅŸÄ±k problemleri ara akÄ±l yÃ¼rÃ¼tme adÄ±mlarÄ±na ayÄ±rmayÄ± Ã¶ÄŸrenir, bu da problem Ã§Ã¶zme sÃ¼recini daha ÅŸeffaf ve gÃ¼venilir hale getirir.

**Ã‡Ä±karÄ±m ZamanÄ± Ã–lÃ§eklendirme**: Modeller, yanÄ±t oluÅŸturma sÄ±rasÄ±nda ek hesaplama kaynaklarÄ±nÄ± kullanarak ayrÄ±ntÄ±lÄ± akÄ±l yÃ¼rÃ¼tme zincirleri oluÅŸturur ve doÄŸruluÄŸu artÄ±rÄ±r.

**Yetkinlik SÄ±nÄ±rÄ±nda EÄŸitim**: EÄŸitim verileri, modelin mevcut yeteneklerinin sÄ±nÄ±rÄ±nda zorluklar yaratacak ÅŸekilde seÃ§ilir ve karmaÅŸÄ±k akÄ±l yÃ¼rÃ¼tme kalÄ±plarÄ±nÄ± Ã¶ÄŸrenmeyi teÅŸvik eder.

### Mimari Yenilikler

Phi ailesi, Ã¶zellikle verimlilik iÃ§in tasarlanmÄ±ÅŸ birkaÃ§ mimari optimizasyon iÃ§erir:

**Parametre VerimliliÄŸi**: Modeldeki her bir parametrenin etkisini en Ã¼st dÃ¼zeye Ã§Ä±karan dikkatli mimari seÃ§imler.

**Ã‡oklu Mod Entegrasyonu**: Metin, gÃ¶rsel ve konuÅŸma iÅŸleme yeteneklerinin kompakt mimariler iÃ§inde verimli entegrasyonu.

**DonanÄ±m Optimizasyonu**: Belirli donanÄ±m platformlarÄ± ve daÄŸÄ±tÄ±m senaryolarÄ± iÃ§in optimize edilmiÅŸ Ã¶zel varyantlar.

## Phi Modelleri iÃ§in DonanÄ±m Optimizasyonu

Modern daÄŸÄ±tÄ±m ortamlarÄ±, Phi modellerinin Ã§eÅŸitli donanÄ±m yapÄ±landÄ±rmalarÄ±nda saÄŸladÄ±ÄŸÄ± verimlilikten faydalanÄ±r:

### CPU Optimizasyonlu DaÄŸÄ±tÄ±m

Phi modelleri, yalnÄ±zca CPU donanÄ±mÄ±nda etkili bir ÅŸekilde Ã§alÄ±ÅŸacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r. Bu, Ã¶zel yapay zeka hÄ±zlandÄ±rÄ±cÄ±larÄ± gerektirmeden standart bilgi iÅŸlem altyapÄ±sÄ±nda daÄŸÄ±tÄ±mÄ± mÃ¼mkÃ¼n kÄ±lar.

### GPU HÄ±zlandÄ±rma

GÃ¼Ã§lÃ¼ GPU'lara ihtiyaÃ§ duymasa da, Phi modelleri mevcut GPU kaynaklarÄ±nÄ± performansÄ± artÄ±rmak iÃ§in kullanabilir ve daÄŸÄ±tÄ±m yapÄ±landÄ±rmalarÄ±nda esneklik saÄŸlar.

### UÃ§ Cihaz Entegrasyonu

Phi-3-Silica gibi Ã¶zel varyantlar, belirli uÃ§ biliÅŸim platformlarÄ± iÃ§in optimize edilmiÅŸtir ve yalnÄ±zca 1.5W gÃ¼Ã§ tÃ¼ketimiyle saniyede 650 token gibi dikkat Ã§ekici verimlilik metriklerine ulaÅŸÄ±r.

## Phi Model Ailesinin FaydalarÄ±

### Maliyet VerimliliÄŸi

Phi modelleri, rekabetÃ§i performansÄ± korurken Ã¶nemli Ã¶lÃ§Ã¼de daha az hesaplama altyapÄ±sÄ± gerektirerek operasyonel maliyetleri Ã¶nemli Ã¶lÃ§Ã¼de azaltÄ±r. Bu, yapay zekayÄ± sÄ±nÄ±rlÄ± bÃ¼tÃ§elere sahip kuruluÅŸlar veya yÃ¼ksek hacimli uygulamalar iÃ§in eriÅŸilebilir hale getirir.

### DaÄŸÄ±tÄ±m EsnekliÄŸi

Phi modellerinin verimliliÄŸi, kiÅŸisel dizÃ¼stÃ¼ bilgisayarlardan kurumsal sunuculara kadar geniÅŸ bir donanÄ±m yapÄ±landÄ±rmasÄ±nda daÄŸÄ±tÄ±mÄ± mÃ¼mkÃ¼n kÄ±lar ve kuruluÅŸlara yapay zeka altyapÄ±sÄ± seÃ§imlerinde daha fazla esneklik saÄŸlar.

### Gizlilik ve GÃ¼venlik

Phi modellerinin verimliliÄŸi, gizlilik hassasiyeti olan uygulamalar iÃ§in yerel daÄŸÄ±tÄ±mÄ± mÃ¼mkÃ¼n kÄ±lar. Bu, hassas verilerin kuruluÅŸun kontrolÃ¼nden Ã§Ä±kmadan gÃ¼Ã§lÃ¼ yapay zeka yetenekleri saÄŸlamasÄ±nÄ± garanti eder.

### GerÃ§ek ZamanlÄ± Performans

AzaltÄ±lmÄ±ÅŸ hesaplama gereksinimleri, daha hÄ±zlÄ± Ã§Ä±karÄ±m sÃ¼relerine dÃ¶nÃ¼ÅŸÃ¼r ve gerÃ§ek zamanlÄ± uygulamalarda anÄ±nda yanÄ±tlar saÄŸlar. Bu, yapay zeka yeteneklerinin kalitesinden Ã¶dÃ¼n vermeden gerÃ§ekleÅŸtirilir.

### EriÅŸilebilir Yapay Zeka

Phi modelleri, yapay zeka daÄŸÄ±tÄ±mÄ±ndaki engelleri azaltarak, geliÅŸmiÅŸ yapay zeka yeteneklerini sÄ±nÄ±rlÄ± kaynaklara sahip kuruluÅŸlara eriÅŸilebilir hale getirir. Bu, kÃ¼Ã§Ã¼k ekiplerin ve bireysel geliÅŸtiricilerin sofistike dil anlayÄ±ÅŸÄ±ndan faydalanmasÄ±nÄ± saÄŸlar.

## Pratik Ã–rnekler ve KullanÄ±m SenaryolarÄ±

Teknik evrime geÃ§meden Ã¶nce, Phi modellerinin neler yapabileceÄŸini gÃ¶steren somut Ã¶rnekleri inceleyelim:

### Matematiksel AkÄ±l YÃ¼rÃ¼tme Ã–rneÄŸi

Phi-4-mini-reasoning, adÄ±m adÄ±m matematiksel problem Ã§Ã¶zmede mÃ¼kemmeldir. Ã–rneÄŸin, "3*x^2+4*x+5=1 nasÄ±l Ã§Ã¶zÃ¼lÃ¼r?" sorulduÄŸunda, model ayrÄ±ntÄ±lÄ± akÄ±l yÃ¼rÃ¼tme adÄ±mlarÄ± saÄŸlar:

```
<|system|>Your name is Phi, an AI math expert developed by Microsoft.<|end|>
<|user|>How to solve 3*x^2+4*x+5=1?<|end|>
<|assistant|>
I need to solve the quadratic equation 3xÂ² + 4x + 5 = 1.

First, let me rearrange this to standard form:
3xÂ² + 4x + 5 = 1
3xÂ² + 4x + 5 - 1 = 0  
3xÂ² + 4x + 4 = 0

Now I can use the quadratic formula: x = (-b Â± âˆš(bÂ² - 4ac)) / (2a)
Where a = 3, b = 4, c = 4

Let me calculate the discriminant:
bÂ² - 4ac = 4Â² - 4(3)(4) = 16 - 48 = -32

Since the discriminant is negative (-32), this equation has no real solutions.
The solutions are complex: x = (-4 Â± âˆš(-32)) / 6 = (-4 Â± 4iâˆš2) / 6 = (-2 Â± 2iâˆš2) / 3
```

### Ã‡ok Dilli Destek Ã–rneÄŸi

Phi-3.5-mini-instruct, Ã§eÅŸitli dillerde gÃ¼Ã§lÃ¼ Ã§ok dilli yetenekler sergiler. Ä°ÅŸte bir Ã¶rnek istem formatÄ±:

```
<|system|>You are a helpful assistant.<|end|>
<|user|>How to explain Internet for a medieval knight?<|end|>
<|assistant|>
Imagine, good sir knight, a vast network of invisible roads that span the entire realm and beyond. The Internet is like a magical system of messenger birds that can carry any message - be it text, images, or even moving pictures - instantly to any castle, village, or hamlet in the world.

Think of it as if every scribe's work could be copied and shared with thousands of people simultaneously, as if you could visit any library in any kingdom without leaving your chambers, or as if you could hold council with knights from distant lands as if they were sitting at your very table.

This "Internet" allows people to:
- Send messages faster than the swiftest horse
- Access knowledge from scholars across all kingdoms
- Trade goods without traveling to distant markets
- Share stories and news from lands you've never seen

'Tis like having a thousand scribes, merchants, and storytellers all working for you at once, good knight!
```

### Ã‡oklu Mod Yetkinlikleri Ã–rneÄŸi

Phi-4-multimodal, metin, gÃ¶rseller ve konuÅŸmayÄ± aynÄ± anda iÅŸleyebilir. Ä°ÅŸte bazÄ± pratik uygulamalar:

**Sesli Girdi ile Seyahat Planlama:**
Phi-4 Multimodal'Ä±n konuÅŸulan dili analiz ederek Seattle'a bir gezi planlamaya nasÄ±l yardÄ±mcÄ± olduÄŸunu izleyin. Bu, geliÅŸmiÅŸ ses iÅŸleme ve Ã¶neri yeteneklerini gÃ¶sterir.

**GÃ¶rsellerden Matematiksel Problem Ã‡Ã¶zme:**
Phi-4 Multimodal'Ä±n gÃ¶rsel girdilerde sunulan denklemleri iÅŸleyip Ã§Ã¶zerek karmaÅŸÄ±k matematiksel problemleri nasÄ±l ele aldÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼n.

**Fonksiyon Ã‡aÄŸrÄ±sÄ± Ã–rneÄŸi:**
Fonksiyon Ã§aÄŸrÄ±sÄ± ile Phi-4-mini ve Phi-4-multimodal, metin iÅŸleme yeteneklerini arama motorlarÄ±, Ã§eÅŸitli araÃ§larla baÄŸlantÄ± kurma ve daha fazlasÄ±nÄ± entegre ederek geniÅŸletebilir. Ã–rneÄŸin, model Phi-4-mini aracÄ±lÄ±ÄŸÄ±yla Premier League maÃ§ bilgilerini alabilir ve harici veri kaynaklarÄ±yla sorunsuz bir ÅŸekilde etkileÅŸim kurma yeteneÄŸini sergiler.

### Kod Ãœretimi Ã–rneÄŸi

Phi-4-multimodal, hem gÃ¶rsel iÃ§erik hem de saÄŸlanan istemlere dayalÄ± olarak yapÄ±landÄ±rÄ±lmÄ±ÅŸ proje kodu Ã¼retebilir. Ä°ÅŸte bu pratik iÅŸ akÄ±ÅŸÄ±nÄ±n bir Ã¶rneÄŸi:

1. Bir tel Ã§erÃ§eve veya tasarÄ±m gÃ¶rÃ¼ntÃ¼sÃ¼ yÃ¼kleyin
2. Proje gereksinimleri hakkÄ±nda baÄŸlam saÄŸlayÄ±n
3. Model, eksiksiz ve iÅŸlevsel kod yapÄ±larÄ± oluÅŸturur
4. Kod, belirli Ã§erÃ§eveler veya diller temelinde Ã¶zelleÅŸtirilebilir

### UÃ§ DaÄŸÄ±tÄ±m Ã–rneÄŸi

Kuantize edilmiÅŸ modeli uÃ§ cihazlarda daÄŸÄ±tabiliriz. Microsoft Olive ve ONNX GenAI Runtime'Ä± birleÅŸtirerek Phi-4-mini'yi Windows, iPhone, Android ve diÄŸer cihazlarda daÄŸÄ±tabiliriz. Bu, iPhone 12 Pro'da Ã§alÄ±ÅŸan bir Ã¶rnektir.

DaÄŸÄ±tÄ±m sÃ¼reci ÅŸunlarÄ± iÃ§erir:
- Mobil optimizasyon iÃ§in model kuantizasyonu
- Ã‡apraz platform uyumluluÄŸu iÃ§in ONNX Ã§alÄ±ÅŸma zamanÄ± entegrasyonu
- Ä°nternet baÄŸlantÄ±sÄ± olmadan yerel Ã§Ä±karÄ±m
- Minimum gÃ¼Ã§ tÃ¼ketimiyle gerÃ§ek zamanlÄ± performans

## Phi Ailesinin Evrimi

### Phi-1 ve Phi-2: Temel Modeller

Erken Phi modelleri, yÃ¼ksek kaliteli eÄŸitim verileri ve verimli mimarilerle ilgili temel ilkeleri oluÅŸturdu:

- **Phi-1 (1.3B parametre)**: Temel dil anlayÄ±ÅŸÄ± ve kod Ã¼retimi iÃ§in Ã¶zenle seÃ§ilmiÅŸ eÄŸitim verisi konseptini tanÄ±ttÄ±.
- **Phi-2 (2.7B parametre)**: Sentetik NLP verileri ve dikkatlice filtrelenmiÅŸ web iÃ§eriÄŸi aracÄ±lÄ±ÄŸÄ±yla akÄ±l yÃ¼rÃ¼tme yeteneklerini geliÅŸtirdi.

### Phi-3 Ailesi: Ana AkÄ±m Benimseme

Phi-3 serisi, birden fazla Ã¶zel varyantla SLM yeteneklerinde bir atÄ±lÄ±m saÄŸladÄ±:

- **Phi-3-mini (3.8B parametre)**: Ä°ki katÄ± bÃ¼yÃ¼klÃ¼ÄŸÃ¼ndeki modelleri geride bÄ±rakan olaÄŸanÃ¼stÃ¼ verimlilikle genel dil gÃ¶revleri.
- **Phi-3-small (7B parametre)**: Ã‡eÅŸitli Ã¶lÃ§Ã¼tlerde GPT-3.5 Turbo'yu geride bÄ±rakan geliÅŸmiÅŸ performans.
- **Phi-3-medium (14B parametre)**: Gemini 1.0 Pro'yu geride bÄ±rakan kurumsal dÃ¼zeyde performans.
- **Phi-3-vision (4.2B parametre)**: GÃ¶rsel ve metin iÅŸleme iÃ§in Ã§oklu mod yetenekleri.
- **Phi-3-Silica (3.3B parametre)**: Windows 11 yerleÅŸik daÄŸÄ±tÄ±mÄ± iÃ§in Ã¶zel optimizasyon.

### Phi-4 Ailesi: GeliÅŸmiÅŸ AkÄ±l YÃ¼rÃ¼tme

Son nesil, akÄ±l yÃ¼rÃ¼tme yeteneklerinin sÄ±nÄ±rlarÄ±nÄ± zorlar:

- **Phi-4 (14B parametre)**: Ã–zellikle matematikte karmaÅŸÄ±k akÄ±l yÃ¼rÃ¼tme uzmanlÄ±ÄŸÄ±.
- **Phi-4-mini (3.8B parametre)**: Fonksiyon Ã§aÄŸrÄ±sÄ± ve uzun baÄŸlam desteÄŸi ile geliÅŸtirilmiÅŸ akÄ±l yÃ¼rÃ¼tme.
- **Phi-4-multimodal**: EÅŸzamanlÄ± konuÅŸma, gÃ¶rsel ve metin iÅŸleme yetenekleri.
- **Phi-4-reasoning (14B parametre)**: KarmaÅŸÄ±k Ã§ok adÄ±mlÄ± akÄ±l yÃ¼rÃ¼tme gÃ¶revleri iÃ§in uzmanlaÅŸmÄ±ÅŸ.
- **Phi-4-reasoning-plus (14B parametre)**: Ek pekiÅŸtirmeli Ã¶ÄŸrenme ile artÄ±rÄ±lmÄ±ÅŸ doÄŸruluk.
- **Phi-4-mini-reasoning (3.8B parametre)**: SÄ±nÄ±rlÄ± ortamlar iÃ§in optimize edilmiÅŸ matematiksel akÄ±l yÃ¼rÃ¼tme.

## Phi Modellerinin UygulamalarÄ±

### Kurumsal Uygulamalar

KuruluÅŸlar, Phi modellerini belge analizi, mÃ¼ÅŸteri hizmetleri otomasyonu, kod Ã¼retim yardÄ±mÄ± ve uyumluluk ve gÃ¼venlik nedenleriyle yerel daÄŸÄ±tÄ±m gerektiren iÅŸ zekasÄ± uygulamalarÄ± iÃ§in kullanÄ±r.

### Mobil ve UÃ§ BiliÅŸim

Mobil uygulamalar, sÃ¼rekli internet baÄŸlantÄ±sÄ± gerektirmeden gerÃ§ek zamanlÄ± Ã§eviri, akÄ±llÄ± asistanlar, iÃ§erik Ã¼retimi ve kiÅŸiselleÅŸtirilmiÅŸ Ã¶neriler iÃ§in Phi modellerinden faydalanÄ±r.

### EÄŸitim Teknolojisi

EÄŸitim platformlarÄ±, Phi modellerini kiÅŸiselleÅŸtirilmiÅŸ Ã¶ÄŸretim, otomatik notlama, iÃ§erik Ã¼retimi ve Ã§evrimdÄ±ÅŸÄ± veya dÃ¼ÅŸÃ¼k baÄŸlantÄ± ortamlarÄ±nda Ã§alÄ±ÅŸabilen etkileÅŸimli Ã¶ÄŸrenme deneyimleri iÃ§in kullanÄ±r.

### SaÄŸlÄ±k ve Uyumluluk

SaÄŸlÄ±k uygulamalarÄ±, Phi modellerinin hassas tÄ±bbi verileri yerel olarak iÅŸleme yeteneÄŸinden faydalanÄ±r. Bu, yapay zeka destekli tanÄ± yardÄ±mÄ±, hasta takibi ve tedavi Ã¶nerileri saÄŸlar.

## Zorluklar ve SÄ±nÄ±rlamalar

### Bilgi SÄ±nÄ±rlamalarÄ±

Verimli olmasÄ±na raÄŸmen, Phi modelleri daha bÃ¼yÃ¼k modellere kÄ±yasla daha az bilgi kapasitesine sahiptir. Bu, geniÅŸ alan uzmanlÄ±ÄŸÄ± gerektiren bilgi yoÄŸun uygulamalarda etkinliklerini sÄ±nÄ±rlayabilir.

### Dil DesteÄŸi

Phi modelleri Ã¶ncelikle Ä°ngilizce iÃ§in optimize edilmiÅŸtir. Ancak, daha yeni varyantlar Ã§ok dilli yetenekler iÃ§erir. G
Phi ailesi, yapay zeka daÄŸÄ±tÄ±mÄ±nÄ±n geleceÄŸinin sadece daha bÃ¼yÃ¼k modeller oluÅŸturmakta deÄŸil, aynÄ± zamanda daha akÄ±llÄ± ve daha verimli modeller geliÅŸtirmekte olduÄŸunu gÃ¶steriyor. Bu modeller, Ã§eÅŸitli donanÄ±m ortamlarÄ±nda yÃ¼ksek performans standartlarÄ±nÄ± koruyarak etkili bir ÅŸekilde Ã§alÄ±ÅŸabilir.

## GeliÅŸtirme ve Entegrasyon Ã–rnekleri

### Transformers ile HÄ±zlÄ± BaÅŸlangÄ±Ã§

Phi modellerini Hugging Face Transformers kÃ¼tÃ¼phanesi ile kullanmaya baÅŸlamak iÃ§in:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load Phi-4-mini-instruct
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    attn_implementation="flash_attention_2"  # For optimized performance
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")

# Format your prompt using the chat template
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Explain quantum computing in simple terms."}
]

# Apply chat template
input_text = tokenizer.apply_chat_template(messages, tokenize=False)
inputs = tokenizer(input_text, return_tensors="pt")

# Generate response
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)
    
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### Ä°nce Ayar Ã–rneÄŸi

AÅŸaÄŸÄ±daki Ã¶rnek, Phi-4-mini-instruct modelini belirli gÃ¶revler iÃ§in nasÄ±l ince ayar yapabileceÄŸinizi gÃ¶steriyor:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig
from trl import SFTTrainer
from datasets import load_dataset

# Configuration for LoRA fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules="all-linear"
)

# Training configuration optimized for efficiency
training_config = TrainingArguments(
    output_dir="./phi-4-mini-finetuned",
    learning_rate=5.0e-06,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=1,
    num_train_epochs=1,
    bf16=True,
    gradient_checkpointing=True,
    warmup_ratio=0.2,
    save_steps=100
)

# Load model and tokenizer
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")
tokenizer.pad_token = tokenizer.unk_token
tokenizer.padding_side = 'right'

# Load and process dataset
train_dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_config,
    peft_config=peft_config,
    train_dataset=train_dataset,
    max_seq_length=2048,
    tokenizer=tokenizer,
    packing=True
)

# Start fine-tuning
trainer.train()
```

### Ã–zel Ä°pucu FormatlarÄ±

**AkÄ±l YÃ¼rÃ¼tme GÃ¶revleri Ä°Ã§in (Phi-4-reasoning-plus):**
```
<|im_start|>system<|im_sep|>
You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions.

Please structure your response into two main sections:
<think>
{Thought section}
</think>
{Solution section}
<|im_end|>
<|im_start|>user<|im_sep|>
What is the derivative of x^2?
<|im_end|>
<|im_start|>assistant<|im_sep|>
```

**Matematiksel GÃ¶revler Ä°Ã§in (Phi-4-mini-reasoning):**
```
<|system|>
Your name is Phi, an AI math expert developed by Microsoft.
<|end|>
<|user|>
Solve this calculus problem: Find the integral of 2x + 3
<|end|>
<|assistant|>
```

### ONNX ile Mobil DaÄŸÄ±tÄ±m

```python
import onnxruntime as ort
import numpy as np

# Load ONNX model for mobile deployment
session = ort.InferenceSession("phi-4-mini-quantized.onnx")

# Prepare input
input_ids = tokenizer.encode("Hello, how are you?", return_tensors="np")

# Run inference
outputs = session.run(None, {"input_ids": input_ids})
predicted_ids = outputs[0]

# Decode response
response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)
```

## Performans KarÅŸÄ±laÅŸtÄ±rmalarÄ± ve BaÅŸarÄ±lar

Phi model ailesi, Ã§eÅŸitli karÅŸÄ±laÅŸtÄ±rmalarda olaÄŸanÃ¼stÃ¼ performans sergileyerek genellikle Ã§ok daha bÃ¼yÃ¼k modelleri geride bÄ±rakmÄ±ÅŸtÄ±r:

### Ã–nemli Performans Ã–zellikleri

**Matematiksel AkÄ±l YÃ¼rÃ¼tme MÃ¼kemmelliÄŸi:**
- Phi-4, AIME 2025 (Matematik OlimpiyatÄ± elemesi) Ã¼zerinde %82.5 doÄŸruluk oranÄ± elde etti
- Phi-4-reasoning (14B), akÄ±l yÃ¼rÃ¼tme karÅŸÄ±laÅŸtÄ±rmalarÄ±nda DeepSeek-R1-Distill-70B (5 kat daha bÃ¼yÃ¼k) modelini geride bÄ±raktÄ±
- Phi-4-mini-reasoning (3.8B), matematiksel akÄ±l yÃ¼rÃ¼tme gÃ¶revlerinde iki katÄ± bÃ¼yÃ¼klÃ¼ÄŸÃ¼ndeki modellerle rekabet ediyor

**Verimlilik BaÅŸarÄ±larÄ±:**
- Phi-3-Silica, yalnÄ±zca 1.5W gÃ¼Ã§ tÃ¼ketimiyle saniyede 650 token iÅŸliyor
- Phi-4-mini (3.8B), Ã§ok daha bÃ¼yÃ¼k modellere benzer performans saÄŸlÄ±yor

**KarÅŸÄ±laÅŸtÄ±rma PerformansÄ±:**
- **MMLU (Massive Multitask Language Understanding)**: 57 akademik konu arasÄ±nda rekabetÃ§i performans
- **HumanEval**: Ã–zellikle Python'da gÃ¼Ã§lÃ¼ kod Ã¼retme yetenekleri
- **MGSM**: Ã‡ok dilli ilkokul matematik problemlerini Ã§Ã¶zme
- **DROP**: KarmaÅŸÄ±k anlama ve akÄ±l yÃ¼rÃ¼tme gÃ¶revleri
- **SimpleQA**: GerÃ§eklere dayalÄ± yanÄ±t doÄŸruluÄŸu

### ğŸ“Š Model KarÅŸÄ±laÅŸtÄ±rma Matrisi

| Model | Parametreler | BaÄŸlam UzunluÄŸu | Temel GÃ¼Ã§lÃ¼ YÃ¶nler | En Ä°yi KullanÄ±m AlanlarÄ± |
|-------|--------------|-----------------|--------------------|--------------------------|
| **Phi-3-mini** | 3.8B | 4K/128K | Genel verimlilik | Mobil uygulamalar, temel sohbet botlarÄ± |
| **Phi-3.5-mini** | 3.8B | 128K | Ã‡ok dilli destek | UluslararasÄ± uygulamalar |
| **Phi-4-mini** | 3.8B | 128K | GeliÅŸmiÅŸ akÄ±l yÃ¼rÃ¼tme, fonksiyon Ã§aÄŸÄ±rma | Ä°ÅŸ otomasyonu |
| **Phi-4-mini-reasoning** | 3.8B | 128K | Matematiksel akÄ±l yÃ¼rÃ¼tme | EÄŸitim platformlarÄ± |
| **Phi-4** | 14B | 32K | KarmaÅŸÄ±k akÄ±l yÃ¼rÃ¼tme | AraÅŸtÄ±rma, ileri analiz |
| **Phi-4-reasoning** | 14B | 32K/64K | Ã‡ok adÄ±mlÄ± akÄ±l yÃ¼rÃ¼tme | Bilimsel hesaplama |
| **Phi-4-reasoning-plus** | 14B | 32K | Maksimum doÄŸrulukta akÄ±l yÃ¼rÃ¼tme | Kritik karar verme |
| **Phi-4-multimodal** | 5.6B | DeÄŸiÅŸken | KonuÅŸma, gÃ¶rsel, metin | Multimedya uygulamalarÄ± |

## Model SeÃ§im Rehberi

### Temel Uygulamalar Ä°Ã§in
- **Phi-3-mini**: Basit metin Ã¼retimi, temel Soru-Cevap, hÄ±zlÄ± yanÄ±tlar
- **Phi-4-mini**: Fonksiyon Ã§aÄŸÄ±rma yetenekleriyle geliÅŸmiÅŸ akÄ±l yÃ¼rÃ¼tme

### Matematiksel ve AkÄ±l YÃ¼rÃ¼tme GÃ¶revleri Ä°Ã§in
- **Phi-4**: KarmaÅŸÄ±k matematik problemleri Ã§Ã¶zme ve akÄ±l yÃ¼rÃ¼tme
- **Phi-4-reasoning**: AyrÄ±ntÄ±lÄ± aÃ§Ä±klamalarla Ã§ok adÄ±mlÄ± akÄ±l yÃ¼rÃ¼tme
- **Phi-4-reasoning-plus**: Kritik akÄ±l yÃ¼rÃ¼tme uygulamalarÄ± iÃ§in maksimum doÄŸruluk
- **Phi-4-mini-reasoning**: Kaynak kÄ±sÄ±tlÄ± ortamlar iÃ§in verimli matematiksel akÄ±l yÃ¼rÃ¼tme

### Multimodal Uygulamalar Ä°Ã§in
- **Phi-3-vision**: GÃ¶rÃ¼ntÃ¼ ve metin iÅŸleme kombinasyonlarÄ±
- **Phi-4-multimodal**: KapsamlÄ± konuÅŸma, gÃ¶rsel ve metin yetenekleri

### Kurumsal DaÄŸÄ±tÄ±m Ä°Ã§in
- **Phi-3-medium**: Ä°ÅŸ uygulamalarÄ± iÃ§in geliÅŸmiÅŸ dil anlayÄ±ÅŸÄ±
- **Phi-3-Silica**: Belirli donanÄ±m platformlarÄ± iÃ§in optimize edilmiÅŸ

## DaÄŸÄ±tÄ±m PlatformlarÄ± ve EriÅŸilebilirlik

### Bulut PlatformlarÄ±
- **Azure AI Foundry**: Kurumsal araÃ§larla tam Ã¶zellikli daÄŸÄ±tÄ±m
- **Hugging Face**: AÃ§Ä±k kaynaklÄ± model deposu ve topluluk kaynaklarÄ±
- **NVIDIA API Catalog**: Mikro hizmet daÄŸÄ±tÄ±m seÃ§enekleri

### Yerel GeliÅŸtirme Ã‡erÃ§eveleri
- **Ollama**: Yerel model daÄŸÄ±tÄ±mÄ± iÃ§in hafif Ã§erÃ§eve
- **ONNX Runtime**: Ã‡eÅŸitli donanÄ±m yapÄ±landÄ±rmalarÄ± iÃ§in optimize edilmiÅŸ  
- **DirectML**: Windows iÃ§in optimize edilmiÅŸ performans
- **llama.cpp**: Platformlar arasÄ± Ã§Ä±karÄ±m motoru

### Ã–ÄŸrenme KaynaklarÄ±
- **Phi Portal**: Microsoft Phi resmi dokÃ¼mantasyon merkezi
- **Phi Cookbook**: KapsamlÄ± Ã¶rnekler ve eÄŸitim materyalleri
- **Teknik Raporlar**: Arxiv'deki ayrÄ±ntÄ±lÄ± araÅŸtÄ±rma makaleleri
- **Topluluk AlanlarÄ±**: Hugging Face etkileÅŸimli demolar

### Phi Modelleriyle BaÅŸlangÄ±Ã§

#### GeliÅŸtirme PlatformlarÄ±
1. **Azure AI Foundry**: Basit yerel CLI ve model yÃ¶netimi.
2. **Hugging Face Transformers**: HÄ±zlÄ± yerel deneyler
3. **Ollama**: Test iÃ§in basit yerel daÄŸÄ±tÄ±m

#### Ã–ÄŸrenme Yolu
1. **Temel KavramlarÄ± AnlayÄ±n**: Temel tasarÄ±m prensiplerini inceleyin
2. **Varyantlarla Deney YapÄ±n**: FarklÄ± Phi modellerini deneyerek yeteneklerini anlayÄ±n
3. **Uygulama PratiÄŸi YapÄ±n**: Modelleri test ortamlarÄ±nda daÄŸÄ±tÄ±n
4. **DaÄŸÄ±tÄ±mÄ± Ã–lÃ§eklendirin**: BaÅŸarÄ±lÄ± pilotlara dayanarak kullanÄ±mÄ± kademeli olarak geniÅŸletin

#### En Ä°yi Uygulamalar
- **KÃ¼Ã§Ã¼k BaÅŸlayÄ±n**: Ä°lk geliÅŸtirme iÃ§in Phi-mini modelleriyle baÅŸlayÄ±n
- **Ä°puÃ§larÄ±nÄ± Optimize Edin**: En iyi sonuÃ§lar iÃ§in uygun sohbet formatlarÄ±nÄ± kullanÄ±n
- **PerformansÄ± Ä°zleyin**: Ã‡Ä±karÄ±m hÄ±zÄ± ve doÄŸruluk metriklerini takip edin
- **DonanÄ±mÄ± DÃ¼ÅŸÃ¼nÃ¼n**: Model boyutunu mevcut hesaplama kaynaklarÄ±na uygun hale getirin

## SonuÃ§

Microsoft Phi model ailesi, yapay zeka model tasarÄ±mÄ±nda devrim niteliÄŸinde bir yaklaÅŸÄ±mÄ± temsil ediyor. Daha kÃ¼Ã§Ã¼k, daha verimli modellerin Ã§eÅŸitli gÃ¶revlerde olaÄŸanÃ¼stÃ¼ performans elde edebileceÄŸini gÃ¶steriyor. YÃ¼ksek kaliteli eÄŸitim verileri ve mimari optimizasyonlara odaklanarak, Phi ailesi geleneksel bÃ¼yÃ¼k dil modellerine kÄ±yasla Ã¶nemli Ã¶lÃ§Ã¼de azaltÄ±lmÄ±ÅŸ hesaplama gereksinimleriyle olaÄŸanÃ¼stÃ¼ yetenekler sunuyor.

## Temel Ã–ÄŸrenme Hedefleri

1. Microsoft'un Phi model ailesinin Phi-1'den Phi-4'e kadar olan tasarÄ±m felsefesini ve evrimini anlamak
2. "Ders kitabÄ± kalitesinde" eÄŸitim ve mimari optimizasyonlar dahil olmak Ã¼zere temel yenilikleri tanÄ±mlamak
3. FarklÄ± Phi varyantlarÄ±nÄ±n farklÄ± daÄŸÄ±tÄ±m senaryolarÄ±ndaki avantajlarÄ±nÄ± ve sÄ±nÄ±rlamalarÄ±nÄ± tanÄ±mak
4. Belirli kullanÄ±m durumlarÄ± ve donanÄ±m kÄ±sÄ±tlamalarÄ± iÃ§in uygun Phi modellerini seÃ§mek
5. Kaynak kÄ±sÄ±tlÄ± cihazlarda Phi modellerini daÄŸÄ±tmak iÃ§in optimizasyon tekniklerini uygulamak
6. Phi model ailesinin geleneksel bÃ¼yÃ¼k dil modellerine gÃ¶re mimari avantajlarÄ±nÄ± aÃ§Ä±klamak
7. Belirli uygulama gereksinimlerine ve donanÄ±m kÄ±sÄ±tlamalarÄ±na gÃ¶re uygun Phi varyantÄ±nÄ± seÃ§mek
8. Phi modellerini optimize edilmiÅŸ yapÄ±landÄ±rmalarla hem bulut hem de uÃ§ daÄŸÄ±tÄ±m senaryolarÄ±nda uygulamak
9. Hedef cihazlarda Phi model performansÄ±nÄ± artÄ±rmak iÃ§in kuantizasyon ve optimizasyon tekniklerini uygulamak
10. Phi ailesi genelinde model boyutu, performans ve yetenekler arasÄ±ndaki Ã¶dÃ¼nleÅŸimleri deÄŸerlendirmek

## SÄ±rada Ne Var

- [02: Qwen Ailesi Temelleri](02.QwenFamily.md)

---

**Feragatname**:  
Bu belge, AI Ã§eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluÄŸu saÄŸlamak iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±k iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan kaynaklanan yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalardan sorumlu deÄŸiliz.