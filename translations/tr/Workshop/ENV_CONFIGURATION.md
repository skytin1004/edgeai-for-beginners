<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "dd4a5b9ec82d35599b0abc9af89e7c9e",
  "translation_date": "2025-10-09T10:40:36+00:00",
  "source_file": "Workshop/ENV_CONFIGURATION.md",
  "language_code": "tr"
}
-->
# Ortam Yapılandırma Kılavuzu

## Genel Bakış

Atölye örnekleri, yapılandırma için depo kökünde bulunan `.env` dosyasında merkezi olarak toplanan ortam değişkenlerini kullanır. Bu, kodu değiştirmeden kolayca özelleştirme yapmanıza olanak tanır.

## Hızlı Başlangıç

### 1. Ön Koşulları Doğrulayın

```bash
# Check Foundry Local is installed
foundry --version

# Check service is running
foundry service status

# Load a model
foundry model run phi-4-mini
```

### 2. Ortamı Yapılandırın

`.env` dosyası zaten mantıklı varsayılanlarla yapılandırılmıştır. Çoğu kullanıcı bir şey değiştirmek zorunda kalmayacaktır.

**İsteğe Bağlı**: Ayarları gözden geçirin ve özelleştirin:
```bash
# Edit .env file
notepad .env  # Windows
nano .env     # macOS/Linux
```

### 3. Yapılandırmayı Uygulayın

**Python Scriptleri için:**
```bash
cd Workshop/samples/session01
python chat_bootstrap.py
# Environment variables automatically loaded
```

**Notebooklar için:**
```python
# Restart kernel after .env changes
# Variables are loaded when cells execute
```

## Ortam Değişkenleri Referansı

### Temel Yapılandırma

| Değişken | Varsayılan | Açıklama |
|----------|------------|----------|
| `FOUNDRY_LOCAL_ALIAS` | `phi-4-mini` | Örnekler için varsayılan model |
| `FOUNDRY_LOCAL_ENDPOINT` | (boş) | Servis uç noktasını geçersiz kıl |
| `PYTHONPATH` | Atölye yolları | Python modül arama yolu |

**FOUNDRY_LOCAL_ENDPOINT ne zaman ayarlanmalı:**
- Uzaktan Foundry Local örneği
- Özel port yapılandırması
- Geliştirme/üretim ayrımı

**Örnek:**
```bash
# Local custom port
FOUNDRY_LOCAL_ENDPOINT=http://localhost:8000

# Remote instance
FOUNDRY_LOCAL_ENDPOINT=http://192.168.1.50:5273/v1
```

### Oturuma Özel Değişkenler

#### Oturum 02: RAG Pipeline
| Değişken | Varsayılan | Amaç |
|----------|------------|------|
| `EMBED_MODEL` | `sentence-transformers/all-MiniLM-L6-v2` | Gömme modeli |
| `RAG_QUESTION` | Önceden yapılandırılmış | Test sorusu |

#### Oturum 03: Benchmarking
| Değişken | Varsayılan | Amaç |
|----------|------------|------|
| `BENCH_MODELS` | `phi-4-mini,qwen2.5-0.5b,gemma-2-2b` | Karşılaştırılacak modeller |
| `BENCH_ROUNDS` | `3` | Model başına yineleme sayısı |
| `BENCH_PROMPT` | Önceden yapılandırılmış | Test istemi |
| `BENCH_STREAM` | `0` | İlk token gecikmesini ölç |

#### Oturum 04: Model Karşılaştırması
| Değişken | Varsayılan | Amaç |
|----------|------------|------|
| `SLM_ALIAS` | `phi-4-mini` | Küçük dil modeli |
| `LLM_ALIAS` | `qwen2.5-7b` | Büyük dil modeli |
| `COMPARE_PROMPT` | Önceden yapılandırılmış | Karşılaştırma istemi |
| `COMPARE_RETRIES` | `2` | Tekrar deneme sayısı |

#### Oturum 05: Çoklu Ajan Orkestrasyonu
| Değişken | Varsayılan | Amaç |
|----------|------------|------|
| `AGENT_MODEL_PRIMARY` | `phi-4-mini` | Araştırmacı ajan modeli |
| `AGENT_MODEL_EDITOR` | `phi-4-mini` | Editör ajan modeli |
| `AGENT_QUESTION` | Önceden yapılandırılmış | Test sorusu |

### Güvenilirlik Yapılandırması

| Değişken | Varsayılan | Amaç |
|----------|------------|------|
| `SHOW_USAGE` | `1` | Token kullanımını yazdır |
| `RETRY_ON_FAIL` | `1` | Yeniden deneme mantığını etkinleştir |
| `RETRY_BACKOFF` | `1.0` | Yeniden deneme gecikmesi (saniye) |

## Yaygın Yapılandırmalar

### Geliştirme Ayarları (Hızlı Yineleme)
```bash
FOUNDRY_LOCAL_ALIAS=phi-4-mini
SLM_ALIAS=phi-4-mini
LLM_ALIAS=phi-4-mini
BENCH_MODELS=phi-4-mini
SHOW_USAGE=1
```

### Üretim Ayarları (Kalite Odaklı)
```bash
FOUNDRY_LOCAL_ALIAS=phi-4-mini
SLM_ALIAS=phi-4-mini
LLM_ALIAS=qwen2.5-7b
AGENT_MODEL_PRIMARY=phi-4-mini
AGENT_MODEL_EDITOR=qwen2.5-7b
SHOW_USAGE=0
```

### Benchmarking Ayarları
```bash
BENCH_MODELS=phi-4-mini,qwen2.5-0.5b,qwen2.5-7b,gemma-2-2b
BENCH_ROUNDS=5
BENCH_STREAM=1
```

### Çoklu Ajan Özelleştirme
```bash
AGENT_MODEL_PRIMARY=phi-4-mini        # Fast for research
AGENT_MODEL_EDITOR=qwen2.5-7b         # Quality for editing
```

### Uzaktan Geliştirme
```bash
FOUNDRY_LOCAL_ENDPOINT=http://dev-server.local:5273/v1
FOUNDRY_LOCAL_ALIAS=phi-4-mini
```

## Önerilen Modeller

### Kullanım Amacına Göre

**Genel Amaçlı:**
- `phi-4-mini` - Dengeli kalite ve hız

**Hızlı Yanıtlar:**
- `qwen2.5-0.5b` - Çok hızlı, sınıflandırma için uygun
- `phi-4-mini` - Hızlı ve iyi kalite

**Yüksek Kalite:**
- `qwen2.5-7b` - En iyi kalite, daha fazla kaynak kullanımı
- `phi-4-mini` - İyi kalite, daha az kaynak

**Kod Üretimi:**
- `deepseek-coder-1.3b` - Kod için özelleştirilmiş
- `phi-4-mini` - Genel amaçlı kodlama

### Kaynak Mevcudiyetine Göre

**Düşük Kaynaklar (< 8GB RAM):**
```bash
FOUNDRY_LOCAL_ALIAS=qwen2.5-0.5b
SLM_ALIAS=qwen2.5-0.5b
LLM_ALIAS=phi-4-mini
```

**Orta Kaynaklar (8-16GB RAM):**
```bash
FOUNDRY_LOCAL_ALIAS=phi-4-mini
SLM_ALIAS=phi-4-mini
LLM_ALIAS=qwen2.5-7b
```

**Yüksek Kaynaklar (16GB+ RAM):**
```bash
FOUNDRY_LOCAL_ALIAS=qwen2.5-7b
SLM_ALIAS=phi-4-mini
LLM_ALIAS=qwen2.5-14b
```

## Gelişmiş Yapılandırma

### Özel Uç Noktalar

```bash
# Development environment
FOUNDRY_LOCAL_ENDPOINT=http://localhost:8000

# Staging environment
FOUNDRY_LOCAL_ENDPOINT=http://staging.internal:5273/v1

# Production environment
FOUNDRY_LOCAL_ENDPOINT=http://prod.internal:5273/v1
```

### Sıcaklık ve Örnekleme (Kodda Geçersiz Kılma)

```python
# In your scripts/notebooks
os.environ['TEMPERATURE'] = '0.7'
os.environ['TOP_P'] = '0.9'
```

### Azure OpenAI Hibrit Kurulumu

```bash
# Use local for development
FOUNDRY_LOCAL_ALIAS=phi-4-mini

# Configure Azure for production fallback
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
AZURE_OPENAI_API_KEY=your-key-here
AZURE_OPENAI_API_VERSION=2024-08-01-preview
```

## Sorun Giderme

### Ortam Değişkenleri Yüklenmiyor

**Belirtiler:**
- Scriptler yanlış modelleri kullanıyor
- Bağlantı hataları
- Değişkenler tanınmıyor

**Çözümler:**
```bash
# 1. Verify .env exists in repository root
ls -la .env  # macOS/Linux
dir .env     # Windows

# 2. Check file is not .env.txt (Windows)
# Ensure no hidden extension

# 3. For notebooks: Restart kernel
# Kernel > Restart

# 4. For scripts: Check working directory
pwd  # Should be in Workshop or repository root
```

### Servis Bağlantı Sorunları

**Belirtiler:**
- "Bağlantı reddedildi" hataları
- "Servis mevcut değil"
- Zaman aşımı hataları

**Çözümler:**
```bash
# 1. Check service status
foundry service status

# 2. Start if not running
foundry service start

# 3. Verify endpoint
# Check port in status output
foundry service status | grep "Port"

# 4. Update .env if needed
FOUNDRY_LOCAL_ENDPOINT=http://localhost:<port>
```

### Model Bulunamadı

**Belirtiler:**
- "Model bulunamadı" hataları
- "Alias tanınmadı"

**Çözümler:**
```bash
# 1. List available models
foundry model list

# 2. Load required model
foundry model run phi-4-mini

# 3. Update .env with available model
FOUNDRY_LOCAL_ALIAS=<available-model>
```

### İçe Aktarma Hataları

**Belirtiler:**
- "Modül bulunamadı" hataları
- "workshop_utils içe aktarılamıyor"

**Çözümler:**
```bash
# 1. Verify PYTHONPATH in .env
PYTHONPATH=${workspaceFolder}/Workshop/samples

# 2. Install dependencies
pip install -r requirements.txt

# 3. Activate virtual environment
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # macOS/Linux
```

## Yapılandırmayı Test Etme

### Ortam Yüklemesini Doğrula

```python
# test_env.py
import os
from dotenv import load_dotenv

load_dotenv()

print("Core Configuration:")
print(f"  FOUNDRY_LOCAL_ALIAS: {os.getenv('FOUNDRY_LOCAL_ALIAS')}")
print(f"  FOUNDRY_LOCAL_ENDPOINT: {os.getenv('FOUNDRY_LOCAL_ENDPOINT') or 'auto'}")

print("\nSession 04:")
print(f"  SLM_ALIAS: {os.getenv('SLM_ALIAS')}")
print(f"  LLM_ALIAS: {os.getenv('LLM_ALIAS')}")

print("\nSession 05:")
print(f"  AGENT_MODEL_PRIMARY: {os.getenv('AGENT_MODEL_PRIMARY')}")
print(f"  AGENT_MODEL_EDITOR: {os.getenv('AGENT_MODEL_EDITOR')}")
```

### Foundry Local Bağlantısını Test Et

```python
# test_connection.py
import os
from foundry_local import FoundryLocalManager

alias = os.getenv('FOUNDRY_LOCAL_ALIAS', 'phi-4-mini')
endpoint = os.getenv('FOUNDRY_LOCAL_ENDPOINT')

try:
    if endpoint:
        manager = FoundryLocalManager(alias, endpoint=endpoint)
    else:
        manager = FoundryLocalManager(alias)
    
    print(f"✓ Connected to {manager.endpoint}")
    print(f"✓ Model: {manager.get_model_info(alias).id}")
    print(f"✓ Available models: {len(manager.list_models())}")
except Exception as e:
    print(f"✗ Connection failed: {e}")
```

## Güvenlik En İyi Uygulamaları

### 1. Asla Gizli Bilgileri Commit Etmeyin

```bash
# .gitignore should include:
.env
.env.local
*.key
```

### 2. Ayrı .env Dosyaları Kullanın

```bash
.env              # Default configuration
.env.local        # Local overrides (gitignored)
.env.production   # Production config (secure storage)
```

### 3. API Anahtarlarını Döndürün

```bash
# For Azure OpenAI or other cloud services
# Regularly rotate keys and update .env
```

### 4. Ortama Özel Yapılandırma Kullanın

```bash
# Development
FOUNDRY_LOCAL_ENDPOINT=http://localhost:5273/v1

# Production (use secrets management)
FOUNDRY_LOCAL_ENDPOINT=${PROD_FOUNDRY_ENDPOINT}
```

## SDK Belgeleri

- **Ana Depo**: https://github.com/microsoft/Foundry-Local
- **Python SDK**: https://github.com/microsoft/Foundry-Local/tree/main/sdk/python/foundry_local
- **API Belgeleri**: En son bilgiler için SDK deposunu kontrol edin

## Ek Kaynaklar

- `QUICK_START.md` - Başlangıç kılavuzu
- `SDK_MIGRATION_NOTES.md` - SDK güncelleme detayları
- `Workshop/samples/*/README.md` - Örnek özel rehberler

---

**Son Güncelleme**: 2025-01-08  
**Sürüm**: 2.0  
**SDK**: Foundry Local Python SDK (en son)

---

**Feragatname**:  
Bu belge, [Co-op Translator](https://github.com/Azure/co-op-translator) adlı yapay zeka çeviri hizmeti kullanılarak çevrilmiştir. Doğruluk için çaba göstersek de, otomatik çevirilerin hata veya yanlışlık içerebileceğini lütfen unutmayın. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler için profesyonel insan çevirisi önerilir. Bu çevirinin kullanımından kaynaklanan yanlış anlamalar veya yanlış yorumlamalar için sorumluluk kabul edilmemektedir.