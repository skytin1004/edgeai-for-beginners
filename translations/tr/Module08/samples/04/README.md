<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "562ac0eae12d808c9f45fbb77eb5c84f",
  "translation_date": "2025-09-24T21:34:24+00:00",
  "source_file": "Module08/samples/04/README.md",
  "language_code": "tr"
}
-->
# Ã–rnek 04: Chainlit ile Ãœretim Chat UygulamalarÄ±

Microsoft Foundry Local kullanarak Ã¼retime hazÄ±r chat uygulamalarÄ± oluÅŸturmanÄ±n Ã§eÅŸitli yaklaÅŸÄ±mlarÄ±nÄ± gÃ¶steren kapsamlÄ± bir Ã¶rnek. Modern web arayÃ¼zleri, akÄ±ÅŸ yanÄ±tlarÄ± ve en son tarayÄ±cÄ± teknolojilerini iÃ§erir.

## Ä°Ã§erik

- **ðŸš€ Chainlit Chat UygulamasÄ±** (`app.py`): AkÄ±ÅŸ destekli Ã¼retime hazÄ±r chat uygulamasÄ±
- **ðŸŒ WebGPU Demo** (`webgpu-demo/`): DonanÄ±m hÄ±zlandÄ±rmalÄ± tarayÄ±cÄ± tabanlÄ± AI Ã§Ä±karÄ±mÄ±
- **ðŸŽ¨ Open WebUI Entegrasyonu** (`open-webui-guide.md`): Profesyonel ChatGPT benzeri arayÃ¼z
- **ðŸ“š EÄŸitim Not Defteri** (`chainlit_app.ipynb`): EtkileÅŸimli Ã¶ÄŸrenme materyalleri

## HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1. Chainlit Chat UygulamasÄ±

```cmd
# Navigate to Module08 directory
cd Module08

# Start your model
foundry model run phi-4-mini

# Run Chainlit app (using port 8080 to avoid conflicts)
chainlit run samples\04\app.py -w --port 8080
```

AÃ§Ä±lÄ±r: `http://localhost:8080`

### 2. WebGPU TarayÄ±cÄ± Demo

```cmd
# Navigate to WebGPU demo
cd Module08\samples\04\webgpu-demo

# Serve the demo
python -m http.server 5173
```

AÃ§Ä±lÄ±r: `http://localhost:5173`

### 3. Open WebUI Kurulumu

```cmd
# Run Open WebUI with Docker
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

AÃ§Ä±lÄ±r: `http://localhost:3000`

## Mimari Modeller

### Yerel vs Bulut Karar Matrisi

| Senaryo | Ã–neri | Sebep |
|---------|-------|-------|
| **Gizlilik Hassas Veriler** | ðŸ  Yerel (Foundry) | Veri cihazdan Ã§Ä±kmaz |
| **KarmaÅŸÄ±k AkÄ±l YÃ¼rÃ¼tme** | â˜ï¸ Bulut (Azure OpenAI) | Daha bÃ¼yÃ¼k modellere eriÅŸim |
| **GerÃ§ek ZamanlÄ± Chat** | ðŸ  Yerel (Foundry) | Daha dÃ¼ÅŸÃ¼k gecikme, daha hÄ±zlÄ± yanÄ±tlar |
| **Belge Analizi** | ðŸ”„ Hibrit | Ã‡Ä±karÄ±m iÃ§in yerel, analiz iÃ§in bulut |
| **Kod Ãœretimi** | ðŸ  Yerel (Foundry) | Gizlilik + Ã¶zel modeller |
| **AraÅŸtÄ±rma GÃ¶revleri** | â˜ï¸ Bulut (Azure OpenAI) | GeniÅŸ bilgi tabanÄ± gerekli |

### Teknoloji KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Teknoloji | KullanÄ±m AlanÄ± | Avantajlar | Dezavantajlar |
|-----------|----------------|------------|---------------|
| **Chainlit** | Python geliÅŸtiricileri, hÄ±zlÄ± prototipleme | Kolay kurulum, akÄ±ÅŸ desteÄŸi | Sadece Python |
| **WebGPU** | Maksimum gizlilik, Ã§evrimdÄ±ÅŸÄ± senaryolar | TarayÄ±cÄ± yerel, sunucu gerekmez | SÄ±nÄ±rlÄ± model boyutu |
| **Open WebUI** | Ãœretim daÄŸÄ±tÄ±mÄ±, ekipler | Profesyonel arayÃ¼z, kullanÄ±cÄ± yÃ¶netimi | Docker gerektirir |

## Ã–n KoÅŸullar

- **Foundry Local**: Kurulu ve Ã§alÄ±ÅŸÄ±yor ([Ä°ndir](https://aka.ms/foundry-local-installer))
- **Python**: 3.10+ ve sanal ortam
- **Model**: En az bir model yÃ¼klÃ¼ (`foundry model run phi-4-mini`)
- **TarayÄ±cÄ±**: Chrome/Edge WebGPU desteÄŸi ile demo iÃ§in
- **Docker**: Open WebUI iÃ§in (isteÄŸe baÄŸlÄ±)

## Kurulum ve Ayar

### 1. Python OrtamÄ± Kurulumu

```cmd
# Navigate to Module08 directory
cd Module08

# Create and activate virtual environment
py -m venv .venv
.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Foundry Local AyarÄ±

```cmd
# Verify Foundry Local installation
foundry --version

# Start the service
foundry service start

# Load a model
foundry model run phi-4-mini

# Verify model is running
foundry service ps
```

## Ã–rnek Uygulamalar

### Chainlit Chat UygulamasÄ±

**Ã–zellikler:**
- ðŸš€ **GerÃ§ek ZamanlÄ± AkÄ±ÅŸ**: Tokenler oluÅŸturuldukÃ§a gÃ¶rÃ¼nÃ¼r
- ðŸ›¡ï¸ **GÃ¼Ã§lÃ¼ Hata YÃ¶netimi**: Sorunsuz bozulma ve kurtarma
- ðŸŽ¨ **Modern ArayÃ¼z**: Kutudan Ã§Ä±kan profesyonel chat arayÃ¼zÃ¼
- ðŸ”§ **Esnek YapÄ±landÄ±rma**: Ortam deÄŸiÅŸkenleri ve otomatik algÄ±lama
- ðŸ“± **DuyarlÄ± TasarÄ±m**: MasaÃ¼stÃ¼ ve mobil cihazlarda Ã§alÄ±ÅŸÄ±r

**HÄ±zlÄ± BaÅŸlangÄ±Ã§:**
```cmd
# Run with default settings (recommended)
chainlit run samples\04\app.py -w --port 8080

# Use specific model
set MODEL=qwen2.5-7b-instruct
chainlit run samples\04\app.py -w --port 8080

# Manual endpoint configuration
set BASE_URL=http://localhost:51211
set API_KEY=your-api-key
chainlit run samples\04\app.py -w --port 8080
```

### WebGPU TarayÄ±cÄ± Demo

**Ã–zellikler:**
- ðŸŒ **TarayÄ±cÄ± Yerel AI**: Sunucu gerekmez, tamamen tarayÄ±cÄ±da Ã§alÄ±ÅŸÄ±r
- âš¡ **WebGPU HÄ±zlandÄ±rma**: DonanÄ±m hÄ±zlandÄ±rmasÄ± mevcut olduÄŸunda
- ðŸ”’ **Maksimum Gizlilik**: Veri cihazÄ±nÄ±zdan asla Ã§Ä±kmaz
- ðŸŽ¯ **SÄ±fÄ±r Kurulum**: Uyumlu herhangi bir tarayÄ±cÄ±da Ã§alÄ±ÅŸÄ±r
- ðŸ”„ **Sorunsuz Geri DÃ¶nÃ¼ÅŸ**: WebGPU yoksa CPU'ya geÃ§er

**Ã‡alÄ±ÅŸtÄ±rma:**
```cmd
cd samples\04\webgpu-demo
python -m http.server 5173
# Open http://localhost:5173
```

### Open WebUI Entegrasyonu

**Ã–zellikler:**
- ðŸŽ¨ **ChatGPT Benzeri ArayÃ¼z**: Profesyonel, tanÄ±dÄ±k arayÃ¼z
- ðŸ‘¥ **Ã‡ok KullanÄ±cÄ±lÄ± Destek**: KullanÄ±cÄ± hesaplarÄ± ve sohbet geÃ§miÅŸi
- ðŸ“ **Dosya Ä°ÅŸleme**: Belgeleri yÃ¼kleyip analiz etme
- ðŸ”„ **Model DeÄŸiÅŸtirme**: FarklÄ± modeller arasÄ±nda kolay geÃ§iÅŸ
- ðŸ³ **Docker DaÄŸÄ±tÄ±mÄ±**: Ãœretime hazÄ±r konteyner kurulumu

**HÄ±zlÄ± Kurulum:**
```cmd
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

## YapÄ±landÄ±rma ReferansÄ±

### Ortam DeÄŸiÅŸkenleri

| DeÄŸiÅŸken | AÃ§Ä±klama | VarsayÄ±lan | Ã–rnek |
|----------|----------|------------|-------|
| `MODEL` | KullanÄ±lacak model takma adÄ± | `phi-4-mini` | `qwen2.5-7b-instruct` |
| `BASE_URL` | Foundry Local uÃ§ noktasÄ± | Otomatik algÄ±lanÄ±r | `http://localhost:51211` |
| `API_KEY` | API anahtarÄ± (yerel iÃ§in isteÄŸe baÄŸlÄ±) | `""` | `your-api-key` |

## Sorun Giderme

### YaygÄ±n Sorunlar

**Chainlit UygulamasÄ±:**

1. **Hizmet mevcut deÄŸil:**
   ```cmd
   # Check Foundry Local status
   foundry service status
   foundry service ps
   
   # Validate API endpoint (note: port 51211)
   curl http://localhost:51211/v1/models
   ```

2. **Port Ã§akÄ±ÅŸmalarÄ±:**
   ```cmd
   # Check what's using port 8080
   netstat -ano | findstr :8080
   
   # Use different port if needed
   chainlit run samples\04\app.py -w --port 3000
   ```

3. **Python ortamÄ± sorunlarÄ±:**
   ```cmd
   # Verify correct interpreter in VS Code
   # Ctrl+Shift+P â†’ Python: Select Interpreter
   # Choose: Module08/.venv/Scripts/python.exe
   
   # Reinstall dependencies
   pip install -r requirements.txt
   ```

**WebGPU Demo:**

1. **WebGPU desteklenmiyor:**
   - Chrome/Edge 113+ sÃ¼rÃ¼mÃ¼ne gÃ¼ncelleyin
   - WebGPU'yu etkinleÅŸtirin: `chrome://flags/#enable-unsafe-webgpu`
   - GPU durumunu kontrol edin: `chrome://gpu`
   - Demo otomatik olarak CPU'ya geÃ§er

2. **Model yÃ¼kleme hatalarÄ±:**
   - Model indirme iÃ§in internet baÄŸlantÄ±sÄ±nÄ± kontrol edin
   - TarayÄ±cÄ± konsolunda CORS hatalarÄ±nÄ± kontrol edin
   - HTTP Ã¼zerinden hizmet verdiÄŸinizden emin olun (file:// deÄŸil)

**Open WebUI:**

1. **BaÄŸlantÄ± reddedildi:**
   ```cmd
   # Check Docker is running
   docker --version
   
   # Check container status
   docker ps | findstr open-webui
   
   # View container logs
   docker logs open-webui
   ```

2. **Modeller gÃ¶rÃ¼nmÃ¼yor:**
   ```cmd
   # Verify Foundry Local endpoint
   curl http://localhost:51211/v1/models
   
   # Restart Open WebUI
   docker restart open-webui
   ```

### DoÄŸrulama Kontrol Listesi

```cmd
# âœ… 1. Foundry Local Setup
foundry --version                    # Should show version
foundry service status               # Should show "running"
foundry model list                   # Should show loaded models
curl http://localhost:51211/v1/models  # Should return JSON

# âœ… 2. Python Environment  
python --version                     # Should be 3.10+
pip list | findstr chainlit         # Should show chainlit package
pip list | findstr openai           # Should show openai package

# âœ… 3. Application Testing
chainlit run samples\04\app.py -w --port 8080  # Should open browser
# Test WebGPU demo at localhost:5173
# Test Open WebUI at localhost:3000
```

## Ä°leri DÃ¼zey KullanÄ±m

### Performans Optimizasyonu

**Chainlit:**
- Daha iyi algÄ±lanan performans iÃ§in akÄ±ÅŸ kullanÄ±n
- YÃ¼ksek eÅŸzamanlÄ±lÄ±k iÃ§in baÄŸlantÄ± havuzlama uygulayÄ±n
- Tekrarlanan sorgular iÃ§in model yanÄ±tlarÄ±nÄ± Ã¶nbelleÄŸe alÄ±n
- BÃ¼yÃ¼k sohbet geÃ§miÅŸleriyle bellek kullanÄ±mÄ±nÄ± izleyin

**WebGPU:**
- Maksimum gizlilik ve hÄ±z iÃ§in WebGPU kullanÄ±n
- Daha kÃ¼Ã§Ã¼k modeller iÃ§in model kuantizasyonu uygulayÄ±n
- Arka plan iÅŸlemleri iÃ§in Web Workers kullanÄ±n
- DerlenmiÅŸ modelleri tarayÄ±cÄ± depolamasÄ±nda Ã¶nbelleÄŸe alÄ±n

**Open WebUI:**
- Sohbet geÃ§miÅŸi iÃ§in kalÄ±cÄ± hacimler kullanÄ±n
- Docker konteyneri iÃ§in kaynak sÄ±nÄ±rlarÄ±nÄ± yapÄ±landÄ±rÄ±n
- KullanÄ±cÄ± verileri iÃ§in yedekleme stratejileri uygulayÄ±n
- SSL sonlandÄ±rma iÃ§in ters proxy ayarlayÄ±n

### Entegrasyon Modelleri

**Hibrit Yerel/Bulut:**
```python
# Route based on complexity and privacy requirements
async def intelligent_routing(prompt: str, metadata: dict):
    if metadata.get("contains_pii"):
        return await foundry_local_completion(prompt)  # Privacy-sensitive
    elif len(prompt.split()) > 200:
        return await azure_openai_completion(prompt)   # Complex reasoning
    else:
        return await foundry_local_completion(prompt)  # Default local
```

**Ã‡ok Modlu Boru HattÄ±:**
```python
# Combine different AI capabilities
async def analyze_document(file_path: str):
    # 1. OCR with WebGPU (browser-based)
    text = await webgpu_ocr(file_path)
    
    # 2. Analysis with Foundry Local (private)
    summary = await foundry_local_analyze(text)
    
    # 3. Enhancement with cloud (if needed)
    if summary.confidence < 0.8:
        summary = await azure_openai_enhance(summary)
    
    return summary
```

## Ãœretim DaÄŸÄ±tÄ±mÄ±

### GÃ¼venlik Dikkatleri

- **API AnahtarlarÄ±**: Ortam deÄŸiÅŸkenlerini kullanÄ±n, asla kod iÃ§ine yazmayÄ±n
- **AÄŸ**: Ãœretimde HTTPS kullanÄ±n, ekip eriÅŸimi iÃ§in VPN dÃ¼ÅŸÃ¼nÃ¼n
- **EriÅŸim KontrolÃ¼**: Open WebUI iÃ§in kimlik doÄŸrulama uygulayÄ±n
- **Veri GizliliÄŸi**: Hangi verilerin yerel kaldÄ±ÄŸÄ±nÄ± ve hangilerinin buluta gittiÄŸini denetleyin
- **GÃ¼ncellemeler**: Foundry Local ve konteynerleri gÃ¼ncel tutun

### Ä°zleme ve BakÄ±m

- **SaÄŸlÄ±k Kontrolleri**: UÃ§ nokta izleme uygulayÄ±n
- **GÃ¼nlÃ¼kler**: TÃ¼m bileÅŸenlerden gelen gÃ¼nlÃ¼kleri merkezileÅŸtirin
- **Metrikler**: YanÄ±t sÃ¼relerini, hata oranlarÄ±nÄ±, kaynak kullanÄ±mÄ±nÄ± izleyin
- **Yedekleme**: Sohbet verilerinin ve yapÄ±landÄ±rmalarÄ±n dÃ¼zenli yedeÄŸini alÄ±n

## Referanslar ve Kaynaklar

### DokÃ¼mantasyon
- [Chainlit DokÃ¼mantasyonu](https://docs.chainlit.io/) - Tam Ã§erÃ§eve rehberi
- [Foundry Local DokÃ¼mantasyonu](https://learn.microsoft.com/azure/ai-foundry/foundry-local/) - Resmi Microsoft belgeleri
- [ONNX Runtime Web](https://onnxruntime.ai/docs/get-started/with-javascript/web.html) - WebGPU entegrasyonu
- [Open WebUI DokÃ¼mantasyonu](https://docs.openwebui.com/) - GeliÅŸmiÅŸ yapÄ±landÄ±rma

### Ã–rnek Dosyalar
- [`app.py`](../../../../../Module08/samples/04/app.py) - Ãœretim Chainlit uygulamasÄ±
- [`chainlit_app.ipynb`](./chainlit_app.ipynb) - EÄŸitim not defteri
- [`webgpu-demo/`](../../../../../Module08/samples/04/webgpu-demo) - TarayÄ±cÄ± tabanlÄ± AI Ã§Ä±karÄ±mÄ±
- [`open-webui-guide.md`](./open-webui-guide.md) - Tam Open WebUI kurulumu

### Ä°lgili Ã–rnekler
- [Oturum 4 DokÃ¼mantasyonu](../../04.CuttingEdgeModels.md) - Tam oturum rehberi
- [Foundry Local Ã–rnekleri](https://github.com/microsoft/foundry-local/tree/main/samples) - Resmi Ã¶rnekler

---

