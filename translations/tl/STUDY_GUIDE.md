<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f86e720f67bb196e2fb6625b2338a1fb",
  "translation_date": "2025-10-09T19:08:11+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "tl"
}
-->
# EdgeAI para sa mga Baguhan: Mga Landas ng Pag-aaral at Iskedyul ng Pag-aaral

### Konsentradong Landas ng Pag-aaral (1 linggo)

| Araw | Pokus | Tinatayang Oras |
|------|-------|------------------|
| Araw 0 | Module 0: Panimula sa EdgeAI | 1-2 oras |
| Araw 1 | Module 1: Mga Pangunahing Kaalaman sa EdgeAI | 3 oras |
| Araw 2 | Module 2: Mga Batayan ng SLM | 3 oras |
| Araw 3 | Module 3: Deployment ng SLM | 2 oras |
| Araw 4-5 | Module 4: Pag-optimize ng Modelo (6 na framework) | 4 oras |
| Araw 6 | Module 5: SLMOps | 3 oras |
| Araw 7 | Module 6-7: AI Agents at Mga Kagamitang Pang-develop | 4 oras |
| Araw 8 | Module 8: Foundry Local Toolkit (Modernong Implementasyon) | 1 oras |

### Konsentradong Landas ng Pag-aaral (2 linggo)

| Araw | Pokus | Tinatayang Oras |
|------|-------|------------------|
| Araw 1-2 | Module 1: Mga Pangunahing Kaalaman sa EdgeAI | 3 oras |
| Araw 3-4 | Module 2: Mga Batayan ng SLM | 3 oras |
| Araw 5-6 | Module 3: Deployment ng SLM | 2 oras |
| Araw 7-8 | Module 4: Pag-optimize ng Modelo | 4 oras |
| Araw 9-10 | Module 5: SLMOps | 3 oras |
| Araw 11-12 | Module 6: AI Agents | 2 oras |
| Araw 13-14 | Module 7: Mga Kagamitang Pang-develop | 3 oras |

### Part-time na Pag-aaral (4 na linggo)

| Linggo | Pokus | Tinatayang Oras |
|------|-------|------------------|
| Linggo 1 | Module 1-2: Mga Pangunahing Kaalaman at Mga Batayan ng SLM | 6 oras |
| Linggo 2 | Module 3-4: Deployment at Pag-optimize | 6 oras |
| Linggo 3 | Module 5-6: SLMOps at AI Agents | 5 oras |
| Linggo 4 | Module 7: Mga Kagamitang Pang-develop at Integrasyon | 3 oras |

| Araw | Pokus | Tinatayang Oras |
|------|-------|------------------|
| Araw 0 | Module 0: Panimula sa EdgeAI | 1-2 oras |
| Araw 1-2 | Module 1: Mga Pangunahing Kaalaman sa EdgeAI | 3 oras |
| Araw 3-4 | Module 2: Mga Batayan ng SLM | 3 oras |
| Araw 5-6 | Module 3: Deployment ng SLM | 2 oras |
| Araw 7-8 | Module 4: Pag-optimize ng Modelo | 4 oras |
| Araw 9-10 | Module 5: SLMOps | 3 oras |
| Araw 11-12 | Module 6: Mga Sistemang Agentic ng SLM | 2 oras |
| Araw 13-14 | Module 7: Mga Halimbawa ng Implementasyon ng EdgeAI | 2 oras |

| Module | Petsa ng Pagkumpleto | Oras na Ginugol | Mahahalagang Natutunan |
|--------|----------------|-------------|--------------|
| Module 0: Panimula sa EdgeAI | | | |
| Module 1: Mga Pangunahing Kaalaman sa EdgeAI | | | |
| Module 2: Mga Batayan ng SLM | | | |
| Module 3: Deployment ng SLM | | | |
| Module 4: Pag-optimize ng Modelo (6 na framework) | | | |
| Module 5: SLMOps | | | |
| Module 6: Mga Sistemang Agentic ng SLM | | | |
| Module 7: Mga Halimbawa ng Implementasyon ng EdgeAI | | | |
| Mga Praktikal na Gawain | | | |
| Mini-Project | | | |

### Part-time na Pag-aaral (4 na linggo)

| Linggo | Pokus | Tinatayang Oras |
|------|-------|------------------|
| Linggo 1 | Module 1-2: Mga Pangunahing Kaalaman at Mga Batayan ng SLM | 6 oras |
| Linggo 2 | Module 3-4: Deployment at Pag-optimize | 6 oras |
| Linggo 3 | Module 5-6: SLMOps at AI Agents | 5 oras |
| Linggo 4 | Module 7: Mga Kagamitang Pang-develop at Integrasyon | 3 oras |

## Panimula

Maligayang pagdating sa gabay sa pag-aaral ng EdgeAI para sa mga Baguhan! Ang dokumentong ito ay idinisenyo upang tulungan kang mag-navigate sa mga materyales ng kurso nang epektibo at mapakinabangan ang iyong karanasan sa pag-aaral. Nagbibigay ito ng mga istrukturadong landas ng pag-aaral, mga mungkahing iskedyul ng pag-aaral, mga buod ng mahahalagang konsepto, at mga karagdagang mapagkukunan upang palalimin ang iyong pag-unawa sa mga teknolohiya ng Edge AI.

Ito ay isang maikli ngunit komprehensibong kurso na may 20 oras ng pag-aaral na nagbibigay ng mahahalagang kaalaman tungkol sa EdgeAI sa isang epektibong format, na perpekto para sa mga abalang propesyonal at estudyante na nais mabilis na makakuha ng praktikal na kasanayan sa umuusbong na larangang ito.

## Pangkalahatang-ideya ng Kurso

Ang kurso na ito ay inayos sa walong komprehensibong module:

0. **Panimula sa EdgeAI** - Pundasyon at pagtatakda ng konteksto gamit ang mga aplikasyon sa industriya at mga layunin sa pag-aaral  
1. **Mga Pangunahing Kaalaman sa EdgeAI at Transformasyon** - Pag-unawa sa mga pangunahing konsepto at pagbabago sa teknolohiya  
2. **Mga Batayan ng Small Language Model (SLM)** - Paggalugad sa iba't ibang pamilya ng SLM at kanilang mga arkitektura  
3. **Deployment ng Small Language Model** - Pagpapatupad ng mga praktikal na estratehiya sa deployment  
4. **Pag-convert ng Format ng Modelo at Quantization** - Advanced na pag-optimize gamit ang 6 na framework kabilang ang OpenVINO  
5. **SLMOps - Operasyon ng Small Language Model** - Pamamahala sa lifecycle ng produksyon at deployment  
6. **Mga Sistemang Agentic ng SLM** - AI agents, function calling, at Model Context Protocol  
7. **Mga Halimbawa ng Implementasyon ng EdgeAI** - AI Toolkit, Windows development, at mga implementasyon na partikular sa platform  
8. **Microsoft Foundry Local – Kumpletong Toolkit ng Developer** - Lokal na unang development na may hybrid Azure integration (Module 08)

## Paano Gamitin ang Gabay sa Pag-aaral na Ito

- **Progressive Learning**: Sundin ang mga module nang sunod-sunod para sa pinakakohesibong karanasan sa pag-aaral  
- **Knowledge Checkpoints**: Gamitin ang mga tanong sa self-assessment pagkatapos ng bawat seksyon  
- **Hands-on Practice**: Kumpletuhin ang mga mungkahing gawain upang mapalakas ang mga teoretikal na konsepto  
- **Supplementary Resources**: Galugarin ang mga karagdagang materyales para sa mga paksang pinaka-interesado ka  

## Mga Rekomendasyon sa Iskedyul ng Pag-aaral

### Konsentradong Landas ng Pag-aaral (1 linggo)

| Araw | Pokus | Tinatayang Oras |
|------|-------|------------------|
| Araw 0 | Module 0: Panimula sa EdgeAI | 1-2 oras |
| Araw 1-2 | Module 1: Mga Pangunahing Kaalaman sa EdgeAI | 6 oras |
| Araw 3-4 | Module 2: Mga Batayan ng SLM | 8 oras |
| Araw 5 | Module 3: Deployment ng SLM | 3 oras |
| Araw 6 | Module 8: Foundry Local Toolkit | 3 oras |

### Part-time na Pag-aaral (3 linggo)

| Linggo | Pokus | Tinatayang Oras |
|------|-------|------------------|
| Linggo 1 | Module 0: Panimula + Module 1: Mga Pangunahing Kaalaman sa EdgeAI | 7-9 oras |
| Linggo 2 | Module 2: Mga Batayan ng SLM | 7-8 oras |
| Linggo 3 | Module 3: Deployment ng SLM (3h) + Module 8: Foundry Local Toolkit (2-3h) | 5-6 oras |

## Module 0: Panimula sa EdgeAI

### Mga Layunin sa Pag-aaral

- Maunawaan kung ano ang Edge AI at bakit ito mahalaga sa kasalukuyang teknolohikal na tanawin  
- Tukuyin ang mga pangunahing industriya na binago ng Edge AI at ang kanilang mga partikular na kaso ng paggamit  
- Maunawaan ang mga benepisyo ng Small Language Models (SLMs) para sa edge deployment  
- Magtatag ng malinaw na mga inaasahan sa pag-aaral at mga resulta para sa buong kurso  
- Kilalanin ang mga oportunidad sa karera at mga kinakailangang kasanayan sa larangan ng Edge AI  

### Mga Pokus na Lugar sa Pag-aaral

#### Seksyon 1: Paradigma at Depinisyon ng Edge AI
- **Mahahalagang Konsepto**:  
  - Edge AI kumpara sa tradisyunal na cloud AI processing  
  - Ang pagsasanib ng hardware, pag-optimize ng modelo, at mga pangangailangan sa negosyo  
  - Real-time, privacy-preserving, at cost-efficient na AI deployment  

#### Seksyon 2: Mga Aplikasyon sa Industriya
- **Mahahalagang Konsepto**:  
  - Manufacturing & Industry 4.0: Predictive maintenance at quality control  
  - Healthcare: Diagnostic imaging at patient monitoring  
  - Autonomous Systems: Mga self-driving na sasakyan at transportasyon  
  - Smart Cities: Pamamahala ng trapiko at pampublikong kaligtasan  
  - Consumer Technology: Mga smartphone, wearables, at smart homes  

#### Seksyon 3: Pundasyon ng Small Language Models
- **Mahahalagang Konsepto**:  
  - Mga katangian ng SLM at mga paghahambing sa performance  
  - Trade-offs sa parameter efficiency kumpara sa capability  
  - Mga limitasyon sa edge deployment at mga estratehiya sa pag-optimize  

#### Seksyon 4: Framework ng Pag-aaral at Landas ng Karera
- **Mahahalagang Konsepto**:  
  - Arkitektura ng kurso at progresibong diskarte sa mastery  
  - Mga teknikal na kasanayan at mga layunin sa praktikal na implementasyon  
  - Mga oportunidad sa karera at mga aplikasyon sa industriya  

### Mga Tanong sa Self-Assessment

1. Ano ang tatlong pangunahing teknolohikal na trend na nagbigay-daan sa Edge AI?  
2. Ihambing ang mga benepisyo at hamon ng Edge AI kumpara sa cloud-based AI.  
3. Magbigay ng tatlong industriya kung saan nagbibigay ang Edge AI ng mahalagang halaga sa negosyo at ipaliwanag kung bakit.  
4. Paano ginagawang praktikal ng Small Language Models ang Edge AI para sa mga totoong deployment?  
5. Ano ang mga pangunahing teknikal na kasanayan na iyong ma-develop sa buong kurso?  
6. Ilarawan ang apat na yugto ng diskarte sa pag-aaral na ginamit sa kurso.  

### Mga Praktikal na Gawain

1. **Pananaliksik sa Industriya**: Pumili ng isang aplikasyon sa industriya at magsaliksik ng totoong implementasyon ng Edge AI (30 minuto)  
2. **Paggalugad ng Modelo**: Mag-browse ng mga available na Small Language Models sa Hugging Face at ihambing ang kanilang mga parameter count at capabilities (30 minuto)  
3. **Pagpaplano ng Pag-aaral**: Suriin ang buong istruktura ng kurso at gumawa ng personal na iskedyul ng pag-aaral (15 minuto)  

### Mga Karagdagang Materyales

- [Edge AI Market Overview - McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-age-of-ai)  
- [Small Language Models Overview - Hugging Face](https://huggingface.co/blog/small-language-models)  
- [Edge Computing Foundation](https://www.edgecomputing.org/)  

## Module 1: Mga Pangunahing Kaalaman sa EdgeAI at Transformasyon

### Mga Layunin sa Pag-aaral

- Maunawaan ang mga pagkakaiba sa pagitan ng cloud-based at edge-based AI  
- Maging bihasa sa mga pangunahing teknik sa pag-optimize para sa mga environment na may limitadong resources  
- Suriin ang mga totoong aplikasyon ng mga teknolohiya ng EdgeAI  
- Mag-set up ng development environment para sa mga proyekto ng EdgeAI  

### Mga Pokus na Lugar sa Pag-aaral

#### Seksyon 1: Mga Pangunahing Kaalaman sa EdgeAI
- **Mahahalagang Konsepto**:  
  - Paradigma ng Edge kumpara sa Cloud computing  
  - Mga teknik sa model quantization  
  - Mga opsyon sa hardware acceleration (NPUs, GPUs, CPUs)  
  - Mga benepisyo sa privacy at seguridad  

- **Mga Karagdagang Materyales**:  
  - [TensorFlow Lite Documentation](https://www.tensorflow.org/lite)  
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)  
  - [Edge Impulse Documentation](https://docs.edgeimpulse.com)  

#### Seksyon 2: Mga Totoong Case Studies
- **Mahahalagang Konsepto**:  
  - Microsoft Phi & Mu model ecosystem  
  - Mga praktikal na implementasyon sa iba't ibang industriya  
  - Mga konsiderasyon sa deployment  

#### Seksyon 3: Praktikal na Gabay sa Implementasyon
- **Mahahalagang Konsepto**:  
  - Pag-set up ng development environment  
  - Mga tool sa quantization at optimization  
  - Mga pamamaraan sa pagsusuri para sa mga implementasyon ng EdgeAI  

#### Seksyon 4: Hardware para sa Edge Deployment
- **Mahahalagang Konsepto**:  
  - Mga paghahambing ng hardware platform  
  - Mga estratehiya sa pag-optimize para sa partikular na hardware  
  - Mga konsiderasyon sa deployment  

### Mga Tanong sa Self-Assessment

1. Ihambing at kontrast ang cloud-based AI sa edge-based AI implementations.  
2. Ipaliwanag ang tatlong pangunahing teknik para sa pag-optimize ng mga modelo para sa edge deployment.  
3. Ano ang mga pangunahing benepisyo ng pagpapatakbo ng mga AI model sa edge?  
4. Ilarawan ang proseso ng pag-quantize ng modelo at kung paano ito nakakaapekto sa performance.  
5. Ipaliwanag kung paano nakakaapekto ang iba't ibang hardware accelerators (NPUs, GPUs, CPUs) sa EdgeAI deployment.  

### Mga Praktikal na Gawain

1. **Mabilis na Pag-set up ng Environment**: Mag-configure ng minimal na development environment gamit ang mga essential na package (30 minuto)  
2. **Paggalugad ng Modelo**: Mag-download at suriin ang isang pre-trained na small language model (1 oras)  
3. **Basic Quantization**: Subukan ang simpleng quantization sa isang maliit na modelo (1 oras)  

## Module 2: Mga Batayan ng Small Language Model

### Mga Layunin sa Pag-aaral

- Maunawaan ang mga prinsipyo ng arkitektura ng iba't ibang pamilya ng SLM  
- Ihambing ang kakayahan ng mga modelo sa iba't ibang parameter scale  
- Suriin ang mga modelo batay sa efficiency, capability, at mga kinakailangan sa deployment  
- Kilalanin ang mga angkop na kaso ng paggamit para sa iba't ibang pamilya ng modelo  

### Mga Pokus na Lugar sa Pag-aaral

#### Seksyon 1: Microsoft Phi Model Family
- **Mahahalagang Konsepto**:  
  - Ebolusyon ng design philosophy  
  - Efficiency-first na arkitektura  
  - Mga espesyal na kakayahan  

#### Seksyon 2: Qwen Family
- **Mahahalagang Konsepto**:  
  - Mga kontribusyon sa open source  
  - Mga opsyon sa scalable deployment  
  - Advanced na arkitektura sa reasoning  

#### Seksyon 3: Gemma Family
- **Mahahalagang Konsepto**:  
  - Innovation na pinangungunahan ng pananaliksik  
  - Multimodal na kakayahan  
  - Mobile optimization  

#### Seksyon 4: BitNET Family
- **Mahahalagang Konsepto**:  
  - Teknolohiya ng 1-bit quantization  
  - Framework ng inference optimization  
  - Mga konsiderasyon sa sustainability  

#### Seksyon 5: Microsoft Mu Model
- **Mahahalagang Konsepto**:  
  - Device-first na arkitektura  
  - Integrasyon ng sistema sa Windows  
  - Privacy-preserving na operasyon  

#### Seksyon 6: Phi-Silica
- **Mahahalagang Konsepto**:  
  - NPU-optimized na arkitektura  
  - Mga performance metrics  
  - Integrasyon ng developer  

### Mga Tanong sa Self-Assessment

1. Ihambing ang mga arkitektural na diskarte ng Phi at Qwen model families.  
2. Ipaliwanag kung paano naiiba ang teknolohiya ng quantization ng BitNET sa tradisyunal na quantization.  
3. Ano ang mga natatanging bentahe ng Mu model para sa integrasyon sa Windows?  
4. Ipaliwanag kung paano ginagamit ng Phi-Silica ang NPU hardware para sa pag-optimize ng performance.  
5. Para sa isang mobile application na may limitadong koneksyon, aling pamilya ng modelo ang pinakaangkop at bakit?  

### Mga Gawain sa Praktikal  

1. **Paghahambing ng Modelo**: Mabilisang pagsusuri ng dalawang magkaibang SLM models (1 oras)  
2. **Simpleng Text Generation**: Pangunahing implementasyon ng text generation gamit ang maliit na modelo (1 oras)  
3. **Mabilis na Pag-optimize**: Mag-apply ng isang teknik sa pag-optimize upang mapabilis ang inference (1 oras)  

## Module 3: Deployment ng Small Language Model  

### Pangunahing Layunin ng Pag-aaral  

- Pumili ng tamang modelo batay sa mga limitasyon ng deployment  
- Maging bihasa sa mga teknik ng pag-optimize para sa iba't ibang deployment scenarios  
- Mag-implement ng SLMs sa parehong lokal at cloud na kapaligiran  
- Magdisenyo ng mga production-ready na configuration para sa mga EdgeAI application  

### Mga Pokus ng Pag-aaral  

#### Seksyon 1: Advanced Learning ng SLM  
- **Mga Prayoridad na Konsepto**:  
  - Framework para sa parameter classification  
  - Mga advanced na teknik sa pag-optimize  
  - Mga estratehiya sa pagkuha ng modelo  

#### Seksyon 2: Deployment sa Lokal na Kapaligiran  
- **Mga Prayoridad na Konsepto**:  
  - Deployment gamit ang Ollama platform  
  - Mga lokal na solusyon ng Microsoft Foundry  
  - Paghahambing ng mga framework  

#### Seksyon 3: Containerized Cloud Deployment  
- **Mga Prayoridad na Konsepto**:  
  - Mataas na performance na inference gamit ang vLLM  
  - Orkestrasyon ng container  
  - Implementasyon ng ONNX Runtime  

### Mga Tanong sa Pagsusuri sa Sarili  

1. Anu-ano ang mga salik na dapat isaalang-alang kapag pumipili sa pagitan ng lokal at cloud deployment?  
2. Ihambing ang Ollama at Microsoft Foundry Local bilang mga opsyon sa deployment.  
3. Ipaliwanag ang mga benepisyo ng containerization para sa deployment ng SLM.  
4. Ano ang mga pangunahing performance metrics na dapat bantayan para sa edge-deployed na SLM?  
5. Ilarawan ang isang kumpletong workflow ng deployment mula sa pagpili ng modelo hanggang sa implementasyon sa produksyon.  

### Mga Gawain sa Praktikal  

1. **Pangunahing Lokal na Deployment**: Mag-deploy ng simpleng SLM gamit ang Ollama (1 oras)  
2. **Pagsusuri ng Performance**: Magsagawa ng mabilisang benchmark sa iyong na-deploy na modelo (30 minuto)  
3. **Simpleng Integrasyon**: Gumawa ng minimal na application na gumagamit ng iyong na-deploy na modelo (1 oras)  

## Module 4: Pag-convert ng Format ng Modelo at Quantization  

### Pangunahing Layunin ng Pag-aaral  

- Maging bihasa sa mga advanced na teknik ng quantization mula 1-bit hanggang 8-bit precision  
- Maunawaan ang mga estratehiya sa pag-convert ng format (GGUF, ONNX)  
- Mag-implement ng pag-optimize sa anim na framework (Llama.cpp, Olive, OpenVINO, MLX, workflow synthesis)  
- Mag-deploy ng mga optimized na modelo para sa production edge environments sa Intel, Apple, at cross-platform hardware  

### Mga Pokus ng Pag-aaral  

#### Seksyon 1: Mga Batayan ng Quantization  
- **Mga Prayoridad na Konsepto**:  
  - Framework para sa precision classification  
  - Trade-offs sa pagitan ng performance at accuracy  
  - Pag-optimize ng memory footprint  

#### Seksyon 2: Implementasyon ng Llama.cpp  
- **Mga Prayoridad na Konsepto**:  
  - Deployment sa iba't ibang platform  
  - Pag-optimize ng GGUF format  
  - Teknik sa hardware acceleration  

#### Seksyon 3: Microsoft Olive Suite  
- **Mga Prayoridad na Konsepto**:  
  - Pag-optimize na aware sa hardware  
  - Deployment na pang-enterprise  
  - Automated na workflows sa pag-optimize  

#### Seksyon 4: OpenVINO Toolkit  
- **Mga Prayoridad na Konsepto**:  
  - Pag-optimize para sa Intel hardware  
  - Neural Network Compression Framework (NNCF)  
  - Deployment ng inference sa iba't ibang platform  
  - OpenVINO GenAI para sa deployment ng LLM  

#### Seksyon 5: Apple MLX Framework  
- **Mga Prayoridad na Konsepto**:  
  - Pag-optimize para sa Apple Silicon  
  - Unified memory architecture  
  - LoRA fine-tuning capabilities  

#### Seksyon 6: Workflow Synthesis para sa Edge AI Development  
- **Mga Prayoridad na Konsepto**:  
  - Unified workflow architecture  
  - Decision trees para sa pagpili ng framework  
  - Validation ng pagiging handa para sa produksyon  
  - Mga estratehiya para sa future-proofing  

### Mga Tanong sa Pagsusuri sa Sarili  

1. Ihambing ang mga estratehiya sa quantization sa iba't ibang antas ng precision (1-bit hanggang 8-bit).  
2. Ipaliwanag ang mga benepisyo ng GGUF format para sa edge deployment.  
3. Paano pinapahusay ng hardware-aware optimization sa Microsoft Olive ang kahusayan ng deployment?  
4. Ano ang mga pangunahing benepisyo ng NNCF ng OpenVINO para sa compression ng modelo?  
5. Ilarawan kung paano ginagamit ng Apple MLX ang unified memory architecture para sa pag-optimize.  
6. Paano nakakatulong ang workflow synthesis sa pagpili ng optimal na optimization frameworks?  

### Mga Gawain sa Praktikal  

1. **Quantization ng Modelo**: Mag-apply ng iba't ibang antas ng quantization sa isang modelo at ihambing ang mga resulta (1 oras)  
2. **Pag-optimize gamit ang OpenVINO**: Gamitin ang NNCF upang i-compress ang isang modelo para sa Intel hardware (1 oras)  
3. **Paghahambing ng Framework**: Subukan ang parehong modelo sa tatlong magkaibang optimization frameworks (1 oras)  
4. **Pagsusuri ng Performance**: Sukatin ang epekto ng optimization sa bilis ng inference at paggamit ng memory (1 oras)  

## Module 5: SLMOps - Operasyon ng Small Language Model  

### Pangunahing Layunin ng Pag-aaral  

- Maunawaan ang mga prinsipyo ng lifecycle management ng SLMOps  
- Maging bihasa sa distillation at fine-tuning techniques para sa edge deployment  
- Mag-implement ng mga estratehiya sa produksyon ng deployment na may kasamang monitoring  
- Bumuo ng mga workflow para sa operasyon at maintenance ng SLM na pang-enterprise  

### Mga Pokus ng Pag-aaral  

#### Seksyon 1: Panimula sa SLMOps  
- **Mga Prayoridad na Konsepto**:  
  - Paradigm shift ng SLMOps sa AI operations  
  - Cost efficiency at privacy-first architecture  
  - Estratehikong epekto sa negosyo at mga competitive advantages  

#### Seksyon 2: Model Distillation  
- **Mga Prayoridad na Konsepto**:  
  - Teknik sa knowledge transfer  
  - Implementasyon ng two-stage distillation process  
  - Workflows ng Azure ML distillation  

#### Seksyon 3: Mga Estratehiya sa Fine-tuning  
- **Mga Prayoridad na Konsepto**:  
  - Parameter-efficient fine-tuning (PEFT)  
  - Mga advanced na pamamaraan ng LoRA at QLoRA  
  - Multi-adapter training at hyperparameter optimization  

#### Seksyon 4: Deployment sa Produksyon  
- **Mga Prayoridad na Konsepto**:  
  - Pag-convert at pag-quantize ng modelo para sa produksyon  
  - Configuration ng Foundry Local deployment  
  - Performance benchmarking at quality validation  

### Mga Tanong sa Pagsusuri sa Sarili  

1. Paano naiiba ang SLMOps sa tradisyunal na MLOps?  
2. Ipaliwanag ang mga benepisyo ng model distillation para sa edge deployment.  
3. Ano ang mga pangunahing konsiderasyon para sa fine-tuning ng SLMs sa mga kapaligirang limitado ang resources?  
4. Ilarawan ang isang kumpletong pipeline ng deployment para sa edge AI applications.  

### Mga Gawain sa Praktikal  

1. **Pangunahing Distillation**: Gumawa ng mas maliit na modelo mula sa mas malaking teacher model (1 oras)  
2. **Eksperimento sa Fine-tuning**: I-fine-tune ang isang modelo para sa isang partikular na domain (1 oras)  
3. **Pipeline ng Deployment**: Mag-set up ng basic CI/CD pipeline para sa deployment ng modelo (1 oras)  

## Module 6: SLM Agentic Systems - AI Agents at Function Calling  

### Pangunahing Layunin ng Pag-aaral  

- Bumuo ng matatalinong AI agents para sa edge environments gamit ang Small Language Models  
- Mag-implement ng function calling capabilities gamit ang systematic workflows  
- Maging bihasa sa Model Context Protocol (MCP) integration para sa standardized tool interaction  
- Gumawa ng mga sopistikadong agentic systems na may minimal na human intervention  

### Mga Pokus ng Pag-aaral  

#### Seksyon 1: AI Agents at SLM Foundations  
- **Mga Prayoridad na Konsepto**:  
  - Framework para sa classification ng agent (reflex, model-based, goal-based, learning agents)  
  - Pagsusuri ng trade-offs sa pagitan ng SLM at LLM  
  - Mga disenyo ng agent na partikular para sa edge  
  - Pag-optimize ng resources para sa mga agents  

#### Seksyon 2: Function Calling sa Small Language Models  
- **Mga Prayoridad na Konsepto**:  
  - Implementasyon ng systematic workflow (intent detection, JSON output, external execution)  
  - Mga implementasyon na partikular sa platform (Phi-4-mini, napiling Qwen models, Microsoft Foundry Local)  
  - Mga advanced na halimbawa (multi-agent collaboration, dynamic tool selection)  
  - Mga konsiderasyon sa produksyon (rate limiting, audit logging, security measures)  

#### Seksyon 3: Model Context Protocol (MCP) Integration  
- **Mga Prayoridad na Konsepto**:  
  - Arkitektura ng protocol at layered system design  
  - Suporta sa multi-backend (Ollama para sa development, vLLM para sa produksyon)  
  - Mga protocol ng koneksyon (STDIO at SSE modes)  
  - Mga aplikasyon sa totoong mundo (web automation, data processing, API integration)  

### Mga Tanong sa Pagsusuri sa Sarili  

1. Ano ang mga pangunahing konsiderasyon sa arkitektura para sa edge AI agents?  
2. Paano pinapahusay ng function calling ang kakayahan ng mga agents?  
3. Ipaliwanag ang papel ng Model Context Protocol sa komunikasyon ng agent.  

### Mga Gawain sa Praktikal  

1. **Simpleng Agent**: Gumawa ng basic AI agent na may function calling (1 oras)  
2. **MCP Integration**: Mag-implement ng MCP sa isang agent application (30 minuto)  

## Workshop: Landas sa Praktikal na Pag-aaral  

### Pangunahing Layunin ng Pag-aaral  

- Bumuo ng production-ready na AI applications gamit ang Foundry Local SDK at best practices  
- Mag-implement ng komprehensibong error handling at user feedback patterns  
- Gumawa ng RAG pipelines na may quality evaluation at performance monitoring  
- Bumuo ng multi-agent systems gamit ang coordinator patterns  
- Maging bihasa sa intelligent model routing para sa task-based na pagpili ng modelo  
- Mag-deploy ng local-first AI solutions na may privacy-preserving architectures  

### Pokus ng Pag-aaral  

#### Session 01: Pagsisimula sa Foundry Local  
- **Mga Prayoridad na Konsepto**:  
  - Integration ng FoundryLocalManager SDK at automatic service discovery  
  - Basic at streaming chat implementations  
  - Mga pattern sa error handling at user feedback  
  - Configuration batay sa environment  

#### Session 02: Pagbuo ng AI Solutions gamit ang RAG  
- **Mga Prayoridad na Konsepto**:  
  - In-memory vector embeddings gamit ang sentence-transformers  
  - Implementasyon ng RAG pipeline (retrieve → generate)  
  - Quality evaluation gamit ang RAGAS metrics  
  - Import safety para sa mga optional dependencies  

#### Session 03: Mga Open Source Models  
- **Mga Prayoridad na Konsepto**:  
  - Mga estratehiya sa multi-model benchmarking  
  - Pagsukat ng latency at throughput  
  - Graceful degradation at error recovery  
  - Paghahambing ng performance sa iba't ibang pamilya ng modelo  

#### Session 04: Mga Cutting-Edge Models  
- **Mga Prayoridad na Konsepto**:  
  - Metodolohiya sa paghahambing ng SLM at LLM  
  - Type hints at komprehensibong output formatting  
  - Per-model error handling  
  - Structured results para sa pagsusuri  

#### Session 05: Mga AI-Powered Agents  
- **Mga Prayoridad na Konsepto**:  
  - Multi-agent orchestration gamit ang coordinator pattern  
  - Pamamahala ng memory ng agent at state tracking  
  - Error handling sa pipeline at stage logging  
  - Performance monitoring at statistics  

#### Session 06: Mga Modelo bilang Tools  
- **Mga Prayoridad na Konsepto**:  
  - Intent detection at pattern matching  
  - Mga algorithm sa keyword-based na model routing  
  - Multi-step pipelines (plan → execute → refine)  
  - Komprehensibong dokumentasyon ng function  

### Mga Tanong sa Pagsusuri sa Sarili  

1. Paano pinapasimple ng FoundryLocalManager ang service management kumpara sa manual REST calls?  
2. Ipaliwanag ang kahalagahan ng import guards para sa mga optional dependencies tulad ng sentence-transformers.  
3. Anong mga estratehiya ang nakasisiguro ng graceful degradation sa multi-model benchmarking?  
4. Paano ino-orchestrate ng coordinator pattern ang maraming specialist agents?  
5. Ilarawan ang mga bahagi ng isang intelligent model router.  
6. Ano ang mga pangunahing elemento ng production-ready na error handling?  

### Mga Gawain sa Praktikal  

1. **Chat Application**: Mag-implement ng streaming chat na may error handling (45 minuto)  
2. **RAG Pipeline**: Gumawa ng minimal na RAG na may quality evaluation (1 oras)  
3. **Model Benchmarking**: Ihambing ang 3+ na modelo sa performance (1 oras)  
4. **Multi-Agent System**: Gumawa ng coordinator na may 2 specialist agents (1.5 oras)  
5. **Intelligent Router**: Gumawa ng task-based na pagpili ng modelo (1 oras)  
6. **Production Deployment**: Magdagdag ng monitoring at komprehensibong error handling (45 minuto)  

### Alokasyon ng Oras  

**Concentrated Learning (1 linggo)**:  
- Araw 1: Session 01-02 (Chat + RAG) - 3 oras  
- Araw 2: Session 03-04 (Benchmarking + Paghahambing) - 3 oras  
- Araw 3: Session 05-06 (Agents + Routing) - 3 oras  
- Araw 4: Mga praktikal na gawain at validation - 2 oras  

**Part-time Study (2 linggo)**:  
- Linggo 1: Sessions 01-03 (6 oras kabuuan)  
- Linggo 2: Sessions 04-06 + mga gawain (5 oras kabuuan)  

## Module 7: Mga Halimbawa ng Implementasyon ng EdgeAI  

### Pangunahing Layunin ng Pag-aaral  

- Maging bihasa sa AI Toolkit para sa Visual Studio Code para sa komprehensibong EdgeAI development workflows  
- Magkaroon ng kaalaman sa Windows AI Foundry platform at mga estratehiya sa NPU optimization  
- Mag-implement ng EdgeAI sa iba't ibang hardware platforms at deployment scenarios  
- Bumuo ng production-ready na EdgeAI applications na may platform-specific optimizations  

### Mga Pokus ng Pag-aaral  

#### Seksyon 1: AI Toolkit para sa Visual Studio Code  
- **Mga Prayoridad na Konsepto**:  
  - Komprehensibong Edge AI development environment sa loob ng VS Code  
  - Model catalog at discovery para sa edge deployment  
  - Lokal na testing, optimization, at agent development workflows  
  - Performance monitoring at evaluation para sa edge scenarios  

#### Seksyon 2: Gabay sa Windows EdgeAI Development  
- **Mga Prayoridad na Konsepto**:  
  - Komprehensibong overview ng Windows AI Foundry platform  
  - Phi Silica API para sa efficient NPU inference  
  - Computer Vision APIs para sa image processing at OCR  
  - Foundry Local CLI para sa lokal na development at testing  

#### Seksyon 3: Mga Implementasyon na Partikular sa Platform  
- **Mga Prayoridad na Konsepto**:  
  - Deployment sa NVIDIA Jetson Orin Nano (67 TOPS AI performance)  
  - Mga mobile application gamit ang .NET MAUI at ONNX Runtime GenAI  
  - Mga solusyon ng Azure EdgeAI na may cloud-edge hybrid architecture  
  - Pag-optimize ng Windows ML na may universal hardware support  
  - Mga aplikasyon ng Foundry Local na may privacy-focused RAG implementation  

### Mga Tanong sa Pagsusuri sa Sarili  

1. Paano pinapasimple ng AI Toolkit ang workflow ng EdgeAI development?  
2. Ihambing ang mga estratehiya sa deployment sa iba't ibang hardware platforms.  
3. Ano ang mga benepisyo ng Windows AI Foundry para sa edge development?  
4. Ipaliwanag ang papel ng NPU optimization sa mga modernong aplikasyon ng edge AI.  
5. Paano ginagamit ng Phi Silica API ang NPU hardware para sa pag-optimize ng performance?  
6. Ihambing ang mga benepisyo ng lokal kumpara sa cloud deployment para sa mga aplikasyon na sensitibo sa privacy.  

### Mga Praktikal na Gawain  

1. **AI Toolkit Setup**: I-configure ang AI Toolkit at i-optimize ang isang modelo (1 oras)  
2. **Windows AI Foundry**: Gumawa ng simpleng Windows AI application gamit ang Phi Silica API (1 oras)  
3. **Cross-Platform Deployment**: I-deploy ang parehong modelo sa dalawang magkaibang platform (1 oras)  
4. **NPU Optimization**: Subukan ang performance ng NPU gamit ang Windows AI Foundry tools (30 minuto)  

## Module 8: Microsoft Foundry Local – Kumpletong Toolkit para sa Developer (Modernisado)  

### Mga Pangunahing Layunin sa Pagkatuto  

- I-install at i-configure ang Foundry Local gamit ang modernong SDK integration  
- Magpatupad ng advanced multi-agent systems gamit ang coordinator patterns  
- Gumawa ng intelligent model routers na may automatic task-based selection  
- Mag-deploy ng production-ready AI solutions na may komprehensibong monitoring  
- Mag-integrate sa Azure AI Foundry para sa hybrid deployment scenarios  
- Masterin ang modernong SDK patterns gamit ang FoundryLocalManager at OpenAI client  

### Mga Pokus na Lugar sa Pag-aaral  

#### Seksyon 1: Modernong Pag-install at Konfigurasyon  
- **Mga Priority Concepts**:  
  - FoundryLocalManager SDK integration  
  - Automatic service discovery at health monitoring  
  - Mga pattern sa konfigurasyon batay sa environment  
  - Mga konsiderasyon sa production deployment  

#### Seksyon 2: Advanced Multi-Agent Systems  
- **Mga Priority Concepts**:  
  - Coordinator pattern gamit ang specialist agents  
  - Retrieval, reasoning, at execution agent specialization  
  - Mga mekanismo ng feedback loop para sa refinement  
  - Performance monitoring at statistics tracking  

#### Seksyon 3: Intelligent Model Routing  
- **Mga Priority Concepts**:  
  - Mga algorithm sa keyword-based model selection  
  - Suporta sa maraming modelo (general, reasoning, code, creative)  
  - Konfigurasyon ng environment variable para sa flexibility  
  - Service health checking at error handling  

#### Seksyon 4: Production-Ready Implementation  
- **Mga Priority Concepts**:  
  - Komprehensibong error handling at fallback mechanisms  
  - Request monitoring at performance tracking  
  - Mga interactive na halimbawa sa Jupyter notebook na may benchmarks  
  - Mga pattern ng integration sa umiiral na mga aplikasyon  

### Mga Tanong sa Self-Assessment  

1. Paano naiiba ang modernong FoundryLocalManager approach sa manual REST calls?  
2. Ipaliwanag ang coordinator pattern at kung paano nito inaayos ang mga specialist agents.  
3. Paano pinipili ng intelligent router ang tamang modelo batay sa nilalaman ng query?  
4. Ano ang mga pangunahing bahagi ng isang production-ready AI agent system?  
5. Paano mo ipapatupad ang komprehensibong health monitoring para sa Foundry Local services?  
6. Ihambing ang mga benepisyo ng modernisadong approach kumpara sa tradisyunal na mga pattern ng implementasyon.  

### Mga Praktikal na Gawain  

1. **Modern SDK Setup**: I-configure ang FoundryLocalManager gamit ang automatic service discovery (30 minuto)  
2. **Multi-Agent System**: Patakbuhin ang advanced coordinator gamit ang specialist agents (30 minuto)  
3. **Intelligent Routing**: Subukan ang model router gamit ang iba't ibang uri ng query (30 minuto)  
4. **Interactive Exploration**: Gamitin ang Jupyter notebooks para tuklasin ang mga advanced na tampok (45 minuto)  
5. **Production Deployment**: Magpatupad ng monitoring at error handling patterns (30 minuto)  
6. **Hybrid Integration**: I-configure ang Azure AI Foundry fallback scenarios (30 minuto)  

## Gabay sa Alokasyon ng Oras  

Para matulungan kang masulit ang 30-oras na kurso (kasama ang Workshop), narito ang isang mungkahing breakdown ng oras:  

| Aktibidad | Alokasyon ng Oras | Deskripsyon |  
|----------|----------------|-------------|  
| Pagbabasa ng Core Materials | 12 oras | Pagtuon sa mahahalagang konsepto sa bawat module |  
| Mga Praktikal na Gawain | 10 oras | Praktikal na implementasyon ng mga pangunahing teknik (kasama ang Workshop) |  
| Self-Assessment | 3 oras | Pagsusuri ng iyong pag-unawa sa pamamagitan ng mga tanong at pagninilay |  
| Mini-Project | 5 oras | Paglalapat ng kaalaman sa isang maliit na praktikal na implementasyon |  

### Mga Pokus na Lugar Batay sa Oras  

**Kung mayroon ka lamang 10 oras:**  
- Kumpletuhin ang Module 0 (Introduction) at Modules 1, 2, at 3 (mga pangunahing konsepto ng EdgeAI)  
- Gumawa ng hindi bababa sa isang praktikal na gawain bawat module  
- Magtuon sa pag-unawa sa mga pangunahing konsepto kaysa sa mga detalye ng implementasyon  

**Kung maaari kang maglaan ng buong 20 oras:**  
- Kumpletuhin ang lahat ng walong module (kasama ang Introduction)  
- Gawin ang mga pangunahing praktikal na gawain mula sa bawat module  
- Kumpletuhin ang isang mini-project mula sa Module 7  
- Tuklasin ang hindi bababa sa 2-3 karagdagang resources  

**Kung mayroon kang higit sa 20 oras:**  
- Kumpletuhin ang lahat ng module (kasama ang Introduction) na may detalyadong mga gawain  
- Gumawa ng maraming mini-projects  
- Tuklasin ang mga advanced optimization techniques sa Module 4  
- Magpatupad ng production deployment mula sa Module 5  

## Mahahalagang Resources  

Ang mga maingat na piniling resources na ito ay nagbibigay ng pinakamalaking halaga para sa iyong limitadong oras ng pag-aaral:  

### Dokumentasyong Dapat Basahin  
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Ang pinaka-epektibong tool para sa model optimization  
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Pinakamabilis na paraan para mag-deploy ng SLMs nang lokal  
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Reference para sa isang nangungunang edge-optimized model  
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Komprehensibong optimization toolkit ng Intel  
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Integrated EdgeAI development environment  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows-specific EdgeAI development platform  

### Mga Tools na Nakakatipid ng Oras  
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Mabilis na access at deployment ng modelo  
- [Gradio](https://www.gradio.app/docs/interface) - Mabilis na UI development para sa AI demos  
- [Microsoft Olive](https://github.com/microsoft/Olive) - Pinadaling model optimization  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Epektibong CPU inference  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Neural network compression framework  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Toolkit para sa deployment ng large language models  

## Template sa Pagsubaybay ng Progreso  

Gamitin ang simpleng template na ito para subaybayan ang iyong progreso sa 20-oras na kurso:  

| Module | Petsa ng Pagkumpleto | Oras na Ginugol | Mga Pangunahing Natutunan |  
|--------|----------------|-------------|---------------|  
| Module 0: Introduction to EdgeAI | | | |  
| Module 1: EdgeAI Fundamentals | | | |  
| Module 2: SLM Foundations | | | |  
| Module 3: SLM Deployment | | | |  
| Module 4: Model Optimization | | | |  
| Module 5: SLMOps | | | |  
| Module 6: AI Agents | | | |  
| Module 7: Development Tools | | | |  
| Workshop: Hands-On Learning | | | |  
| Module 8: Foundry Local Toolkit | | | |  
| Mga Praktikal na Gawain | | | |  
| Mini-Project | | | |  

## Mga Ideya para sa Mini Project  

Isaalang-alang ang pagkumpleto ng isa sa mga proyektong ito upang maisagawa ang mga konsepto ng EdgeAI (bawat isa ay idinisenyo upang tumagal ng 2-4 na oras):  

### Mga Proyekto para sa Baguhan (2-3 oras bawat isa)  
1. **Edge Text Assistant**: Gumawa ng simpleng offline text completion tool gamit ang isang maliit na language model  
2. **Model Comparison Dashboard**: Gumawa ng basic visualization ng performance metrics sa iba't ibang SLMs  
3. **Optimization Experiment**: Sukatin ang epekto ng iba't ibang antas ng quantization sa parehong base model  

### Mga Proyekto para sa Intermediate (3-4 oras bawat isa)  
4. **AI Toolkit Workflow**: Gamitin ang VS Code AI Toolkit upang i-optimize at i-deploy ang isang modelo mula simula hanggang matapos  
5. **Windows AI Foundry Application**: Gumawa ng Windows app gamit ang Phi Silica API at NPU optimization  
6. **Cross-Platform Deployment**: I-deploy ang parehong optimized model sa Windows (OpenVINO) at mobile (.NET MAUI)  
7. **Function Calling Agent**: Gumawa ng AI agent na may function calling capabilities para sa edge scenarios  

### Mga Proyekto para sa Advanced Integration (4-5 oras bawat isa)  
8. **OpenVINO Optimization Pipeline**: Magpatupad ng kumpletong model optimization gamit ang NNCF at GenAI toolkit  
9. **SLMOps Pipeline**: Magpatupad ng kumpletong lifecycle ng modelo mula training hanggang edge deployment  
10. **Multi-Model Edge System**: Mag-deploy ng maraming specialized models na nagtutulungan sa edge hardware  
11. **MCP Integration System**: Gumawa ng agentic system gamit ang Model Context Protocol para sa tool interaction  

## Mga Sanggunian  

- Microsoft Learn (Foundry Local)  
  - Overview: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/  
  - Get started: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started  
  - CLI reference: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli  
  - Integrate with inference SDKs: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks  
  - Open WebUI how-to: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui  
  - Compile Hugging Face models: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models  
- Azure AI Foundry  
  - Overview: https://learn.microsoft.com/en-us/azure/ai-foundry/  
  - Agents (overview): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview  
- Optimization and Inference Tooling  
  - Microsoft Olive (docs): https://microsoft.github.io/Olive/  
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive  
  - ONNX Runtime (getting started): https://onnxruntime.ai/docs/get-started/with-python.html  
  - ONNX Runtime Olive integration: https://onnxruntime.ai/docs/performance/olive.html  
  - OpenVINO (docs): https://docs.openvino.ai/2025/index.html  
  - Apple MLX (docs): https://ml-explore.github.io/mlx/build/html/index.html  
- Deployment Frameworks and Models  
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp  
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index  
  - vLLM (docs): https://docs.vllm.ai/  
  - Ollama (quick start): https://github.com/ollama/ollama#get-started  
- Developer Tools (Windows and VS Code)  
  - AI Toolkit for VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview  
  - Windows ML (overview): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview  

## Komunidad ng Pagkatuto  

Sumali sa talakayan at makipag-ugnayan sa mga kapwa mag-aaral:  
- GitHub Discussions sa [EdgeAI for Beginners repository](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## Konklusyon  

Ang EdgeAI ay kumakatawan sa hangganan ng implementasyon ng artificial intelligence, na nagdadala ng makapangyarihang kakayahan nang direkta sa mga device habang tinutugunan ang mahahalagang isyu tungkol sa privacy, latency, at connectivity. Ang 20-oras na kursong ito ay nagbibigay sa iyo ng mahahalagang kaalaman at praktikal na kasanayan upang agad na magsimula sa paggamit ng mga teknolohiya ng EdgeAI.  

Ang kurso ay sadyang maikli at nakatuon sa pinakamahalagang konsepto, na nagbibigay-daan sa iyo upang mabilis na makakuha ng mahalagang kaalaman nang hindi nangangailangan ng labis na oras. Tandaan na ang praktikal na pagsasanay, kahit na sa mga simpleng halimbawa, ang susi sa pagpapalakas ng iyong natutunan.  

Masayang pag-aaral!  

---

**Paunawa**:  
Ang dokumentong ito ay isinalin gamit ang AI translation service na [Co-op Translator](https://github.com/Azure/co-op-translator). Bagama't sinisikap naming maging tumpak, pakitandaan na ang mga awtomatikong pagsasalin ay maaaring maglaman ng mga pagkakamali o hindi pagkakatugma. Ang orihinal na dokumento sa orihinal nitong wika ang dapat ituring na opisyal na sanggunian. Para sa mahalagang impormasyon, inirerekomenda ang propesyonal na pagsasalin ng tao. Hindi kami mananagot sa anumang hindi pagkakaunawaan o maling interpretasyon na dulot ng paggamit ng pagsasaling ito.