<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e94a6b6e8c8f3f9c881b7d6222cd9c6b",
  "translation_date": "2025-09-22T22:30:54+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "tl"
}
-->
# EdgeAI para sa mga Baguhan: Mga Landas ng Pag-aaral at Iskedyul ng Pag-aaral

### Konsentradong Landas ng Pag-aaral (1 linggo)

| Araw | Pokus | Tinatayang Oras |
|------|-------|------------------|
| Araw 1 | Module 1: Mga Pangunahing Kaalaman sa EdgeAI | 3 oras |
| Araw 2 | Module 2: Mga Batayan ng SLM | 3 oras |
| Araw 3 | Module 3: Deployment ng SLM | 2 oras |
| Araw 4-5 | Module 4: Pag-optimize ng Modelo (6 na framework) | 4 oras |
| Araw 6 | Module 5: SLMOps | 3 oras |
| Araw 7 | Module 6-7: AI Agents at Mga Kagamitang Pang-develop | 5 oras |

### Konsentradong Landas ng Pag-aaral (2 linggo)

| Araw | Pokus | Tinatayang Oras |
|------|-------|------------------|
| Araw 1-2 | Module 1: Mga Pangunahing Kaalaman sa EdgeAI | 3 oras |
| Araw 3-4 | Module 2: Mga Batayan ng SLM | 3 oras |
| Araw 5-6 | Module 3: Deployment ng SLM | 2 oras |
| Araw 7-8 | Module 4: Pag-optimize ng Modelo | 4 oras |
| Araw 9-10 | Module 5: SLMOps | 3 oras |
| Araw 11-12 | Module 6: AI Agents | 2 oras |
| Araw 13-14 | Module 7: Mga Kagamitang Pang-develop | 3 oras |

### Part-time na Pag-aaral (4 na linggo)

| Linggo | Pokus | Tinatayang Oras |
|------|-------|------------------|
| Linggo 1 | Module 1-2: Mga Pangunahing Kaalaman at Mga Batayan ng SLM | 6 oras |
| Linggo 2 | Module 3-4: Deployment at Pag-optimize | 6 oras |
| Linggo 3 | Module 5-6: SLMOps at AI Agents | 5 oras |
| Linggo 4 | Module 7: Mga Kagamitang Pang-develop at Integrasyon | 3 oras |

| Araw | Pokus | Tinatayang Oras |
|------|-------|------------------|
| Araw 1-2 | Module 1: Mga Pangunahing Kaalaman sa EdgeAI | 3 oras |
| Araw 3-4 | Module 2: Mga Batayan ng SLM | 3 oras |
| Araw 5-6 | Module 3: Deployment ng SLM | 2 oras |
| Araw 7-8 | Module 4: Pag-optimize ng Modelo | 4 oras |
| Araw 9-10 | Module 5: SLMOps | 3 oras |
| Araw 11-12 | Module 6: Mga Sistemang SLM Agentic | 2 oras |
| Araw 13-14 | Module 7: Mga Halimbawa ng Implementasyon ng EdgeAI | 2 oras |

| Module | Petsa ng Pagkumpleto | Oras na Ginugol | Mahahalagang Natutunan |
|--------|----------------|-------------|--------------|
| Module 1: Mga Pangunahing Kaalaman sa EdgeAI | | | |
| Module 2: Mga Batayan ng SLM | | | |
| Module 3: Deployment ng SLM | | | |
| Module 4: Pag-optimize ng Modelo (6 na framework) | | | |
| Module 5: SLMOps | | | |
| Module 6: Mga Sistemang SLM Agentic | | | |
| Module 7: Mga Halimbawa ng Implementasyon ng EdgeAI | | | |
| Mga Hands-on na Ehersisyo | | | |
| Mini-Project | | | |

### Part-time na Pag-aaral (4 na linggo)

| Linggo | Pokus | Tinatayang Oras |
|------|-------|------------------|
| Linggo 1 | Module 1-2: Mga Pangunahing Kaalaman at Mga Batayan ng SLM | 6 oras |
| Linggo 2 | Module 3-4: Deployment at Pag-optimize | 6 oras |
| Linggo 3 | Module 5-6: SLMOps at AI Agents | 5 oras |
| Linggo 4 | Module 7: Mga Kagamitang Pang-develop at Integrasyon | 3 oras |

## Panimula

Maligayang pagdating sa gabay sa pag-aaral ng EdgeAI para sa mga Baguhan! Ang dokumentong ito ay idinisenyo upang tulungan kang mag-navigate sa mga materyales ng kurso nang epektibo at mapakinabangan ang iyong karanasan sa pag-aaral. Nagbibigay ito ng mga istrukturadong landas ng pag-aaral, mga mungkahing iskedyul ng pag-aaral, mga buod ng mahahalagang konsepto, at mga karagdagang mapagkukunan upang palalimin ang iyong pag-unawa sa mga teknolohiya ng EdgeAI.

Ito ay isang maikling 20-oras na kurso na naghahatid ng mahahalagang kaalaman tungkol sa EdgeAI sa isang epektibong format, na perpekto para sa mga abalang propesyonal at estudyante na nais mabilis na makakuha ng praktikal na kasanayan sa umuusbong na larangang ito.

## Pangkalahatang-ideya ng Kurso

Ang kurso na ito ay inayos sa pitong komprehensibong module:

1. **Mga Pangunahing Kaalaman at Transformasyon ng EdgeAI** - Pag-unawa sa mga pangunahing konsepto at pagbabago sa teknolohiya
2. **Mga Batayan ng Small Language Model (SLM)** - Paggalugad sa iba't ibang pamilya ng SLM at kanilang mga arkitektura
3. **Deployment ng Small Language Model** - Pagpapatupad ng mga praktikal na estratehiya sa deployment
4. **Pag-convert ng Format ng Modelo at Quantization** - Advanced na pag-optimize gamit ang 6 na framework kabilang ang OpenVINO
5. **SLMOps - Mga Operasyon ng Small Language Model** - Pamamahala sa lifecycle ng produksyon at deployment
6. **Mga Sistemang SLM Agentic** - AI agents, function calling, at Model Context Protocol
7. **Mga Halimbawa ng Implementasyon ng EdgeAI** - AI Toolkit, Windows development, at mga implementasyon na partikular sa platform
8. **Microsoft Foundry Local – Kumpletong Toolkit ng Developer** - Lokal na development na may hybrid Azure integration (Module 08)

## Paano Gamitin ang Gabay sa Pag-aaral na Ito

- **Progressive Learning**: Sundin ang mga module nang sunod-sunod para sa pinakakohesibong karanasan sa pag-aaral
- **Knowledge Checkpoints**: Gamitin ang mga tanong sa self-assessment pagkatapos ng bawat seksyon
- **Hands-on Practice**: Kumpletuhin ang mga mungkahing ehersisyo upang mapalakas ang mga teoretikal na konsepto
- **Supplementary Resources**: Galugarin ang mga karagdagang materyales para sa mga paksang pinaka-interesado ka

## Mga Rekomendasyon sa Iskedyul ng Pag-aaral

### Konsentradong Landas ng Pag-aaral (1 linggo)

| Araw | Pokus | Tinatayang Oras |
|------|-------|-----------------|
| Araw 1-2 | Module 1: Mga Pangunahing Kaalaman sa EdgeAI | 6 oras |
| Araw 3-4 | Module 2: Mga Batayan ng SLM | 8 oras |
| Araw 5 | Module 3: Deployment ng SLM | 3 oras |
| Araw 6 | Module 8: Foundry Local Toolkit | 3 oras |

### Part-time na Pag-aaral (3 linggo)

| Linggo | Pokus | Tinatayang Oras |
|------|-------|-----------------|
| Linggo 1 | Module 1: Mga Pangunahing Kaalaman sa EdgeAI | 6-7 oras |
| Linggo 2 | Module 2: Mga Batayan ng SLM | 7-8 oras |
| Linggo 3 | Module 3: Deployment ng SLM (3h) + Module 8: Foundry Local Toolkit (2-3h) | 5-6 oras |

## Module 1: Mga Pangunahing Kaalaman at Transformasyon ng EdgeAI

### Mga Layunin sa Pag-aaral

- Maunawaan ang mga pagkakaiba sa pagitan ng cloud-based at edge-based na AI
- Masterin ang mga pangunahing teknik sa pag-optimize para sa mga environment na may limitadong resources
- Suriin ang mga aplikasyon ng EdgeAI sa totoong mundo
- Mag-set up ng development environment para sa mga proyekto ng EdgeAI

### Mga Pokus na Lugar ng Pag-aaral

#### Seksyon 1: Mga Pangunahing Kaalaman sa EdgeAI
- **Mga Priority Concept**: 
  - Paradigm ng Edge vs. Cloud computing
  - Teknik sa model quantization
  - Mga opsyon sa hardware acceleration (NPUs, GPUs, CPUs)
  - Mga benepisyo sa privacy at seguridad

- **Mga Karagdagang Materyales**:
  - [TensorFlow Lite Documentation](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse Documentation](https://docs.edgeimpulse.com)

#### Seksyon 2: Mga Case Study sa Totoong Mundo
- **Mga Priority Concept**: 
  - Microsoft Phi & Mu model ecosystem
  - Mga praktikal na implementasyon sa iba't ibang industriya
  - Mga konsiderasyon sa deployment

#### Seksyon 3: Gabay sa Praktikal na Implementasyon
- **Mga Priority Concept**: 
  - Pag-set up ng development environment
  - Mga tool sa quantization at optimization
  - Mga pamamaraan sa pagsusuri para sa mga implementasyon ng EdgeAI

#### Seksyon 4: Hardware para sa Edge Deployment
- **Mga Priority Concept**: 
  - Paghahambing ng mga platform ng hardware
  - Mga estratehiya sa pag-optimize para sa partikular na hardware
  - Mga konsiderasyon sa deployment

### Mga Tanong sa Self-Assessment

1. Ihambing at kontrast ang cloud-based na AI sa edge-based na mga implementasyon ng AI.
2. Ipaliwanag ang tatlong pangunahing teknik para sa pag-optimize ng mga modelo para sa edge deployment.
3. Ano ang mga pangunahing benepisyo ng pagpapatakbo ng mga modelo ng AI sa edge?
4. Ilarawan ang proseso ng pag-quantize ng isang modelo at kung paano ito nakakaapekto sa performance.
5. Ipaliwanag kung paano nakakaapekto ang iba't ibang hardware accelerators (NPUs, GPUs, CPUs) sa deployment ng EdgeAI.

### Mga Hands-on na Ehersisyo

1. **Quick Environment Setup**: Mag-configure ng minimal na development environment na may mga essential na package (30 minuto)
2. **Model Exploration**: Mag-download at suriin ang isang pre-trained na small language model (1 oras)
3. **Basic Quantization**: Subukan ang simpleng quantization sa isang maliit na modelo (1 oras)

## Module 2: Mga Batayan ng Small Language Model

### Mga Layunin sa Pag-aaral

- Maunawaan ang mga prinsipyo ng arkitektura ng iba't ibang pamilya ng SLM
- Ihambing ang kakayahan ng mga modelo sa iba't ibang parameter scale
- Suriin ang mga modelo batay sa efficiency, capability, at mga kinakailangan sa deployment
- Kilalanin ang mga angkop na use case para sa iba't ibang pamilya ng modelo

### Mga Pokus na Lugar ng Pag-aaral

#### Seksyon 1: Microsoft Phi Model Family
- **Mga Priority Concept**: 
  - Ebolusyon ng design philosophy
  - Efficiency-first na arkitektura
  - Mga espesyal na kakayahan

#### Seksyon 2: Qwen Family
- **Mga Priority Concept**: 
  - Mga kontribusyon sa open source
  - Mga opsyon sa scalable deployment
  - Advanced na arkitektura sa reasoning

#### Seksyon 3: Gemma Family
- **Mga Priority Concept**: 
  - Innovation na pinangungunahan ng research
  - Multimodal na kakayahan
  - Mobile optimization

#### Seksyon 4: BitNET Family
- **Mga Priority Concept**: 
  - Teknolohiya sa 1-bit quantization
  - Framework sa inference optimization
  - Mga konsiderasyon sa sustainability

#### Seksyon 5: Microsoft Mu Model
- **Mga Priority Concept**: 
  - Device-first na arkitektura
  - Integrasyon ng sistema sa Windows
  - Privacy-preserving na operasyon

#### Seksyon 6: Phi-Silica
- **Mga Priority Concept**: 
  - NPU-optimized na arkitektura
  - Mga performance metrics
  - Integrasyon ng developer

### Mga Tanong sa Self-Assessment

1. Ihambing ang mga arkitektural na approach ng Phi at Qwen model families.
2. Ipaliwanag kung paano naiiba ang teknolohiya ng quantization ng BitNET sa tradisyunal na quantization.
3. Ano ang mga natatanging benepisyo ng Mu model para sa integrasyon sa Windows?
4. Ilarawan kung paano ginagamit ng Phi-Silica ang NPU hardware para sa performance optimization.
5. Para sa isang mobile application na may limitadong connectivity, aling pamilya ng modelo ang pinakaangkop at bakit?

### Mga Hands-on na Ehersisyo

1. **Model Comparison**: Mabilis na benchmark ng dalawang magkaibang SLM models (1 oras)
2. **Simple Text Generation**: Pangunahing implementasyon ng text generation gamit ang isang maliit na modelo (1 oras)
3. **Fast Optimization**: Mag-apply ng isang teknik sa optimization upang mapabuti ang inference speed (1 oras)

## Module 3: Deployment ng Small Language Model

### Mga Layunin sa Pag-aaral

- Pumili ng angkop na mga modelo batay sa mga limitasyon sa deployment
- Masterin ang mga teknik sa pag-optimize para sa iba't ibang deployment scenarios
- Magpatupad ng SLMs sa parehong lokal at cloud environments
- Magdisenyo ng mga production-ready na configuration para sa mga aplikasyon ng EdgeAI

### Mga Pokus na Lugar ng Pag-aaral

#### Seksyon 1: Advanced na Pag-aaral ng SLM
- **Mga Priority Concept**: 
  - Framework sa parameter classification
  - Advanced na mga teknik sa optimization
  - Mga estratehiya sa pagkuha ng modelo

#### Seksyon 2: Deployment sa Lokal na Environment
- **Mga Priority Concept**: 
  - Deployment sa Ollama platform
  - Mga solusyon ng Microsoft Foundry local
  - Paghahambing ng mga framework

#### Seksyon 3: Containerized na Deployment sa Cloud
- **Mga Priority Concept**: 
  - vLLM high-performance inference
  - Container orchestration
  - Implementasyon ng ONNX Runtime

### Mga Tanong sa Self-Assessment

1. Anong mga salik ang dapat isaalang-alang kapag pumipili sa pagitan ng lokal na deployment at cloud deployment?
2. Ihambing ang Ollama at Microsoft Foundry Local bilang mga opsyon sa deployment.
3. Ipaliwanag ang mga benepisyo ng containerization para sa deployment ng SLM.
4. Ano ang mga pangunahing performance metrics na dapat i-monitor para sa isang edge-deployed na SLM?
5. Ilarawan ang isang kumpletong workflow ng deployment mula sa pagpili ng modelo hanggang sa implementasyon sa produksyon.

### Mga Hands-on na Ehersisyo

1. **Basic Local Deployment**: Mag-deploy ng simpleng SLM gamit ang Ollama (1 oras)
2. **Performance Check**: Magpatakbo ng mabilis na benchmark sa iyong na-deploy na modelo (30 minuto)
3. **Simple Integration**: Gumawa ng minimal na application na gumagamit ng iyong na-deploy na modelo (1 oras)

## Module 4: Pag-convert ng Format ng Modelo at Quantization

### Mga Layunin sa Pag-aaral

- Masterin ang advanced na mga teknik sa quantization mula 1-bit hanggang 8-bit precision
- Maunawaan ang mga estratehiya sa pag-convert ng format (GGUF, ONNX)
- Magpatupad ng optimization sa anim na framework (Llama.cpp, Olive, OpenVINO, MLX, workflow synthesis)
- Mag-deploy ng mga optimized na modelo para sa production edge environments sa Intel, Apple, at cross-platform hardware

### Mga Pokus na Lugar ng Pag-aaral

#### Seksyon 1: Mga Batayan ng Quantization
- **Mga Priority Concept**: 
  - Framework sa precision classification
  - Trade-offs sa performance vs. accuracy
  - Optimization ng memory footprint

#### Seksyon 2: Implementasyon ng Llama.cpp
- **Mga Priority Concept**: 
  - Deployment sa cross-platform
  - Optimization ng GGUF format
  - Teknik sa hardware acceleration

#### Seksyon 3: Microsoft Olive Suite
- **Mga Priority Concept**: 
  - Optimization na aware sa hardware
  - Deployment na pang-enterprise
  - Automated na mga workflow sa optimization

#### Seksyon 4: OpenVINO Toolkit
- **Mga Priority Concept**: 
  - Optimization sa Intel hardware
  - Neural Network Compression Framework (NNCF)
  - Deployment ng inference sa cross-platform
  - OpenVINO GenAI para sa deployment ng LLM

#### Seksyon 5: Apple MLX Framework
- **Mga Konseptong Prayoridad**:  
  - Pag-optimize para sa Apple Silicon  
  - Arkitektura ng unified memory  
  - Kakayahan sa LoRA fine-tuning  

#### Seksyon 6: Sintesis ng Workflow para sa Edge AI Development  
- **Mga Konseptong Prayoridad**:  
  - Unified workflow architecture  
  - Mga desisyon sa pagpili ng framework  
  - Pagpapatunay ng kahandaan para sa produksyon  
  - Mga estratehiya para sa future-proofing  

### Mga Tanong para sa Pagsusuri sa Sarili  

1. Ihambing ang mga estratehiya sa quantization sa iba't ibang antas ng precision (1-bit hanggang 8-bit).  
2. Ipaliwanag ang mga benepisyo ng GGUF format para sa edge deployment.  
3. Paano pinapahusay ng hardware-aware optimization sa Microsoft Olive ang kahusayan ng deployment?  
4. Ano ang mga pangunahing benepisyo ng NNCF ng OpenVINO para sa compression ng modelo?  
5. Ilarawan kung paano ginagamit ng Apple MLX ang unified memory architecture para sa optimization.  
6. Paano nakakatulong ang workflow synthesis sa pagpili ng optimal na optimization frameworks?  

### Mga Gawain sa Praktikal  

1. **Model Quantization**: Mag-apply ng iba't ibang antas ng quantization sa isang modelo at ihambing ang mga resulta (1 oras)  
2. **OpenVINO Optimization**: Gumamit ng NNCF para i-compress ang isang modelo para sa Intel hardware (1 oras)  
3. **Paghahambing ng Framework**: Subukan ang parehong modelo sa tatlong magkaibang optimization frameworks (1 oras)  
4. **Performance Benchmarking**: Sukatin ang epekto ng optimization sa bilis ng inference at paggamit ng memorya (1 oras)  

## Module 5: SLMOps - Operasyon para sa Maliit na Language Model  

### Mga Layunin sa Pagkatuto  

- Maunawaan ang mga prinsipyo ng lifecycle management ng SLMOps  
- Maging bihasa sa distillation at fine-tuning techniques para sa edge deployment  
- Magpatupad ng mga estratehiya sa deployment para sa produksyon na may monitoring  
- Bumuo ng workflows para sa operasyon at maintenance ng enterprise-grade SLM  

### Mga Pokus na Lugar sa Pag-aaral  

#### Seksyon 1: Panimula sa SLMOps  
- **Mga Konseptong Prayoridad**:  
  - Paradigm shift ng SLMOps sa AI operations  
  - Cost efficiency at privacy-first architecture  
  - Estratehikong epekto sa negosyo at competitive advantages  

#### Seksyon 2: Model Distillation  
- **Mga Konseptong Prayoridad**:  
  - Teknik sa knowledge transfer  
  - Implementasyon ng two-stage distillation process  
  - Mga workflow ng Azure ML para sa distillation  

#### Seksyon 3: Mga Estratehiya sa Fine-tuning  
- **Mga Konseptong Prayoridad**:  
  - Parameter-efficient fine-tuning (PEFT)  
  - Mga advanced na pamamaraan ng LoRA at QLoRA  
  - Multi-adapter training at hyperparameter optimization  

#### Seksyon 4: Deployment para sa Produksyon  
- **Mga Konseptong Prayoridad**:  
  - Conversion ng modelo at quantization para sa produksyon  
  - Konfigurasyon ng Foundry Local deployment  
  - Performance benchmarking at validation ng kalidad  

### Mga Tanong para sa Pagsusuri sa Sarili  

1. Paano naiiba ang SLMOps sa tradisyunal na MLOps?  
2. Ipaliwanag ang mga benepisyo ng model distillation para sa edge deployment.  
3. Ano ang mga pangunahing konsiderasyon para sa fine-tuning ng SLMs sa mga environment na may limitadong resources?  
4. Ilarawan ang isang kumpletong pipeline para sa deployment ng produksyon sa edge AI applications.  

### Mga Gawain sa Praktikal  

1. **Basic Distillation**: Gumawa ng mas maliit na modelo mula sa mas malaking teacher model (1 oras)  
2. **Fine-tuning Experiment**: Mag-fine-tune ng modelo para sa isang partikular na domain (1 oras)  
3. **Deployment Pipeline**: Mag-set up ng basic CI/CD pipeline para sa deployment ng modelo (1 oras)  

## Module 6: SLM Agentic Systems - AI Agents at Function Calling  

### Mga Layunin sa Pagkatuto  

- Bumuo ng matatalinong AI agents para sa edge environments gamit ang Maliit na Language Models  
- Magpatupad ng function calling capabilities gamit ang sistematikong workflows  
- Maging bihasa sa Model Context Protocol (MCP) integration para sa standardized tool interaction  
- Lumikha ng mga sopistikadong agentic systems na may minimal na interbensyon ng tao  

### Mga Pokus na Lugar sa Pag-aaral  

#### Seksyon 1: AI Agents at SLM Foundations  
- **Mga Konseptong Prayoridad**:  
  - Framework para sa classification ng agent (reflex, model-based, goal-based, learning agents)  
  - Pagsusuri ng trade-offs sa pagitan ng SLM at LLM  
  - Mga disenyo ng pattern para sa edge-specific agents  
  - Pag-optimize ng resources para sa agents  

#### Seksyon 2: Function Calling sa Maliit na Language Models  
- **Mga Konseptong Prayoridad**:  
  - Implementasyon ng sistematikong workflow (intent detection, JSON output, external execution)  
  - Mga implementasyon na specific sa platform (Phi-4-mini, mga napiling Qwen models, Microsoft Foundry Local)  
  - Mga advanced na halimbawa (multi-agent collaboration, dynamic tool selection)  
  - Mga konsiderasyon para sa produksyon (rate limiting, audit logging, security measures)  

#### Seksyon 3: Model Context Protocol (MCP) Integration  
- **Mga Konseptong Prayoridad**:  
  - Arkitektura ng protocol at layered system design  
  - Suporta para sa multi-backend (Ollama para sa development, vLLM para sa produksyon)  
  - Mga protocol para sa koneksyon (STDIO at SSE modes)  
  - Mga aplikasyon sa totoong mundo (web automation, data processing, API integration)  

### Mga Tanong para sa Pagsusuri sa Sarili  

1. Ano ang mga pangunahing konsiderasyon sa arkitektura para sa edge AI agents?  
2. Paano pinapahusay ng function calling ang kakayahan ng agents?  
3. Ipaliwanag ang papel ng Model Context Protocol sa komunikasyon ng agent.  

### Mga Gawain sa Praktikal  

1. **Simple Agent**: Bumuo ng basic AI agent na may function calling (1 oras)  
2. **MCP Integration**: Magpatupad ng MCP sa isang agent application (30 minuto)  

## Module 7: Mga Halimbawa ng Implementasyon ng EdgeAI  

### Mga Layunin sa Pagkatuto  

- Maging bihasa sa AI Toolkit para sa Visual Studio Code para sa komprehensibong EdgeAI development workflows  
- Magkaroon ng expertise sa Windows AI Foundry platform at mga estratehiya sa NPU optimization  
- Magpatupad ng EdgeAI sa iba't ibang hardware platforms at deployment scenarios  
- Bumuo ng production-ready EdgeAI applications na may platform-specific optimizations  

### Mga Pokus na Lugar sa Pag-aaral  

#### Seksyon 1: AI Toolkit para sa Visual Studio Code  
- **Mga Konseptong Prayoridad**:  
  - Komprehensibong environment para sa Edge AI development sa loob ng VS Code  
  - Catalog ng modelo at discovery para sa edge deployment  
  - Local testing, optimization, at agent development workflows  
  - Performance monitoring at evaluation para sa edge scenarios  

#### Seksyon 2: Gabay sa Windows EdgeAI Development  
- **Mga Konseptong Prayoridad**:  
  - Komprehensibong overview ng Windows AI Foundry platform  
  - Phi Silica API para sa efficient NPU inference  
  - Computer Vision APIs para sa image processing at OCR  
  - Foundry Local CLI para sa local development at testing  

#### Seksyon 3: Mga Implementasyon na Specific sa Platform  
- **Mga Konseptong Prayoridad**:  
  - Deployment sa NVIDIA Jetson Orin Nano (67 TOPS AI performance)  
  - Mga mobile application gamit ang .NET MAUI at ONNX Runtime GenAI  
  - Mga solusyon sa Azure EdgeAI na may cloud-edge hybrid architecture  
  - Optimization ng Windows ML na may universal hardware support  
  - Mga aplikasyon ng Foundry Local na may privacy-focused RAG implementation  

### Mga Tanong para sa Pagsusuri sa Sarili  

1. Paano pinapadali ng AI Toolkit ang workflow ng EdgeAI development?  
2. Ihambing ang mga estratehiya sa deployment sa iba't ibang hardware platforms.  
3. Ano ang mga benepisyo ng Windows AI Foundry para sa edge development?  
4. Ipaliwanag ang papel ng NPU optimization sa modernong edge AI applications.  
5. Paano ginagamit ng Phi Silica API ang NPU hardware para sa performance optimization?  
6. Ihambing ang mga benepisyo ng local vs. cloud deployment para sa mga application na sensitibo sa privacy.  

### Mga Gawain sa Praktikal  

1. **AI Toolkit Setup**: I-configure ang AI Toolkit at i-optimize ang isang modelo (1 oras)  
2. **Windows AI Foundry**: Bumuo ng simpleng Windows AI application gamit ang Phi Silica API (1 oras)  
3. **Cross-Platform Deployment**: I-deploy ang parehong modelo sa dalawang magkaibang platform (1 oras)  
4. **NPU Optimization**: Subukan ang performance ng NPU gamit ang Windows AI Foundry tools (30 minuto)  

## Module 8: Microsoft Foundry Local – Kumpletong Toolkit para sa Developer  

### Mga Layunin sa Pagkatuto  

- I-install at i-configure ang Foundry Local sa Windows  
- Patakbuhin, tuklasin, at pamahalaan ang mga modelo nang lokal gamit ang Foundry CLI  
- Mag-integrate sa OpenAI-compatible REST at SDK clients  
- Bumuo ng mga praktikal na halimbawa: Chainlit chat, agents, at model router  
- Maunawaan ang hybrid patterns gamit ang Azure AI Foundry  

### Mga Pokus na Lugar sa Pag-aaral  

- Mga pangunahing kaalaman sa installation at CLI (model, service, cache)  
- SDK integration (OpenAI-compatible clients at Azure OpenAI)  
- Mabilis na validation gamit ang Open WebUI  
- Mga pattern para sa agents at function-calling  
- Models-as-tools (disenyo ng router at registry)  

### Mga Tanong para sa Pagsusuri sa Sarili  

1. Paano mo matutuklasan ang local endpoint at ilista ang mga available na modelo?  
2. Ano ang mga pagkakaiba sa pagitan ng Foundry Local REST at Azure OpenAI usage?  
3. Paano mo ididisenyo ang simpleng router para pumili ng mga modelo bilang tools?  
4. Aling mga kategorya ng CLI ang pinaka-relevant sa araw-araw na development?  
5. Paano mo iva-validate ang kahandaan ng Foundry Local bago patakbuhin ang mga apps?  

### Mga Gawain sa Praktikal  

1. I-install/upgrade ang Foundry Local at patakbuhin ang `phi-4-mini` nang lokal (30 minuto)  
2. Tumawag sa `/v1/models` at patakbuhin ang simpleng chat gamit ang REST (30 minuto)  
3. I-launch ang Chainlit app sample at mag-chat nang lokal (30 minuto)  
4. Patakbuhin ang multi-agent coordinator at suriin ang mga output (30 minuto)  
5. Subukan ang models-as-tools router na may env-based overrides (30 minuto)  

## Gabay sa Alokasyon ng Oras  

Para matulungan kang masulit ang 20-oras na timeline ng kurso, narito ang iminungkahing breakdown ng oras:  

| Aktibidad | Alokasyon ng Oras | Deskripsyon |  
|----------|----------------|-------------|  
| Pagbabasa ng Core Materials | 9 oras | Pagtuon sa mahahalagang konsepto sa bawat module |  
| Mga Gawain sa Praktikal | 6 oras | Praktikal na implementasyon ng mga pangunahing teknik |  
| Pagsusuri sa Sarili | 2 oras | Pagsusuri ng iyong pag-unawa sa pamamagitan ng mga tanong at pagninilay |  
| Mini-Project | 3 oras | Paglalapat ng kaalaman sa maliit na praktikal na implementasyon |  

### Mga Pokus na Lugar Batay sa Oras  

**Kung mayroon ka lamang 10 oras:**  
- Kumpletuhin ang Modules 1, 2, at 3 (mga pangunahing konsepto ng EdgeAI)  
- Gawin ang hindi bababa sa isang hands-on exercise bawat module  
- Magtuon sa pag-unawa sa mga pangunahing konsepto kaysa sa mga detalye ng implementasyon  

**Kung maaari kang maglaan ng buong 20 oras:**  
- Kumpletuhin ang lahat ng pitong module  
- Gawin ang mga pangunahing hands-on exercises mula sa bawat module  
- Kumpletuhin ang isang mini-project mula sa Module 7  
- Tuklasin ang hindi bababa sa 2-3 karagdagang resources  

**Kung mayroon kang higit sa 20 oras:**  
- Kumpletuhin ang lahat ng module na may detalyadong exercises  
- Bumuo ng maraming mini-projects  
- Tuklasin ang mga advanced optimization techniques sa Module 4  
- Magpatupad ng deployment para sa produksyon mula sa Module 5  

## Mahahalagang Resources  

Ang mga maingat na piniling resources na ito ay nagbibigay ng pinakamalaking halaga para sa iyong limitadong oras sa pag-aaral:  

### Dokumentasyong Dapat Basahin  
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Ang pinaka-epektibong tool para sa model optimization  
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Pinakamabilis na paraan para mag-deploy ng SLMs nang lokal  
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Reference para sa isang nangungunang edge-optimized model  
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Komprehensibong optimization toolkit ng Intel  
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Integrated EdgeAI development environment  
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows-specific EdgeAI development platform  

### Mga Tool na Nakakatipid ng Oras  
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Mabilis na access at deployment ng modelo  
- [Gradio](https://www.gradio.app/docs/interface) - Mabilis na pagbuo ng UI para sa AI demos  
- [Microsoft Olive](https://github.com/microsoft/Olive) - Pinadaling model optimization  
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Epektibong CPU inference  
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Neural network compression framework  
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Toolkit para sa deployment ng large language models  

## Template para sa Pagsubaybay ng Progreso  

Gamitin ang simpleng template na ito para subaybayan ang iyong progreso sa pag-aaral sa 20-oras na kurso:  

| Module | Petsa ng Pagkumpleto | Oras na Ginugol | Mga Pangunahing Natutunan |  
|--------|----------------|-------------|---------------|  
| Module 1: Mga Pangunahing Konsepto ng EdgeAI | | | |  
| Module 2: Mga Batayan ng SLM | | | |  
| Module 3: Deployment ng SLM | | | |  
| Module 4: Optimization ng Modelo | | | |  
| Module 5: SLMOps | | | |  
| Module 6: AI Agents | | | |  
| Module 7: Mga Tools para sa Development | | | |  
| Module 8: Foundry Local Toolkit | | | |  
| Mga Gawain sa Praktikal | | | |  
| Mini-Project | | | |  

## Mga Ideya para sa Mini Project  

Isaalang-alang ang pagkumpleto ng isa sa mga proyektong ito upang maisagawa ang mga konsepto ng EdgeAI (bawat isa ay idinisenyo upang tumagal ng 2-4 oras):  

### Mga Proyekto para sa Baguhan (2-3 oras bawat isa)  
1. **Edge Text Assistant**: Gumawa ng simpleng offline text completion tool gamit ang maliit na language model  
2. **Dashboard para sa Paghahambing ng Modelo**: Bumuo ng basic visualization ng performance metrics sa iba't ibang SLMs  
3. **Eksperimento sa Optimization**: Sukatin ang epekto ng iba't ibang antas ng quantization sa parehong base model  

### Mga Proyekto para sa Intermediate (3-4 oras bawat isa)  
4. **Workflow ng AI Toolkit**: Gumamit ng VS Code AI Toolkit para i-optimize at i-deploy ang isang modelo mula simula hanggang matapos  
5. **Application ng Windows AI Foundry**: Gumawa ng Windows app gamit ang Phi Silica API at NPU optimization  
6. **Deployment sa Iba't ibang Platform**: I-deploy ang parehong optimized model sa Windows (OpenVINO) at mobile (.NET MAUI)  
7. **Agent na may Function Calling**: Bumuo ng AI agent na may function calling capabilities para sa edge scenarios  

### Mga Proyekto para sa Advanced Integration (4-5 oras bawat isa)  
8. **OpenVINO Optimization Pipeline**: Ipatupad ang kumpletong pag-optimize ng modelo gamit ang NNCF at GenAI toolkit  
9. **SLMOps Pipeline**: Ipatupad ang kumpletong lifecycle ng modelo mula sa training hanggang sa edge deployment  
10. **Multi-Model Edge System**: Mag-deploy ng maraming espesyal na modelo na nagtutulungan sa edge hardware  
11. **MCP Integration System**: Bumuo ng isang agentic system gamit ang Model Context Protocol para sa tool interaction  

## Mga Sanggunian  

- Microsoft Learn (Foundry Local)  
  - Overview: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/  
  - Get started: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started  
  - CLI reference: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli  
  - Integrate with inference SDKs: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks  
  - Open WebUI how-to: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui  
  - Compile Hugging Face models: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models  
- Azure AI Foundry  
  - Overview: https://learn.microsoft.com/en-us/azure/ai-foundry/  
  - Agents (overview): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview  
- Optimization and Inference Tooling  
  - Microsoft Olive (docs): https://microsoft.github.io/Olive/  
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive  
  - ONNX Runtime (getting started): https://onnxruntime.ai/docs/get-started/with-python.html  
  - ONNX Runtime Olive integration: https://onnxruntime.ai/docs/performance/olive.html  
  - OpenVINO (docs): https://docs.openvino.ai/2025/index.html  
  - Apple MLX (docs): https://ml-explore.github.io/mlx/build/html/index.html  
- Deployment Frameworks and Models  
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp  
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index  
  - vLLM (docs): https://docs.vllm.ai/  
  - Ollama (quick start): https://github.com/ollama/ollama#get-started  
- Developer Tools (Windows and VS Code)  
  - AI Toolkit for VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview  
  - Windows ML (overview): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview  

## Komunidad ng Pag-aaral  

Sumali sa talakayan at makipag-ugnayan sa kapwa mga nag-aaral:  
- GitHub Discussions sa [EdgeAI for Beginners repository](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)  
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)  

## Konklusyon  

Ang EdgeAI ay kumakatawan sa pinakabagong hangganan ng implementasyon ng artificial intelligence, na nagdadala ng makapangyarihang kakayahan direkta sa mga device habang tinutugunan ang mahahalagang isyu tulad ng privacy, latency, at connectivity. Ang 20-oras na kursong ito ay nagbibigay sa iyo ng mahalagang kaalaman at praktikal na kasanayan upang agad na makapagsimula sa EdgeAI technologies.  

Ang kurso ay sadyang maikli at nakatuon sa pinakamahalagang konsepto, na nagbibigay-daan sa iyo upang mabilis na makakuha ng mahalagang kaalaman nang hindi nangangailangan ng labis na oras. Tandaan na ang praktikal na pagsasanay, kahit na sa mga simpleng halimbawa, ang susi sa pagpapalakas ng iyong natutunan.  

Masayang pag-aaral!  

---

