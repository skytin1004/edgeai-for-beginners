<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ef04a48f3f1428fa008738033017e0e8",
  "translation_date": "2025-09-25T00:50:46+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "tl"
}
-->
# EdgeAI para sa mga Baguhan: Mga Landas ng Pag-aaral at Iskedyul ng Pag-aaral

### Konsentradong Landas ng Pag-aaral (1 linggo)

| Araw | Pokus | Tinatayang Oras |
|------|-------|------------------|
| Araw 1 | Module 1: Mga Pangunahing Kaalaman sa EdgeAI | 3 oras |
| Araw 2 | Module 2: Mga Batayan ng SLM | 3 oras |
| Araw 3 | Module 3: Deployment ng SLM | 2 oras |
| Araw 4-5 | Module 4: Pag-optimize ng Modelo (6 na framework) | 4 oras |
| Araw 6 | Module 5: SLMOps | 3 oras |
| Araw 7 | Module 6-7: AI Agents at Mga Kagamitang Pang-develop | 4 oras |
| Araw 8 | Module 8: Foundry Local Toolkit (Modernong Implementasyon) | 1 oras |

### Konsentradong Landas ng Pag-aaral (2 linggo)

| Araw | Pokus | Tinatayang Oras |
|------|-------|------------------|
| Araw 1-2 | Module 1: Mga Pangunahing Kaalaman sa EdgeAI | 3 oras |
| Araw 3-4 | Module 2: Mga Batayan ng SLM | 3 oras |
| Araw 5-6 | Module 3: Deployment ng SLM | 2 oras |
| Araw 7-8 | Module 4: Pag-optimize ng Modelo | 4 oras |
| Araw 9-10 | Module 5: SLMOps | 3 oras |
| Araw 11-12 | Module 6: AI Agents | 2 oras |
| Araw 13-14 | Module 7: Mga Kagamitang Pang-develop | 3 oras |

### Part-time na Pag-aaral (4 na linggo)

| Linggo | Pokus | Tinatayang Oras |
|------|-------|------------------|
| Linggo 1 | Module 1-2: Mga Pangunahing Kaalaman at Mga Batayan ng SLM | 6 oras |
| Linggo 2 | Module 3-4: Deployment at Pag-optimize | 6 oras |
| Linggo 3 | Module 5-6: SLMOps at AI Agents | 5 oras |
| Linggo 4 | Module 7: Mga Kagamitang Pang-develop at Integrasyon | 3 oras |

| Araw | Pokus | Tinatayang Oras |
|------|-------|------------------|
| Araw 1-2 | Module 1: Mga Pangunahing Kaalaman sa EdgeAI | 3 oras |
| Araw 3-4 | Module 2: Mga Batayan ng SLM | 3 oras |
| Araw 5-6 | Module 3: Deployment ng SLM | 2 oras |
| Araw 7-8 | Module 4: Pag-optimize ng Modelo | 4 oras |
| Araw 9-10 | Module 5: SLMOps | 3 oras |
| Araw 11-12 | Module 6: Mga Sistemang Agentic ng SLM | 2 oras |
| Araw 13-14 | Module 7: Mga Halimbawa ng Implementasyon ng EdgeAI | 2 oras |

| Module | Petsa ng Pagkumpleto | Oras na Ginugol | Mahahalagang Natutunan |
|--------|----------------|-------------|--------------|
| Module 1: Mga Pangunahing Kaalaman sa EdgeAI | | | |
| Module 2: Mga Batayan ng SLM | | | |
| Module 3: Deployment ng SLM | | | |
| Module 4: Pag-optimize ng Modelo (6 na framework) | | | |
| Module 5: SLMOps | | | |
| Module 6: Mga Sistemang Agentic ng SLM | | | |
| Module 7: Mga Halimbawa ng Implementasyon ng EdgeAI | | | |
| Mga Hands-on na Ehersisyo | | | |
| Mini-Project | | | |

### Part-time na Pag-aaral (4 na linggo)

| Linggo | Pokus | Tinatayang Oras |
|------|-------|------------------|
| Linggo 1 | Module 1-2: Mga Pangunahing Kaalaman at Mga Batayan ng SLM | 6 oras |
| Linggo 2 | Module 3-4: Deployment at Pag-optimize | 6 oras |
| Linggo 3 | Module 5-6: SLMOps at AI Agents | 5 oras |
| Linggo 4 | Module 7: Mga Kagamitang Pang-develop at Integrasyon | 3 oras |

## Panimula

Maligayang pagdating sa gabay sa pag-aaral ng EdgeAI para sa mga Baguhan! Ang dokumentong ito ay idinisenyo upang tulungan kang mag-navigate sa mga materyales ng kurso nang epektibo at makuha ang pinakamataas na benepisyo sa iyong pag-aaral. Nagbibigay ito ng mga istrukturadong landas ng pag-aaral, mga mungkahing iskedyul ng pag-aaral, mga buod ng mahahalagang konsepto, at mga karagdagang mapagkukunan upang palalimin ang iyong kaalaman sa mga teknolohiya ng EdgeAI.

Ito ay isang maikli ngunit komprehensibong kurso na tumatagal ng 20 oras, na nagbibigay ng mahahalagang kaalaman tungkol sa EdgeAI sa isang epektibong format, perpekto para sa mga abalang propesyonal at estudyante na nais mabilis na makakuha ng praktikal na kasanayan sa lumalaking larangang ito.

## Pangkalahatang-ideya ng Kurso

Ang kurso na ito ay inayos sa pitong komprehensibong module:

1. **Mga Pangunahing Kaalaman sa EdgeAI at Transformasyon** - Pag-unawa sa mga pangunahing konsepto at pagbabago sa teknolohiya
2. **Mga Batayan ng Small Language Model (SLM)** - Pagsusuri sa iba't ibang pamilya ng SLM at kanilang mga arkitektura
3. **Deployment ng Small Language Model** - Pagpapatupad ng mga praktikal na estratehiya sa deployment
4. **Pag-convert ng Format ng Modelo at Quantization** - Advanced na pag-optimize gamit ang 6 na framework kabilang ang OpenVINO
5. **SLMOps - Operasyon ng Small Language Model** - Pamamahala sa lifecycle ng produksyon at deployment
6. **Mga Sistemang Agentic ng SLM** - AI agents, function calling, at Model Context Protocol
7. **Mga Halimbawa ng Implementasyon ng EdgeAI** - AI Toolkit, Windows development, at mga platform-specific na implementasyon
8. **Microsoft Foundry Local – Kumpletong Toolkit para sa Developer** - Lokal na development na may hybrid Azure integration (Module 08)

## Paano Gamitin ang Gabay na Ito

- **Progressive Learning**: Sundin ang mga module nang sunod-sunod para sa pinakakohesibong karanasan sa pag-aaral
- **Knowledge Checkpoints**: Gamitin ang mga tanong sa self-assessment pagkatapos ng bawat seksyon
- **Hands-on Practice**: Kumpletuhin ang mga mungkahing ehersisyo upang mapalakas ang teoretikal na kaalaman
- **Supplementary Resources**: Tuklasin ang mga karagdagang materyales para sa mga paksang pinaka-interesado ka

## Mga Rekomendasyon sa Iskedyul ng Pag-aaral

### Konsentradong Landas ng Pag-aaral (1 linggo)

| Araw | Pokus | Tinatayang Oras |
|------|-------|-----------------|
| Araw 1-2 | Module 1: Mga Pangunahing Kaalaman sa EdgeAI | 6 oras |
| Araw 3-4 | Module 2: Mga Batayan ng SLM | 8 oras |
| Araw 5 | Module 3: Deployment ng SLM | 3 oras |
| Araw 6 | Module 8: Foundry Local Toolkit | 3 oras |

### Part-time na Pag-aaral (3 linggo)

| Linggo | Pokus | Tinatayang Oras |
|------|-------|-----------------|
| Linggo 1 | Module 1: Mga Pangunahing Kaalaman sa EdgeAI | 6-7 oras |
| Linggo 2 | Module 2: Mga Batayan ng SLM | 7-8 oras |
| Linggo 3 | Module 3: Deployment ng SLM (3h) + Module 8: Foundry Local Toolkit (2-3h) | 5-6 oras |

## Module 1: Mga Pangunahing Kaalaman sa EdgeAI at Transformasyon

### Mga Layunin sa Pag-aaral

- Maunawaan ang mga pagkakaiba ng cloud-based at edge-based na AI
- Maging bihasa sa mga pangunahing teknik sa pag-optimize para sa mga environment na may limitadong resources
- Suriin ang mga tunay na aplikasyon ng mga teknolohiya ng EdgeAI
- Mag-set up ng development environment para sa mga proyekto ng EdgeAI

### Mga Pokus sa Pag-aaral

#### Seksyon 1: Mga Pangunahing Kaalaman sa EdgeAI
- **Mga Priority na Konsepto**: 
  - Paradigma ng Edge vs. Cloud computing
  - Teknik sa model quantization
  - Mga opsyon sa hardware acceleration (NPUs, GPUs, CPUs)
  - Mga benepisyo sa privacy at seguridad

- **Mga Karagdagang Materyales**:
  - [TensorFlow Lite Documentation](https://www.tensorflow.org/lite)
  - [ONNX Runtime GitHub](https://github.com/microsoft/onnxruntime)
  - [Edge Impulse Documentation](https://docs.edgeimpulse.com)

#### Seksyon 2: Mga Tunay na Kaso ng Pag-aaral
- **Mga Priority na Konsepto**: 
  - Microsoft Phi & Mu model ecosystem
  - Mga praktikal na implementasyon sa iba't ibang industriya
  - Mga konsiderasyon sa deployment

#### Seksyon 3: Gabay sa Praktikal na Implementasyon
- **Mga Priority na Konsepto**: 
  - Pag-set up ng development environment
  - Mga tool sa quantization at optimization
  - Mga pamamaraan sa pagsusuri ng mga implementasyon ng EdgeAI

#### Seksyon 4: Hardware para sa Edge Deployment
- **Mga Priority na Konsepto**: 
  - Paghahambing ng mga platform ng hardware
  - Mga estratehiya sa pag-optimize para sa partikular na hardware
  - Mga konsiderasyon sa deployment

### Mga Tanong sa Self-Assessment

1. Ihambing at kontrast ang cloud-based na AI sa edge-based na AI na mga implementasyon.
2. Ipaliwanag ang tatlong pangunahing teknik para sa pag-optimize ng mga modelo para sa edge deployment.
3. Ano ang mga pangunahing benepisyo ng pagpapatakbo ng mga AI model sa edge?
4. Ilarawan ang proseso ng pag-quantize ng isang modelo at kung paano ito nakakaapekto sa performance.
5. Ipaliwanag kung paano nakakaapekto ang iba't ibang hardware accelerators (NPUs, GPUs, CPUs) sa deployment ng EdgeAI.

### Mga Hands-on na Ehersisyo

1. **Mabilis na Pag-set up ng Environment**: Mag-configure ng minimal na development environment gamit ang mga essential na package (30 minuto)
2. **Pag-explore ng Modelo**: Mag-download at suriin ang isang pre-trained na small language model (1 oras)
3. **Basic Quantization**: Subukan ang simpleng quantization sa isang maliit na modelo (1 oras)

## Module 2: Mga Batayan ng Small Language Model

### Mga Layunin sa Pag-aaral

- Maunawaan ang mga prinsipyo ng arkitektura ng iba't ibang pamilya ng SLM
- Ihambing ang kakayahan ng mga modelo sa iba't ibang parameter scale
- Suriin ang mga modelo batay sa efficiency, capability, at mga pangangailangan sa deployment
- Kilalanin ang mga angkop na use case para sa iba't ibang pamilya ng modelo

### Mga Pokus sa Pag-aaral

#### Seksyon 1: Microsoft Phi Model Family
- **Mga Priority na Konsepto**: 
  - Ebolusyon ng design philosophy
  - Efficiency-first na arkitektura
  - Mga espesyal na kakayahan

#### Seksyon 2: Qwen Family
- **Mga Priority na Konsepto**: 
  - Mga kontribusyon sa open source
  - Mga scalable na opsyon sa deployment
  - Advanced na arkitektura sa reasoning

#### Seksyon 3: Gemma Family
- **Mga Priority na Konsepto**: 
  - Innovation na pinangungunahan ng research
  - Multimodal na kakayahan
  - Optimization para sa mobile

#### Seksyon 4: BitNET Family
- **Mga Priority na Konsepto**: 
  - Teknolohiya ng 1-bit quantization
  - Framework para sa inference optimization
  - Mga konsiderasyon sa sustainability

#### Seksyon 5: Microsoft Mu Model
- **Mga Priority na Konsepto**: 
  - Device-first na arkitektura
  - Integrasyon ng sistema sa Windows
  - Privacy-preserving na operasyon

#### Seksyon 6: Phi-Silica
- **Mga Priority na Konsepto**: 
  - NPU-optimized na arkitektura
  - Mga performance metrics
  - Integrasyon para sa developer

### Mga Tanong sa Self-Assessment

1. Ihambing ang mga arkitektural na approach ng Phi at Qwen model families.
2. Ipaliwanag kung paano naiiba ang teknolohiya ng quantization ng BitNET sa tradisyunal na quantization.
3. Ano ang mga natatanging benepisyo ng Mu model para sa integrasyon sa Windows?
4. Ilarawan kung paano ginagamit ng Phi-Silica ang NPU hardware para sa performance optimization.
5. Para sa isang mobile application na may limitadong connectivity, aling pamilya ng modelo ang pinaka-angkop at bakit?

### Mga Hands-on na Ehersisyo

1. **Paghahambing ng Modelo**: Mabilis na benchmark ng dalawang magkaibang SLM models (1 oras)
2. **Simpleng Text Generation**: Basic na implementasyon ng text generation gamit ang isang maliit na modelo (1 oras)
3. **Mabilis na Optimization**: Mag-apply ng isang teknik sa optimization para mapabilis ang inference (1 oras)

## Module 3: Deployment ng Small Language Model

### Mga Layunin sa Pag-aaral

- Pumili ng angkop na mga modelo batay sa mga limitasyon ng deployment
- Maging bihasa sa mga teknik sa pag-optimize para sa iba't ibang deployment scenarios
- Magpatupad ng SLMs sa parehong lokal at cloud na environment
- Magdisenyo ng mga production-ready na configuration para sa mga aplikasyon ng EdgeAI

### Mga Pokus sa Pag-aaral

#### Seksyon 1: Advanced na Pag-aaral ng SLM
- **Mga Priority na Konsepto**: 
  - Framework para sa parameter classification
  - Advanced na teknik sa optimization
  - Mga estratehiya sa pagkuha ng modelo

#### Seksyon 2: Deployment sa Lokal na Environment
- **Mga Priority na Konsepto**: 
  - Deployment sa Ollama platform
  - Mga solusyon ng Microsoft Foundry Local
  - Paghahambing ng mga framework

#### Seksyon 3: Containerized na Deployment sa Cloud
- **Mga Priority na Konsepto**: 
  - vLLM high-performance inference
  - Orchestration ng container
  - Implementasyon ng ONNX Runtime

### Mga Tanong sa Self-Assessment

1. Anong mga salik ang dapat isaalang-alang sa pagpili sa pagitan ng lokal na deployment at cloud deployment?
2. Ihambing ang Ollama at Microsoft Foundry Local bilang mga opsyon sa deployment.
3. Ipaliwanag ang mga benepisyo ng containerization para sa deployment ng SLM.
4. Ano ang mga pangunahing performance metrics na dapat i-monitor para sa isang edge-deployed na SLM?
5. Ilarawan ang isang kumpletong workflow ng deployment mula sa pagpili ng modelo hanggang sa implementasyon sa produksyon.

### Mga Hands-on na Ehersisyo

1. **Basic na Lokal na Deployment**: Mag-deploy ng simpleng SLM gamit ang Ollama (1 oras)
2. **Performance Check**: Magpatakbo ng mabilis na benchmark sa iyong na-deploy na modelo (30 minuto)
3. **Simpleng Integrasyon**: Gumawa ng minimal na application na gumagamit ng iyong na-deploy na modelo (1 oras)

## Module 4: Pag-convert ng Format ng Modelo at Quantization

### Mga Layunin sa Pag-aaral

- Maging bihasa sa advanced na teknik sa quantization mula 1-bit hanggang 8-bit precision
- Maunawaan ang mga estratehiya sa pag-convert ng format (GGUF, ONNX)
- Magpatupad ng optimization sa anim na framework (Llama.cpp, Olive, OpenVINO, MLX, workflow synthesis)
- Mag-deploy ng mga optimized na modelo para sa production edge environments sa Intel, Apple, at cross-platform hardware

### Mga Pokus sa Pag-aaral

#### Seksyon 1: Mga Batayan ng Quantization
- **Mga Priority na Konsepto**: 
  - Framework para sa precision classification
  - Trade-offs sa performance vs. accuracy
  - Optimization ng memory footprint

#### Seksyon 2: Implementasyon ng Llama.cpp
- **Mga Priority na Konsepto**: 
  - Deployment sa cross-platform
  - Optimization ng GGUF format
  - Teknik sa hardware acceleration

#### Seksyon 3: Microsoft Olive Suite
- **Mga Priority na Konsepto**: 
  - Optimization na aware sa hardware
  - Deployment na pang-enterprise
  - Automated na workflow sa optimization

#### Seksyon 4: OpenVINO Toolkit
- **Mga Priority na Konsepto**: 
  - Optimization para sa Intel hardware
  - Neural Network Compression Framework (NNCF)
  - Deployment ng inference sa cross-platform
- OpenVINO GenAI para sa LLM deployment

#### Seksyon 5: Apple MLX Framework
- **Mga Pangunahing Konsepto**: 
  - Pag-optimize para sa Apple Silicon
  - Unified memory architecture
  - Kakayahan sa LoRA fine-tuning

#### Seksyon 6: Edge AI Development Workflow Synthesis
- **Mga Pangunahing Konsepto**: 
  - Unified workflow architecture
  - Mga desisyon sa pagpili ng framework
  - Pagpapatunay ng kahandaan para sa produksyon
  - Mga estratehiya para sa hinaharap na pag-aangkop

### Mga Tanong para sa Sariling Pagsusuri

1. Ihambing ang mga estratehiya sa quantization sa iba't ibang antas ng precision (1-bit hanggang 8-bit).
2. Ipaliwanag ang mga benepisyo ng GGUF format para sa edge deployment.
3. Paano pinapahusay ng hardware-aware optimization sa Microsoft Olive ang kahusayan ng deployment?
4. Ano ang mga pangunahing benepisyo ng OpenVINO's NNCF para sa compression ng modelo?
5. Ilarawan kung paano ginagamit ng Apple MLX ang unified memory architecture para sa optimization.
6. Paano nakakatulong ang workflow synthesis sa pagpili ng pinakamainam na optimization frameworks?

### Mga Gawain sa Praktikal na Pagsasanay

1. **Model Quantization**: Mag-apply ng iba't ibang antas ng quantization sa isang modelo at ihambing ang mga resulta (1 oras)
2. **OpenVINO Optimization**: Gumamit ng NNCF para i-compress ang isang modelo para sa Intel hardware (1 oras)
3. **Paghahambing ng Framework**: Subukan ang parehong modelo sa tatlong iba't ibang optimization frameworks (1 oras)
4. **Performance Benchmarking**: Sukatin ang epekto ng optimization sa bilis ng inference at paggamit ng memorya (1 oras)

## Module 5: SLMOps - Small Language Model Operations

### Mga Pangunahing Layunin sa Pagkatuto

- Maunawaan ang mga prinsipyo ng lifecycle management sa SLMOps
- Maging bihasa sa distillation at fine-tuning techniques para sa edge deployment
- Magpatupad ng mga estratehiya sa produksyon na may monitoring
- Bumuo ng workflows para sa enterprise-grade SLM operations at maintenance

### Mga Pokus na Lugar sa Pag-aaral

#### Seksyon 1: Panimula sa SLMOps
- **Mga Pangunahing Konsepto**: 
  - Paradigm shift ng SLMOps sa AI operations
  - Cost efficiency at privacy-first architecture
  - Estratehikong epekto sa negosyo at mga competitive advantages

#### Seksyon 2: Model Distillation
- **Mga Pangunahing Konsepto**: 
  - Mga teknik sa knowledge transfer
  - Implementasyon ng two-stage distillation process
  - Azure ML distillation workflows

#### Seksyon 3: Fine-tuning Strategies
- **Mga Pangunahing Konsepto**: 
  - Parameter-efficient fine-tuning (PEFT)
  - Mga advanced na pamamaraan ng LoRA at QLoRA
  - Multi-adapter training at hyperparameter optimization

#### Seksyon 4: Production Deployment
- **Mga Pangunahing Konsepto**: 
  - Conversion ng modelo at quantization para sa produksyon
  - Foundry Local deployment configuration
  - Performance benchmarking at quality validation

### Mga Tanong para sa Sariling Pagsusuri

1. Paano naiiba ang SLMOps sa tradisyunal na MLOps?
2. Ipaliwanag ang mga benepisyo ng model distillation para sa edge deployment.
3. Ano ang mga pangunahing konsiderasyon para sa fine-tuning ng SLMs sa mga environment na may limitadong resources?
4. Ilarawan ang isang kumpletong production deployment pipeline para sa edge AI applications.

### Mga Gawain sa Praktikal na Pagsasanay

1. **Basic Distillation**: Gumawa ng mas maliit na modelo mula sa mas malaking teacher model (1 oras)
2. **Fine-tuning Experiment**: Mag-fine-tune ng modelo para sa isang partikular na domain (1 oras)
3. **Deployment Pipeline**: Mag-set up ng basic CI/CD pipeline para sa model deployment (1 oras)

## Module 6: SLM Agentic Systems - AI Agents at Function Calling

### Mga Pangunahing Layunin sa Pagkatuto

- Bumuo ng matatalinong AI agents para sa edge environments gamit ang Small Language Models
- Magpatupad ng function calling capabilities gamit ang systematic workflows
- Maging bihasa sa Model Context Protocol (MCP) integration para sa standardized tool interaction
- Lumikha ng mga sopistikadong agentic systems na may minimal na interbensyon ng tao

### Mga Pokus na Lugar sa Pag-aaral

#### Seksyon 1: AI Agents at SLM Foundations
- **Mga Pangunahing Konsepto**: 
  - Framework para sa classification ng agent (reflex, model-based, goal-based, learning agents)
  - Pagsusuri ng trade-offs sa pagitan ng SLM at LLM
  - Mga disenyo ng pattern para sa edge-specific agents
  - Pag-optimize ng resources para sa agents

#### Seksyon 2: Function Calling sa Small Language Models
- **Mga Pangunahing Konsepto**: 
  - Implementasyon ng systematic workflow (intent detection, JSON output, external execution)
  - Mga platform-specific implementations (Phi-4-mini, mga napiling Qwen models, Microsoft Foundry Local)
  - Mga advanced na halimbawa (multi-agent collaboration, dynamic tool selection)
  - Mga konsiderasyon sa produksyon (rate limiting, audit logging, security measures)

#### Seksyon 3: Model Context Protocol (MCP) Integration
- **Mga Pangunahing Konsepto**: 
  - Arkitektura ng protocol at layered system design
  - Multi-backend support (Ollama para sa development, vLLM para sa produksyon)
  - Mga protocol sa koneksyon (STDIO at SSE modes)
  - Mga aplikasyon sa totoong mundo (web automation, data processing, API integration)

### Mga Tanong para sa Sariling Pagsusuri

1. Ano ang mga pangunahing konsiderasyon sa arkitektura para sa edge AI agents?
2. Paano pinapahusay ng function calling ang kakayahan ng agents?
3. Ipaliwanag ang papel ng Model Context Protocol sa komunikasyon ng agent.

### Mga Gawain sa Praktikal na Pagsasanay

1. **Simple Agent**: Bumuo ng basic AI agent na may function calling (1 oras)
2. **MCP Integration**: Magpatupad ng MCP sa isang agent application (30 minuto)

## Module 7: Mga Halimbawa ng EdgeAI Implementation

### Mga Pangunahing Layunin sa Pagkatuto

- Maging bihasa sa AI Toolkit para sa Visual Studio Code para sa komprehensibong EdgeAI development workflows
- Magkaroon ng kaalaman sa Windows AI Foundry platform at mga estratehiya sa NPU optimization
- Magpatupad ng EdgeAI sa iba't ibang hardware platforms at deployment scenarios
- Bumuo ng production-ready EdgeAI applications na may platform-specific optimizations

### Mga Pokus na Lugar sa Pag-aaral

#### Seksyon 1: AI Toolkit para sa Visual Studio Code
- **Mga Pangunahing Konsepto**: 
  - Komprehensibong Edge AI development environment sa loob ng VS Code
  - Model catalog at discovery para sa edge deployment
  - Local testing, optimization, at agent development workflows
  - Performance monitoring at evaluation para sa edge scenarios

#### Seksyon 2: Windows EdgeAI Development Guide
- **Mga Pangunahing Konsepto**: 
  - Komprehensibong overview ng Windows AI Foundry platform
  - Phi Silica API para sa efficient NPU inference
  - Computer Vision APIs para sa image processing at OCR
  - Foundry Local CLI para sa local development at testing

#### Seksyon 3: Platform-Specific Implementations
- **Mga Pangunahing Konsepto**: 
  - Deployment sa NVIDIA Jetson Orin Nano (67 TOPS AI performance)
  - Mga mobile application gamit ang .NET MAUI at ONNX Runtime GenAI
  - Azure EdgeAI solutions na may cloud-edge hybrid architecture
  - Windows ML optimization na may universal hardware support
  - Foundry Local applications na may privacy-focused RAG implementation

### Mga Tanong para sa Sariling Pagsusuri

1. Paano pinapadali ng AI Toolkit ang EdgeAI development workflow?
2. Ihambing ang mga estratehiya sa deployment sa iba't ibang hardware platforms.
3. Ano ang mga benepisyo ng Windows AI Foundry para sa edge development?
4. Ipaliwanag ang papel ng NPU optimization sa modernong edge AI applications.
5. Paano ginagamit ng Phi Silica API ang NPU hardware para sa performance optimization?
6. Ihambing ang mga benepisyo ng local vs. cloud deployment para sa privacy-sensitive applications.

### Mga Gawain sa Praktikal na Pagsasanay

1. **AI Toolkit Setup**: I-configure ang AI Toolkit at i-optimize ang isang modelo (1 oras)
2. **Windows AI Foundry**: Bumuo ng simpleng Windows AI application gamit ang Phi Silica API (1 oras)
3. **Cross-Platform Deployment**: I-deploy ang parehong modelo sa dalawang magkaibang platform (1 oras)
4. **NPU Optimization**: Subukan ang performance ng NPU gamit ang Windows AI Foundry tools (30 minuto)

## Module 8: Microsoft Foundry Local – Kumpletong Developer Toolkit (Modernized)

### Mga Pangunahing Layunin sa Pagkatuto

- I-install at i-configure ang Foundry Local na may modern SDK integration
- Magpatupad ng advanced multi-agent systems gamit ang coordinator patterns
- Bumuo ng intelligent model routers na may automatic task-based selection
- Mag-deploy ng production-ready AI solutions na may komprehensibong monitoring
- Mag-integrate sa Azure AI Foundry para sa hybrid deployment scenarios
- Maging bihasa sa modern SDK patterns gamit ang FoundryLocalManager at OpenAI client

### Mga Pokus na Lugar sa Pag-aaral

#### Seksyon 1: Modern Installation at Configuration
- **Mga Pangunahing Konsepto**: 
  - FoundryLocalManager SDK integration
  - Automatic service discovery at health monitoring
  - Mga pattern sa configuration batay sa environment
  - Mga konsiderasyon sa produksyon

#### Seksyon 2: Advanced Multi-Agent Systems
- **Mga Pangunahing Konsepto**: 
  - Coordinator pattern na may specialist agents
  - Retrieval, reasoning, at execution agent specialization
  - Mga mekanismo ng feedback loop para sa refinement
  - Performance monitoring at statistics tracking

#### Seksyon 3: Intelligent Model Routing
- **Mga Pangunahing Konsepto**: 
  - Mga algorithm sa keyword-based model selection
  - Suporta sa maraming modelo (general, reasoning, code, creative)
  - Configuration ng environment variable para sa flexibility
  - Service health checking at error handling

#### Seksyon 4: Production-Ready Implementation
- **Mga Pangunahing Konsepto**: 
  - Komprehensibong error handling at fallback mechanisms
  - Request monitoring at performance tracking
  - Mga interactive na Jupyter notebook na may benchmarks
  - Mga pattern ng integration sa mga umiiral na applications

### Mga Tanong para sa Sariling Pagsusuri

1. Paano naiiba ang modern FoundryLocalManager approach sa manual REST calls?
2. Ipaliwanag ang coordinator pattern at kung paano nito inaayos ang mga specialist agents.
3. Paano pinipili ng intelligent router ang angkop na modelo batay sa query content?
4. Ano ang mga pangunahing bahagi ng isang production-ready AI agent system?
5. Paano mo ipapatupad ang komprehensibong health monitoring para sa Foundry Local services?
6. Ihambing ang mga benepisyo ng modernized approach vs. tradisyunal na mga pattern ng implementasyon.

### Mga Gawain sa Praktikal na Pagsasanay

1. **Modern SDK Setup**: I-configure ang FoundryLocalManager na may automatic service discovery (30 minuto)
2. **Multi-Agent System**: Patakbuhin ang advanced coordinator na may specialist agents (30 minuto)
3. **Intelligent Routing**: Subukan ang model router gamit ang iba't ibang uri ng query (30 minuto)
4. **Interactive Exploration**: Gamitin ang Jupyter notebooks para tuklasin ang mga advanced na features (45 minuto)
5. **Production Deployment**: Magpatupad ng monitoring at error handling patterns (30 minuto)
6. **Hybrid Integration**: I-configure ang Azure AI Foundry fallback scenarios (30 minuto)

## Gabay sa Alokasyon ng Oras

Para matulungan kang masulit ang 20-oras na timeline ng kurso, narito ang iminungkahing breakdown ng oras:

| Aktibidad | Alokasyon ng Oras | Deskripsyon |
|----------|----------------|-------------|
| Pagbabasa ng Core Materials | 9 oras | Pagtuon sa mahahalagang konsepto sa bawat module |
| Mga Gawain sa Praktikal na Pagsasanay | 6 oras | Praktikal na implementasyon ng mga pangunahing teknik |
| Sariling Pagsusuri | 2 oras | Pagsusuri ng iyong pag-unawa sa pamamagitan ng mga tanong at pagninilay |
| Mini-Project | 3 oras | Paglalapat ng kaalaman sa isang maliit na praktikal na implementasyon |

### Mga Pokus na Lugar Batay sa Limitasyon ng Oras

**Kung mayroon kang 10 oras lamang:**
- Kumpletuhin ang Modules 1, 2, at 3 (mga pangunahing konsepto ng EdgeAI)
- Gawin ang hindi bababa sa isang hands-on exercise bawat module
- Magtuon sa pag-unawa sa mga pangunahing konsepto kaysa sa mga detalye ng implementasyon

**Kung maaari kang maglaan ng buong 20 oras:**
- Kumpletuhin ang lahat ng pitong modules
- Gawin ang mga pangunahing hands-on exercises mula sa bawat module
- Kumpletuhin ang isang mini-project mula sa Module 7
- Tuklasin ang hindi bababa sa 2-3 supplementary resources

**Kung mayroon kang higit sa 20 oras:**
- Kumpletuhin ang lahat ng modules na may detalyadong exercises
- Bumuo ng maraming mini-projects
- Tuklasin ang mga advanced optimization techniques sa Module 4
- Magpatupad ng production deployment mula sa Module 5

## Mahahalagang Resources

Ang mga maingat na piniling resources na ito ay nagbibigay ng pinakamalaking halaga para sa iyong limitadong oras ng pag-aaral:

### Kailangang Basahin na Dokumentasyon
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Ang pinaka-epektibong tool para sa model optimization
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Pinakamabilis na paraan para mag-deploy ng SLMs locally
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Reference para sa isang nangungunang edge-optimized model
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Komprehensibong optimization toolkit ng Intel
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Integrated EdgeAI development environment
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Windows-specific EdgeAI development platform

### Mga Tools na Nakakatipid ng Oras
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Mabilis na access at deployment ng modelo
- [Gradio](https://www.gradio.app/docs/interface) - Mabilis na UI development para sa AI demos
- [Microsoft Olive](https://github.com/microsoft/Olive) - Simplified model optimization
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Efficient CPU inference
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Neural network compression framework
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Toolkit para sa deployment ng large language model

## Template para sa Pagsubaybay ng Progreso

Gamitin ang simpleng template na ito para subaybayan ang iyong progreso sa pag-aaral sa 20-oras na kurso:

| Module | Petsa ng Pagkumpleto | Oras na Ginugol | Mga Pangunahing Natutunan |
|--------|----------------|-------------|---------------|
| Module 1: EdgeAI Fundamentals | | | |
| Module 2: SLM Foundations | | | |
| Module 3: SLM Deployment | | | |
| Module 4: Model Optimization | | | |
| Module 5: SLMOps | | | |
| Module 6: AI Agents | | | |
| Module 7: Development Tools | | | |
| Module 8: Foundry Local Toolkit | | | |
| Mga Aktibidad na Praktikal | | | |
| Mini-Proyekto | | | |

## Mga Ideya para sa Mini-Proyekto

Isaalang-alang ang pagsasagawa ng isa sa mga proyektong ito upang magsanay ng mga konsepto ng EdgeAI (bawat isa ay dinisenyo upang tumagal ng 2-4 na oras):

### Mga Proyekto para sa Baguhan (2-3 oras bawat isa)
1. **Edge Text Assistant**: Gumawa ng simpleng offline na tool para sa text completion gamit ang maliit na language model
2. **Model Comparison Dashboard**: Bumuo ng pangunahing visualization ng mga performance metrics sa iba't ibang SLMs
3. **Optimization Experiment**: Sukatin ang epekto ng iba't ibang antas ng quantization sa parehong base model

### Mga Proyekto para sa Intermediate (3-4 oras bawat isa)
4. **AI Toolkit Workflow**: Gamitin ang VS Code AI Toolkit upang i-optimize at i-deploy ang isang modelo mula simula hanggang matapos
5. **Windows AI Foundry Application**: Gumawa ng Windows app gamit ang Phi Silica API at NPU optimization
6. **Cross-Platform Deployment**: I-deploy ang parehong optimized na modelo sa Windows (OpenVINO) at mobile (.NET MAUI)
7. **Function Calling Agent**: Bumuo ng AI agent na may kakayahang tumawag ng mga function para sa edge scenarios

### Mga Proyekto para sa Advanced Integration (4-5 oras bawat isa)
8. **OpenVINO Optimization Pipeline**: Ipatupad ang kumpletong model optimization gamit ang NNCF at GenAI toolkit
9. **SLMOps Pipeline**: Ipatupad ang kumpletong lifecycle ng modelo mula sa training hanggang sa edge deployment
10. **Multi-Model Edge System**: I-deploy ang maraming specialized na modelo na nagtutulungan sa edge hardware
11. **MCP Integration System**: Bumuo ng agentic system gamit ang Model Context Protocol para sa tool interaction

## Mga Sanggunian

- Microsoft Learn (Foundry Local)
  - Overview: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
  - Get started: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
  - CLI reference: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
  - Integrate with inference SDKs: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
  - Open WebUI how-to: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
  - Compile Hugging Face models: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Azure AI Foundry
  - Overview: https://learn.microsoft.com/en-us/azure/ai-foundry/
  - Agents (overview): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- Optimization and Inference Tooling
  - Microsoft Olive (docs): https://microsoft.github.io/Olive/
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive
  - ONNX Runtime (getting started): https://onnxruntime.ai/docs/get-started/with-python.html
  - ONNX Runtime Olive integration: https://onnxruntime.ai/docs/performance/olive.html
  - OpenVINO (docs): https://docs.openvino.ai/2025/index.html
  - Apple MLX (docs): https://ml-explore.github.io/mlx/build/html/index.html
- Deployment Frameworks and Models
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index
  - vLLM (docs): https://docs.vllm.ai/
  - Ollama (quick start): https://github.com/ollama/ollama#get-started
- Developer Tools (Windows and VS Code)
  - AI Toolkit for VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview
  - Windows ML (overview): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview

## Komunidad ng Pag-aaral

Sumali sa talakayan at makipag-ugnayan sa kapwa mga nag-aaral:
- GitHub Discussions sa [EdgeAI for Beginners repository](https://github.com/microsoft/edgeai-for-beginners/discussions)
- [Microsoft Tech Community](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## Konklusyon

Ang EdgeAI ay kumakatawan sa hangganan ng implementasyon ng artificial intelligence, na nagdadala ng makapangyarihang kakayahan direkta sa mga device habang tinutugunan ang mahahalagang isyu tulad ng privacy, latency, at connectivity. Ang 20-oras na kursong ito ay nagbibigay sa iyo ng mahalagang kaalaman at praktikal na kasanayan upang agad na magsimula sa paggamit ng mga teknolohiya ng EdgeAI.

Ang kurso ay sadyang maikli at nakatuon sa pinakamahalagang konsepto, na nagbibigay-daan sa iyo upang mabilis na makakuha ng mahalagang kaalaman nang hindi nangangailangan ng labis na oras. Tandaan na ang praktikal na pagsasanay, kahit na sa mga simpleng halimbawa, ang susi sa pagpapalakas ng iyong natutunan.

Masayang pag-aaral!

---

