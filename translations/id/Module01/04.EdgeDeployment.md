<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b1f5ed7b55962c3dccafd3da6f9ec252",
  "translation_date": "2025-09-18T14:30:09+00:00",
  "source_file": "Module01/04.EdgeDeployment.md",
  "language_code": "id"
}
-->
# Bagian 4: Platform Perangkat Keras untuk Penerapan Edge AI

Penerapan Edge AI merupakan puncak dari optimasi model dan pemilihan perangkat keras, menghadirkan kemampuan cerdas langsung ke perangkat tempat data dihasilkan. Bagian ini membahas pertimbangan praktis, kebutuhan perangkat keras, dan manfaat strategis dari penerapan Edge AI di berbagai platform, dengan fokus pada solusi perangkat keras terkemuka dari Intel, Qualcomm, NVIDIA, dan Windows AI PCs.

## Sumber Daya untuk Pengembang

### Dokumentasi dan Sumber Belajar
- [Microsoft Learn: Pengembangan Edge AI](https://learn.microsoft.com/azure/ai-foundry/foundry-local/)
- [Sumber Daya Edge AI Intel](https://www.intel.com/content/www/us/en/developer/topic-technology/edge-5g/edge-ai.html)
- [Sumber Daya Pengembang AI Qualcomm](https://developer.qualcomm.com/software/qualcomm-neural-processing-sdk)
- [Dokumentasi NVIDIA Jetson](https://developer.nvidia.com/embedded/learn/getting-started-jetson)
- [Dokumentasi Windows AI](https://learn.microsoft.com/windows/ai/)

### Alat dan SDK
- [ONNX Runtime](https://onnxruntime.ai/) - Kerangka kerja inferensi lintas platform
- [OpenVINO Toolkit](https://docs.openvino.ai/) - Toolkit optimasi dari Intel
- [TensorRT](https://developer.nvidia.com/tensorrt) - SDK inferensi berperforma tinggi dari NVIDIA
- [DirectML](https://learn.microsoft.com/windows/ai/directml/dml-intro) - API ML yang dipercepat perangkat keras dari Microsoft

## Pendahuluan

Di bagian ini, kita akan membahas aspek praktis penerapan model AI ke perangkat edge. Kita akan mengulas pertimbangan penting untuk penerapan edge yang sukses, pemilihan platform perangkat keras, dan strategi optimasi yang spesifik untuk berbagai skenario komputasi edge.

## Tujuan Pembelajaran

Pada akhir bagian ini, Anda akan dapat:

- Memahami pertimbangan utama untuk penerapan Edge AI yang sukses
- Mengidentifikasi platform perangkat keras yang sesuai untuk berbagai beban kerja Edge AI
- Mengenali kompromi antara berbagai solusi perangkat keras Edge AI
- Menerapkan teknik optimasi yang spesifik untuk berbagai platform perangkat keras Edge AI

## Pertimbangan Penerapan Edge AI

Penerapan AI ke perangkat edge menghadirkan tantangan dan kebutuhan unik dibandingkan dengan penerapan di cloud. Implementasi Edge AI yang sukses memerlukan pertimbangan cermat terhadap beberapa faktor:

### Keterbatasan Sumber Daya Perangkat Keras

Perangkat edge biasanya memiliki sumber daya komputasi yang terbatas dibandingkan dengan infrastruktur cloud:

- **Keterbatasan Memori**: Banyak perangkat edge memiliki RAM yang terbatas (dari beberapa MB hingga beberapa GB)
- **Keterbatasan Penyimpanan**: Penyimpanan persisten yang terbatas memengaruhi ukuran model dan manajemen data
- **Daya Pemrosesan**: Kemampuan CPU/GPU/NPU yang terbatas memengaruhi kecepatan inferensi
- **Konsumsi Daya**: Banyak perangkat edge beroperasi dengan daya baterai atau memiliki batasan termal

### Pertimbangan Konektivitas

Edge AI harus berfungsi secara efektif dengan konektivitas yang bervariasi:

- **Konektivitas Intermiten**: Operasi harus tetap berjalan selama gangguan jaringan
- **Keterbatasan Bandwidth**: Kemampuan transfer data yang lebih rendah dibandingkan dengan pusat data
- **Persyaratan Latensi**: Banyak aplikasi memerlukan pemrosesan real-time atau hampir real-time
- **Sinkronisasi Data**: Mengelola pemrosesan lokal dengan sinkronisasi cloud secara berkala

### Persyaratan Keamanan dan Privasi

Edge AI menghadirkan tantangan keamanan tertentu:

- **Keamanan Fisik**: Perangkat mungkin ditempatkan di lokasi yang dapat diakses secara fisik
- **Perlindungan Data**: Pemrosesan data sensitif pada perangkat yang berpotensi rentan
- **Otentikasi**: Kontrol akses yang aman untuk fungsi perangkat edge
- **Manajemen Pembaruan**: Mekanisme yang aman untuk pembaruan model dan perangkat lunak

### Penerapan dan Manajemen

Pertimbangan praktis penerapan meliputi:

- **Manajemen Armada**: Banyak penerapan edge melibatkan perangkat yang tersebar luas
- **Kontrol Versi**: Mengelola versi model di berbagai perangkat yang tersebar
- **Pemantauan**: Pelacakan kinerja dan deteksi anomali di edge
- **Manajemen Siklus Hidup**: Dari penerapan awal hingga pembaruan hingga penghentian

## Pilihan Platform Perangkat Keras untuk Edge AI

### Solusi Edge AI Intel

Intel menawarkan beberapa platform perangkat keras yang dioptimalkan untuk penerapan Edge AI:

#### Intel NUC

Intel NUC (Next Unit of Computing) menyediakan performa kelas desktop dalam bentuk yang ringkas:

- **Prosesor Intel Core** dengan grafis terintegrasi Iris Xe
- **RAM**: Mendukung hingga 64GB DDR4
- Kompatibilitas **Neural Compute Stick 2** untuk akselerasi AI tambahan
- **Terbaik untuk**: Beban kerja Edge AI yang sedang hingga kompleks di lokasi tetap dengan ketersediaan daya

[Intel NUC untuk Edge AI](https://www.intel.com/content/www/us/en/products/details/nuc.html)

#### Intel Movidius Vision Processing Units (VPUs)

Perangkat keras khusus untuk akselerasi visi komputer dan jaringan neural:

- **Konsumsi daya ultra-rendah** (1-3W tipikal)
- **Akselerasi jaringan neural khusus**
- **Bentuk yang ringkas** untuk integrasi ke kamera dan sensor
- **Terbaik untuk**: Aplikasi visi komputer dengan batasan daya yang ketat

[Intel Movidius VPU](https://www.intel.com/content/www/us/en/products/details/processors/movidius-vpu.html)

#### Intel Neural Compute Stick 2

Akselerator jaringan neural plug-and-play USB:

- **Intel Movidius Myriad X VPU**
- **Hingga 4 TOPS** performa
- **Antarmuka USB 3.0** untuk integrasi yang mudah
- **Terbaik untuk**: Prototipe cepat dan menambahkan kemampuan AI ke sistem yang ada

[Intel Neural Compute Stick 2](https://www.intel.com/content/www/us/en/developer/tools/neural-compute-stick/overview.html)

#### Pendekatan Pengembangan

Intel menyediakan toolkit OpenVINO untuk mengoptimalkan dan menerapkan model:

```python
# Example: Using OpenVINO for edge deployment
from openvino.inference_engine import IECore

# Initialize the Inference Engine
ie = IECore()

# Read the network from IR files
net = ie.read_network(model="optimized_model.xml", weights="optimized_model.bin")

# Prepare input and output blobs
input_blob = next(iter(net.input_info))
output_blob = next(iter(net.outputs))

# Load the network to the device (CPU, GPU, MYRIAD, etc.)
exec_net = ie.load_network(network=net, device_name="CPU")

# Prepare input
input_data = preprocess_image("sample.jpg")

# Run inference
result = exec_net.infer(inputs={input_blob: input_data})

# Process output
output = result[output_blob]
```

### Solusi AI Qualcomm

Platform Qualcomm berfokus pada aplikasi mobile dan embedded:

#### Qualcomm Snapdragon

Snapdragon Systems-on-Chip (SoCs) mengintegrasikan:

- **Qualcomm AI Engine** dengan Hexagon DSP
- **Adreno GPU** untuk grafis dan komputasi paralel
- **Core CPU Kryo** untuk pemrosesan umum
- **Terbaik untuk**: Smartphone, tablet, headset XR, dan kamera pintar

[Qualcomm Snapdragon untuk Edge AI](https://www.qualcomm.com/products/mobile/snapdragon/pcs/product-list)

#### Qualcomm Cloud AI 100

Akselerator inferensi AI edge khusus:

- **Hingga 400 TOPS** performa AI
- **Efisiensi daya** dioptimalkan untuk pusat data dan penerapan edge
- **Arsitektur yang dapat diskalakan** untuk berbagai skenario penerapan
- **Terbaik untuk**: Aplikasi Edge AI throughput tinggi di lingkungan yang terkendali

[Qualcomm Cloud AI 100](https://www.qualcomm.com/products/technology/processors/cloud-artificial-intelligence)

#### Qualcomm RB5/RB6 Robotics Platform

Dirancang khusus untuk robotika dan komputasi edge tingkat lanjut:

- **Konektivitas 5G terintegrasi**
- **Kemampuan AI dan visi komputer yang canggih**
- **Dukungan sensor yang komprehensif**
- **Terbaik untuk**: Robot otonom, drone, dan sistem industri pintar

[Qualcomm Robotics Platform](https://www.qualcomm.com/products/application/robotics/qualcomm-robotics-rb6-platform)

#### Pendekatan Pengembangan

Qualcomm menyediakan Neural Processing SDK dan AI Model Efficiency Toolkit:

```python
# Example: Using Qualcomm Neural Processing SDK
from qti.aisw.dlc_utils import modeltools

# Convert your model to DLC format
converter = modeltools.DlcConverter()
converter.convert(
    input_network="model.tflite",
    input_dim=[1, 224, 224, 3],
    output_path="optimized_model.dlc"
)

# Use SNPE runtime for inference
from qti.aisw.snpe_runtime import SnpeRuntime

# Initialize runtime
runtime = SnpeRuntime()
runtime.load("optimized_model.dlc")

# Prepare input
input_tensor = preprocess_image("sample.jpg")

# Run inference
outputs = runtime.execute(input_tensor)

# Process results
predictions = postprocess_output(outputs)
```

### üéÆ Solusi Edge AI NVIDIA

NVIDIA menawarkan platform yang dipercepat GPU untuk penerapan edge:

#### Keluarga NVIDIA Jetson

Platform komputasi Edge AI yang dirancang khusus:

##### Seri Jetson Orin
- **Hingga 275 TOPS** performa AI
- **Arsitektur GPU NVIDIA Ampere**
- **Konfigurasi daya** dari 5W hingga 60W
- **Terbaik untuk**: Robotika canggih, analitik video pintar, dan perangkat medis

##### Jetson Nano
- **Komputasi AI tingkat pemula** (472 GFLOPS)
- **GPU Maxwell 128-core**
- **Efisien daya** (5-10W)
- **Terbaik untuk**: Proyek hobi, aplikasi pendidikan, dan penerapan AI sederhana

[Platform NVIDIA Jetson](https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/)

#### NVIDIA Clara Guardian

Platform untuk aplikasi AI di bidang kesehatan:

- **Pemantauan real-time** untuk pasien
- **Dibangun di atas Jetson** atau server yang dipercepat GPU
- **Optimasi khusus kesehatan**
- **Terbaik untuk**: Rumah sakit pintar, pemantauan pasien, dan pencitraan medis

[NVIDIA Clara Guardian](https://developer.nvidia.com/clara)

#### Platform NVIDIA EGX

Solusi komputasi edge kelas enterprise:

- **Dapat diskalakan dari GPU NVIDIA A100 hingga T4**
- **Solusi server bersertifikasi** dari mitra OEM
- **Suite perangkat lunak NVIDIA AI Enterprise** disertakan
- **Terbaik untuk**: Penerapan Edge AI skala besar di lingkungan industri dan enterprise

[Platform NVIDIA EGX](https://www.nvidia.com/en-us/data-center/products/egx-edge-computing/)

#### Pendekatan Pengembangan

NVIDIA menyediakan TensorRT untuk penerapan model yang dioptimalkan:

```python
# Example: Using TensorRT for optimized inference
import tensorrt as trt
import numpy as np

# Create builder and network
logger = trt.Logger(trt.Logger.INFO)
builder = trt.Builder(logger)
network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))

# Parse ONNX model
parser = trt.OnnxParser(network, logger)
with open("model.onnx", "rb") as f:
    parser.parse(f.read())

# Create optimization config
config = builder.create_builder_config()
config.max_workspace_size = 1 << 30  # 1GB
config.set_flag(trt.BuilderFlag.FP16)

# Build and serialize engine
engine = builder.build_engine(network, config)
with open("model.trt", "wb") as f:
    f.write(engine.serialize())

# Create runtime and execute
runtime = trt.Runtime(logger)
engine = runtime.deserialize_cuda_engine(open("model.trt", "rb").read())
context = engine.create_execution_context()

# Run inference
input_data = preprocess_image("sample.jpg")
output = run_inference(context, input_data, engine)
```

### Windows AI PCs

Windows AI PCs merupakan kategori terbaru perangkat keras Edge AI, yang dilengkapi dengan Neural Processing Units (NPUs) khusus:

#### Qualcomm Snapdragon X Elite/Plus

Generasi pertama Windows Copilot+ PCs memiliki:

- **Hexagon NPU** dengan performa AI 45+ TOPS
- **CPU Qualcomm Oryon** dengan hingga 12 core
- **GPU Adreno** untuk grafis dan akselerasi AI tambahan
- **Terbaik untuk**: Produktivitas yang ditingkatkan AI, pembuatan konten, dan pengembangan perangkat lunak

[Qualcomm Snapdragon X Elite](https://www.qualcomm.com/snapdragon/laptops)

#### Intel Core Ultra (Meteor Lake dan seterusnya)

Prosesor PC AI Intel memiliki:

- **Intel AI Boost (NPU)** yang memberikan hingga 10 TOPS
- **GPU Intel Arc** yang menyediakan akselerasi AI tambahan
- **Core CPU performa dan efisiensi**
- **Terbaik untuk**: Laptop bisnis, workstation kreatif, dan komputasi sehari-hari yang ditingkatkan AI

[Prosesor Intel Core Ultra](https://www.intel.com/content/www/us/en/products/details/processors/core/ultra.html)

#### AMD Ryzen AI Series

Prosesor AMD yang berfokus pada AI meliputi:

- **NPU berbasis XDNA** yang menyediakan hingga 16 TOPS
- **Core CPU Zen 4** untuk pemrosesan umum
- **Grafis RDNA 3** untuk kemampuan komputasi tambahan
- **Terbaik untuk**: Profesional kreatif, pengembang, dan pengguna tingkat lanjut

[Prosesor AMD Ryzen AI](https://www.amd.com/en/processors/ryzen-ai.html)

#### Pendekatan Pengembangan

Windows AI PCs memanfaatkan Windows Developer Platform dan DirectML:

```csharp
// Example: Using Windows App SDK and DirectML
using Microsoft.AI.DirectML;
using Microsoft.Windows.AI;

// Load model
var modelPath = "optimized_model.onnx";
var modelOptions = new OnnxModelOptions
{
    InterOpNumThreads = 4,
    IntraOpNumThreads = 4
};

// Create model
var model = await OnnxModel.CreateFromFileAsync(modelPath, modelOptions);

// Prepare input
var inputFeatures = new List<InputFeature>
{
    new InputFeature
    {
        Name = "input",
        Value = imageData
    }
};

// Run inference
var results = await model.EvaluateAsync(inputFeatures);

// Process output
var output = results.First().Value;
```

## ‚ö° Teknik Optimasi Khusus Perangkat Keras

### üîç Pendekatan Kuantisasi

Berbagai platform perangkat keras memanfaatkan teknik kuantisasi tertentu:

#### Optimasi Intel OpenVINO
- **Kuantisasi INT8** untuk CPU dan GPU terintegrasi
- **Presisi FP16** untuk meningkatkan performa dengan kehilangan akurasi minimal
- **Kuantisasi asimetris** untuk menangani distribusi aktivasi

#### Optimasi Qualcomm AI Engine
- **Kuantisasi UINT8** untuk Hexagon DSP
- **Presisi campuran** yang memanfaatkan semua unit komputasi yang tersedia
- **Kuantisasi per-channel** untuk meningkatkan akurasi

#### Optimasi NVIDIA TensorRT
- **Presisi INT8 dan FP16** untuk akselerasi GPU
- **Fusi layer** untuk mengurangi transfer memori
- **Auto-tuning kernel** untuk arsitektur GPU tertentu

#### Optimasi Windows NPU
- **Kuantisasi INT8/INT4** untuk eksekusi NPU
- **Optimasi graf DirectML**
- **Akselerasi runtime Windows ML**

### Adaptasi Spesifik Arsitektur

Berbagai perangkat keras memerlukan pertimbangan arsitektur tertentu:

- **Intel**: Optimalkan untuk instruksi vektor AVX-512 dan Intel Deep Learning Boost
- **Qualcomm**: Manfaatkan komputasi heterogen di Hexagon DSP, Adreno GPU, dan Kryo CPU
- **NVIDIA**: Maksimalkan paralelisme GPU dan pemanfaatan core CUDA
- **Windows NPU**: Rancang untuk pemrosesan kolaboratif NPU-CPU-GPU

### Strategi Manajemen Memori

Penanganan memori yang efektif bervariasi menurut platform:

- **Intel**: Optimalkan untuk pemanfaatan cache dan pola akses memori
- **Qualcomm**: Kelola memori bersama di seluruh prosesor heterogen
- **NVIDIA**: Gunakan memori terpadu CUDA dan optimalkan penggunaan VRAM
- **Windows NPU**: Seimbangkan beban kerja di memori NPU khusus dan RAM sistem

## Benchmarking Kinerja dan Metrik

Saat mengevaluasi penerapan Edge AI, pertimbangkan metrik utama berikut:

### Metrik Kinerja

- **Waktu Inferensi**: Milidetik per inferensi (lebih rendah lebih baik)
- **Throughput**: Inferensi per detik (lebih tinggi lebih baik)
- **Latensi**: Waktu respons end-to-end (lebih rendah lebih baik)
- **FPS**: Frame per detik untuk aplikasi visi (lebih tinggi lebih baik)

### Metrik Efisiensi

- **Performa per Watt**: TOPS/W atau inferensi/detik/watt
- **Energi per Inferensi**: Joule yang dikonsumsi per inferensi
- **Dampak Baterai**: Pengurangan runtime saat menjalankan beban kerja AI
- **Efisiensi Termal**: Peningkatan suhu selama operasi berkelanjutan

### Metrik Akurasi

- **Akurasi Top-1/Top-5**: Persentase kebenaran klasifikasi
- **mAP**: Mean Average Precision untuk deteksi objek
- **Skor F1**: Keseimbangan presisi dan recall
- **Dampak Kuantisasi**: Perbedaan akurasi antara model presisi penuh dan kuantisasi

## Pola Penerapan dan Praktik Terbaik

### Strategi Penerapan Enterprise

- **Containerization**: Menggunakan Docker atau serupa untuk penerapan yang konsisten
- **Manajemen Armada**: Solusi seperti Azure IoT Edge untuk manajemen perangkat
- **Pemantauan**: Pengumpulan telemetri dan pelacakan kinerja
- **Manajemen Pembaruan**: Mekanisme pembaruan OTA untuk model dan perangkat lunak

### Pola Hybrid Cloud-Edge

- **Pelatihan di Cloud, Inferensi di Edge**: Melatih di cloud, menerapkan di edge
- **Praproses di Edge, Analisis di Cloud**: Pemrosesan dasar di edge, analisis kompleks di cloud
- **Pembelajaran Federasi**: Peningkatan model secara terdistribusi tanpa memusatkan data
- **Pembelajaran Inkremental**: Peningkatan model berkelanjutan dari data edge

### Pola Integrasi

- **Integrasi Sensor**: Koneksi langsung ke kamera, mikrofon, dan sensor lainnya
- **Kontrol Aktuator**: Kontrol real-time untuk motor, layar, dan output lainnya
- **Integrasi Sistem**: Komunikasi dengan sistem perusahaan yang sudah ada
- **Integrasi IoT**: Koneksi dengan ekosistem IoT yang lebih luas

## Pertimbangan Penerapan Khusus Industri

### Kesehatan

- **Privasi Pasien**: Kepatuhan HIPAA untuk data medis
- **Regulasi Perangkat Medis**: Persyaratan FDA dan regulasi lainnya
- **Persyaratan Keandalan**: Toleransi kesalahan untuk aplikasi kritis
- **Standar Integrasi**: FHIR, HL7, dan standar interoperabilitas kesehatan lainnya

### Manufaktur

- **Lingkungan Industri**: Penguatan untuk kondisi yang keras
- **Persyaratan Real-time**: Performa deterministik untuk sistem kontrol
- **Sistem Keamanan**: Integrasi dengan protokol keamanan industri
- **Integrasi Sistem Lama**: Koneksi dengan infrastruktur OT yang sudah ada

### Otomotif

- **Keamanan Fungsional**: Kepatuhan ISO 26262
- **Penguatan Lingkungan**: Operasi di berbagai suhu ekstrem
- **Manajemen Daya**: Operasi yang efisien terhadap baterai
- **Manajemen Siklus Hidup**: Dukungan jangka panjang untuk masa pakai kendaraan

### Kota Pintar

- **Penerapan Luar Ruangan**: Ketahanan terhadap cuaca dan keamanan fisik
- **Manajemen Skala**: Ribuan hingga jutaan perangkat terdistribusi
- **Variabilitas Jaringan**: Operasi dengan konektivitas yang tidak konsisten
- **Pertimbangan Privasi**: Penanganan data ruang publik secara bertanggung jawab

## Tren Masa Depan dalam Perangkat Keras AI Edge

### Perkembangan Perangkat Keras yang Muncul

- **Silicon Khusus AI**: NPU dan akselerator AI yang lebih spesifik
- **Komputasi Neuromorfik**: Arsitektur yang terinspirasi otak untuk efisiensi yang lebih baik
- **Komputasi Dalam Memori**: Mengurangi pergerakan data untuk operasi AI
- **Pengemasan Multi-Die**: Integrasi heterogen dari prosesor AI khusus

### Ko-evolusi Perangkat Lunak-Perangkat Keras

- **Pencarian Arsitektur Neural yang Sadar Perangkat Keras**: Model yang dioptimalkan untuk perangkat keras tertentu
- **Kemajuan Compiler**: Peningkatan penerjemahan model ke instruksi perangkat keras
- **Optimisasi Graf Khusus**: Transformasi jaringan yang spesifik perangkat keras
- **Adaptasi Dinamis**: Optimisasi runtime berdasarkan sumber daya yang tersedia

### Upaya Standarisasi

- **ONNX dan ONNX Runtime**: Interoperabilitas model lintas platform
- **MLIR**: Representasi intermediate multi-level untuk ML
- **OpenXLA**: Kompilasi aljabar linier yang dipercepat
- **TMUL**: Lapisan abstraksi prosesor tensor

## Memulai Penerapan AI Edge

### Pengaturan Lingkungan Pengembangan

1. **Pilih Perangkat Keras Target**: Pilih platform yang sesuai untuk kasus penggunaan Anda
2. **Instal SDK dan Alat**: Siapkan kit pengembangan dari produsen
3. **Konfigurasi Alat Optimisasi**: Instal perangkat lunak kuantisasi dan kompilasi
4. **Siapkan Pipeline CI/CD**: Bangun alur kerja pengujian dan penerapan otomatis

### Daftar Periksa Penerapan

- **Optimisasi Model**: Kuantisasi, pemangkasan, dan optimisasi arsitektur
- **Pengujian Performa**: Benchmark pada perangkat keras target dalam kondisi realistis
- **Analisis Daya**: Ukur pola konsumsi energi
- **Audit Keamanan**: Verifikasi perlindungan data dan kontrol akses
- **Mekanisme Pembaruan**: Terapkan kemampuan pembaruan yang aman
- **Pengaturan Pemantauan**: Pasang pengumpulan telemetri dan sistem peringatan

## ‚û°Ô∏è Langkah Selanjutnya

- Tinjau [Ikhtisar Modul 1](./README.md)
- Jelajahi [Modul 2: Dasar-Dasar Model Bahasa Kecil](../Module02/README.md)
- Lanjutkan ke [Modul 3: Strategi Penerapan SLM](../Module03/README.md)

---

**Penafian**:  
Dokumen ini telah diterjemahkan menggunakan layanan penerjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Meskipun kami berusaha untuk memberikan hasil yang akurat, harap diingat bahwa terjemahan otomatis mungkin mengandung kesalahan atau ketidakakuratan. Dokumen asli dalam bahasa aslinya harus dianggap sebagai sumber yang otoritatif. Untuk informasi yang bersifat kritis, disarankan menggunakan jasa penerjemahan profesional oleh manusia. Kami tidak bertanggung jawab atas kesalahpahaman atau penafsiran yang keliru yang timbul dari penggunaan terjemahan ini.