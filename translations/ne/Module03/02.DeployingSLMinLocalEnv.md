<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "308873206bc5ec5d87e34ca2907d2c9c",
  "translation_date": "2025-09-17T21:28:21+00:00",
  "source_file": "Module03/02.DeployingSLMinLocalEnv.md",
  "language_code": "ne"
}
-->
# рдЦрдгреНрдб реи: рд╕реНрдерд╛рдиреАрдп рд╡рд╛рддрд╛рд╡рд░рдгрдорд╛ рдкрд░рд┐рдирд┐рдпреЛрдЬрди - рдЧреЛрдкрдиреАрдпрддрд╛-рдкреНрд░рдердо рд╕рдорд╛рдзрд╛рдирд╣рд░реВ

рд╕рд╛рдиреЛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓ (SLMs) рдХреЛ рд╕реНрдерд╛рдиреАрдп рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдЧреЛрдкрдиреАрдпрддрд╛-рд╕рдВрд░рдХреНрд╖рдг рдЧрд░реНрдиреЗ, рд▓рд╛рдЧрдд-рдкреНрд░рднрд╛рд╡рдХрд╛рд░реА AI рд╕рдорд╛рдзрд╛рдирддрд░реНрдлрдХреЛ рдПрдХ рдирдпрд╛рдБ рджреГрд╖реНрдЯрд┐рдХреЛрдг рд╣реЛред рдпреЛ рд╡рд┐рд╕реНрддреГрдд рдорд╛рд░реНрдЧрджрд░реНрд╢рдирд▓реЗ рджреБрдИ рд╢рдХреНрддрд┐рд╢рд╛рд▓реА рдлреНрд░реЗрдорд╡рд░реНрдХрд╣рд░реВтАФOllama рд░ Microsoft Foundry LocalтАФрдХреЛ рдЕрдиреНрд╡реЗрд╖рдг рдЧрд░реНрджрдЫ, рдЬрд╕рд▓реЗ рд╡рд┐рдХрд╛рд╕рдХрд░реНрддрд╛рд╣рд░реВрд▓рд╛рдИ SLMs рдХреЛ рдкреВрд░реНрдг рдХреНрд╖рдорддрд╛ рдЙрдкрдпреЛрдЧ рдЧрд░реНрди рд╕рдХреНрд╖рдо рдмрдирд╛рдЙрдБрдЫ, рд╕рд╛рдерд╕рд╛рдереИ рдЖрдлреНрдиреЛ рдкрд░рд┐рдирд┐рдпреЛрдЬрди рд╡рд╛рддрд╛рд╡рд░рдгрдорд╛ рдкреВрд░реНрдг рдирд┐рдпрдиреНрддреНрд░рдг рдХрд╛рдпрдо рд░рд╛рдЦреНрди рдорджреНрджрдд рдЧрд░реНрджрдЫред

## рдкрд░рд┐рдЪрдп

рдпрд╕ рдкрд╛рдардорд╛, рд╣рд╛рдореА рд╕рд╛рдиреЛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓рд╣рд░реВрдХреЛ рд╕реНрдерд╛рдиреАрдп рд╡рд╛рддрд╛рд╡рд░рдгрдорд╛ рдЙрдиреНрдирдд рдкрд░рд┐рдирд┐рдпреЛрдЬрди рд░рдгрдиреАрддрд┐рд╣рд░реВрдХреЛ рдЕрдиреНрд╡реЗрд╖рдг рдЧрд░реНрдиреЗрдЫреМрдВред рд╣рд╛рдореА рд╕реНрдерд╛рдиреАрдп AI рдкрд░рд┐рдирд┐рдпреЛрдЬрдирдХрд╛ рдЖрдзрд╛рд░рднреВрдд рдЕрд╡рдзрд╛рд░рдгрд╛рд╣рд░реВрд▓рд╛рдИ рдХрднрд░ рдЧрд░реНрдиреЗрдЫреМрдВ, рджреБрдИ рдкреНрд░рдореБрдЦ рдкреНрд▓реЗрдЯрдлрд░реНрдорд╣рд░реВ (Ollama рд░ Microsoft Foundry Local) рдХреЛ рдЕрдзреНрдпрдпрди рдЧрд░реНрдиреЗрдЫреМрдВ, рд░ рдЙрддреНрдкрд╛рджрди-рддрдп рд╕рдорд╛рдзрд╛рдирд╣рд░реВрдХреЛ рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдорд╛рд░реНрдЧрджрд░реНрд╢рди рдкреНрд░рджрд╛рди рдЧрд░реНрдиреЗрдЫреМрдВред

## рд╕рд┐рдХрд╛рдЗ рдЙрджреНрджреЗрд╢реНрдпрд╣рд░реВ

рдпрд╕ рдкрд╛рдардХреЛ рдЕрдиреНрддреНрдпрд╕рдореНрдо, рддрдкрд╛рдИрдВ рд╕рдХреНрд╖рдо рд╣реБрдиреБрд╣реБрдиреЗрдЫ:

- рд╕реНрдерд╛рдиреАрдп SLM рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдлреНрд░реЗрдорд╡рд░реНрдХрд╣рд░реВрдХреЛ рд╡рд╛рд╕реНрддреБрдХрд▓рд╛ рд░ рдлрд╛рдЗрджрд╛рд╣рд░реВ рдмреБрдЭреНрдиред
- Ollama рд░ Microsoft Foundry Local рдкреНрд░рдпреЛрдЧ рдЧрд░реЗрд░ рдЙрддреНрдкрд╛рджрди-рддрдп рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдЧрд░реНрдиред
- рд╡рд┐рд╢рд┐рд╖реНрдЯ рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВ рд░ рд╕реАрдорд╛рд╣рд░реВрдХреЛ рдЖрдзрд╛рд░рдорд╛ рдЙрдкрдпреБрдХреНрдд рдкреНрд▓реЗрдЯрдлрд░реНрдордХреЛ рддреБрд▓рдирд╛ рд░ рдЪрдпрди рдЧрд░реНрдиред
- рдкреНрд░рджрд░реНрд╢рди, рд╕реБрд░рдХреНрд╖рд╛, рд░ рд╕реНрдХреЗрд▓реЗрдмрд┐рд▓рд┐рдЯреАрдХрд╛ рд▓рд╛рдЧрд┐ рд╕реНрдерд╛рдиреАрдп рдкрд░рд┐рдирд┐рдпреЛрдЬрдирд╣рд░реВ рдЕрдиреБрдХреВрд▓рд┐рдд рдЧрд░реНрдиред

## рд╕реНрдерд╛рдиреАрдп SLM рдкрд░рд┐рдирд┐рдпреЛрдЬрди рд╡рд╛рд╕реНрддреБрдХрд▓рд╛рд╣рд░реВрдХреЛ рд╕рдордЭ

рд╕реНрдерд╛рдиреАрдп SLM рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдХреНрд▓рд╛рдЙрдб-рдирд┐рд░реНрднрд░ AI рд╕реЗрд╡рд╛рд╣рд░реВрдмрд╛рдЯ рдЧреЛрдкрдиреАрдпрддрд╛-рд╕рдВрд░рдХреНрд╖рдг рдЧрд░реНрдиреЗ рд╕рдорд╛рдзрд╛рдирддрд░реНрдлрдХреЛ рдПрдХ рдореМрд▓рд┐рдХ рдкрд░рд┐рд╡рд░реНрддрди рд╣реЛред рдпрд╕ рджреГрд╖реНрдЯрд┐рдХреЛрдгрд▓реЗ рд╕рдВрдЧрдардирд╣рд░реВрд▓рд╛рдИ рдЖрдлреНрдиреЛ AI рдкреВрд░реНрд╡рд╛рдзрд╛рд░рдорд╛ рдкреВрд░реНрдг рдирд┐рдпрдиреНрддреНрд░рдг рдХрд╛рдпрдо рд░рд╛рдЦреНрди рд╕рдХреНрд╖рдо рдмрдирд╛рдЙрдБрдЫ, рд╕рд╛рдерд╕рд╛рдереИ рдбрд╛рдЯрд╛ рд╕рд╛рд░реНрд╡рднреМрдорд┐рдХрддрд╛ рд░ рд╕рдЮреНрдЪрд╛рд▓рди рд╕реНрд╡рддрдиреНрддреНрд░рддрд╛ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдЧрд░реНрджрдЫред

### рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдлреНрд░реЗрдорд╡рд░реНрдХ рд╡рд░реНрдЧреАрдХрд░рдгрд╣рд░реВ

рд╡рд┐рднрд┐рдиреНрди рдкрд░рд┐рдирд┐рдпреЛрдЬрди рджреГрд╖реНрдЯрд┐рдХреЛрдгрд╣рд░реВрдХреЛ рд╕рдордЭрд▓реЗ рд╡рд┐рд╢рд┐рд╖реНрдЯ рдкреНрд░рдпреЛрдЧ рдХреЗрд╕рд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╕рд╣реА рд░рдгрдиреАрддрд┐ рдЪрдпрди рдЧрд░реНрди рдорджреНрджрдд рдЧрд░реНрджрдЫ:

- **рд╡рд┐рдХрд╛рд╕-рдХреЗрдВрджреНрд░рд┐рдд**: рдкреНрд░рдпреЛрдЧ рд░ рдкреНрд░реЛрдЯреЛрдЯрд╛рдЗрдкрдХреЛ рд▓рд╛рдЧрд┐ рд╕рд░рд▓ рд╕реЗрдЯрдЕрдк
- **рдЙрджреНрдпрдо-рд╕реНрддрд░реАрдп**: рдЙрджреНрдпрдо рдПрдХреАрдХрд░рдг рдХреНрд╖рдорддрд╛рд╣рд░реВ рд╕рд╣рд┐рдд рдЙрддреНрдкрд╛рджрди-рддрдп рд╕рдорд╛рдзрд╛рдирд╣рд░реВ  
- **рдХреНрд░рд╕-рдкреНрд▓реЗрдЯрдлрд░реНрдо**: рд╡рд┐рднрд┐рдиреНрди рдЕрдкрд░реЗрдЯрд┐рдЩ рд╕рд┐рд╕реНрдЯрдо рд░ рд╣рд╛рд░реНрдбрд╡реЗрдпрд░рдорд╛ рд╕рд╛рд░реНрд╡рднреМрдорд┐рдХ рдЕрдиреБрдХреВрд▓рддрд╛

### рд╕реНрдерд╛рдиреАрдп SLM рдкрд░рд┐рдирд┐рдпреЛрдЬрдирдХрд╛ рдкреНрд░рдореБрдЦ рдлрд╛рдЗрджрд╛рд╣рд░реВ

рд╕реНрдерд╛рдиреАрдп SLM рдкрд░рд┐рдирд┐рдпреЛрдЬрдирд▓реЗ рдЙрджреНрдпрдо рд░ рдЧреЛрдкрдиреАрдпрддрд╛-рд╕рдВрд╡реЗрджрдирд╢реАрд▓ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЖрджрд░реНрд╢ рдмрдирд╛рдЙрдиреЗ рдзреЗрд░реИ рдореМрд▓рд┐рдХ рдлрд╛рдЗрджрд╛рд╣рд░реВ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ:

**рдЧреЛрдкрдиреАрдпрддрд╛ рд░ рд╕реБрд░рдХреНрд╖рд╛**: рд╕реНрдерд╛рдиреАрдп рдкреНрд░рд╢реЛрдзрдирд▓реЗ рд╕рдВрд╡реЗрджрдирд╢реАрд▓ рдбрд╛рдЯрд╛ рдХрд╣рд┐рд▓реНрдпреИ рд╕рдВрдЧрдардирдХреЛ рдкреВрд░реНрд╡рд╛рдзрд╛рд░ рдмрд╛рд╣рд┐рд░ рдЬрд╛рди рдирджрд┐рдиреЗ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдЧрд░реНрджрдЫ, GDPR, HIPAA, рд░ рдЕрдиреНрдп рдирд┐рдпрд╛рдордХ рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВрдХреЛ рдкрд╛рд▓рдирд╛ рдЧрд░реНрди рд╕рдХреНрд╖рдо рдмрдирд╛рдЙрдБрдЫред рд╡рд░реНрдЧреАрдХреГрдд рд╡рд╛рддрд╛рд╡рд░рдгрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдПрдпрд░-рдЧреНрдпрд╛рдк рдЧрд░рд┐рдПрдХреЛ рдкрд░рд┐рдирд┐рдпреЛрдЬрди рд╕рдореНрднрд╡ рдЫ, рдЬрдмрдХрд┐ рдкреВрд░реНрдг рдЕрдбрд┐рдЯ рдЯреНрд░реЗрд▓рд╣рд░реВрд▓реЗ рд╕реБрд░рдХреНрд╖рд╛ рдирд┐рд░реАрдХреНрд╖рдг рдХрд╛рдпрдо рд░рд╛рдЦреНрдЫред

**рд▓рд╛рдЧрдд рдкреНрд░рднрд╛рд╡рдХрд╛рд░рд┐рддрд╛**: рдкреНрд░рддрд┐-рдЯреЛрдХрди рдореВрд▓реНрдп рдирд┐рд░реНрдзрд╛рд░рдг рдореЛрдбреЗрд▓рдХреЛ рдЙрдиреНрдореВрд▓рдирд▓реЗ рд╕рдЮреНрдЪрд╛рд▓рди рд▓рд╛рдЧрддрд▓рд╛рдИ рдЙрд▓реНрд▓реЗрдЦрдиреАрдп рд░реВрдкрдорд╛ рдШрдЯрд╛рдЙрдБрдЫред рдХрдо рдмреНрдпрд╛рдиреНрдбрд╡рд┐рде рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВ рд░ рдШрдЯрд╛рдЗрдПрдХреЛ рдХреНрд▓рд╛рдЙрдб рдирд┐рд░реНрднрд░рддрд╛ рдЙрджреНрдпрдо рдмрдЬреЗрдЯрд┐рдЩрдХреЛ рд▓рд╛рдЧрд┐ рдкреВрд░реНрд╡рд╛рдиреБрдорд╛рди рдпреЛрдЧреНрдп рд▓рд╛рдЧрдд рд╕рдВрд░рдЪрдирд╛ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред

**рдкреНрд░рджрд░реНрд╢рди рд░ рд╡рд┐рд╢реНрд╡рд╕рдиреАрдпрддрд╛**: рдиреЗрдЯрд╡рд░реНрдХ рд╡рд┐рд▓рдореНрдмрддрд╛ рдмрд┐рдирд╛ рдЫрд┐рдЯреЛ рдЕрдиреБрдорд╛рди рд╕рдордпрд▓реЗ рд╡рд╛рд╕реНрддрд╡рд┐рдХ-рд╕рдордп рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВ рд╕рдХреНрд╖рдо рдмрдирд╛рдЙрдБрдЫред рдЕрдлрд▓рд╛рдЗрди рдХрд╛рд░реНрдпрдХреНрд╖рдорддрд╛ рдЗрдиреНрдЯрд░рдиреЗрдЯ рдЬрдбрд╛рдирдХреЛ рдкрд░рд╡рд╛рд╣ рдирдЧрд░реА рдирд┐рд░рдиреНрддрд░ рд╕рдЮреНрдЪрд╛рд▓рди рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдЧрд░реНрджрдЫ, рдЬрдмрдХрд┐ рд╕реНрдерд╛рдиреАрдп рд╕реНрд░реЛрдд рдЕрдиреБрдХреВрд▓рдирд▓реЗ рд╕реНрдерд┐рд░ рдкреНрд░рджрд░реНрд╢рди рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред

## Ollama: рд╕рд╛рд░реНрд╡рднреМрдорд┐рдХ рд╕реНрдерд╛рдиреАрдп рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдкреНрд▓реЗрдЯрдлрд░реНрдо

### рдХреЛрд░ рд╡рд╛рд╕реНрддреБрдХрд▓рд╛ рд░ рджрд░реНрд╢рди

Ollama рдПрдХ рд╕рд╛рд░реНрд╡рднреМрдорд┐рдХ, рд╡рд┐рдХрд╛рд╕рдХрд░реНрддрд╛-рдЕрдиреБрдХреВрд▓ рдкреНрд▓реЗрдЯрдлрд░реНрдордХреЛ рд░реВрдкрдорд╛ рдЗрдиреНрдЬрд┐рдирд┐рдпрд░ рдЧрд░рд┐рдПрдХреЛ рдЫ рдЬрд╕рд▓реЗ рд╡рд┐рднрд┐рдиреНрди рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдХрдиреНрдлрд┐рдЧрд░реЗрд╕рдирд╣рд░реВ рд░ рдЕрдкрд░реЗрдЯрд┐рдЩ рд╕рд┐рд╕реНрдЯрдорд╣рд░реВрдорд╛ рд╕реНрдерд╛рдиреАрдп LLM рдкрд░рд┐рдирд┐рдпреЛрдЬрдирд▓рд╛рдИ рд▓реЛрдХрддрд╛рдиреНрддреНрд░рд┐рдХ рдмрдирд╛рдЙрдБрдЫред

**рдкреНрд░рд╛рд╡рд┐рдзрд┐рдХ рдЖрдзрд╛рд░**: рдмрд▓рд┐рдпреЛ llama.cpp рдлреНрд░реЗрдорд╡рд░реНрдХрдорд╛ рдирд┐рд░реНрдорд╛рдг рдЧрд░рд┐рдПрдХреЛ, Ollama рд▓реЗ рдХреБрд╢рд▓ GGUF рдореЛрдбреЗрд▓ рдврд╛рдБрдЪрд╛рдХреЛ рдЙрдкрдпреЛрдЧ рдЧрд░реНрджрдЫред рдХреНрд░рд╕-рдкреНрд▓реЗрдЯрдлрд░реНрдо рдЕрдиреБрдХреВрд▓рддрд╛рд▓реЗ Windows, macOS, рд░ Linux рд╡рд╛рддрд╛рд╡рд░рдгрд╣рд░реВрдорд╛ рд╕реНрдерд┐рд░ рд╡реНрдпрд╡рд╣рд╛рд░ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдЧрд░реНрджрдЫ, рдЬрдмрдХрд┐ рдмреБрджреНрдзрд┐рдорд╛рди рд╕реНрд░реЛрдд рд╡реНрдпрд╡рд╕реНрдерд╛рдкрдирд▓реЗ CPU, GPU, рд░ рдореЗрдореЛрд░реА рдЙрдкрдпреЛрдЧрд▓рд╛рдИ рдЕрдиреБрдХреВрд▓рд┐рдд рдЧрд░реНрджрдЫред

**рдбрд┐рдЬрд╛рдЗрди рджрд░реНрд╢рди**: Ollama рд▓реЗ рдХрд╛рд░реНрдпрдХреНрд╖рдорддрд╛ рддреНрдпрд╛рдЧ рдирдЧрд░реА рд╕рд░рд▓рддрд╛ рдкреНрд░рд╛рдердорд┐рдХрддрд╛ рджрд┐рдиреНрдЫ, рддрддреНрдХрд╛рд▓ рдЙрддреНрдкрд╛рджрдХрддрд╛рдХреЛ рд▓рд╛рдЧрд┐ рд╢реВрдиреНрдп-рдХрдиреНрдлрд┐рдЧрд░реЗрд╕рди рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред рдкреНрд▓реЗрдЯрдлрд░реНрдорд▓реЗ рд╡реНрдпрд╛рдкрдХ рдореЛрдбреЗрд▓ рдЕрдиреБрдХреВрд▓рддрд╛ рдХрд╛рдпрдо рд░рд╛рдЦреНрдЫ, рдЬрдмрдХрд┐ рд╡рд┐рднрд┐рдиреНрди рдореЛрдбреЗрд▓ рд╡рд╛рд╕реНрддреБрдХрд▓рд╛рд╣рд░реВрдорд╛ рд╕реНрдерд┐рд░ APIs рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред

### рдЙрдиреНрдирдд рд╕реБрд╡рд┐рдзрд╛рд╣рд░реВ рд░ рдХреНрд╖рдорддрд╛рд╣рд░реВ

**рдореЛрдбреЗрд▓ рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди рдЙрддреНрдХреГрд╖реНрдЯрддрд╛**: Ollama рд▓реЗ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдкреБрд▓рд┐рдЩ, рдХреНрдпрд╛рд╕рд┐рдЩ, рд░ рд╕рдВрд╕реНрдХрд░рдг рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди рд╕рд╣рд┐рдд рд╡реНрдпрд╛рдкрдХ рдореЛрдбреЗрд▓ рдЬреАрд╡рдирдЪрдХреНрд░ рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред рдкреНрд▓реЗрдЯрдлрд░реНрдорд▓реЗ Llama 3.2, Google Gemma 2, Microsoft Phi-4, Qwen 2.5, DeepSeek, Mistral, рд░ рд╡рд┐рд╢реЗрд╖ рдПрдореНрдмреЗрдбрд┐рдЩ рдореЛрдбреЗрд▓рд╣рд░реВ рд╕рд╣рд┐рдд рд╡рд┐рд╕реНрддреГрдд рдореЛрдбреЗрд▓ рдкрд╛рд░рд┐рд╕реНрдерд┐рддрд┐рдХреА рддрдиреНрддреНрд░рд▓рд╛рдИ рд╕рдорд░реНрдерди рдЧрд░реНрджрдЫред

**Modelfiles рдорд╛рд░реНрдлрдд рдЕрдиреБрдХреВрд▓рди**: рдЙрдиреНрдирдд рдкреНрд░рдпреЛрдЧрдХрд░реНрддрд╛рд╣рд░реВрд▓реЗ рд╡рд┐рд╢рд┐рд╖реНрдЯ рдкреНрдпрд╛рд░рд╛рдорд┐рдЯрд░рд╣рд░реВ, рдкреНрд░рдгрд╛рд▓реА рдкреНрд░реЙрдореНрдкреНрдЯрд╣рд░реВ, рд░ рд╡реНрдпрд╡рд╣рд╛рд░ рд╕рдВрд╢реЛрдзрдирд╣рд░реВрд╕рд╣рд┐рдд рдЕрдиреБрдХреВрд▓рд┐рдд рдореЛрдбреЗрд▓ рдХрдиреНрдлрд┐рдЧрд░реЗрд╕рдирд╣рд░реВ рд╕рд┐рд░реНрдЬрдирд╛ рдЧрд░реНрди рд╕рдХреНрдЫрдиреНред рдпрд╕рд▓реЗ рдбреЛрдореЗрди-рд╡рд┐рд╢рд┐рд╖реНрдЯ рдЕрдиреБрдХреВрд▓рдирд╣рд░реВ рд░ рд╡рд┐рд╢реЗрд╖ рдЕрдиреБрдкреНрд░рдпреЛрдЧ рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВ рд╕рдХреНрд╖рдо рдмрдирд╛рдЙрдБрдЫред

**рдкреНрд░рджрд░реНрд╢рди рдЕрдиреБрдХреВрд▓рди**: Ollama рд▓реЗ рдЙрдкрд▓рдмреНрдз рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдПрдХреНрд╕реЗрд▓реЗрд░реЗрд╢рди (рдЬрд╕реНрддреИ NVIDIA CUDA, Apple Metal, рд░ OpenCL) рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рд░реВрдкрдорд╛ рдкрддреНрддрд╛ рд▓рдЧрд╛рдЙрдБрдЫ рд░ рдЙрдкрдпреЛрдЧ рдЧрд░реНрджрдЫред рдмреБрджреНрдзрд┐рдорд╛рди рдореЗрдореЛрд░реА рд╡реНрдпрд╡рд╕реНрдерд╛рдкрдирд▓реЗ рд╡рд┐рднрд┐рдиреНрди рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдХрдиреНрдлрд┐рдЧрд░реЗрд╕рдирд╣рд░реВрдорд╛ рдЗрд╖реНрдЯрддрдо рд╕реНрд░реЛрдд рдЙрдкрдпреЛрдЧ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдЧрд░реНрджрдЫред

### рдЙрддреНрдкрд╛рджрди рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рд░рдгрдиреАрддрд┐рд╣рд░реВ

**рд╕реНрдерд╛рдкрдирд╛ рд░ рд╕реЗрдЯрдЕрдк**: Ollama рд▓реЗ рджреЗрд╢реА рдЗрдиреНрд╕реНрдЯрд▓рд░рд╣рд░реВ, рдкреНрдпрд╛рдХреЗрдЬ рдореНрдпрд╛рдиреЗрдЬрд░рд╣рд░реВ (WinGet, Homebrew, APT), рд░ рдХрдиреНрдЯреЗрдирд░рд╛рдЗрдЬреНрдб рдкрд░рд┐рдирд┐рдпреЛрдЬрдирд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ Docker рдХрдиреНрдЯреЗрдирд░рд╣рд░реВ рдорд╛рд░реНрдлрдд рдкреНрд▓реЗрдЯрдлрд░реНрдорд╣рд░реВрдорд╛ рд╕рд░рд▓ рд╕реНрдерд╛рдкрдирд╛ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред

```bash
# Cross-platform installation examples
# Windows (WinGet)
winget install Ollama.Ollama

# macOS (Homebrew)  
brew install ollama

# Linux (curl)
curl -fsSL https://ollama.com/install.sh | sh

# Docker deployment
docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
```

**рдЖрд╡рд╢реНрдпрдХ рдЖрджреЗрд╢рд╣рд░реВ рд░ рдЕрдкрд░реЗрд╢рдирд╣рд░реВ**:

```bash
# Model management
ollama pull qwen2.5:3b          # Download specific model
ollama pull phi4:mini           # Download Phi-4 mini variant
ollama list                     # List installed models
ollama rm <model>               # Remove model

# Model execution
ollama run qwen2.5:3b           # Interactive mode
ollama run phi4:mini "Explain quantum computing"  # Single query

# Custom model creation
ollama create enterprise-assistant -f ./Modelfile
```

**рдЙрдиреНрдирдд рдХрдиреНрдлрд┐рдЧрд░реЗрд╕рди**: Modelfiles рдЙрджреНрдпрдо рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдкрд░рд┐рд╖реНрдХреГрдд рдЕрдиреБрдХреВрд▓рди рд╕рдХреНрд╖рдо рдЧрд░реНрджрдЫ:

```dockerfile
FROM qwen2.5:3b

PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER context_length 4096
PARAMETER num_gpu 1
PARAMETER num_thread 8

SYSTEM """
You are an enterprise assistant for Contoso Corporation.
Always maintain a professional tone and prioritize security best practices.
Never share confidential information without proper authentication.
"""

# Custom model knowledge (optional)
FILE ./contoso_guidelines.txt
FILE ./security_protocols.pdf
```

### рд╡рд┐рдХрд╛рд╕рдХрд░реНрддрд╛ рдПрдХреАрдХрд░рдг рдЙрджрд╛рд╣рд░рдгрд╣рд░реВ

**Python API рдПрдХреАрдХрд░рдг**:

```python
import requests
import json

# API endpoint configuration
OLLAMA_ENDPOINT = "http://localhost:11434/api/generate"

# Model parameters
params = {
    "model": "phi4:mini",
    "prompt": "Write a function to calculate the Fibonacci sequence in Python",
    "system": "You are a helpful Python programming assistant. Provide clean, efficient code with comments.",
    "stream": False,
    "options": {
        "temperature": 0.2,
        "top_p": 0.95,
        "num_predict": 1024
    }
}

# Make API request
response = requests.post(OLLAMA_ENDPOINT, json=params)
result = response.json()

# Process and display response
print(result["response"])

# Streaming example (for real-time responses)
def stream_response():
    params["stream"] = True
    response = requests.post(OLLAMA_ENDPOINT, json=params, stream=True)
    
    for line in response.iter_lines():
        if line:
            chunk = json.loads(line)
            if "response" in chunk:
                print(chunk["response"], end="", flush=True)
            if chunk.get("done", False):
                print()
                break

# stream_response()  # Uncomment to run streaming example
```

**JavaScript/TypeScript рдПрдХреАрдХрд░рдг (Node.js)**:

```javascript
const axios = require('axios');

// API configuration
const OLLAMA_API = 'http://localhost:11434/api';

// Function to generate text with Ollama
async function generateText(model, prompt, systemPrompt = '') {
  try {
    const response = await axios.post(`${OLLAMA_API}/generate`, {
      model: model,
      prompt: prompt,
      system: systemPrompt,
      stream: false,
      options: {
        temperature: 0.7,
        top_k: 40,
        top_p: 0.9,
        num_predict: 1024
      }
    });
    
    return response.data.response;
  } catch (error) {
    console.error('Error generating text:', error.message);
    throw error;
  }
}

// Example usage in an Express API
const express = require('express');
const app = express();
app.use(express.json());

app.post('/api/chat', async (req, res) => {
  const { message } = req.body;
  
  try {
    const response = await generateText(
      'phi4:mini',
      message,
      'You are a helpful AI assistant.'
    );
    
    res.json({ response });
  } catch (error) {
    res.status(500).json({ error: 'Failed to generate response' });
  }
});

app.listen(3000, () => {
  console.log('API server running on port 3000');
});
```

**RESTful API рдкреНрд░рдпреЛрдЧ cURL рдорд╛рд░реНрдлрдд**:

```bash
# Basic text generation
curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "phi4:mini",
    "prompt": "Write a recursive function to calculate factorial",
    "stream": false
  }'

# Chat completion (conversational)
curl -X POST http://localhost:11434/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen2.5:3b",
    "messages": [
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "What is edge computing?"}
    ],
    "stream": false
  }'

# Embedding generation (for vector databases)
curl -X POST http://localhost:11434/api/embeddings \
  -H "Content-Type: application/json" \
  -d '{
    "model": "nomic-embed-text",
    "prompt": "Edge AI represents a paradigm shift in artificial intelligence deployment"
  }'
```

### рдкреНрд░рджрд░реНрд╢рди рдЯреНрдпреБрдирд┐рдЩ рд░ рдЕрдиреБрдХреВрд▓рди

**рдореЗрдореЛрд░реА рд░ рдереНрд░реЗрдб рдХрдиреНрдлрд┐рдЧрд░реЗрд╕рди**:

```bash
# Adjust memory and thread allocation for large models
OLLAMA_HOST=0.0.0.0 OLLAMA_NUM_GPU=1 OLLAMA_NUM_THREAD=8 ollama serve

# GPU layer configuration for optimal performance
OLLAMA_GPU_LAYERS=35 ollama run qwen2.5:3b

# Run with specific CUDA device (multi-GPU systems)
CUDA_VISIBLE_DEVICES=0 ollama run phi4:mini
```

**рд╡рд┐рднрд┐рдиреНрди рд╣рд╛рд░реНрдбрд╡реЗрдпрд░рдХреЛ рд▓рд╛рдЧрд┐ рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╕рди рдЪрдпрди**:

```bash
# Pull specific quantization variants for performance/quality tradeoffs
# F16 format (highest quality, highest memory usage)
ollama pull phi4:mini-f16

# Q8_0 format (high quality, moderate memory usage)
ollama pull phi4:mini-q8_0

# Q4_K_M format (good quality, lowest memory usage)
ollama pull phi4:mini-q4_k_m
```

```SYSTEM """
You are a specialized enterprise assistant focused on technical documentation and code analysis.
Provide concise, accurate responses with practical examples.
"""

TEMPLATE """{{ .System }}
User: {{ .Prompt }}
Assistant: """
```

## Microsoft Foundry Local: рдЙрджреНрдпрдо рдПрдЬ AI рдкреНрд▓реЗрдЯрдлрд░реНрдо

### рдЙрджреНрдпрдо-рд╕реНрддрд░реАрдп рд╡рд╛рд╕реНрддреБрдХрд▓рд╛

Microsoft Foundry Local рдЙрддреНрдкрд╛рджрди рдПрдЬ AI рдкрд░рд┐рдирд┐рдпреЛрдЬрдирд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╡рд┐рд╢реЗрд╖ рд░реВрдкрдорд╛ рдбрд┐рдЬрд╛рдЗрди рдЧрд░рд┐рдПрдХреЛ рдПрдХ рд╡реНрдпрд╛рдкрдХ рдЙрджреНрдпрдо рд╕рдорд╛рдзрд╛рди рд╣реЛ, рдЬрд╕рд▓реЗ Microsoft рдкрд╛рд░рд┐рд╕реНрдерд┐рддрд┐рдХреА рддрдиреНрддреНрд░рдорд╛ рдЧрд╣рд┐рд░реЛ рдПрдХреАрдХрд░рдг рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред

**ONNX-рдЖрдзрд╛рд░рд┐рдд рдЖрдзрд╛рд░**: рдЙрджреНрдпреЛрдЧ-рдорд╛рдирдХ ONNX Runtime рдорд╛ рдирд┐рд░реНрдорд╛рдг рдЧрд░рд┐рдПрдХреЛ, Foundry Local рд▓реЗ рд╡рд┐рд╡рд┐рдз рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рд╡рд╛рд╕реНрддреБрдХрд▓рд╛рд╣рд░реВрдорд╛ рдЕрдиреБрдХреВрд▓рд┐рдд рдкреНрд░рджрд░реНрд╢рди рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред рдкреНрд▓реЗрдЯрдлрд░реНрдорд▓реЗ Windows ML рдПрдХреАрдХрд░рдгрдХреЛ рдЙрдкрдпреЛрдЧ рдЧрд░реНрджрдЫ, рджреЗрд╢реА Windows рдЕрдиреБрдХреВрд▓рдирдХреЛ рд▓рд╛рдЧрд┐, рдЬрдмрдХрд┐ рдХреНрд░рд╕-рдкреНрд▓реЗрдЯрдлрд░реНрдо рдЕрдиреБрдХреВрд▓рддрд╛ рдХрд╛рдпрдо рд░рд╛рдЦреНрдЫред

**рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдПрдХреНрд╕реЗрд▓реЗрд░реЗрд╢рди рдЙрддреНрдХреГрд╖реНрдЯрддрд╛**: Foundry Local рд▓реЗ CPU, GPU, рд░ NPUрд╣рд░реВрдорд╛ рдмреБрджреНрдзрд┐рдорд╛рди рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдкрддреНрддрд╛ рд▓рдЧрд╛рдЙрдиреЗ рд░ рдЕрдиреБрдХреВрд▓рди рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рд╡рд┐рдХреНрд░реЗрддрд╛рд╣рд░реВ (AMD, Intel, NVIDIA, Qualcomm) рд╕рдБрдЧрдХреЛ рдЧрд╣рд┐рд░реЛ рд╕рд╣рдпреЛрдЧрд▓реЗ рдЙрджреНрдпрдо рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдХрдиреНрдлрд┐рдЧрд░реЗрд╕рдирд╣рд░реВрдорд╛ рдЗрд╖реНрдЯрддрдо рдкреНрд░рджрд░реНрд╢рди рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдЧрд░реНрджрдЫред

### рдЙрдиреНрдирдд рд╡рд┐рдХрд╛рд╕рдХрд░реНрддрд╛ рдЕрдиреБрднрд╡

**рдмрд╣реБ-рдЗрдиреНрдЯрд░рдлреЗрд╕ рдкрд╣реБрдБрдЪ**: Foundry Local рд▓реЗ рдореЛрдбреЗрд▓ рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди рд░ рдкрд░рд┐рдирд┐рдпреЛрдЬрдирдХреЛ рд▓рд╛рдЧрд┐ рд╢рдХреНрддрд┐рд╢рд╛рд▓реА CLI, рджреЗрд╢реА рдПрдХреАрдХрд░рдгрдХреЛ рд▓рд╛рдЧрд┐ рдмрд╣реБ-рднрд╛рд╖рд╛ SDKs (Python, NodeJS), рд░ рд╕рд╣рдЬ рдорд╛рдЗрдЧреНрд░реЗрд╢рдирдХреЛ рд▓рд╛рдЧрд┐ OpenAI рдЕрдиреБрдХреВрд▓рддрд╛ рд╕рд╣рд┐рдд RESTful APIs рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред

**Visual Studio рдПрдХреАрдХрд░рдг**: рдкреНрд▓реЗрдЯрдлрд░реНрдорд▓реЗ AI Toolkit for VS Code рд╕рдБрдЧ рд╕рд╣рдЬ рдПрдХреАрдХрд░рдг рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ, рдЬрд╕рд▓реЗ рд╡рд┐рдХрд╛рд╕ рд╡рд╛рддрд╛рд╡рд░рдг рднрд┐рддреНрд░ рдореЛрдбреЗрд▓ рд░реВрдкрд╛рдиреНрддрд░рдг, рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╕рди, рд░ рдЕрдиреБрдХреВрд▓рди рдЙрдкрдХрд░рдгрд╣рд░реВ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред рдпрд╕ рдПрдХреАрдХрд░рдгрд▓реЗ рд╡рд┐рдХрд╛рд╕ рдХрд╛рд░реНрдпрдкреНрд░рд╡рд╛рд╣рд▓рд╛рдИ рдЧрддрд┐ рджрд┐рдиреНрдЫ рд░ рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдЬрдЯрд┐рд▓рддрд╛ рдШрдЯрд╛рдЙрдБрдЫред

**рдореЛрдбреЗрд▓ рдЕрдиреБрдХреВрд▓рди рдкрд╛рдЗрдкрд▓рд╛рдЗрди**: Microsoft Olive рдПрдХреАрдХрд░рдгрд▓реЗ рдЧрддрд┐рд╢реАрд▓ рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╕рди, рдЧреНрд░рд╛рдл рдЕрдиреБрдХреВрд▓рди, рд░ рд╣рд╛рд░реНрдбрд╡реЗрдпрд░-рд╡рд┐рд╢рд┐рд╖реНрдЯ рдЯреНрдпреБрдирд┐рдЩ рд╕рд╣рд┐рдд рдкрд░рд┐рд╖реНрдХреГрдд рдореЛрдбреЗрд▓ рдЕрдиреБрдХреВрд▓рди рдХрд╛рд░реНрдпрдкреНрд░рд╡рд╛рд╣ рд╕рдХреНрд╖рдо рдЧрд░реНрджрдЫред Azure ML рдорд╛рд░реНрдлрдд рдХреНрд▓рд╛рдЙрдб-рдЖрдзрд╛рд░рд┐рдд рд░реВрдкрд╛рдиреНрддрд░рдг рдХреНрд╖рдорддрд╛рд╣рд░реВрд▓реЗ рдареВрд▓рд╛ рдореЛрдбреЗрд▓рд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╕реНрдХреЗрд▓реЗрдмрд▓ рдЕрдиреБрдХреВрд▓рди рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред

### рдЙрддреНрдкрд╛рджрди рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рд░рдгрдиреАрддрд┐рд╣рд░реВ

**рд╕реНрдерд╛рдкрдирд╛ рд░ рдХрдиреНрдлрд┐рдЧрд░реЗрд╕рди**:

```bash
# Windows installation via WinGet
winget install Microsoft.FoundryLocal

# Verify installation
foundry-local --version

# Initialize local environment
foundry-local init
```

**рдореЛрдбреЗрд▓ рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди рдЕрдкрд░реЗрд╢рдирд╣рд░реВ**:

```bash
# Browse available models
foundry-local models list

# Filter by specific criteria
foundry-local models list --size small --type instruct

# Download and deploy models
foundry-local models pull microsoft/phi-4-mini
foundry-local models pull deepseek/r1-distill-qwen-1.5b

# Test model performance
foundry-local models test microsoft/phi-4-mini --benchmark
```

**рдЙрдиреНрдирдд рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдХрдиреНрдлрд┐рдЧрд░реЗрд╕рди**:

```json
{
  "deployment": {
    "model": "microsoft/phi-4-mini",
    "hardware": {
      "preferred": "npu",
      "fallback": ["gpu", "cpu"]
    },
    "optimization": {
      "quantization": "dynamic",
      "batch_size": 4,
      "max_context": 4096
    },
    "api": {
      "port": 8080,
      "openai_compatible": true
    }
  }
}
```

### рдЙрджреНрдпрдо рдкрд╛рд░рд┐рд╕реНрдерд┐рддрд┐рдХреА рддрдиреНрддреНрд░ рдПрдХреАрдХрд░рдг

**рд╕реБрд░рдХреНрд╖рд╛ рд░ рдЕрдиреБрдкрд╛рд▓рди**: Foundry Local рд▓реЗ рднреВрдорд┐рдХрд╛-рдЖрдзрд╛рд░рд┐рдд рдкрд╣реБрдБрдЪ рдирд┐рдпрдиреНрддреНрд░рдг, рдЕрдбрд┐рдЯ рд▓рдЧрд┐рдЩ, рдЕрдиреБрдкрд╛рд▓рди рд░рд┐рдкреЛрд░реНрдЯрд┐рдЩ, рд░ рдПрдиреНрдХреНрд░рд┐рдкреНрдЯреЗрдб рдореЛрдбреЗрд▓ рднрдгреНрдбрд╛рд░рдг рд╕рд╣рд┐рдд рдЙрджреНрдпрдо-рд╕реНрддрд░реАрдп рд╕реБрд░рдХреНрд╖рд╛ рд╕реБрд╡рд┐рдзрд╛рд╣рд░реВ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред Microsoft рд╕реБрд░рдХреНрд╖рд╛ рдкреВрд░реНрд╡рд╛рдзрд╛рд░рд╕рдБрдЧрдХреЛ рдПрдХреАрдХрд░рдгрд▓реЗ рдЙрджреНрдпрдо рд╕реБрд░рдХреНрд╖рд╛ рдиреАрддрд┐рд╣рд░реВрдХреЛ рдкрд╛рд▓рдирд╛ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдЧрд░реНрджрдЫред

**рдирд┐рд░реНрдорд┐рдд AI рд╕реЗрд╡рд╛рд╣рд░реВ**: рдкреНрд▓реЗрдЯрдлрд░реНрдорд▓реЗ рд╕реНрдерд╛рдиреАрдп рднрд╛рд╖рд╛ рдкреНрд░рд╢реЛрдзрдирдХреЛ рд▓рд╛рдЧрд┐ Phi Silica, рдЫрд╡рд┐ рд╕реБрдзрд╛рд░ рд░ рд╡рд┐рд╢реНрд▓реЗрд╖рдгрдХреЛ рд▓рд╛рдЧрд┐ AI Imaging, рд░ рд╕рд╛рдорд╛рдиреНрдп рдЙрджреНрдпрдо AI рдХрд╛рд░реНрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╡рд┐рд╢реЗрд╖ APIs рд╕рд╣рд┐рдд рддрдпрд╛рд░-рдкреНрд░рдпреЛрдЧ AI рдХреНрд╖рдорддрд╛рд╣рд░реВ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред

## Ollama vs Foundry Local: рддреБрд▓рдирд╛рддреНрдордХ рд╡рд┐рд╢реНрд▓реЗрд╖рдг

### рдкреНрд░рд╛рд╡рд┐рдзрд┐рдХ рд╡рд╛рд╕реНрддреБрдХрд▓рд╛ рддреБрд▓рдирд╛

| **рдкрдХреНрд╖** | **Ollama** | **Foundry Local** |
|------------|------------|-------------------|
| **рдореЛрдбреЗрд▓ рдврд╛рдБрдЪрд╛** | GGUF (llama.cpp рдорд╛рд░реНрдлрдд) | ONNX (ONNX Runtime рдорд╛рд░реНрдлрдд) |
| **рдкреНрд▓реЗрдЯрдлрд░реНрдо рдлреЛрдХрд╕** | рдХреНрд░рд╕-рдкреНрд▓реЗрдЯрдлрд░реНрдо рд╕рд╛рд░реНрд╡рднреМрдорд┐рдХрддрд╛ | Windows/рдЙрджреНрдпрдо рдЕрдиреБрдХреВрд▓рди |
| **рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдПрдХреАрдХрд░рдг** | рд╕рд╛рдорд╛рдиреНрдп GPU/CPU рд╕рдорд░реНрдерди | Windows ML, NPU рд╕рдорд░реНрдерди |
| **рдЕрдиреБрдХреВрд▓рди** | llama.cpp рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╕рди | Microsoft Olive + ONNX Runtime |
| **рдЙрджреНрдпрдо рд╕реБрд╡рд┐рдзрд╛рд╣рд░реВ** | рд╕рдореБрджрд╛рдп-рдЪрд╛рд▓рд┐рдд | рдЙрджреНрдпрдо-рд╕реНрддрд░реАрдп SLA рд╕рд╣рд┐рдд |

### рдкреНрд░рджрд░реНрд╢рди рд╡рд┐рд╢реЗрд╖рддрд╛рд╣рд░реВ

**Ollama рдкреНрд░рджрд░реНрд╢рди рдмрд▓рд╣рд░реВ**:
- llama.cpp рдЕрдиреБрдХреВрд▓рди рдорд╛рд░реНрдлрдд рдЙрддреНрдХреГрд╖реНрдЯ CPU рдкреНрд░рджрд░реНрд╢рди
- рд╡рд┐рднрд┐рдиреНрди рдкреНрд▓реЗрдЯрдлрд░реНрдо рд░ рд╣рд╛рд░реНрдбрд╡реЗрдпрд░рдорд╛ рд╕реНрдерд┐рд░ рд╡реНрдпрд╡рд╣рд╛рд░
- рдмреБрджреНрдзрд┐рдорд╛рди рдореЛрдбреЗрд▓ рд▓реЛрдбрд┐рдЩрдХреЛ рд╕рд╛рде рдХреБрд╢рд▓ рдореЗрдореЛрд░реА рдЙрдкрдпреЛрдЧ
- рд╡рд┐рдХрд╛рд╕ рд░ рдкрд░реАрдХреНрд╖рдг рдкрд░рд┐рджреГрд╢реНрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЫрд┐рдЯреЛ рдХреЛрд▓реНрдб-рд╕реНрдЯрд╛рд░реНрдЯ рд╕рдордп

**Foundry Local рдкреНрд░рджрд░реНрд╢рди рдлрд╛рдЗрджрд╛рд╣рд░реВ**:
- рдЖрдзреБрдирд┐рдХ Windows рд╣рд╛рд░реНрдбрд╡реЗрдпрд░рдорд╛ рдЙрддреНрдХреГрд╖реНрдЯ NPU рдЙрдкрдпреЛрдЧ
- рд╡рд┐рдХреНрд░реЗрддрд╛ рд╕рд╛рдЭреЗрджрд╛рд░реАрд╣рд░реВ рдорд╛рд░реНрдлрдд GPU рдПрдХреНрд╕реЗрд▓реЗрд░реЗрд╢рди рдЕрдиреБрдХреВрд▓рд┐рдд
- рдЙрджреНрдпрдо-рд╕реНрддрд░реАрдп рдкреНрд░рджрд░реНрд╢рди рдирд┐рдЧрд░рд╛рдиреА рд░ рдЕрдиреБрдХреВрд▓рди
- рдЙрддреНрдкрд╛рджрди рд╡рд╛рддрд╛рд╡рд░рдгрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╕реНрдХреЗрд▓реЗрдмрд▓ рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдХреНрд╖рдорддрд╛

### рд╡рд┐рдХрд╛рд╕ рдЕрдиреБрднрд╡ рд╡рд┐рд╢реНрд▓реЗрд╖рдг

**Ollama рд╡рд┐рдХрд╛рд╕рдХрд░реНрддрд╛ рдЕрдиреБрднрд╡**:
- рдиреНрдпреВрдирддрдо рд╕реЗрдЯрдЕрдк рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВрдХреЛ рд╕рд╛рде рддрддреНрдХрд╛рд▓ рдЙрддреНрдкрд╛рджрдХрддрд╛
- рд╕рдмреИ рдЕрдкрд░реЗрд╢рдирд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╕рд╣рдЬ рдХрдорд╛рдгреНрдб-рд▓рд╛рдЗрди рдЗрдиреНрдЯрд░рдлреЗрд╕
- рд╡реНрдпрд╛рдкрдХ рд╕рдореБрджрд╛рдп рд╕рдорд░реНрдерди рд░ рджрд╕реНрддрд╛рд╡реЗрдЬреАрдХрд░рдг
- Modelfiles рдорд╛рд░реНрдлрдд рд▓рдЪрд┐рд▓реЛ рдЕрдиреБрдХреВрд▓рди

**Foundry Local рд╡рд┐рдХрд╛рд╕рдХрд░реНрддрд╛ рдЕрдиреБрднрд╡**:
- Visual Studio рдкрд╛рд░рд┐рд╕реНрдерд┐рддрд┐рдХреА рддрдиреНрддреНрд░рд╕рдБрдЧ рд╡реНрдпрд╛рдкрдХ IDE рдПрдХреАрдХрд░рдг
- рдЯреАрдо рд╕рд╣рдпреЛрдЧ рд╕реБрд╡рд┐рдзрд╛рд╣рд░реВ рд╕рд╣рд┐рдд рдЙрджреНрдпрдо рд╡рд┐рдХрд╛рд╕ рдХрд╛рд░реНрдпрдкреНрд░рд╡рд╛рд╣
- Microsoft рд╕рдорд░реНрдерди рдЪреНрдпрд╛рдирд▓рд╣рд░реВрд╕рдБрдЧ рд╡реНрдпрд╛рд╡рд╕рд╛рдпрд┐рдХ рд╕рдорд░реНрдерди
- рдЙрдиреНрдирдд рдбрд┐рдмрдЧрд┐рдЩ рд░ рдЕрдиреБрдХреВрд▓рди рдЙрдкрдХрд░рдгрд╣рд░реВ

### рдкреНрд░рдпреЛрдЧ рдХреЗрд╕ рдЕрдиреБрдХреВрд▓рди

**Ollama рдЪрдпрди рдЧрд░реНрдиреБрд╣реЛрд╕реН рдЬрдм**:
- рдХреНрд░рд╕-рдкреНрд▓реЗрдЯрдлрд░реНрдо рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВ рд╡рд┐рдХрд╛рд╕ рдЧрд░реНрджреИ рд╕реНрдерд┐рд░ рд╡реНрдпрд╡рд╣рд╛рд░ рдЖрд╡рд╢реНрдпрдХ рдЫ
- рдЦреБрд▓рд╛-рд╕реНрд░реЛрдд рдкрд╛рд░рджрд░реНрд╢рд┐рддрд╛ рд░ рд╕рдореБрджрд╛рдп рдпреЛрдЧрджрд╛рдирд▓рд╛рдИ рдкреНрд░рд╛рдердорд┐рдХрддрд╛ рджрд┐рдБрджреИ
- рд╕реАрдорд┐рдд рд╕реНрд░реЛрддрд╣рд░реВ рд╡рд╛ рдмрдЬреЗрдЯ рдмрд╛рдзрд╛рд╣рд░реВрдХреЛ рд╕рд╛рде рдХрд╛рдо рдЧрд░реНрджреИ
- рдкреНрд░рдпреЛрдЧрд╛рддреНрдордХ рд╡рд╛ рдЕрдиреБрд╕рдиреНрдзрд╛рди-рдХреЗрдВрджреНрд░рд┐рдд рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВ рдирд┐рд░реНрдорд╛рдг рдЧрд░реНрджреИ
- рд╡рд┐рднрд┐рдиреНрди рд╡рд╛рд╕реНрддреБрдХрд▓рд╛рд╣рд░реВрдорд╛ рд╡реНрдпрд╛рдкрдХ рдореЛрдбреЗрд▓ рдЕрдиреБрдХреВрд▓рддрд╛ рдЖрд╡рд╢реНрдпрдХ рдЫ

**Foundry Local рдЪрдпрди рдЧрд░реНрдиреБрд╣реЛрд╕реН рдЬрдм**:
- рдХрдбрд╛ рдкреНрд░рджрд░реНрд╢рди рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВ рд╕рд╣рд┐рдд рдЙрджреНрдпрдо рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВ рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдЧрд░реНрджреИ
- Windows-рд╡рд┐рд╢рд┐рд╖реНрдЯ рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдЕрдиреБрдХреВрд▓рди (NPU, Windows ML) рдЙрдкрдпреЛрдЧ рдЧрд░реНрджреИ
- рдЙрджреНрдпрдо рд╕рдорд░реНрдерди, SLA, рд░ рдЕрдиреБрдкрд╛рд▓рди рд╕реБрд╡рд┐рдзрд╛рд╣рд░реВ рдЖрд╡рд╢реНрдпрдХ рдЫ
- Microsoft рдкрд╛рд░рд┐рд╕реНрдерд┐рддрд┐рдХреА рддрдиреНрддреНрд░ рдПрдХреАрдХрд░рдгрдХреЛ рд╕рд╛рде рдЙрддреНрдкрд╛рджрди рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВ рдирд┐рд░реНрдорд╛рдг рдЧрд░реНрджреИ
- рдЙрдиреНрдирдд рдЕрдиреБрдХреВрд▓рди рдЙрдкрдХрд░рдгрд╣рд░реВ рд░ рд╡реНрдпрд╛рд╡рд╕рд╛рдпрд┐рдХ рд╡рд┐рдХрд╛рд╕ рдХрд╛рд░реНрдпрдкреНрд░рд╡рд╛рд╣ рдЖрд╡рд╢реНрдпрдХ рдЫ

## рдЙрдиреНрдирдд рдкрд░рд┐рдирд┐рдпреЛрдЬрди рд░рдгрдиреАрддрд┐рд╣рд░реВ

### рдХрдиреНрдЯреЗрдирд░рд╛рдЗрдЬреНрдб рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдврд╛рдБрдЪрд╛рд╣рд░реВ

**Ollama рдХрдиреНрдЯреЗрдирд░рд╛рдЗрдЬреЗрд╢рди**:

```dockerfile
FROM ollama/ollama:latest

# Pre-load models for faster startup
RUN ollama pull qwen2.5:3b
RUN ollama pull phi4:mini

# Custom configuration
COPY modelfile ./
RUN ollama create enterprise-model -f modelfile

# Expose API port
EXPOSE 11434

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:11434/api/health || exit 1
```

**Foundry Local рдЙрджреНрдпрдо рдкрд░рд┐рдирд┐рдпреЛрдЬрди**:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: foundry-local-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: foundry-local
  template:
    metadata:
      labels:
        app: foundry-local
    spec:
      containers:
      - name: foundry-local
        image: microsoft/foundry-local:latest
        ports:
        - containerPort: 8080
        resources:
          requests:
            memory: "4Gi"
            cpu: "2000m"
          limits:
            memory: "8Gi"
            cpu: "4000m"
        env:
        - name: FOUNDRY_MODEL
          value: "microsoft/phi-4-mini"
        - name: FOUNDRY_HARDWARE
          value: "npu,gpu,cpu"
```

### рдкреНрд░рджрд░реНрд╢рди рдЕрдиреБрдХреВрд▓рди рдкреНрд░рд╡рд┐рдзрд┐рд╣рд░реВ

**Ollama рдЕрдиреБрдХреВрд▓рди рд░рдгрдиреАрддрд┐рд╣рд░реВ**:

```bash
# GPU acceleration configuration
export OLLAMA_NUM_PARALLEL=4
export OLLAMA_MAX_LOADED_MODELS=2
export OLLAMA_FLASH_ATTENTION=1

# Memory optimization
export OLLAMA_MAX_VRAM=8G
export OLLAMA_KEEP_ALIVE=10m

# Start optimized server
ollama serve
```

**Foundry Local рдЕрдиреБрдХреВрд▓рди**:

```json
{
  "performance": {
    "batch_processing": true,
    "parallel_requests": 8,
    "memory_optimization": {
      "enable_kv_cache": true,
      "max_cache_size": "4GB"
    },
    "hardware_scheduling": {
      "enable_dynamic_batching": true,
      "max_batch_size": 16
    }
  }
}
```

## рд╕реБрд░рдХреНрд╖рд╛ рд░ рдЕрдиреБрдкрд╛рд▓рди рд╡рд┐рдЪрд╛рд░рд╣рд░реВ

### рдЙрджреНрдпрдо рд╕реБрд░рдХреНрд╖рд╛ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди

**Ollama рд╕реБрд░рдХреНрд╖рд╛ рдЙрддреНрддрдо рдЕрднреНрдпрд╛рд╕рд╣рд░реВ**:
- рдлрд╛рдпрд░рд╡рд╛рд▓ рдирд┐рдпрдорд╣рд░реВ рд░ VPN рдкрд╣реБрдБрдЪрдХреЛ рд╕рд╛рде рдиреЗрдЯрд╡рд░реНрдХ рдЕрд▓рдЧрд╛рд╡
- рд░рд┐рднрд░реНрд╕ рдкреНрд░реЛрдХреНрд╕реА рдПрдХреАрдХрд░рдг рдорд╛рд░реНрдлрдд рдкреНрд░рдорд╛рдгреАрдХрд░рдг
- рдореЛрдбреЗрд▓ рдЕрдЦрдгреНрдбрддрд╛ рдкреНрд░рдорд╛рдгреАрдХрд░рдг рд░ рд╕реБрд░рдХреНрд╖рд┐рдд рдореЛрдбреЗрд▓ рд╡рд┐рддрд░рдг
- API рдкрд╣реБрдБрдЪ рд░ рдореЛрдбреЗрд▓ рдЕрдкрд░реЗрд╢рдирд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЕрдбрд┐рдЯ рд▓рдЧрд┐рдЩ

**Foundry Local рдЙрджреНрдпрдо рд╕реБрд░рдХреНрд╖рд╛**:
- рд╕рдХреНрд░рд┐рдп рдирд┐рд░реНрджреЗрд╢рд┐рдХрд╛ рдПрдХреАрдХрд░рдгрдХреЛ рд╕рд╛рде рдирд┐рд░реНрдорд┐рдд рднреВрдорд┐рдХрд╛-рдЖрдзрд╛рд░рд┐рдд рдкрд╣реБрдБрдЪ рдирд┐рдпрдиреНрддреНрд░рдг
- рдЕрдиреБрдкрд╛рд▓рди рд░рд┐рдкреЛрд░реНрдЯрд┐рдЩрдХреЛ рд╕рд╛рде рд╡реНрдпрд╛рдкрдХ рдЕрдбрд┐рдЯ рдЯреНрд░реЗрд▓рд╣рд░реВ
- рдПрдиреНрдХреНрд░рд┐рдкреНрдЯреЗрдб рдореЛрдбреЗрд▓ рднрдгреНрдбрд╛рд░рдг рд░ рд╕реБрд░рдХреНрд╖рд┐рдд рдореЛрдбреЗрд▓ рдкрд░рд┐рдирд┐рдпреЛрдЬрди
- Microsoft рд╕реБрд░рдХреНрд╖рд╛ рдкреВрд░реНрд╡рд╛рдзрд╛рд░рд╕рдБрдЧрдХреЛ рдПрдХреАрдХрд░рдг

### рдЕрдиреБрдкрд╛рд▓рди рд░ рдирд┐рдпрд╛рдордХ рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВ

рджреБрд╡реИ рдкреНрд▓реЗрдЯрдлрд░реНрдорд▓реЗ рдирд┐рдореНрди рдорд╛рд░реНрдлрдд рдирд┐рдпрд╛рдордХ рдЕрдиреБрдкрд╛рд▓рдирд▓рд╛рдИ рд╕рдорд░реНрдерди рдЧрд░реНрджрдЫ:
- рд╕реНрдерд╛рдиреАрдп рдкреНрд░рд╢реЛрдзрди рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдЧрд░реНрдиреЗ рдбрд╛рдЯрд╛ рдирд┐рд╡рд╛рд╕ рдирд┐рдпрдиреНрддреНрд░рдгрд╣рд░реВ
- рдирд┐рдпрд╛рдордХ рд░рд┐рдкреЛрд░реНрдЯрд┐рдЩ рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЕрдбрд┐рдЯ рд▓рдЧрд┐рдЩ
- рд╕рдВрд╡реЗрджрдирд╢реАрд▓ рдбрд╛рдЯрд╛ рд╣реНрдпрд╛рдиреНрдбрд▓рд┐рдЩрдХреЛ рд▓рд╛рдЧрд┐ рдкрд╣реБрдБрдЪ рдирд┐рдпрдиреНрддреНрд░рдгрд╣рд░реВ
- рдбрд╛рдЯрд╛ рд╕рдВрд░рдХреНрд╖рдгрдХреЛ рд▓рд╛рдЧрд┐ рд╡рд┐рд╢реНрд░рд╛рдо рд░ рдЯреНрд░рд╛рдиреНрдЬрд┐рдЯрдорд╛ рдПрдиреНрдХреНрд░рд┐рдкреНрд╢рди

## рдЙрддреНрдкрд╛рджрди рдкрд░рд┐рдирд┐рдпреЛрдЬрдирдХрд╛ рд▓рд╛рдЧрд┐ рдЙрддреНрддрдо рдЕрднреНрдпрд╛рд╕рд╣рд░реВ

### рдирд┐рдЧрд░рд╛рдиреА рд░ рдЕрд╡рд▓реЛрдХрдиреАрдпрддрд╛

**рдирд┐рдЧрд░рд╛рдиреА рдЧрд░реНрдиреБрдкрд░реНрдиреЗ рдкреНрд░рдореБрдЦ рдореЗрдЯреНрд░рд┐рдХреНрд╕рд╣рд░реВ**:
- рдореЛрдбреЗрд▓ рдЕрдиреБрдорд╛рди рд╡рд┐рд▓рдореНрдмрддрд╛ рд░ рдереНрд░реВрдкреБрдЯ
- рд╕реНрд░реЛрдд рдЙрдкрдпреЛрдЧ (CPU, GPU, рдореЗрдореЛрд░реА)
- API рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рд╕рдордп рд░ рддреНрд░реБрдЯрд┐ рджрд░
- рдореЛрдбреЗрд▓ рд╕рдЯреАрдХрддрд╛ рд░ рдкреНрд░рджрд░реНрд╢рди рд╡рд┐рдЪрд▓рди

**рдирд┐рдЧрд░рд╛рдиреА рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди**:

```yaml
# Prometheus monitoring configuration
- job_name: 'ollama'
  static_configs:
    - targets: ['localhost:11434']
  metrics_path: '/metrics'
  
- job_name: 'foundry-local'
  static_configs:
    - targets: ['localhost:8080']
  metrics_path: '/api/metrics'
```

### рдирд┐рд░рдиреНрддрд░ рдПрдХреАрдХрд░рдг рд░ рдкрд░рд┐рдирд┐рдпреЛрдЬрди

**CI/CD рдкрд╛рдЗрдкрд▓рд╛рдЗрди рдПрдХреАрдХрд░рдг**:

```yaml
name: Deploy SLM Models
on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Deploy to Ollama
      run: |
        ollama pull qwen2.5:3b
        ollama create production-model -f Modelfile
        
    - name: Deploy to Foundry Local
      run: |
        foundry-local models pull microsoft/phi-4-mini
        foundry-local deploy --config production.json
```

## рднрд╡рд┐рд╖реНрдпрдХрд╛ рдкреНрд░рд╡реГрддреНрддрд┐рд╣рд░реВ рд░ рд╡рд┐рдЪрд╛рд░рд╣рд░реВ

### рдЙрджреАрдпрдорд╛рди рдкреНрд░рд╡рд┐рдзрд┐рд╣рд░реВ

рд╕реНрдерд╛рдиреАрдп SLM рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдкрд░рд┐рджреГрд╢реНрдпрд▓реЗ рдирд┐рдореНрди рдкреНрд░рдореБрдЦ рдкреНрд░рд╡реГрддреНрддрд┐рд╣рд░реВрдХреЛ рд╕рд╛рде рд╡рд┐рдХрд╛рд╕ рдЬрд╛рд░реА рд░рд╛рдЦреНрдЫ:

**рдЙрдиреНрдирдд рдореЛрдбреЗрд▓ рд╡рд╛рд╕реНрддреБрдХрд▓рд╛рд╣рд░реВ**: рд╕реБрдзрд╛рд░рд┐рдПрдХреЛ рджрдХреНрд╖рддрд╛ рд░ рдХреНрд╖рдорддрд╛ рдЕрдиреБрдкрд╛рддрд╣рд░реВ рд╕рд╣рд┐рддрдХреЛ рдЕрд░реНрдХреЛ рдкреБрд╕реНрддрд╛рдХреЛ SLMs рджреЗрдЦрд╛ рдкрд░реНрджреИрдЫрдиреН, рдЬрд╕рдорд╛ рдЧрддрд┐рд╢реАрд▓ рд╕реНрдХреЗрд▓рд┐рдЩрдХреЛ рд▓рд╛рдЧрд┐ mixture-of-experts рдореЛрдбреЗрд▓рд╣рд░реВ рд░ рдПрдЬ рдкрд░рд┐рдирд┐рдпреЛрдЬрдирдХрд╛ рд▓рд╛рдЧрд┐ рд╡рд┐рд╢реЗрд╖ рд╡рд╛рд╕реНрддреБрдХрд▓рд╛рд╣рд░реВ рд╕рдорд╛рд╡реЗрд╢ рдЫрдиреНред

**рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдПрдХреАрдХрд░рдг**: рд╡рд┐рд╢реЗрд╖ AI рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ (рдЬрд╕реНрддреИ NPUs, рдХрд╕реНрдЯрдо рд╕рд┐рд▓рд┐рдХрди, рд░ рдПрдЬ рдХрдореНрдкреНрдпреБрдЯрд┐рдЩ рдПрдХреНрд╕реЗрд▓реЗрд░реЗрдЯрд░рд╣рд░реВ) рд╕рдБрдЧрдХреЛ рдЧрд╣рд┐рд░реЛ рдПрдХреАрдХрд░рдгрд▓реЗ рд╕реБрдзрд╛рд░рд┐рдПрдХреЛ рдкреНрд░рджрд░реНрд╢рди рдХреНрд╖рдорддрд╛рд╣рд░реВ рдкреНрд░рджрд╛рди рдЧрд░реНрдиреЗрдЫред

**рдкрд╛рд░рд┐рд╕реНрдерд┐рддрд┐рдХреА рддрдиреНрддреНрд░ рд╡рд┐рдХрд╛рд╕**: рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдкреНрд▓реЗрдЯрдлрд░реНрдорд╣рд░реВрдорд╛ рдорд╛рдирдХреАрдХрд░рдг рдкреНрд░рдпрд╛рд╕рд╣рд░реВ рд░ рд╡рд┐рднрд┐рдиреНрди рдлреНрд░реЗрдорд╡рд░реНрдХрд╣рд░реВ рдмреАрдЪрдХреЛ рд╕реБрдзрд╛рд░рд┐рдПрдХреЛ рдЕрдиреНрддрд░рд╕рдЮреНрдЪрд╛рд▓рдирд▓реЗ рдмрд╣реБ-рдкреНрд▓реЗрдЯрдлрд░реНрдо рдкрд░рд┐рдирд┐рдпреЛрдЬрдирд▓рд╛рдИ рд╕рд░рд▓ рдмрдирд╛рдЙрдиреЗрдЫред

### рдЙрджреНрдпреЛрдЧ рдЕрдкрдирд╛рдЙрдиреЗ рдврд╛рдБрдЪрд╛рд╣рд░реВ

**рдЙрджреНрдпрдо рдЕрдкрдирд╛рдЙрдиреЗ**: рдЧреЛрдкрдиреАрдпрддрд╛ рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВ, рд▓рд╛рдЧрдд рдЕрдиреБрдХреВрд▓рди, рд░ рдирд┐рдпрд╛рдордХ рдЕрдиреБрдкрд╛рд▓рди рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВрд▓реЗ рдкреНрд░реЗрд░рд┐рдд рдмрдвреНрджреЛ рдЙрджреНрдпрдо рдЕрдкрдирд╛рдЙрдиреЗред рд╕рд░рдХрд╛рд░ рд░ рд░рдХреНрд╖рд╛ рдХреНрд╖реЗрддреНрд░рд╣рд░реВ рд╡рд┐рд╢реЗрд╖ рд░реВрдкрдорд╛ рдПрдпрд░-рдЧреНрдпрд╛рдк рдЧрд░рд┐рдПрдХреЛ рдкрд░рд┐рдирд┐рдпреЛрдЬрдирдорд╛ рдХреЗрдиреНрджреНрд░рд┐рдд рдЫрдиреНред

**рд╡реИрд╢реНрд╡рд┐рдХ рд╡рд┐рдЪрд╛рд░рд╣рд░реВ**: рдЕрдиреНрддрд░реНрд░рд╛рд╖реНрдЯреНрд░рд┐рдп рдбрд╛рдЯрд╛ рд╕рд╛рд░реНрд╡рднреМрдорд┐рдХрддрд╛ рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВрд▓реЗ рд╕реНрдерд╛рдиреАрдп рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдЕрдкрдирд╛рдЙрдиреЗрд▓рд╛рдИ рдкреНрд░реЗрд░рд┐рдд рдЧрд░реНрджреИрдЫрдиреН, рд╡рд┐рд╢реЗрд╖ рдЧрд░реА рдХрдбрд╛ рдбрд╛рдЯрд╛ рд╕рдВрд░рдХреНрд╖рдг рдирд┐рдпрдорд╣рд░реВ рднрдПрдХрд╛ рдХреНрд╖реЗрддреНрд░рд╣рд░реВрдорд╛ред

## рдЪреБрдиреМрддреАрд╣рд░реВ рд░ рд╡рд┐рдЪрд╛рд░рд╣рд░реВ

### рдкреНрд░рд╛рд╡рд┐рдзрд┐рдХ рдЪреБрдиреМрддреАрд╣рд░реВ

**рдкреВрд░реНрд╡рд╛рдзрд╛рд░ рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВ**: рд╕реНрдерд╛рдиреАрдп рдкрд░рд┐рдирд┐рдпреЛрдЬрдирд▓реЗ рд╕рд╛рд╡рдзрд╛рдиреАрдкреВрд░реНрд╡рдХ рдХреНрд╖рдорддрд╛ рдпреЛрдЬрдирд╛ рд░ рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдЪрдпрди рдЖрд╡рд╢реНрдпрдХ рдЫред рд╕рдВрдЧрдардирд╣рд░реВрд▓реЗ рдкреНрд░рджрд░реНрд╢рди рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВрд▓рд╛рдИ рд▓рд╛рдЧрдд рдмрд╛рдзрд╛рд╣рд░реВрдХреЛ рд╕рд╛рде рд╕рдиреНрддреБрд▓рди рдЧрд░реНрдиреБрдкрд░реНрдЫ, рдЬрдмрдХрд┐ рдмрдвреНрджреЛ рдХрд╛рд░реНрдпрднрд╛рд░рд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╕реНрдХреЗрд▓реЗрдмрд┐рд▓рд┐рдЯреА рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдЧрд░реНрдиреБрдкрд░реНрдЫред

**ЁЯФз рдорд░реНрдордд рд░ рдЕрдкрдбреЗрдЯрд╣рд░реВ**: рдирд┐рдпрдорд┐рдд рдореЛрдбреЗрд▓ рдЕрдкрдбреЗрдЯрд╣рд░реВ, рд╕реБрд░рдХреНрд╖рд╛ рдкреНрдпрд╛рдЪрд╣рд░реВ, рд░ рдкреНрд░рджрд░реНрд╢рди рдЕрдиреБрдХреВрд▓рдирд▓реЗ рд╕рдорд░реНрдкрд┐рдд рд╕реНрд░реЛрддрд╣рд░реВ рд░ рд╡рд┐рд╢реЗрд╖рдЬреНрдЮрддрд╛ рдЖрд╡рд╢реНрдпрдХ рдЫред рдЙрддреНрдкрд╛рджрди рд╡рд╛рддрд╛рд╡рд░рдгрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдкрд╛рдЗрдкрд▓рд╛рдЗрдирд╣рд░реВ рдЖрд╡рд╢реНрдпрдХ рд╣реБрдиреНрдЫ

---

**рдЕрд╕реНрд╡реАрдХрд░рдг**:  
рдпреЛ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ AI рдЕрдиреБрд╡рд╛рдж рд╕реЗрд╡рд╛ [Co-op Translator](https://github.com/Azure/co-op-translator) рдкреНрд░рдпреЛрдЧ рдЧрд░реЗрд░ рдЕрдиреБрд╡рд╛рдж рдЧрд░рд┐рдПрдХреЛ рдЫред рд╣рд╛рдореА рдпрдерд╛рд░реНрдерддрд╛рдХреЛ рд▓рд╛рдЧрд┐ рдкреНрд░рдпрд╛рд╕ рдЧрд░реНрдЫреМрдВ, рддрд░ рдХреГрдкрдпрд╛ рдзреНрдпрд╛рди рджрд┐рдиреБрд╣реЛрд╕реН рдХрд┐ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдЕрдиреБрд╡рд╛рджрдорд╛ рддреНрд░реБрдЯрд┐рд╣рд░реВ рд╡рд╛ рдЕрд╢реБрджреНрдзрддрд╛рд╣рд░реВ рд╣реБрди рд╕рдХреНрдЫред рдпрд╕рдХреЛ рдореВрд▓ рднрд╛рд╖рд╛ рдорд╛ рд░рд╣реЗрдХреЛ рдореВрд▓ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝рд▓рд╛рдИ рдЖрдзрд┐рдХрд╛рд░рд┐рдХ рд╕реНрд░реЛрдд рдорд╛рдирд┐рдиреБрдкрд░реНрдЫред рдорд╣рддреНрд╡рдкреВрд░реНрдг рдЬрд╛рдирдХрд╛рд░реАрдХреЛ рд▓рд╛рдЧрд┐, рд╡реНрдпрд╛рд╡рд╕рд╛рдпрд┐рдХ рдорд╛рдирд╡ рдЕрдиреБрд╡рд╛рдж рд╕рд┐рдлрд╛рд░рд┐рд╕ рдЧрд░рд┐рдиреНрдЫред рдпрд╕ рдЕрдиреБрд╡рд╛рджрдХреЛ рдкреНрд░рдпреЛрдЧрдмрд╛рдЯ рдЙрддреНрдкрдиреНрди рд╣реБрдиреЗ рдХреБрдиреИ рдкрдирд┐ рдЧрд▓рддрдлрд╣рдореА рд╡рд╛ рдЧрд▓рдд рд╡реНрдпрд╛рдЦреНрдпрд╛рдХреЛ рд▓рд╛рдЧрд┐ рд╣рд╛рдореА рдЬрд┐рдореНрдореЗрд╡рд╛рд░ рд╣реБрдиреЗ рдЫреИрдиреМрдВред