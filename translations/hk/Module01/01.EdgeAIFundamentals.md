<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "76b134be93f45283a2df8f8a93717d06",
  "translation_date": "2025-10-17T09:16:38+00:00",
  "source_file": "Module01/01.EdgeAIFundamentals.md",
  "language_code": "hk"
}
-->
# ç¬¬ä¸€ç« ï¼šEdgeAI åŸºç¤çŸ¥è­˜

EdgeAI ä»£è¡¨äººå·¥æ™ºèƒ½éƒ¨ç½²çš„ä¸€å€‹æ–°ç¯„å¼ï¼Œå°‡ AI èƒ½åŠ›ç›´æ¥å¸¶åˆ°é‚Šç·£è¨­å‚™ï¼Œè€Œä¸åƒ…åƒ…ä¾è³´æ–¼åŸºæ–¼é›²ç«¯çš„è™•ç†ã€‚äº†è§£ EdgeAI å¦‚ä½•åœ¨è³‡æºæœ‰é™çš„è¨­å‚™ä¸Šé€²è¡Œæœ¬åœ° AI è™•ç†ï¼ŒåŒæ™‚ä¿æŒåˆç†çš„æ€§èƒ½ä¸¦è§£æ±ºéš±ç§ã€å»¶é²å’Œé›¢ç·šåŠŸèƒ½ç­‰æŒ‘æˆ°æ˜¯éå¸¸é‡è¦çš„ã€‚

## ç°¡ä»‹

åœ¨æœ¬èª²ç¨‹ä¸­ï¼Œæˆ‘å€‘å°‡æ¢è¨ EdgeAI åŠå…¶åŸºæœ¬æ¦‚å¿µã€‚æˆ‘å€‘å°‡æ¶µè“‹å‚³çµ± AI è¨ˆç®—ç¯„å¼ã€é‚Šç·£è¨ˆç®—çš„æŒ‘æˆ°ã€æ”¯æŒ EdgeAI çš„é—œéµæŠ€è¡“ï¼Œä»¥åŠåœ¨å„è¡Œæ¥­ä¸­çš„å¯¦éš›æ‡‰ç”¨ã€‚

## å­¸ç¿’ç›®æ¨™

å®Œæˆæœ¬èª²ç¨‹å¾Œï¼Œæ‚¨å°‡èƒ½å¤ ï¼š

- ç†è§£å‚³çµ±åŸºæ–¼é›²ç«¯çš„ AI æ–¹æ³•èˆ‡ EdgeAI æ–¹æ³•çš„å€åˆ¥ã€‚
- è­˜åˆ¥æ”¯æŒé‚Šç·£è¨­å‚™ä¸Š AI è™•ç†çš„é—œéµæŠ€è¡“ã€‚
- èªè­˜ EdgeAI å¯¦æ–½çš„å„ªå‹¢å’Œå±€é™æ€§ã€‚
- å°‡ EdgeAI çš„çŸ¥è­˜æ‡‰ç”¨æ–¼çœŸå¯¦å ´æ™¯å’Œä½¿ç”¨æ¡ˆä¾‹ã€‚

## ç†è§£å‚³çµ± AI è¨ˆç®—ç¯„å¼

å‚³çµ±ä¸Šï¼Œç”Ÿæˆå¼ AI æ‡‰ç”¨ä¾è³´æ–¼é«˜æ€§èƒ½è¨ˆç®—åŸºç¤è¨­æ–½ä¾†æœ‰æ•ˆé‹è¡Œå¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚çµ„ç¹”é€šå¸¸å°‡é€™äº›æ¨¡å‹éƒ¨ç½²åœ¨é›²ç«¯ç’°å¢ƒä¸­çš„ GPU é›†ç¾¤ä¸Šï¼Œé€šé API æ¥å£è¨ªå•å…¶åŠŸèƒ½ã€‚

é€™ç¨®é›†ä¸­å¼æ¨¡å‹å°è¨±å¤šæ‡‰ç”¨ä¾†èªªæ•ˆæœè‰¯å¥½ï¼Œä½†åœ¨é‚Šç·£è¨ˆç®—å ´æ™¯ä¸­å­˜åœ¨å›ºæœ‰çš„å±€é™æ€§ã€‚å‚³çµ±æ–¹æ³•æ¶‰åŠå°‡ç”¨æˆ¶æŸ¥è©¢ç™¼é€åˆ°é ç¨‹æœå‹™å™¨ï¼Œä½¿ç”¨å¼·å¤§çš„ç¡¬ä»¶é€²è¡Œè™•ç†ï¼Œä¸¦é€šéäº’è¯ç¶²è¿”å›çµæœã€‚é›–ç„¶æ­¤æ–¹æ³•æä¾›äº†æœ€å…ˆé€²çš„æ¨¡å‹è¨ªå•ï¼Œä½†å®ƒå°äº’è¯ç¶²é€£æ¥ç”¢ç”Ÿä¾è³´ï¼Œå¼•å…¥äº†å»¶é²å•é¡Œï¼Œä¸¦åœ¨éœ€è¦å°‡æ•æ„Ÿæ•¸æ“šå‚³è¼¸åˆ°å¤–éƒ¨æœå‹™å™¨æ™‚å¼•ç™¼éš±ç§å•é¡Œã€‚

åœ¨ä½¿ç”¨å‚³çµ± AI è¨ˆç®—ç¯„å¼æ™‚ï¼Œæˆ‘å€‘éœ€è¦ç†è§£ä¸€äº›æ ¸å¿ƒæ¦‚å¿µï¼š

- **â˜ï¸ åŸºæ–¼é›²ç«¯çš„è™•ç†**ï¼šAI æ¨¡å‹åœ¨å…·æœ‰é«˜è¨ˆç®—è³‡æºçš„å¼·å¤§æœå‹™å™¨åŸºç¤è¨­æ–½ä¸Šé‹è¡Œã€‚
- **ğŸ”Œ åŸºæ–¼ API çš„è¨ªå•**ï¼šæ‡‰ç”¨é€šéé ç¨‹ API èª¿ç”¨è¨ªå• AI åŠŸèƒ½ï¼Œè€Œéæœ¬åœ°è™•ç†ã€‚
- **ğŸ›ï¸ é›†ä¸­å¼æ¨¡å‹ç®¡ç†**ï¼šæ¨¡å‹é›†ä¸­ç¶­è­·å’Œæ›´æ–°ï¼Œç¢ºä¿ä¸€è‡´æ€§ä½†éœ€è¦ç¶²çµ¡é€£æ¥ã€‚
- **ğŸ“ˆ è³‡æºå¯æ“´å±•æ€§**ï¼šé›²åŸºç¤è¨­æ–½å¯ä»¥å‹•æ…‹æ“´å±•ä»¥æ‡‰å°ä¸åŒçš„è¨ˆç®—éœ€æ±‚ã€‚

## é‚Šç·£è¨ˆç®—çš„æŒ‘æˆ°

é‚Šç·£è¨­å‚™å¦‚ç­†è¨˜æœ¬é›»è…¦ã€æ‰‹æ©Ÿä»¥åŠç‰©è¯ç¶²ï¼ˆIoTï¼‰è¨­å‚™ï¼ˆå¦‚ Raspberry Pi å’Œ NVIDIA Orin Nanoï¼‰å…·æœ‰ç¨ç‰¹çš„è¨ˆç®—é™åˆ¶ã€‚èˆ‡æ•¸æ“šä¸­å¿ƒåŸºç¤è¨­æ–½ç›¸æ¯”ï¼Œé€™äº›è¨­å‚™é€šå¸¸å…·æœ‰æœ‰é™çš„è™•ç†èƒ½åŠ›ã€å…§å­˜å’Œèƒ½æºè³‡æºã€‚

ç”±æ–¼é€™äº›ç¡¬ä»¶é™åˆ¶ï¼Œå‚³çµ± LLMs åœ¨æ­¤é¡è¨­å‚™ä¸Šé‹è¡Œä¸€ç›´å…·æœ‰æŒ‘æˆ°æ€§ã€‚ç„¶è€Œï¼Œåœ¨å„ç¨®å ´æ™¯ä¸­ï¼Œé‚Šç·£ AI è™•ç†çš„éœ€æ±‚è®Šå¾—è¶Šä¾†è¶Šé‡è¦ã€‚è€ƒæ…®ä»¥ä¸‹æƒ…æ³ï¼šäº’è¯ç¶²é€£æ¥ä¸å¯é æˆ–ä¸å¯ç”¨ï¼Œä¾‹å¦‚åé çš„å·¥æ¥­åœ°é»ã€è¡Œé§›ä¸­çš„è»Šè¼›æˆ–ç¶²çµ¡è¦†è“‹ä¸ä½³çš„åœ°å€ã€‚æ­¤å¤–ï¼Œè¦æ±‚é«˜å®‰å…¨æ¨™æº–çš„æ‡‰ç”¨ï¼ˆå¦‚é†«ç™‚è¨­å‚™ã€é‡‘èç³»çµ±æˆ–æ”¿åºœæ‡‰ç”¨ï¼‰å¯èƒ½éœ€è¦æœ¬åœ°è™•ç†æ•æ„Ÿæ•¸æ“šä»¥ä¿æŒéš±ç§å’Œåˆè¦æ€§ã€‚

### é‚Šç·£è¨ˆç®—çš„ä¸»è¦é™åˆ¶

é‚Šç·£è¨ˆç®—ç’°å¢ƒé¢è‡¨ä¸€äº›å‚³çµ±åŸºæ–¼é›²ç«¯çš„ AI è§£æ±ºæ–¹æ¡ˆæ‰€ä¸é‡åˆ°çš„åŸºæœ¬é™åˆ¶ï¼š

- **æœ‰é™çš„è™•ç†èƒ½åŠ›**ï¼šé‚Šç·£è¨­å‚™é€šå¸¸å…·æœ‰è¼ƒå°‘çš„ CPU æ ¸å¿ƒå’Œè¼ƒä½çš„æ™‚é˜é€Ÿåº¦ï¼Œèˆ‡æœå‹™å™¨ç´šç¡¬ä»¶ç›¸æ¯”ã€‚
- **å…§å­˜é™åˆ¶**ï¼šé‚Šç·£è¨­å‚™ä¸Šçš„å¯ç”¨ RAM å’Œå­˜å„²å®¹é‡é¡¯è‘—æ¸›å°‘ã€‚
- **èƒ½æºé™åˆ¶**ï¼šé›»æ± ä¾›é›»çš„è¨­å‚™å¿…é ˆåœ¨æ€§èƒ½å’Œèƒ½æºæ¶ˆè€—ä¹‹é–“å–å¾—å¹³è¡¡ï¼Œä»¥å»¶é•·é‹è¡Œæ™‚é–“ã€‚
- **ç†±ç®¡ç†**ï¼šç·Šæ¹Šçš„å¤–å½¢é™åˆ¶äº†å†·å»èƒ½åŠ›ï¼Œå½±éŸ¿äº†è² è¼‰ä¸‹çš„æŒçºŒæ€§èƒ½ã€‚

## ä»€éº¼æ˜¯ EdgeAIï¼Ÿ

### æ¦‚å¿µï¼šEdgeAI å®šç¾©

EdgeAI æ˜¯æŒ‡äººå·¥æ™ºèƒ½ç®—æ³•ç›´æ¥éƒ¨ç½²å’ŒåŸ·è¡Œæ–¼é‚Šç·£è¨­å‚™â€”â€”å³ç¶²çµ¡â€œé‚Šç·£â€è™•çš„ç‰©ç†ç¡¬ä»¶ï¼Œé è¿‘æ•¸æ“šç”Ÿæˆå’Œæ”¶é›†çš„åœ°æ–¹ã€‚é€™äº›è¨­å‚™åŒ…æ‹¬æ™ºèƒ½æ‰‹æ©Ÿã€IoT å‚³æ„Ÿå™¨ã€æ™ºèƒ½æ”åƒé ­ã€è‡ªå‹•é§•é§›è»Šè¼›ã€å¯ç©¿æˆ´è¨­å‚™å’Œå·¥æ¥­è¨­å‚™ã€‚èˆ‡ä¾è³´é›²æœå‹™å™¨é€²è¡Œè™•ç†çš„å‚³çµ± AI ç³»çµ±ä¸åŒï¼ŒEdgeAI å°‡æ™ºèƒ½ç›´æ¥å¸¶åˆ°æ•¸æ“šæºã€‚

EdgeAI çš„æ ¸å¿ƒæ˜¯å»ä¸­å¿ƒåŒ– AI è™•ç†ï¼Œå°‡å…¶å¾é›†ä¸­å¼æ•¸æ“šä¸­å¿ƒç§»å‹•åˆ°æ§‹æˆæˆ‘å€‘æ•¸å­—ç”Ÿæ…‹ç³»çµ±çš„å»£æ³›è¨­å‚™ç¶²çµ¡ä¸­åˆ†ä½ˆã€‚é€™ä»£è¡¨äº† AI ç³»çµ±è¨­è¨ˆå’Œéƒ¨ç½²æ–¹å¼çš„æ ¹æœ¬æ¶æ§‹è½‰è®Šã€‚

EdgeAI çš„é—œéµæ¦‚å¿µæ”¯æŸ±åŒ…æ‹¬ï¼š

- **å°±è¿‘è™•ç†**ï¼šè¨ˆç®—åœ¨æ•¸æ“šä¾†æºé™„è¿‘ç‰©ç†ç™¼ç”Ÿ
- **åˆ†æ•£å¼æ™ºèƒ½**ï¼šæ±ºç­–èƒ½åŠ›åˆ†ä½ˆæ–¼å¤šå€‹è¨­å‚™
- **æ•¸æ“šä¸»æ¬Š**ï¼šä¿¡æ¯ä¿æŒåœ¨æœ¬åœ°æ§åˆ¶ä¹‹ä¸‹ï¼Œé€šå¸¸ä¸é›¢é–‹è¨­å‚™
- **è‡ªä¸»é‹è¡Œ**ï¼šè¨­å‚™å¯ä»¥åœ¨ä¸éœ€è¦æŒçºŒé€£æ¥çš„æƒ…æ³ä¸‹æ™ºèƒ½é‹è¡Œ
- **åµŒå…¥å¼ AI**ï¼šæ™ºèƒ½æˆç‚ºæ—¥å¸¸è¨­å‚™çš„å…§åœ¨èƒ½åŠ›

### EdgeAI æ¶æ§‹å¯è¦–åŒ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         TRADITIONAL AI ARCHITECTURE                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   Data Transfer  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   API Response   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Edge Devices â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚ Cloud Servers â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ End Users â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     Data                         Model Inference                     Results
   Collection                     High Latency
                                  High Bandwidth
                                  Privacy Concerns
                               
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            EDGE AI ARCHITECTURE                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   Direct Response  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Edge Devices with Embedded AI         â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚ End Users â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â”‚ Sensors â”‚â”€>â”‚ SLM Inference â”‚â”€>â”‚ Local Action â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     Data         Low Latency       Immediate
   Collection     Processing        Response
                  No Data Transfer
                  Enhanced Privacy
```

EdgeAI ä»£è¡¨äººå·¥æ™ºèƒ½éƒ¨ç½²çš„ä¸€å€‹æ–°ç¯„å¼ï¼Œå°‡ AI èƒ½åŠ›ç›´æ¥å¸¶åˆ°é‚Šç·£è¨­å‚™ï¼Œè€Œä¸åƒ…åƒ…ä¾è³´æ–¼åŸºæ–¼é›²ç«¯çš„è™•ç†ã€‚æ­¤æ–¹æ³•ä½¿ AI æ¨¡å‹èƒ½å¤ åœ¨å…·æœ‰æœ‰é™è¨ˆç®—è³‡æºçš„è¨­å‚™ä¸Šæœ¬åœ°é‹è¡Œï¼Œæä¾›å¯¦æ™‚æ¨ç†èƒ½åŠ›è€Œç„¡éœ€æŒçºŒçš„äº’è¯ç¶²é€£æ¥ã€‚

EdgeAI æ¶µè“‹äº†å„ç¨®æŠ€è¡“å’Œæ–¹æ³•ï¼Œæ—¨åœ¨ä½¿ AI æ¨¡å‹æ›´é«˜æ•ˆä¸¦é©åˆåœ¨è³‡æºæœ‰é™çš„è¨­å‚™ä¸Šéƒ¨ç½²ã€‚ç›®æ¨™æ˜¯åœ¨é¡¯è‘—é™ä½ AI æ¨¡å‹çš„è¨ˆç®—å’Œå…§å­˜éœ€æ±‚çš„åŒæ™‚ä¿æŒåˆç†çš„æ€§èƒ½ã€‚

è®“æˆ‘å€‘ä¾†çœ‹çœ‹æ”¯æŒ EdgeAI åœ¨ä¸åŒè¨­å‚™é¡å‹å’Œä½¿ç”¨æ¡ˆä¾‹ä¸­å¯¦æ–½çš„åŸºæœ¬æ–¹æ³•ã€‚

### EdgeAI æ ¸å¿ƒåŸå‰‡

EdgeAI å»ºç«‹åœ¨å¹¾å€‹å€åˆ¥æ–¼å‚³çµ±åŸºæ–¼é›²ç«¯ AI çš„åŸºç¤åŸå‰‡ä¹‹ä¸Šï¼š

- **æœ¬åœ°è™•ç†**ï¼šAI æ¨ç†ç›´æ¥åœ¨é‚Šç·£è¨­å‚™ä¸Šé€²è¡Œï¼Œç„¡éœ€å¤–éƒ¨é€£æ¥ã€‚
- **è³‡æºå„ªåŒ–**ï¼šæ¨¡å‹å°ˆé–€é‡å°ç›®æ¨™è¨­å‚™çš„ç¡¬ä»¶é™åˆ¶é€²è¡Œå„ªåŒ–ã€‚
- **å¯¦æ™‚æ€§èƒ½**ï¼šè™•ç†ä»¥æœ€å°å»¶é²é€²è¡Œï¼Œé©ç”¨æ–¼æ™‚é–“æ•æ„Ÿçš„æ‡‰ç”¨ã€‚
- **éš±ç§è¨­è¨ˆ**ï¼šæ•æ„Ÿæ•¸æ“šä¿æŒåœ¨è¨­å‚™ä¸Šï¼Œå¢å¼·å®‰å…¨æ€§å’Œåˆè¦æ€§ã€‚

## æ”¯æŒ EdgeAI çš„é—œéµæŠ€è¡“

### æ¨¡å‹é‡åŒ–

EdgeAI ä¸­æœ€é‡è¦çš„æŠ€è¡“ä¹‹ä¸€æ˜¯æ¨¡å‹é‡åŒ–ã€‚æ­¤éç¨‹æ¶‰åŠå°‡æ¨¡å‹åƒæ•¸çš„ç²¾åº¦å¾ 32 ä½æµ®é»æ•¸é™ä½åˆ° 8 ä½æ•´æ•¸ç”šè‡³æ›´ä½çš„ç²¾åº¦æ ¼å¼ã€‚é›–ç„¶ç²¾åº¦çš„é™ä½å¯èƒ½çœ‹èµ·ä¾†ä»¤äººæ“”æ†‚ï¼Œä½†ç ”ç©¶è¡¨æ˜ï¼Œè¨±å¤š AI æ¨¡å‹å³ä½¿åœ¨ç²¾åº¦é¡¯è‘—é™ä½çš„æƒ…æ³ä¸‹ä»èƒ½ä¿æŒå…¶æ€§èƒ½ã€‚

é‡åŒ–é€šéå°‡æµ®é»å€¼çš„ç¯„åœæ˜ å°„åˆ°ä¸€çµ„è¼ƒå°çš„é›¢æ•£å€¼ä¾†å·¥ä½œã€‚ä¾‹å¦‚ï¼Œé‡åŒ–å¯èƒ½åƒ…ä½¿ç”¨ 8 ä½ä¾†è¡¨ç¤ºæ¯å€‹åƒæ•¸ï¼Œè€Œä¸æ˜¯ä½¿ç”¨ 32 ä½ï¼Œå¾è€Œæ¸›å°‘ 4 å€çš„å…§å­˜éœ€æ±‚ï¼Œä¸¦é€šå¸¸å°è‡´æ›´å¿«çš„æ¨ç†æ™‚é–“ã€‚

```python
# Example: PyTorch model quantization 
import torch

# Load a pre-trained model
model = torch.load('large_model.pth')

# Quantize the model to INT8
quantized_model = torch.quantization.quantize_dynamic(
    model,  # model to quantize
    {torch.nn.Linear, torch.nn.Conv2d},  # layers to quantize
    dtype=torch.qint8  # quantization data type
)

# Save the quantized model
torch.save(quantized_model, 'quantized_model.pth')

# Memory usage comparison
original_size = model.size()
quantized_size = quantized_model.size()
print(f"Memory reduction: {original_size / quantized_size:.2f}x")
```

ä¸åŒçš„é‡åŒ–æŠ€è¡“åŒ…æ‹¬ï¼š

- **å¾Œè¨“ç·´é‡åŒ–ï¼ˆPTQï¼‰**ï¼šåœ¨æ¨¡å‹è¨“ç·´å¾Œæ‡‰ç”¨ï¼Œç„¡éœ€é‡æ–°è¨“ç·´
- **é‡åŒ–æ„ŸçŸ¥è¨“ç·´ï¼ˆQATï¼‰**ï¼šåœ¨è¨“ç·´æœŸé–“ç´å…¥é‡åŒ–æ•ˆæœä»¥æé«˜æº–ç¢ºæ€§
- **å‹•æ…‹é‡åŒ–**ï¼šå°‡æ¬Šé‡é‡åŒ–ç‚º int8ï¼Œä½†å‹•æ…‹è¨ˆç®—æ¿€æ´»
- **éœæ…‹é‡åŒ–**ï¼šé å…ˆè¨ˆç®—æ¬Šé‡å’Œæ¿€æ´»çš„æ‰€æœ‰é‡åŒ–åƒæ•¸

å°æ–¼ EdgeAI éƒ¨ç½²ï¼Œé¸æ“‡é©ç•¶çš„é‡åŒ–ç­–ç•¥å–æ±ºæ–¼ç‰¹å®šçš„æ¨¡å‹æ¶æ§‹ã€æ€§èƒ½éœ€æ±‚ä»¥åŠç›®æ¨™è¨­å‚™çš„ç¡¬ä»¶èƒ½åŠ›ã€‚

### æ¨¡å‹å£“ç¸®å’Œå„ªåŒ–

é™¤äº†é‡åŒ–ä¹‹å¤–ï¼Œå„ç¨®å£“ç¸®æŠ€è¡“æœ‰åŠ©æ–¼æ¸›å°‘æ¨¡å‹å¤§å°å’Œè¨ˆç®—éœ€æ±‚ï¼ŒåŒ…æ‹¬ï¼š

**å‰ªæ**ï¼šæ­¤æŠ€è¡“ç§»é™¤ç¥ç¶“ç¶²çµ¡ä¸­ä¸å¿…è¦çš„é€£æ¥æˆ–ç¥ç¶“å…ƒã€‚é€šéè­˜åˆ¥ä¸¦æ¶ˆé™¤å°æ¨¡å‹æ€§èƒ½è²¢ç»è¼ƒå°çš„åƒæ•¸ï¼Œå‰ªæå¯ä»¥é¡¯è‘—æ¸›å°‘æ¨¡å‹å¤§å°ï¼ŒåŒæ™‚ä¿æŒæº–ç¢ºæ€§ã€‚

```python
# Example: Neural network pruning in TensorFlow
import tensorflow as tf
import tensorflow_model_optimization as tfmot

# Define the model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Apply pruning during training
pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(
    initial_sparsity=0.0,
    final_sparsity=0.5,  # 50% of connections will be pruned
    begin_step=0,
    end_step=10000
)

pruned_model = tfmot.sparsity.keras.prune_low_magnitude(
    model, pruning_schedule=pruning_schedule
)

# Compile the pruned model
pruned_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model while pruning
pruned_model.fit(x_train, y_train, epochs=10)

# Convert to a smaller model for deployment
final_model = tfmot.sparsity.keras.strip_pruning(pruned_model)
```

**çŸ¥è­˜è’¸é¤¾**ï¼šæ­¤æ–¹æ³•æ¶‰åŠè¨“ç·´ä¸€å€‹è¼ƒå°çš„â€œå­¸ç”Ÿâ€æ¨¡å‹ä¾†æ¨¡ä»¿è¼ƒå¤§çš„â€œæ•™å¸«â€æ¨¡å‹çš„è¡Œç‚ºã€‚å­¸ç”Ÿæ¨¡å‹å­¸ç¿’è¿‘ä¼¼æ•™å¸«çš„è¼¸å‡ºï¼Œé€šå¸¸ä»¥é¡¯è‘—è¼ƒå°‘çš„åƒæ•¸å¯¦ç¾é¡ä¼¼çš„æ€§èƒ½ã€‚

**æ¨¡å‹æ¶æ§‹å„ªåŒ–**ï¼šç ”ç©¶äººå“¡é–‹ç™¼äº†å°ˆé–€è¨­è¨ˆç”¨æ–¼é‚Šç·£éƒ¨ç½²çš„æ¶æ§‹ï¼Œä¾‹å¦‚ MobileNetsã€EfficientNets å’Œå…¶ä»–è¼•é‡ç´šæ¶æ§‹ï¼Œå¹³è¡¡æ€§èƒ½èˆ‡è¨ˆç®—æ•ˆç‡ã€‚

### å°å‹èªè¨€æ¨¡å‹ï¼ˆSLMsï¼‰

EdgeAI çš„ä¸€å€‹æ–°èˆˆè¶¨å‹¢æ˜¯å°å‹èªè¨€æ¨¡å‹ï¼ˆSLMsï¼‰çš„é–‹ç™¼ã€‚é€™äº›æ¨¡å‹å¾é›¶é–‹å§‹è¨­è¨ˆï¼Œæ—¢ç·Šæ¹Šåˆé«˜æ•ˆï¼ŒåŒæ™‚ä»æä¾›æœ‰æ„ç¾©çš„è‡ªç„¶èªè¨€åŠŸèƒ½ã€‚SLMs é€šéç²¾å¿ƒçš„æ¶æ§‹é¸æ“‡ã€é«˜æ•ˆçš„è¨“ç·´æŠ€è¡“ä»¥åŠå°ˆæ³¨æ–¼ç‰¹å®šé ˜åŸŸæˆ–ä»»å‹™çš„è¨“ç·´ä¾†å¯¦ç¾ã€‚

èˆ‡å‚³çµ±æ–¹æ³•å£“ç¸®å¤§å‹æ¨¡å‹ä¸åŒï¼ŒSLMs é€šå¸¸ä½¿ç”¨è¼ƒå°çš„æ•¸æ“šé›†å’Œå°ˆé–€è¨­è¨ˆçš„æ¶æ§‹é€²è¡Œè¨“ç·´ï¼Œå°ˆé–€é‡å°é‚Šç·£éƒ¨ç½²ã€‚æ­¤æ–¹æ³•å¯ä»¥ç”¢ç”Ÿä¸åƒ…æ›´å°ä¸”æ›´é«˜æ•ˆçš„æ¨¡å‹ï¼Œé©ç”¨æ–¼ç‰¹å®šä½¿ç”¨æ¡ˆä¾‹ã€‚

## EdgeAI çš„ç¡¬ä»¶åŠ é€Ÿ

ç¾ä»£é‚Šç·£è¨­å‚™è¶Šä¾†è¶Šå¤šåœ°åŒ…æ‹¬å°ˆé–€è¨­è¨ˆç”¨æ–¼åŠ é€Ÿ AI å·¥ä½œè² è¼‰çš„ç¡¬ä»¶ï¼š

### ç¥ç¶“è™•ç†å–®å…ƒï¼ˆNPUsï¼‰

NPUs æ˜¯å°ˆé–€è¨­è¨ˆç”¨æ–¼ç¥ç¶“ç¶²çµ¡è¨ˆç®—çš„è™•ç†å™¨ã€‚é€™äº›èŠ¯ç‰‡å¯ä»¥æ¯”å‚³çµ± CPU æ›´é«˜æ•ˆåœ°åŸ·è¡Œ AI æ¨ç†ä»»å‹™ï¼Œé€šå¸¸å…·æœ‰æ›´ä½çš„åŠŸè€—ã€‚è¨±å¤šç¾ä»£æ™ºèƒ½æ‰‹æ©Ÿã€ç­†è¨˜æœ¬é›»è…¦å’Œ IoT è¨­å‚™ç¾åœ¨éƒ½åŒ…æ‹¬ NPUsï¼Œä»¥æ”¯æŒè¨­å‚™ä¸Šçš„ AI è™•ç†ã€‚

```csharp
// Example: Using Windows ML to target NPU acceleration in C#
using Microsoft.ML.OnnxRuntime;

// Create session options with NPU provider
var sessionOptions = new SessionOptions();
sessionOptions.AppendExecutionProvider_DmlExecutionProvider();  // DirectML for NPU

// Load the ONNX model
using var session = new InferenceSession("model.onnx", sessionOptions);

// Create input tensor
var inputTensor = new DenseTensor<float>(new[] { 1, 3, 224, 224 });  // Example input shape
var inputs = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor("input", inputTensor) };

// Run inference with NPU acceleration
using var results = session.Run(inputs);
var output = results.First().AsTensor<float>();

// Process output
Console.WriteLine($"Inference result: {output[0]}");
```

å…·æœ‰ NPUs çš„è¨­å‚™åŒ…æ‹¬ï¼š

- **Apple**ï¼šé…å‚™ Neural Engine çš„ A ç³»åˆ—å’Œ M ç³»åˆ—èŠ¯ç‰‡
- **Qualcomm**ï¼šé…å‚™ Hexagon DSP/NPU çš„ Snapdragon è™•ç†å™¨
- **Samsung**ï¼šé…å‚™ NPU çš„ Exynos è™•ç†å™¨
- **Intel**ï¼šMovidius VPUs å’Œ Habana Labs åŠ é€Ÿå™¨
- **Microsoft**ï¼šé…å‚™ NPUs çš„ Windows Copilot+ PC

### ğŸ® GPU åŠ é€Ÿ

é›–ç„¶é‚Šç·£è¨­å‚™å¯èƒ½æ²’æœ‰æ•¸æ“šä¸­å¿ƒä¸­çš„å¼·å¤§ GPUï¼Œä½†è¨±å¤šä»åŒ…æ‹¬é›†æˆæˆ–ç¨ç«‹ GPUï¼Œå¯ä»¥åŠ é€Ÿ AI å·¥ä½œè² è¼‰ã€‚ç¾ä»£ç§»å‹• GPU å’Œé›†æˆåœ–å½¢è™•ç†å™¨å¯ä»¥ç‚º AI æ¨ç†ä»»å‹™æä¾›é¡¯è‘—çš„æ€§èƒ½æå‡ã€‚

```python
# Example: Using TensorRT for GPU acceleration on edge devices
import tensorrt as trt
import numpy as np

# Create TensorRT logger and builder
TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
builder = trt.Builder(TRT_LOGGER)
network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
parser = trt.OnnxParser(network, TRT_LOGGER)

# Parse ONNX model
with open('model.onnx', 'rb') as model:
    parser.parse(model.read())

# Configure builder
config = builder.create_builder_config()
config.max_workspace_size = 1 << 28  # 256 MiB
config.set_flag(trt.BuilderFlag.FP16)  # Use FP16 precision for edge GPU

# Build and serialize engine
engine = builder.build_engine(network, config)
with open('model.trt', 'wb') as f:
    f.write(engine.serialize())
```

### CPU å„ªåŒ–

å³ä½¿æ˜¯åƒ…é…å‚™ CPU çš„è¨­å‚™ä¹Ÿå¯ä»¥é€šéå„ªåŒ–å¯¦ç¾ EdgeAIã€‚ç¾ä»£ CPU åŒ…æ‹¬å°ˆé–€çš„ AI å·¥ä½œè² è¼‰æŒ‡ä»¤ï¼Œä¸¦ä¸”å·²é–‹ç™¼å‡ºè»Ÿä»¶æ¡†æ¶ä»¥æœ€å¤§åŒ– CPU åœ¨ AI æ¨ç†ä¸­çš„æ€§èƒ½ã€‚

```bash
# Example: Using XNNPACK with TFLite for optimized CPU inference
# Compilation command with XNNPACK acceleration enabled

bazel build -c opt --copt=-O3 --copt=-march=native \
  tensorflow/lite/delegates/xnnpack:libxnnpack_delegate.so

# Convert TensorFlow model to TFLite with optimization
tflite_convert \
  --keras_model_file=model.h5 \
  --output_file=model.tflite \
  --inference_type=FLOAT \
  --experimental_new_converter \
  --experimental_new_quantizer
```

å°æ–¼å¾äº‹ EdgeAI çš„è»Ÿä»¶å·¥ç¨‹å¸«ä¾†èªªï¼Œäº†è§£å¦‚ä½•åˆ©ç”¨é€™äº›ç¡¬ä»¶åŠ é€Ÿé¸é …å°æ–¼å„ªåŒ–ç›®æ¨™è¨­å‚™ä¸Šçš„æ¨ç†æ€§èƒ½å’Œèƒ½æºæ•ˆç‡è‡³é—œé‡è¦ã€‚

## EdgeAI çš„å„ªå‹¢

### éš±ç§å’Œå®‰å…¨

EdgeAI çš„æœ€å¤§å„ªå‹¢ä¹‹ä¸€æ˜¯å¢å¼·çš„éš±ç§å’Œå®‰å…¨æ€§ã€‚é€šéåœ¨è¨­å‚™ä¸Šæœ¬åœ°è™•ç†æ•¸æ“šï¼Œæ•æ„Ÿä¿¡æ¯æ°¸é ä¸æœƒé›¢é–‹ç”¨æˆ¶çš„æ§åˆ¶ç¯„åœã€‚é€™å°æ–¼è™•ç†å€‹äººæ•¸æ“šã€é†«ç™‚ä¿¡æ¯æˆ–æ©Ÿå¯†å•†æ¥­æ•¸æ“šçš„æ‡‰ç”¨å°¤ç‚ºé‡è¦ã€‚

### æ¸›å°‘å»¶é²

EdgeAI æ¶ˆé™¤äº†å°‡æ•¸æ“šç™¼é€åˆ°é ç¨‹æœå‹™å™¨é€²è¡Œè™•ç†çš„éœ€æ±‚ï¼Œé¡¯è‘—æ¸›å°‘äº†å»¶é²ã€‚é€™å°æ–¼éœ€è¦å³æ™‚éŸ¿æ‡‰çš„æ‡‰ç”¨ï¼ˆå¦‚è‡ªå‹•é§•é§›è»Šè¼›ã€å·¥æ¥­è‡ªå‹•åŒ–æˆ–äº¤äº’å¼æ‡‰ç”¨ï¼‰è‡³é—œé‡è¦ã€‚

### é›¢ç·šåŠŸèƒ½

EdgeAI å³ä½¿åœ¨äº’è¯ç¶²é€£æ¥ä¸å¯ç”¨æ™‚ä¹Ÿèƒ½å¯¦ç¾ AI åŠŸèƒ½ã€‚é€™å°æ–¼åé åœ°å€ã€æ—…è¡ŒæœŸé–“æˆ–ç¶²çµ¡å¯é æ€§æˆå•é¡Œçš„æƒ…æ³ä¸‹çš„æ‡‰ç”¨éå¸¸æœ‰åƒ¹å€¼ã€‚

### æˆæœ¬æ•ˆç›Š

é€šéæ¸›å°‘å°åŸºæ–¼é›²ç«¯çš„ AI æœå‹™çš„ä¾è³´ï¼ŒEdgeAI å¯ä»¥å¹«åŠ©é™ä½é‹ç‡Ÿæˆæœ¬ï¼Œç‰¹åˆ¥æ˜¯å°æ–¼ä½¿ç”¨é‡å¤§çš„æ‡‰ç”¨ã€‚çµ„ç¹”å¯ä»¥é¿å…æŒçºŒçš„ API æˆæœ¬ä¸¦æ¸›å°‘å¸¶å¯¬éœ€æ±‚ã€‚

### å¯æ“´å±•æ€§

EdgeAI å°‡è¨ˆç®—è² è¼‰åˆ†ä½ˆåˆ°é‚Šç·£è¨­å‚™ä¸Šï¼Œè€Œä¸æ˜¯é›†ä¸­åœ¨æ•¸æ“šä¸­å¿ƒã€‚é€™å¯ä»¥å¹«åŠ©é™ä½åŸºç¤è¨­æ–½æˆæœ¬ä¸¦æé«˜æ•´é«”ç³»çµ±çš„å¯æ“´å±•æ€§ã€‚

## EdgeAI çš„æ‡‰ç”¨

### æ™ºèƒ½è¨­å‚™å’Œç‰©è¯ç¶²

EdgeAI ç‚ºè¨±å¤šæ™ºèƒ½è¨­å‚™åŠŸèƒ½æä¾›æ”¯æŒï¼Œå¾å¯ä»¥æœ¬åœ°è™•ç†å‘½ä»¤çš„èªéŸ³åŠ©æ‰‹åˆ°å¯ä»¥è­˜åˆ¥ç‰©é«”å’Œäººç‰©çš„æ™ºèƒ½æ”åƒé ­ï¼Œè€Œç„¡éœ€å°‡è¦–é »ç™¼é€åˆ°é›²ç«¯ã€‚ç‰©è¯ç¶²è¨­å‚™ä½¿ç”¨ EdgeAI é€²è¡Œé æ¸¬æ€§ç¶­è­·ã€ç’°å¢ƒç›£æ¸¬å’Œè‡ªå‹•åŒ–æ±ºç­–ã€‚

### ç§»å‹•æ‡‰ç”¨

æ™ºèƒ½æ‰‹æ©Ÿå’Œå¹³æ¿é›»è…¦ä½¿ç”¨ EdgeAI æä¾›å„ç¨®åŠŸèƒ½ï¼ŒåŒ…æ‹¬ç…§ç‰‡å¢å¼·ã€å¯¦æ™‚ç¿»è­¯ã€å¢å¼·ç¾å¯¦å’Œå€‹æ€§åŒ–æ¨è–¦ã€‚é€™äº›æ‡‰ç”¨å—ç›Šæ–¼æœ¬åœ°è™•ç†çš„ä½å»¶é²å’Œéš±ç§å„ªå‹¢ã€‚

### å·¥æ¥­æ‡‰ç”¨

è£½é€ å’Œå·¥æ¥­ç’°å¢ƒä½¿ç”¨ EdgeAI é€²è¡Œè³ªé‡æ§åˆ¶ã€é æ¸¬æ€§ç¶­è­·å’Œæµç¨‹å„ªåŒ–ã€‚é€™äº›æ‡‰ç”¨é€šå¸¸éœ€è¦å¯¦æ™‚è™•ç†ï¼Œä¸¦å¯èƒ½åœ¨é€£æ¥æœ‰é™çš„ç’°å¢ƒä¸­é‹è¡Œã€‚

### é†«ç™‚ä¿å¥

é†«ç™‚è¨­å‚™å’Œé†«ç™‚æ‡‰ç”¨ä½¿ç”¨ EdgeAI é€²è¡Œæ‚£è€…ç›£æ¸¬ã€è¨ºæ–·è¼”åŠ©å’Œæ²»ç™‚å»ºè­°ã€‚æœ¬åœ°è™•ç†çš„éš±ç§å’Œå®‰å…¨æ€§å„ªå‹¢åœ¨é†«ç™‚æ‡‰ç”¨ä¸­ç‰¹åˆ¥é‡è¦ã€‚

## æŒ‘æˆ°å’Œå±€é™æ€§

### æ€§èƒ½å–æ¨

EdgeAI é€šå¸¸æ¶‰åŠæ¨¡å‹å¤§å°ã€è¨ˆç®—æ•ˆç‡å’Œæ€§èƒ½ä¹‹é–“çš„å–æ¨ã€‚é›–ç„¶é‡åŒ–å’Œå‰ªæç­‰æŠ€è¡“å¯ä»¥é¡¯è‘—æ¸›å°‘è³‡æºéœ€æ±‚ï¼Œä½†å®ƒå€‘ä¹Ÿå¯èƒ½å½±éŸ¿æ¨¡å‹çš„æº–ç¢ºæ€§æˆ–èƒ½åŠ›ã€‚

### é–‹ç™¼è¤‡é›œæ€§

é–‹ç™¼ EdgeAI æ‡‰ç”¨éœ€è¦å°ˆæ¥­çŸ¥è­˜å’Œå·¥å…·ã€‚é–‹ç™¼äººå“¡å¿…é ˆäº†è§£å„ªåŒ–æŠ€è¡“ã€ç¡¬ä»¶èƒ½åŠ›å’Œéƒ¨ç½²é™åˆ¶ï¼Œé€™å¯èƒ½å¢åŠ é–‹ç™¼çš„è¤‡é›œæ€§ã€‚

### ç¡¬ä»¶é™åˆ¶

å„˜ç®¡é‚Šç·£ç¡¬ä»¶å–å¾—äº†é€²æ­¥ï¼Œä½†èˆ‡æ•¸æ“šä¸­å¿ƒåŸºç¤è¨­æ–½ç›¸æ¯”ï¼Œé€™äº›è¨­å‚™ä»ç„¶å­˜åœ¨é¡¯è‘—é™åˆ¶ã€‚ä¸¦éæ‰€æœ‰ AI æ‡‰ç”¨éƒ½èƒ½æœ‰æ•ˆéƒ¨ç½²åœ¨é‚Šç·£è¨­å‚™ä¸Šï¼Œæœ‰äº›å¯èƒ½éœ€è¦æ··åˆæ–¹æ³•ã€‚

### æ¨¡å‹æ›´æ–°å’Œç¶­è­·

æ›´æ–°éƒ¨ç½²åœ¨é‚Šç·£è¨­å‚™ä¸Šçš„ AI æ¨¡å‹å¯èƒ½å…·æœ‰æŒ‘æˆ°æ€§ï¼Œç‰¹åˆ¥æ˜¯å°æ–¼é€£æ¥æˆ–å­˜å„²å®¹é‡æœ‰é™çš„è¨­å‚™ã€‚çµ„ç¹”å¿…é ˆåˆ¶å®šæ¨¡å‹ç‰ˆæœ¬ç®¡ç†ã€æ›´æ–°å’Œç¶­è­·çš„ç­–ç•¥ã€‚

## EdgeAI çš„æœªä¾†

EdgeAI é ˜åŸŸæ­£åœ¨å¿«é€Ÿç™¼å±•ï¼Œç¡¬ä»¶ã€è»Ÿä»¶å’ŒæŠ€è¡“æ–¹é¢çš„æŒçºŒé€²æ­¥ã€‚æœªä¾†è¶¨å‹¢åŒ…æ‹¬æ›´å¤šå°ˆé–€çš„é‚Šç·£ AI èŠ¯ç‰‡ã€æ”¹é€²çš„å„ªåŒ–æŠ€è¡“ä»¥åŠæ›´å¥½çš„ EdgeAI é–‹ç™¼å’Œéƒ¨ç½²å·¥å…·ã€‚

éš¨è‘— 5G ç¶²çµ¡çš„æ™®åŠï¼Œæˆ‘å€‘å¯èƒ½æœƒçœ‹åˆ°çµåˆé‚Šç·£è™•ç†å’Œé›²ç«¯èƒ½åŠ›çš„æ··åˆæ–¹æ³•ï¼Œå¯¦ç¾æ›´è¤‡é›œçš„ AI æ‡‰ç”¨ï¼ŒåŒæ™‚ä¿æŒæœ¬åœ°è™•ç†çš„å„ªå‹¢ã€‚

EdgeAI ä»£è¡¨äº†ä¸€ç¨®æ›´åˆ†æ•£ã€æ›´é«˜æ•ˆã€æ›´æ³¨é‡éš±ç§çš„ AI ç³»çµ±çš„æ ¹æœ¬è½‰è®Šã€‚éš¨è‘—æŠ€è¡“çš„ä¸æ–·æˆç†Ÿï¼Œæˆ‘å€‘å¯ä»¥é æœŸ EdgeAI åœ¨æ”¯æŒå„ç¨®æ‡‰ç”¨å’Œè¨­å‚™çš„ AI èƒ½åŠ›æ–¹é¢è®Šå¾—è¶Šä¾†è¶Šé‡è¦ã€‚

é€šé EdgeAI çš„ AI æ°‘ä¸»åŒ–é–‹å•Ÿäº†å‰µæ–°çš„æ–°å¯èƒ½æ€§ï¼Œä½¿é–‹ç™¼è€…èƒ½å¤ å‰µå»ºåœ¨å¤šæ¨£åŒ–ç’°å¢ƒä¸­å¯é é‹è¡Œçš„ AI é©…å‹•æ‡‰ç”¨ï¼ŒåŒæ™‚å°Šé‡ç”¨æˆ¶éš±ç§ä¸¦æä¾›éŸ¿æ‡‰è¿…é€Ÿçš„å¯¦æ™‚é«”é©—ã€‚ç†è§£ EdgeAI å°æ–¼ä»»ä½•å¾äº‹ AI æŠ€è¡“çš„äººä¾†èªªè¶Šä¾†è¶Šé‡è¦ï¼Œå› ç‚ºå®ƒä»£è¡¨äº† AI åœ¨æˆ‘å€‘æ—¥å¸¸ç”Ÿæ´»ä¸­éƒ¨ç½²å’Œé«”é©—çš„æœªä¾†ã€‚

## â¡ï¸ ä¸‹ä¸€æ­¥
- [02: EdgeAI æ‡‰ç”¨](02.RealWorldCaseStudies.md)

---

**å…è²¬è²æ˜**ï¼š  
æ­¤æ–‡ä»¶å·²ä½¿ç”¨äººå·¥æ™ºèƒ½ç¿»è­¯æœå‹™ [Co-op Translator](https://github.com/Azure/co-op-translator) é€²è¡Œç¿»è­¯ã€‚æˆ‘å€‘è‡´åŠ›æ–¼æä¾›æº–ç¢ºçš„ç¿»è­¯ï¼Œä½†è«‹æ³¨æ„ï¼Œè‡ªå‹•ç¿»è­¯å¯èƒ½åŒ…å«éŒ¯èª¤æˆ–ä¸æº–ç¢ºä¹‹è™•ã€‚åŸå§‹æ–‡ä»¶çš„æ¯èªç‰ˆæœ¬æ‡‰è¢«è¦–ç‚ºæ¬Šå¨ä¾†æºã€‚å°æ–¼é‡è¦ä¿¡æ¯ï¼Œå»ºè­°ä½¿ç”¨å°ˆæ¥­äººå·¥ç¿»è­¯ã€‚æˆ‘å€‘ä¸å°å› ä½¿ç”¨æ­¤ç¿»è­¯è€Œå¼•èµ·çš„ä»»ä½•èª¤è§£æˆ–èª¤é‡‹æ‰¿æ“”è²¬ä»»ã€‚