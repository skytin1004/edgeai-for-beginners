<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20892f7994d9e5d2473ad19dfa93cf6d",
  "translation_date": "2025-09-18T09:28:12+00:00",
  "source_file": "Module02/01.PhiFamily.md",
  "language_code": "da"
}
-->
# Afsnit 1: Grundl√¶ggende om Microsoft Phi Model Family

Microsoft Phi-model familien repr√¶senterer et paradigmeskift inden for kunstig intelligens og viser, at kompakte, effektive modeller kan opn√• bem√¶rkelsesv√¶rdig ydeevne, samtidig med at de er betydeligt mere ressourceeffektive end traditionelle store sprogmodeller. Det er vigtigt at forst√•, hvordan Phi-familien muligg√∏r kraftfulde AI-funktioner med reducerede beregningskrav, mens den opretholder h√∏j ydeevne p√• tv√¶rs af forskellige opgaver.

## Ressourcer til udviklere

### Azure AI Foundry Model Catalog
Phi-modellerne (undtagen Phi-silica) er tilg√¶ngelige via [Azure AI Foundry Model Catalog](https://ai.azure.com/explore/models?q=phi), hvilket g√∏r det nemt for udviklere at f√• adgang til, finjustere og implementere disse modeller i deres applikationer. Kataloget giver en str√∏mlinet m√•de at eksperimentere med forskellige Phi-varianter og integrere dem i dine projekter.

### Azure AI Foundry
Du kan implementere og eksperimentere med Phi-modeller ved hj√¶lp af [Azure AI Foundry](https://ai.azure.com), som tilbyder et omfattende milj√∏ til at bygge, teste og implementere AI-l√∏sninger med minimal ops√¶tning.

### Foundry Local
Til lokal udvikling og implementering kan du tjekke [Microsoft Foundry Local](https://github.com/microsoft/foundry-local), som g√∏r det muligt at k√∏re Phi-modeller p√• din udviklingsmaskine med optimerede konfigurationer.

### Dokumentationsressourcer
- [Microsoft Research: Phi Model Technical Reports](https://ai.azure.com/labs/projects/phi-4)
- [Phi Cookbook](https://aka.ms/phicookbook)

## Introduktion

I denne lektion vil vi udforske Microsofts Phi-model familie og dens grundl√¶ggende koncepter. Vi vil d√¶kke udviklingen af Phi-familien, de innovative tr√¶ningsmetoder, der g√∏r Phi-modeller effektive, n√∏glevarianter i familien og praktiske anvendelser p√• tv√¶rs af forskellige scenarier.

## L√¶ringsm√•l

Ved afslutningen af denne lektion vil du kunne:

- Forst√• designfilosofien og udviklingen af Microsofts Phi-model familie.
- Identificere de vigtigste innovationer, der g√∏r det muligt for Phi-modeller at opn√• h√∏j ydeevne med f√¶rre parametre.
- Genkende fordelene og begr√¶nsningerne ved forskellige Phi-model varianter.
- Anvende viden om Phi-modeller til at v√¶lge passende varianter til virkelige scenarier.

## Forst√•else af det traditionelle AI-model paradigme

Traditionelt har det kr√¶vet massive sprogmodeller med milliarder eller hundrede milliarder parametre at opn√• h√∏j ydeevne inden for naturlig sprogbehandling. Organisationer implementerer typisk disse modeller p√• kraftfulde GPU-klynger og f√•r adgang til deres funktioner via API-gr√¶nseflader eller specialiseret hardwareinfrastruktur.

Denne tilgang fungerer godt for mange applikationer, men har iboende begr√¶nsninger i praktiske implementeringsscenarier. Den konventionelle metode involverer brug af modeller, der kr√¶ver betydelige beregningsressourcer, store m√¶ngder hukommelse og betydeligt energiforbrug. Selvom denne tilgang giver adgang til avancerede funktioner, skaber den afh√¶ngighed af dyr hardware, introducerer h√∏je driftsomkostninger og begr√¶nser implementeringsfleksibilitet.

## Udfordringen med effektiv AI-implementering

Behovet for mere effektiv AI er blevet stadig vigtigere p√• tv√¶rs af forskellige scenarier. Overvej applikationer, der kr√¶ver lokal implementering af hensyn til privatliv, omkostningsf√∏lsomme l√∏sninger, hvor cloud-API-omkostninger bliver uoverkommelige, edge computing-scenarier med begr√¶nsede hardware ressourcer eller realtidsapplikationer, hvor lav latenstid er kritisk.

### Centrale implementeringsbegr√¶nsninger

Traditionelle implementeringer af store modeller st√•r over for flere grundl√¶ggende begr√¶nsninger, der begr√¶nser deres praktiske anvendelighed:

- **Omkostningsbegr√¶nsninger**: H√∏je beregningsomkostninger g√∏r kontinuerlig implementering dyr for mange organisationer.
- **Ressourcebegr√¶nsninger**: Begr√¶nset adgang til avanceret GPU-infrastruktur begr√¶nser implementeringsmuligheder.
- **Privatlivskrav**: F√∏lsomme applikationer kr√¶ver lokal behandling for at opretholde databeskyttelse.
- **Latenstidssensitivitet**: Realtidsapplikationer har brug for √∏jeblikkelige svar uden forsinkelser fra cloud-rundture.

## Microsoft Phi Model Filosofien

Microsoft Phi-model familien repr√¶senterer et fundamentalt skift i AI-model designfilosofi, der prioriterer effektivitet og praktisk implementering, samtidig med at den opretholder st√¶rke ydeevneegenskaber. Phi-modeller opn√•r dette gennem innovative arkitekturer, h√∏j kvalitet i tr√¶ningsmetoder og specialiserede optimeringsteknikker.

Phi-familien omfatter forskellige tilgange designet til at maksimere ydeevne pr. parameter, hvilket muligg√∏r implementering p√• standardhardware, samtidig med at der leveres meningsfulde AI-funktioner. M√•let er at opretholde konkurrencedygtig ydeevne, samtidig med at beregningskrav, hukommelsesforbrug og driftsomkostninger reduceres dramatisk.

### Centrale Phi Designprincipper

Phi-modeller er bygget p√• flere grundl√¶ggende principper, der adskiller dem fra traditionelle store sprogmodeller:

- **Effektivitet f√∏rst**: Optimeret til maksimal ydeevne pr. parameter frem for absolut skala.
- **Kvalitetstr√¶ning**: Fokus p√• h√∏j kvalitet, kurateret tr√¶ningsdata frem for massive datas√¶t.
- **Implementeringsfleksibilitet**: Designet til at fungere effektivt p√• forskellige hardwarekonfigurationer.
- **Specialiserede funktioner**: Ofte optimeret til specifikke opgaver eller dom√¶ner for at maksimere effektiviteten.

## N√∏gleteknologier, der muligg√∏r Phi-familien

### Den "l√¶rebogsbaserede" tr√¶ningsmetode

En af de mest revolutionerende aspekter ved Phi-familien er den "l√¶rebogskvalitet" tr√¶ningsmetode. I stedet for at tr√¶ne p√• massive m√¶ngder ufiltreret internetdata bruger Phi-modeller omhyggeligt kurateret, h√∏j kvalitet uddannelsesindhold designet til effektivt at undervise i r√¶sonnement, matematik, kodning og generel viden.

Denne tilgang fungerer ved at skabe syntetisk uddannelsesindhold, der afspejler h√∏j kvalitet l√¶reb√∏ger og akademiske materialer. Tr√¶ningsdataene er specifikt designet til at v√¶re p√¶dagogisk solide med fokus p√• klare forklaringer, trin-for-trin r√¶sonnement og struktureret videnspr√¶sentation.

### Avanceret r√¶sonnementstr√¶ning

Nylige Phi-modeller inkorporerer sofistikerede r√¶sonnementstr√¶ningsmetoder, der muligg√∏r kompleks multi-trins probleml√∏sning. Disse teknikker inkluderer:

**Chain-of-Thought Training**: Modeller l√¶rer at opdele komplekse problemer i mellemliggende r√¶sonnementstrin, hvilket g√∏r deres probleml√∏sningsproces mere gennemsigtig og p√•lidelig.

**Inference-Time Scaling**: Modeller genererer detaljerede r√¶sonnementsk√¶der, der udnytter yderligere beregningsressourcer under responsgenerering for forbedret n√∏jagtighed.

**Edge-of-Capability Training**: Tr√¶ningsdata er specifikt udvalgt til at udfordre modellen p√• kanten af dens nuv√¶rende kapaciteter, hvilket fremmer l√¶ring af komplekse r√¶sonnementsm√∏nstre.

### Arkitektoniske innovationer

Phi-familien inkorporerer flere arkitektoniske optimeringer designet specifikt til effektivitet:

**Parametereffektivitet**: Omhyggelige arkitektoniske valg, der maksimerer effekten af hver parameter i modellen.

**Multimodal integration**: Effektiv integration af tekst-, billed- og talebehandlingsfunktioner inden for kompakte arkitekturer.

**Hardwareoptimering**: Specialiserede varianter optimeret til specifikke hardwareplatforme og implementeringsscenarier.

## Hardwareoptimering for Phi-modeller

Moderne implementeringsmilj√∏er drager fordel af Phi-modellers effektivitet p√• tv√¶rs af forskellige hardwarekonfigurationer:

### CPU-optimeret implementering

Phi-modeller er designet til at fungere effektivt p√• CPU-baseret hardware, hvilket g√∏r dem tilg√¶ngelige til implementering p√• standard computere uden behov for specialiserede AI-acceleratorer.

### GPU-acceleration

Selvom de ikke kr√¶ver kraftfulde GPU'er, kan Phi-modeller udnytte tilg√¶ngelige GPU-ressourcer for forbedret ydeevne, hvilket giver fleksibilitet i implementeringskonfigurationer.

### Edge-enhedsintegration

Specialiserede varianter som Phi-3-Silica er optimeret til specifikke edge computing-platforme og opn√•r bem√¶rkelsesv√¶rdige effektivitetsm√•linger, s√•som 650 tokens per sekund med kun 1,5W str√∏mforbrug.

## Fordele ved Phi-model familien

### Omkostningseffektivitet

Phi-modeller reducerer driftsomkostninger dramatisk ved at kr√¶ve betydeligt mindre beregningsinfrastruktur, samtidig med at de opretholder konkurrencedygtig ydeevne. Dette g√∏r AI tilg√¶ngelig for organisationer med begr√¶nsede budgetter eller applikationer med h√∏j volumen, hvor omkostninger pr. inferens er afg√∏rende.

### Implementeringsfleksibilitet

Phi-modellers effektivitet muligg√∏r implementering p√• tv√¶rs af en bred vifte af hardwarekonfigurationer, fra personlige laptops til virksomhedens servere, hvilket giver organisationer st√∏rre fleksibilitet i deres AI-infrastrukturvalg.

### Privatliv og sikkerhed

Phi-modellers effektivitet muligg√∏r lokal implementering for privatlivsf√∏lsomme applikationer, hvilket sikrer, at f√∏lsomme data aldrig forlader organisationens kontrol, samtidig med at der leveres kraftfulde AI-funktioner.

### Realtidsydelse

Reducerede beregningskrav overs√¶ttes til hurtigere inferenstider, hvilket muligg√∏r realtidsapplikationer, der kr√¶ver √∏jeblikkelige svar uden at g√• p√• kompromis med kvaliteten af AI-funktioner.

### Tilg√¶ngelig AI

Ved at reducere barrierer for AI-implementering g√∏r Phi-modeller avancerede AI-funktioner tilg√¶ngelige for organisationer med begr√¶nsede ressourcer, hvilket giver mindre teams og individuelle udviklere mulighed for at udnytte sofistikeret sprogforst√•else.

## Praktiske eksempler og anvendelser

F√∏r vi dykker ned i den tekniske udvikling, lad os udforske nogle konkrete eksempler p√•, hvad Phi-modeller kan opn√•:

### Eksempel p√• matematisk r√¶sonnement

Phi-4-mini-reasoning udm√¶rker sig ved trin-for-trin matematisk probleml√∏sning. For eksempel, n√•r den bliver spurgt "Hvordan l√∏ser man 3*x^2+4*x+5=1?", giver modellen detaljerede r√¶sonnementstrin:

```
<|system|>Your name is Phi, an AI math expert developed by Microsoft.<|end|>
<|user|>How to solve 3*x^2+4*x+5=1?<|end|>
<|assistant|>
I need to solve the quadratic equation 3x¬≤ + 4x + 5 = 1.

First, let me rearrange this to standard form:
3x¬≤ + 4x + 5 = 1
3x¬≤ + 4x + 5 - 1 = 0  
3x¬≤ + 4x + 4 = 0

Now I can use the quadratic formula: x = (-b ¬± ‚àö(b¬≤ - 4ac)) / (2a)
Where a = 3, b = 4, c = 4

Let me calculate the discriminant:
b¬≤ - 4ac = 4¬≤ - 4(3)(4) = 16 - 48 = -32

Since the discriminant is negative (-32), this equation has no real solutions.
The solutions are complex: x = (-4 ¬± ‚àö(-32)) / 6 = (-4 ¬± 4i‚àö2) / 6 = (-2 ¬± 2i‚àö2) / 3
```

### Eksempel p√• flersproget support

Phi-3.5-mini-instruct demonstrerer st√¶rke flersprogede funktioner p√• tv√¶rs af forskellige sprog. Her er et eksempel p√• promptformat:

```
<|system|>You are a helpful assistant.<|end|>
<|user|>How to explain Internet for a medieval knight?<|end|>
<|assistant|>
Imagine, good sir knight, a vast network of invisible roads that span the entire realm and beyond. The Internet is like a magical system of messenger birds that can carry any message - be it text, images, or even moving pictures - instantly to any castle, village, or hamlet in the world.

Think of it as if every scribe's work could be copied and shared with thousands of people simultaneously, as if you could visit any library in any kingdom without leaving your chambers, or as if you could hold council with knights from distant lands as if they were sitting at your very table.

This "Internet" allows people to:
- Send messages faster than the swiftest horse
- Access knowledge from scholars across all kingdoms
- Trade goods without traveling to distant markets
- Share stories and news from lands you've never seen

'Tis like having a thousand scribes, merchants, and storytellers all working for you at once, good knight!
```

### Eksempel p√• multimodale funktioner

Phi-4-multimodal kan behandle tekst, billeder og tale samtidigt. Her er nogle praktiske anvendelser:

**Rejseplanl√¶gning med lydinput:**
Se, hvordan Phi-4 Multimodal analyserer talt sprog for at hj√¶lpe med at planl√¶gge en tur til Seattle, hvilket demonstrerer dens avancerede lydbehandling og anbefalingsfunktioner.

**Matematisk probleml√∏sning fra billeder:**
Se, hvordan Phi-4 Multimodal tackler komplekse matematiske problemer gennem visuelle input, hvilket demonstrerer dens evne til at behandle og l√∏se ligninger pr√¶senteret i billeder.

**Eksempel p√• funktionkald:**
Med funktionkald kan Phi-4-mini og Phi-4-multimodal udvide deres tekstbehandlingsfunktioner ved at integrere s√∏gemaskiner, forbinde forskellige v√¶rkt√∏jer og mere. Som illustreret kan modellen hente Premier League kampinformation via Phi-4-mini, hvilket viser dens evne til problemfrit at interagere med eksterne datakilder.

### Eksempel p√• kodegenerering

Phi-4-multimodal kan generere struktureret projektkode baseret p√• b√•de billedindhold og givne prompts, som vist i denne praktiske arbejdsgang:

1. Upload et billede af en wireframe eller design
2. Giv kontekst om projektkravene
3. Modellen genererer komplette, funktionelle kodestrukturer
4. Koden kan tilpasses baseret p√• specifikke frameworks eller sprog

### Eksempel p√• edge-implementering

Vi kan implementere den kvantiserede model p√• edge-enheder. Ved at kombinere Microsoft Olive og ONNX GenAI Runtime kan vi implementere Phi-4-mini p√• Windows, iPhone, Android og andre enheder. Dette er et eksempel, der k√∏rer p√• en iPhone 12 Pro.

Implementeringsprocessen involverer:
- Modelkvantisering for mobiloptimering
- ONNX runtime integration for tv√¶rplatformskompatibilitet
- Lokal inferens uden internetforbindelse
- Realtidsydelse med minimal str√∏mforbrug

## Phi-familiens udvikling

### Phi-1 og Phi-2: Grundl√¶ggende modeller

De tidlige Phi-modeller etablerede de grundl√¶ggende principper for h√∏j kvalitet tr√¶ningsdata og effektive arkitekturer:

- **Phi-1 (1.3B parametre)**: Introducerede konceptet med kurateret tr√¶ningsdata til grundl√¶ggende sprogforst√•else og kodegenerering.
- **Phi-2 (2.7B parametre)**: Forbedrede r√¶sonnementsevner gennem syntetiske NLP-data og omhyggeligt filtreret webindhold.

### Phi-3 familien: Mainstream adoption

Phi-3 serien markerede et gennembrud i SLM-funktioner med flere specialiserede varianter:

- **Phi-3-mini (3.8B parametre)**: Generelle sproglige opgaver med exceptionel effektivitet, der overg√•r modeller dobbelt s√• store.
- **Phi-3-small (7B parametre)**: Avanceret ydeevne, der sl√•r GPT-3.5 Turbo p√• forskellige benchmarks.
- **Phi-3-medium (14B parametre)**: Enterprise-grade ydeevne, der overg√•r Gemini 1.0 Pro.
- **Phi-3-vision (4.2B parametre)**: Multimodale funktioner til billed- og tekstbehandling.
- **Phi-3-Silica (3.3B parametre)**: Specialiseret optimering til Windows 11 indbygget implementering.

### Phi-4 familien: Avanceret r√¶sonnement

Den nyeste generation skubber gr√¶nserne for r√¶sonnementsevner:

- **Phi-4 (14B parametre)**: Specialisering i komplekse r√¶sonnementer, is√¶r inden for matematik.
- **Phi-4-mini (3.8B parametre)**: Forbedret r√¶sonnement med funktionkald og lang kontekstst√∏tte.
- **Phi-4-multimodal**: Samtidig tale-, syns- og tekstbehandlingsfunktioner.
- **Phi-4-reasoning (14B parametre)**: Specialiseret til komplekse multi-trins r√¶sonnementopgaver.
- **Phi-4-reasoning-plus (14B parametre)**: Forbedret n√∏jagtighed gennem yderligere forst√¶rkningsl√¶ring.
- **Phi-4-mini-reasoning (3.8B parametre)**: Matematisk r√¶sonnement optimeret til begr√¶nsede milj√∏er.

## Anvendelser af Phi-modeller

### Virksomhedsapplikationer

Organisationer bruger Phi-modeller til dokumentanalyse, automatisering af kundeservice, kodegenereringsassistance og forretningsintelligensapplikationer, der kr√¶ver lokal implementering for overholdelse og sikkerhed.

### Mobil og edge computing

Mobilapplikationer udnytter Phi-modeller til realtidsovers√¶ttelse, intelligente assistenter, indholdsgenerering og personlige anbefalinger uden behov for konstant internetforbindelse.

### Uddannelsesteknologi

Uddannelsesplatforme bruger Phi-modeller til personlig vejledning, automatiseret bed√∏mmelse, indholdsgenerering og interaktive l√¶ringsoplevelser, der kan fungere offline eller i milj√∏er med lav forbindelse.

### Sundhed og overholdelse

Sundhedsapplikationer drager fordel af Phi-modellers evne til at behandle f√∏lsomme medicinske data lokalt, samtidig med at de leverer AI-drevet diagnostisk assistance, patientoverv√•gning og behandlingsanbefalinger.

## Udfordringer og begr√¶nsninger

### Vidensbegr√¶nsninger

Selvom de er effektive, har Phi-modeller reduceret faktuel videnskapacitet sammenlignet med st√∏rre modeller, hvilket kan begr√¶nse deres effektivitet i vidensintensive applikationer, der kr√¶ver omfattende dom√¶neekspertise.

### Sprogsupport

Phi-modeller er prim√¶rt optimeret til engelsk, selvom nyere varianter inkluderer flersprogede funktioner. Applikationer, der kr√¶ver omfattende ikke-engelsk sprogsupport, kan st√• over for begr√¶nsninger.

### Komplekse planl√¶gningsopgaver

Multi-trins, komplekse opgaveplanl√¶gning, der kr√¶ver omfattende r√¶sonnement over lange kontekster, kan udfordre mindre modeller, selvom de r√¶sonnement-specialiserede varianter adresserer mange af disse begr√¶nsninger.

### Specialiseret dom√¶neydelse

Meget specialiserede dom
Phi-familien demonstrerer, at fremtiden for AI-implementering ikke kun handler om at bygge st√∏rre modeller, men om at udvikle smartere og mere effektive modeller, der kan fungere effektivt p√• tv√¶rs af forskellige hardwaremilj√∏er, samtidig med at de opretholder h√∏je pr√¶stationsstandarder.

## Udviklings- og integrations-eksempler

### Hurtig start med Transformers

S√•dan kommer du i gang med Phi-modeller ved hj√¶lp af Hugging Face Transformers-biblioteket:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load Phi-4-mini-instruct
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    attn_implementation="flash_attention_2"  # For optimized performance
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")

# Format your prompt using the chat template
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Explain quantum computing in simple terms."}
]

# Apply chat template
input_text = tokenizer.apply_chat_template(messages, tokenize=False)
inputs = tokenizer(input_text, return_tensors="pt")

# Generate response
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)
    
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### Eksempel p√• finjustering

F√∏lgende eksempel viser, hvordan man finjusterer Phi-4-mini-instruct til specifikke opgaver:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig
from trl import SFTTrainer
from datasets import load_dataset

# Configuration for LoRA fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules="all-linear"
)

# Training configuration optimized for efficiency
training_config = TrainingArguments(
    output_dir="./phi-4-mini-finetuned",
    learning_rate=5.0e-06,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=1,
    num_train_epochs=1,
    bf16=True,
    gradient_checkpointing=True,
    warmup_ratio=0.2,
    save_steps=100
)

# Load model and tokenizer
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")
tokenizer.pad_token = tokenizer.unk_token
tokenizer.padding_side = 'right'

# Load and process dataset
train_dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_config,
    peft_config=peft_config,
    train_dataset=train_dataset,
    max_seq_length=2048,
    tokenizer=tokenizer,
    packing=True
)

# Start fine-tuning
trainer.train()
```

### Specialiserede promptformater

**Til r√¶sonnement-opgaver (Phi-4-reasoning-plus):**
```
<|im_start|>system<|im_sep|>
You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions.

Please structure your response into two main sections:
<think>
{Thought section}
</think>
{Solution section}
<|im_end|>
<|im_start|>user<|im_sep|>
What is the derivative of x^2?
<|im_end|>
<|im_start|>assistant<|im_sep|>
```

**Til matematiske opgaver (Phi-4-mini-reasoning):**
```
<|system|>
Your name is Phi, an AI math expert developed by Microsoft.
<|end|>
<|user|>
Solve this calculus problem: Find the integral of 2x + 3
<|end|>
<|assistant|>
```

### Mobil implementering med ONNX

```python
import onnxruntime as ort
import numpy as np

# Load ONNX model for mobile deployment
session = ort.InferenceSession("phi-4-mini-quantized.onnx")

# Prepare input
input_ids = tokenizer.encode("Hello, how are you?", return_tensors="np")

# Run inference
outputs = session.run(None, {"input_ids": input_ids})
predicted_ids = outputs[0]

# Decode response
response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)
```

## Pr√¶stations-benchmarks og resultater

Phi-modelfamilien har opn√•et bem√¶rkelsesv√¶rdige resultater p√• tv√¶rs af forskellige benchmarks og overg√•r ofte langt st√∏rre modeller:

### Vigtige pr√¶stationsh√∏jdepunkter

**Ekspertise i matematisk r√¶sonnement:**
- Phi-4 opn√•r 82,5% n√∏jagtighed p√• AIME 2025 (Math Olympiad kvalifikation)
- Phi-4-reasoning (14B) overg√•r DeepSeek-R1-Distill-70B (5x st√∏rre) p√• r√¶sonnements-benchmarks
- Phi-4-mini-reasoning (3.8B) matcher modeller, der er dobbelt s√• store, p√• matematiske r√¶sonnementsopgaver

**Effektivitet:**
- Phi-3-Silica opn√•r 650 tokens per sekund med kun 1,5W str√∏mforbrug
- Phi-4-mini (3.8B) leverer lignende pr√¶station som langt st√∏rre modeller

**Benchmark-pr√¶station:**
- **MMLU (Massive Multitask Language Understanding)**: Konkurrencedygtig pr√¶station p√• tv√¶rs af 57 akademiske emner
- **HumanEval**: St√¶rke kodegenereringskapaciteter, is√¶r i Python
- **MGSM**: Multisproget l√∏sning af matematiske opgaver p√• grundskoleniveau
- **DROP**: Kompleks forst√•else og r√¶sonnement
- **SimpleQA**: Faktuelt pr√¶cise svar

### üìä Model-sammenligningsmatrix

| Model | Parametre | Kontekstl√¶ngde | Styrker | Bedste anvendelser |
|-------|-----------|----------------|---------|--------------------|
| **Phi-3-mini** | 3.8B | 4K/128K | Generel effektivitet | Mobilapps, simple chatbots |
| **Phi-3.5-mini** | 3.8B | 128K | Multisproget support | Internationale applikationer |
| **Phi-4-mini** | 3.8B | 128K | Forbedret r√¶sonnement, funktionkald | Forretningsautomatisering |
| **Phi-4-mini-reasoning** | 3.8B | 128K | Matematiske r√¶sonnementer | Uddannelsesplatforme |
| **Phi-4** | 14B | 32K | Kompleks r√¶sonnement | Forskning, avanceret analyse |
| **Phi-4-reasoning** | 14B | 32K/64K | Multitrins r√¶sonnement | Videnskabelig beregning |
| **Phi-4-reasoning-plus** | 14B | 32K | Maksimal n√∏jagtighed i r√¶sonnement | Kritisk beslutningstagning |
| **Phi-4-multimodal** | 5.6B | Variabel | Tale, vision, tekst | Multimedieapplikationer |

## Guide til modelvalg

### Til basale applikationer
- **Phi-3-mini**: Simpel tekstgenerering, grundl√¶ggende Q&A, hurtige svar
- **Phi-4-mini**: Forbedret r√¶sonnement med funktionkald

### Til matematiske og r√¶sonnementsopgaver
- **Phi-4**: Kompleks matematisk probleml√∏sning og r√¶sonnement
- **Phi-4-reasoning**: Multitrins r√¶sonnement med detaljerede forklaringer
- **Phi-4-reasoning-plus**: Maksimal n√∏jagtighed til kritiske r√¶sonnementsopgaver
- **Phi-4-mini-reasoning**: Effektivt matematisk r√¶sonnement til ressourcebegr√¶nsede milj√∏er

### Til multimodale applikationer
- **Phi-3-vision**: Kombination af billed- og tekstbehandling
- **Phi-4-multimodal**: Omfattende tale-, vision- og tekstfunktioner

### Til virksomhedsimplementering
- **Phi-3-medium**: Avanceret sprogforst√•else til forretningsapplikationer
- **Phi-3-Silica**: Optimeret til specifikke hardwareplatforme

## Implementeringsplatforme og tilg√¶ngelighed

### Cloud-platforme
- **Azure AI Foundry**: Fuldt udstyret implementering med virksomhedsv√¶rkt√∏jer
- **Hugging Face**: Open-source modelrepository og f√¶llesskabsressourcer
- **NVIDIA API Catalog**: Microservice-implementeringsmuligheder

### Lokale udviklingsrammer
- **Ollama**: Letv√¶gtsramme til lokal modelimplementering
- **ONNX Runtime**: Optimeret til forskellige hardwarekonfigurationer  
- **DirectML**: Windows-optimeret ydeevne
- **llama.cpp**: Cross-platform inferensmotor

### L√¶ringsressourcer
- **Phi Portal**: Officiel Microsoft Phi dokumentationshub
- **Phi Cookbook**: Omfattende eksempler og vejledninger
- **Tekniske rapporter**: Dybtg√•ende forskningsartikler p√• arxiv
- **Community Spaces**: Hugging Face interaktive demoer

### Kom godt i gang med Phi-modeller

#### Udviklingsplatforme
1. **Azure AI Foundry**: Enkel lokal CLI og modelstyring.
2. **Hugging Face Transformers**: Hurtig lokal eksperimentering
3. **Ollama**: Enkel lokal implementering til test

#### L√¶ringsvej
1. **Forst√• kernekoncepter**: Stud√©r de grundl√¶ggende designprincipper
2. **Eksperiment√©r med varianter**: Pr√∏v forskellige Phi-modeller for at forst√• kapaciteter
3. **√òv implementering**: Implement√©r modeller i testmilj√∏er
4. **Skal√©r implementering**: Udvid gradvist brugen baseret p√• succesfulde pilotprojekter

#### Bedste praksis
- **Start sm√•t**: Begynd med Phi-mini-modeller til den indledende udvikling
- **Optimer prompts**: Brug korrekt chatformat for bedste resultater
- **Overv√•g ydeevne**: F√∏lg inferenshastighed og n√∏jagtighedsmetrikker
- **Overvej hardware**: Match modelst√∏rrelse med tilg√¶ngelige computerm√¶ssige ressourcer

## Konklusion

Microsofts Phi-modelfamilie repr√¶senterer en revolutionerende tilgang til AI-modeldesign og viser, at mindre, mere effektive modeller kan opn√• bem√¶rkelsesv√¶rdige resultater p√• tv√¶rs af forskellige opgaver. Ved at fokusere p√• h√∏j kvalitet i tr√¶ningsdata og arkitektoniske optimeringer leverer Phi-familien exceptionelle kapaciteter med betydeligt reducerede beregningskrav sammenlignet med traditionelle store sprogmodeller.

## Centrale l√¶ringsm√•l

1. Forst√• designfilosofien og udviklingen af Microsofts Phi-modelfamilie fra Phi-1 til Phi-4
2. Identific√©r de vigtigste innovationer, herunder "l√¶rebogskvalitet" tr√¶ning og arkitektoniske optimeringer
3. Genkend fordelene og begr√¶nsningerne ved forskellige Phi-varianter p√• tv√¶rs af implementeringsscenarier
4. Anvend viden til at v√¶lge passende Phi-modeller til specifikke anvendelser og hardwarebegr√¶nsninger
5. Implement√©r optimeringsteknikker til implementering af Phi-modeller p√• ressourcebegr√¶nsede enheder
6. Forklar de arkitektoniske fordele ved Phi-modelfamilien i forhold til traditionelle store sprogmodeller
7. V√¶lg den passende Phi-variant baseret p√• specifikke applikationskrav og hardwarebegr√¶nsninger
8. Implement√©r Phi-modeller i b√•de cloud- og edge-implementeringsscenarier med optimerede konfigurationer
9. Anvend kvantisering og optimeringsteknikker for at forbedre Phi-modelpr√¶stationen p√• m√•lenheder
10. Evaluer afvejningerne mellem modelst√∏rrelse, ydeevne og kapaciteter p√• tv√¶rs af Phi-familien

## Hvad er n√¶ste skridt

- [02: Qwen Family Fundamentals](02.QwenFamily.md)

---

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• at sikre n√∏jagtighed, skal du v√¶re opm√¶rksom p√•, at automatiserede overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det originale dokument p√• dets oprindelige sprog b√∏r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs√¶ttelse. Vi p√•tager os ikke ansvaret for eventuelle misforst√•elser eller fejltolkninger, der m√•tte opst√• som f√∏lge af brugen af denne overs√¶ttelse.