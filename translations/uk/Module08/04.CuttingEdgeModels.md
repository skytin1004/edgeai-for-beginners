<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8ccc4f76611daedf918e34460128fc21",
  "translation_date": "2025-10-01T01:54:51+00:00",
  "source_file": "Module08/04.CuttingEdgeModels.md",
  "language_code": "uk"
}
-->
# –°–µ—Å—ñ—è 4: –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —á–∞—Ç-–¥–æ–¥–∞—Ç–∫—ñ–≤ –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–Ω —ñ–∑ Chainlit

## –û–≥–ª—è–¥

–¶—è —Å–µ—Å—ñ—è –ø—Ä–∏—Å–≤—è—á–µ–Ω–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—é –≥–æ—Ç–æ–≤–∏—Ö –¥–æ –ø—Ä–æ–¥–∞–∫—à–Ω —á–∞—Ç-–¥–æ–¥–∞—Ç–∫—ñ–≤ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é Chainlit —Ç–∞ Microsoft Foundry Local. –í–∏ –Ω–∞–≤—á–∏—Ç–µ—Å—è —Å—Ç–≤–æ—Ä—é–≤–∞—Ç–∏ —Å—É—á–∞—Å–Ω—ñ –≤–µ–±-—ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∏ –¥–ª—è AI-—Ä–æ–∑–º–æ–≤, —Ä–µ–∞–ª—ñ–∑–æ–≤—É–≤–∞—Ç–∏ –ø–æ—Ç–æ–∫–æ–≤—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ —Ç–∞ —Ä–æ–∑–≥–æ—Ä—Ç–∞—Ç–∏ –Ω–∞–¥—ñ–π–Ω—ñ —á–∞—Ç-–¥–æ–¥–∞—Ç–∫–∏ –∑ –Ω–∞–ª–µ–∂–Ω–æ—é –æ–±—Ä–æ–±–∫–æ—é –ø–æ–º–∏–ª–æ–∫ —ñ –¥–∏–∑–∞–π–Ω–æ–º –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–æ–≥–æ –¥–æ—Å–≤—ñ–¥—É.

**–©–æ –≤–∏ —Å—Ç–≤–æ—Ä–∏—Ç–µ:**
- **–ß–∞—Ç-–¥–æ–¥–∞—Ç–æ–∫ Chainlit**: –°—É—á–∞—Å–Ω–∏–π –≤–µ–±-—ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å —ñ–∑ –ø–æ—Ç–æ–∫–æ–≤–∏–º–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—è–º–∏
- **–î–µ–º–æ WebGPU**: –Ü–Ω—Ñ–µ—Ä–µ–Ω—Å —É –±—Ä–∞—É–∑–µ—Ä—ñ –¥–ª—è –¥–æ–¥–∞—Ç–∫—ñ–≤ —ñ–∑ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç–æ–º –∫–æ–Ω—Ñ—ñ–¥–µ–Ω—Ü—ñ–π–Ω–æ—Å—Ç—ñ  
- **–Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è Open WebUI**: –ü—Ä–æ—Ñ–µ—Å—ñ–π–Ω–∏–π —á–∞—Ç-—ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å —ñ–∑ Foundry Local
- **–ü—Ä–æ–¥–∞–∫—à–Ω-–ø–∞—Ç–µ—Ä–Ω–∏**: –û–±—Ä–æ–±–∫–∞ –ø–æ–º–∏–ª–æ–∫, –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ —ñ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—ó —Ä–æ–∑–≥–æ—Ä—Ç–∞–Ω–Ω—è

## –¶—ñ–ª—ñ –Ω–∞–≤—á–∞–Ω–Ω—è

- –°—Ç–≤–æ—Ä—é–≤–∞—Ç–∏ —á–∞—Ç-–¥–æ–¥–∞—Ç–∫–∏, –≥–æ—Ç–æ–≤—ñ –¥–æ –ø—Ä–æ–¥–∞–∫—à–Ω, –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é Chainlit
- –†–µ–∞–ª—ñ–∑–æ–≤—É–≤–∞—Ç–∏ –ø–æ—Ç–æ–∫–æ–≤—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –¥–ª—è –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–æ–≥–æ –¥–æ—Å–≤—ñ–¥—É
- –û—Å–≤–æ—ó—Ç–∏ –ø–∞—Ç–µ—Ä–Ω–∏ —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—ó SDK Foundry Local
- –ó–∞—Å—Ç–æ—Å–æ–≤—É–≤–∞—Ç–∏ –Ω–∞–ª–µ–∂–Ω—É –æ–±—Ä–æ–±–∫—É –ø–æ–º–∏–ª–æ–∫ —ñ –ø–ª–∞–≤–Ω—É –¥–µ–≥—Ä–∞–¥–∞—Ü—ñ—é
- –†–æ–∑–≥–æ—Ä—Ç–∞—Ç–∏ —Ç–∞ –Ω–∞–ª–∞—à—Ç–æ–≤—É–≤–∞—Ç–∏ —á–∞—Ç-–¥–æ–¥–∞—Ç–∫–∏ –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö —Å–µ—Ä–µ–¥–æ–≤–∏—â
- –†–æ–∑—É–º—ñ—Ç–∏ —Å—É—á–∞—Å–Ω—ñ –≤–µ–±-–ø–∞—Ç–µ—Ä–Ω–∏ UI –¥–ª—è —Ä–æ–∑–º–æ–≤–Ω–æ–≥–æ AI

## –ü–æ–ø–µ—Ä–µ–¥–Ω—ñ –≤–∏–º–æ–≥–∏

- **Foundry Local**: –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–π —ñ –∑–∞–ø—É—â–µ–Ω–∏–π ([–Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è –∑ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è](https://learn.microsoft.com/azure/ai-foundry/foundry-local/))
- **Python**: –í–µ—Ä—Å—ñ—è 3.10 –∞–±–æ –Ω–æ–≤—ñ—à–∞ –∑ –º–æ–∂–ª–∏–≤—ñ—Å—Ç—é —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤—ñ—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞
- **–ú–æ–¥–µ–ª—å**: –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞ —Ö–æ—á–∞ –± –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å (`foundry model run phi-4-mini`)
- **–ë—Ä–∞—É–∑–µ—Ä**: –°—É—á–∞—Å–Ω–∏–π –≤–µ–±-–±—Ä–∞—É–∑–µ—Ä —ñ–∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é WebGPU (Chrome/Edge)
- **Docker**: –î–ª—è —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—ó Open WebUI (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)

## –ß–∞—Å—Ç–∏–Ω–∞ 1: –†–æ–∑—É–º—ñ–Ω–Ω—è —Å—É—á–∞—Å–Ω–∏—Ö —á–∞—Ç-–¥–æ–¥–∞—Ç–∫—ñ–≤

### –û–≥–ª—è–¥ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏

```
User Browser ‚Üê‚Üí Chainlit UI ‚Üê‚Üí Python Backend ‚Üê‚Üí Foundry Local ‚Üê‚Üí AI Model
      ‚Üì              ‚Üì              ‚Üì              ‚Üì            ‚Üì
   Web UI      Event Handlers   OpenAI Client   HTTP API    Local GPU
```

### –û—Å–Ω–æ–≤–Ω—ñ —Ç–µ—Ö–Ω–æ–ª–æ–≥—ñ—ó

**–ü–∞—Ç–µ—Ä–Ω–∏ SDK Foundry Local:**
- `FoundryLocalManager(alias)`: –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ —É–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è —Å–µ—Ä–≤—ñ—Å–∞–º–∏
- `manager.endpoint` —ñ `manager.api_key`: –î–µ—Ç–∞–ª—ñ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è
- `manager.get_model_info(alias).id`: –Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ü—ñ—è –º–æ–¥–µ–ª—ñ

**–§—Ä–µ–π–º–≤–æ—Ä–∫ Chainlit:**
- `@cl.on_chat_start`: –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —á–∞—Ç-—Å–µ—Å—ñ–π
- `@cl.on_message`: –û–±—Ä–æ–±–∫–∞ –≤—Ö—ñ–¥–Ω–∏—Ö –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞  
- `cl.Message().stream_token()`: –ü–æ—Ç–æ–∫–æ–≤–∞ –ø–µ—Ä–µ–¥–∞—á–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º—É —á–∞—Å—ñ
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è UI —Ç–∞ —É–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è WebSocket

## –ß–∞—Å—Ç–∏–Ω–∞ 2: –õ–æ–∫–∞–ª—å–Ω–∏–π vs —Ö–º–∞—Ä–Ω–∏–π —Ä—ñ—à–µ–Ω–Ω—è

### –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ

| –ê—Å–ø–µ–∫—Ç | –õ–æ–∫–∞–ª—å–Ω–∏–π (Foundry) | –•–º–∞—Ä–∞ (Azure OpenAI) |
|--------|---------------------|---------------------|
| **–ó–∞—Ç—Ä–∏–º–∫–∞** | üöÄ 50-200–º—Å (–±–µ–∑ –º–µ—Ä–µ–∂—ñ) | ‚è±Ô∏è 200-2000–º—Å (–∑–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ –º–µ—Ä–µ–∂—ñ) |
| **–ö–æ–Ω—Ñ—ñ–¥–µ–Ω—Ü—ñ–π–Ω—ñ—Å—Ç—å** | üîí –î–∞–Ω—ñ –Ω–µ –∑–∞–ª–∏—à–∞—é—Ç—å –ø—Ä–∏—Å—Ç—Ä—ñ–π | ‚ö†Ô∏è –î–∞–Ω—ñ –Ω–∞–¥—Å–∏–ª–∞—é—Ç—å—Å—è –≤ —Ö–º–∞—Ä—É |
| **–í–∞—Ä—Ç—ñ—Å—Ç—å** | üí∞ –ë–µ–∑–∫–æ—à—Ç–æ–≤–Ω–æ –ø—ñ—Å–ª—è –ø—Ä–∏–¥–±–∞–Ω–Ω—è –æ–±–ª–∞–¥–Ω–∞–Ω–Ω—è | üí∏ –û–ø–ª–∞—Ç–∞ –∑–∞ —Ç–æ–∫–µ–Ω |
| **–û—Ñ–ª–∞–π–Ω** | ‚úÖ –ü—Ä–∞—Ü—é—î –±–µ–∑ —ñ–Ω—Ç–µ—Ä–Ω–µ—Ç—É | ‚ùå –ü–æ—Ç—Ä—ñ–±–µ–Ω —ñ–Ω—Ç–µ—Ä–Ω–µ—Ç |
| **–†–æ–∑–º—ñ—Ä –º–æ–¥–µ–ª—ñ** | ‚ö†Ô∏è –û–±–º–µ–∂–µ–Ω–∏–π –æ–±–ª–∞–¥–Ω–∞–Ω–Ω—è–º | ‚úÖ –î–æ—Å—Ç—É–ø –¥–æ –Ω–∞–π–±—ñ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π |
| **–ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è** | ‚ö†Ô∏è –ó–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ –æ–±–ª–∞–¥–Ω–∞–Ω–Ω—è | ‚úÖ –ù–µ–æ–±–º–µ–∂–µ–Ω–µ –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è |

### –ü–∞—Ç–µ—Ä–Ω–∏ –≥—ñ–±—Ä–∏–¥–Ω–æ—ó —Å—Ç—Ä–∞—Ç–µ–≥—ñ—ó

**–õ–æ–∫–∞–ª—å–Ω–∏–π –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç —ñ–∑ —Ä–µ–∑–µ—Ä–≤–Ω–∏–º –≤–∞—Ä—ñ–∞–Ω—Ç–æ–º:**
```python
async def hybrid_completion(prompt: str, complexity_threshold: int = 100):
    if len(prompt.split()) < complexity_threshold:
        return await local_completion(prompt)  # Fast, private
    else:
        return await cloud_completion(prompt)   # Complex reasoning
```

**–ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü—ñ—è –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∑–∞–≤–¥–∞–Ω—å:**
```python
async def smart_routing(prompt: str, task_type: str):
    routing_rules = {
        "code_generation": "local",     # Privacy-sensitive
        "creative_writing": "cloud",    # Benefits from larger models
        "data_analysis": "local",       # Fast iteration needed
        "research": "cloud"             # Requires broad knowledge
    }
    
    if routing_rules.get(task_type) == "local":
        return await foundry_completion(prompt)
    else:
        return await azure_completion(prompt)
```

## –ß–∞—Å—Ç–∏–Ω–∞ 3: –ó—Ä–∞–∑–æ–∫ 04 - –ß–∞—Ç-–¥–æ–¥–∞—Ç–æ–∫ Chainlit

### –®–≤–∏–¥–∫–∏–π —Å—Ç–∞—Ä—Ç

```cmd
# Navigate to Module08 directory  
cd Module08

# Start your preferred model
foundry model run phi-4-mini

# Run the Chainlit application (avoiding port conflicts)
chainlit run samples\04\app.py -w --port 8080
```

–î–æ–¥–∞—Ç–æ–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≤—ñ–¥–∫—Ä–∏–≤–∞—î—Ç—å—Å—è –∑–∞ –∞–¥—Ä–µ—Å–æ—é `http://localhost:8080` —ñ–∑ —Å—É—á–∞—Å–Ω–∏–º —á–∞—Ç-—ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º.

### –û—Å–Ω–æ–≤–Ω–∞ —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—è

–ó—Ä–∞–∑–æ–∫ 04 –¥–µ–º–æ–Ω—Å—Ç—Ä—É—î –ø–∞—Ç–µ—Ä–Ω–∏, –≥–æ—Ç–æ–≤—ñ –¥–æ –ø—Ä–æ–¥–∞–∫—à–Ω:

**–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –≤–∏—è–≤–ª–µ–Ω–Ω—è —Å–µ—Ä–≤—ñ—Å—ñ–≤:**
```python
import chainlit as cl
from openai import OpenAI
from foundry_local import FoundryLocalManager

# Global variables for client and model
client = None
model_name = None

async def initialize_client():
    global client, model_name
    alias = os.environ.get("MODEL", "phi-4-mini")
    
    try:
        # Use FoundryLocalManager for proper service management
        manager = FoundryLocalManager(alias)
        model_info = manager.get_model_info(alias)
        
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key or "not-required"
        )
        model_name = model_info.id if model_info else alias
        return True
    except Exception as e:
        # Fallback to manual configuration
        base_url = os.environ.get("BASE_URL", "http://localhost:51211")
        client = OpenAI(base_url=f"{base_url}/v1", api_key="not-required")
        model_name = alias
        return True
```

**–û–±—Ä–æ–±–Ω–∏–∫ –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ —á–∞—Ç—É:**
```python
@cl.on_message
async def main(message: cl.Message):
    # Create streaming response
    msg = cl.Message(content="")
    await msg.send()
    
    stream = client.chat.completions.create(
        model=model_name,
        messages=[
            {"role": "system", "content": "You are a helpful AI assistant."},
            {"role": "user", "content": message.content}
        ],
        stream=True
    )
    
    # Stream tokens in real-time
    for chunk in stream:
        if chunk.choices[0].delta.content:
            await msg.stream_token(chunk.choices[0].delta.content)
    
    await msg.update()
```

### –û–ø—Ü—ñ—ó –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó

**–ó–º—ñ–Ω–Ω—ñ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞:**

| –ó–º—ñ–Ω–Ω–∞ | –û–ø–∏—Å | –ó–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º | –ü—Ä–∏–∫–ª–∞–¥ |
|--------|------|------------------|---------|
| `MODEL` | –ü—Å–µ–≤–¥–æ–Ω—ñ–º –º–æ–¥–µ–ª—ñ –¥–ª—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è | `phi-4-mini` | `qwen2.5-7b` |
| `BASE_URL` | Endpoint Foundry Local | –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≤–∏–∑–Ω–∞—á–∞—î—Ç—å—Å—è | `http://localhost:51211` |
| `API_KEY` | API-–∫–ª—é—á (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ) | `""` | `your-api-key` |

**–†–æ–∑—à–∏—Ä–µ–Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
```cmd
# Use different model
set MODEL=qwen2.5-7b
chainlit run samples\04\app.py -w --port 8080

# Use different ports (avoid 51211 which is used by Foundry Local)
chainlit run samples\04\app.py -w --port 3000
chainlit run samples\04\app.py -w --port 5000
```

## –ß–∞—Å—Ç–∏–Ω–∞ 4: –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è Jupyter Notebook

### –û–≥–ª—è–¥ –ø—ñ–¥—Ç—Ä–∏–º–∫–∏ Notebook

–ó—Ä–∞–∑–æ–∫ 04 –≤–∫–ª—é—á–∞—î –∫–æ–º–ø–ª–µ–∫—Å–Ω–∏–π Jupyter Notebook (`chainlit_app.ipynb`), —è–∫–∏–π –ø—Ä–æ–ø–æ–Ω—É—î:

- **üìö –ù–∞–≤—á–∞–ª—å–Ω—ñ –º–∞—Ç–µ—Ä—ñ–∞–ª–∏**: –ü–æ–∫—Ä–æ–∫–æ–≤—ñ –Ω–∞–≤—á–∞–ª—å–Ω—ñ –º–∞—Ç–µ—Ä—ñ–∞–ª–∏
- **üî¨ –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–µ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è**: –ó–∞–ø—É—Å–∫ —ñ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏ –∑ –∫–æ–¥–æ–≤–∏–º–∏ –±–ª–æ–∫–∞–º–∏
- **üìä –í—ñ–∑—É–∞–ª—å–Ω—ñ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—ó**: –ì—Ä–∞—Ñ—ñ–∫–∏, –¥—ñ–∞–≥—Ä–∞–º–∏ —Ç–∞ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
- **üõ†Ô∏è –Ü–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏ —Ä–æ–∑—Ä–æ–±–∫–∏**: –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è —Ç–∞ –Ω–∞–ª–∞–≥–æ–¥–∂–µ–Ω–Ω—è

### –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤–ª–∞—Å–Ω–∏—Ö Notebook

#### –ö—Ä–æ–∫ 1: –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞ Jupyter

```cmd
# Ensure you're in the Module08 directory
cd Module08

# Activate your virtual environment
.venv\Scripts\activate

# Install Jupyter and dependencies
pip install jupyter notebook jupyterlab ipykernel
pip install -r requirements.txt

# Register the kernel for VS Code
python -m ipykernel install --user --name=foundry-local --display-name="Foundry Local"
```

#### –ö—Ä–æ–∫ 2: –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–æ–≤–æ–≥–æ Notebook

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è VS Code:**
1. –í—ñ–¥–∫—Ä–∏–π—Ç–µ VS Code —É –∫–∞—Ç–∞–ª–æ–∑—ñ Module08
2. –°—Ç–≤–æ—Ä—ñ—Ç—å –Ω–æ–≤–∏–π —Ñ–∞–π–ª —ñ–∑ —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è–º `.ipynb`
3. –í–∏–±–µ—Ä—ñ—Ç—å —è–¥—Ä–æ "Foundry Local", –∫–æ–ª–∏ –±—É–¥–µ –∑–∞–ø—Ä–æ–ø–æ–Ω–æ–≤–∞–Ω–æ
4. –ü–æ—á–∏–Ω–∞–π—Ç–µ –¥–æ–¥–∞–≤–∞—Ç–∏ –±–ª–æ–∫–∏ –∑ –≤–∞—à–∏–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è Jupyter Lab:**
```cmd
# Start Jupyter Lab
jupyter lab

# Navigate to samples/04/ and create new notebook
# Choose Python 3 kernel
```

### –ù–∞–π–∫—Ä–∞—â—ñ –ø—Ä–∞–∫—Ç–∏–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ Notebook

#### –û—Ä–≥–∞–Ω—ñ–∑–∞—Ü—ñ—è –±–ª–æ–∫—ñ–≤

```python
# Cell 1: Imports and Setup
import os
import sys
import chainlit as cl
from openai import OpenAI
from foundry_local import FoundryLocalManager

print("‚úÖ Libraries imported successfully")
```

```python
# Cell 2: Configuration and Client Setup
class FoundryClientManager:
    def __init__(self, model_name="phi-4-mini"):
        self.model_name = model_name
        self.client = None
        
    def initialize_client(self):
        # Client initialization logic
        pass

# Initialize and test
client_manager = FoundryClientManager()
result = client_manager.initialize_client()
print(f"Client initialized: {result}")
```

### –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ñ –ø—Ä–∏–∫–ª–∞–¥–∏ —Ç–∞ –≤–ø—Ä–∞–≤–∏

#### –í–ø—Ä–∞–≤–∞ 1: –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –∫–ª—ñ—î–Ω—Ç–∞

```python
# Test different configuration methods
configurations = [
    {"method": "foundry_sdk", "model": "phi-4-mini"},
    {"method": "manual", "base_url": "http://localhost:51211", "model": "qwen2.5-7b"},
]

for config in configurations:
    print(f"\nüß™ Testing {config['method']} configuration...")
    # Implementation here
    result = test_configuration(config)
    print(f"Result: {'‚úÖ Success' if result['status'] == 'ok' else '‚ùå Failed'}")
```

#### –í–ø—Ä–∞–≤–∞ 2: –°–∏–º—É–ª—è—Ü—ñ—è –ø–æ—Ç–æ–∫–æ–≤–æ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ

```python
import asyncio

async def simulate_streaming_response(text, delay=0.1):
    """Simulate how streaming works in Chainlit."""
    print("üåä Simulating streaming response...")
    
    for char in text:
        print(char, end='', flush=True)
        await asyncio.sleep(delay)
    
    print("\n‚úÖ Streaming complete!")

# Test the simulation
sample_text = "This is how streaming responses work in Chainlit applications!"
await simulate_streaming_response(sample_text)
```

## –ß–∞—Å—Ç–∏–Ω–∞ 5: –î–µ–º–æ —ñ–Ω—Ñ–µ—Ä–µ–Ω—Å—É –≤ –±—Ä–∞—É–∑–µ—Ä—ñ –∑ WebGPU

### –û–≥–ª—è–¥

WebGPU –¥–æ–∑–≤–æ–ª—è—î –∑–∞–ø—É—Å–∫–∞—Ç–∏ AI-–º–æ–¥–µ–ª—ñ –±–µ–∑–ø–æ—Å–µ—Ä–µ–¥–Ω—å–æ –≤ –±—Ä–∞—É–∑–µ—Ä—ñ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä—ñ–≤–Ω—è –∫–æ–Ω—Ñ—ñ–¥–µ–Ω—Ü—ñ–π–Ω–æ—Å—Ç—ñ —Ç–∞ –±–µ–∑ –Ω–µ–æ–±—Ö—ñ–¥–Ω–æ—Å—Ç—ñ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è. –¶–µ–π –∑—Ä–∞–∑–æ–∫ –¥–µ–º–æ–Ω—Å—Ç—Ä—É—î ONNX Runtime Web —ñ–∑ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è–º —á–µ—Ä–µ–∑ WebGPU.

### –ö—Ä–æ–∫ 1: –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∏ WebGPU

**–í–∏–º–æ–≥–∏ –¥–æ –±—Ä–∞—É–∑–µ—Ä–∞:**
- Chrome/Edge 113+ —ñ–∑ —É–≤—ñ–º–∫–Ω–µ–Ω–∏–º WebGPU
- –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞: `chrome://gpu` ‚Üí –ø—ñ–¥—Ç–≤–µ—Ä–¥–∏—Ç–∏ —Å—Ç–∞—Ç—É—Å "WebGPU"
- –ü—Ä–æ–≥—Ä–∞–º–Ω–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞: `if (!('gpu' in navigator)) { /* no WebGPU */ }`

### –ö—Ä–æ–∫ 2: –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–µ–º–æ WebGPU

–°—Ç–≤–æ—Ä—ñ—Ç—å –∫–∞—Ç–∞–ª–æ–≥: `samples/04/webgpu-demo/`

**index.html:**
```html
<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <title>WebGPU + ONNX Runtime Demo</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.webgpu.min.js"></script>
    <style>
        body { font-family: system-ui, sans-serif; margin: 2rem; }
        pre { background: #f5f5f5; padding: 1rem; overflow: auto; }
        .status { padding: 1rem; background: #e3f2fd; border-radius: 4px; }
    </style>
</head>
<body>
    <h1>üöÄ WebGPU + Foundry Local Integration</h1>
    <div id="status" class="status">Initializing...</div>
    <pre id="output"></pre>
    <script type="module" src="./main.js"></script>
</body>
</html>
```

**main.js:**
```javascript
const statusEl = document.getElementById('status');
const outputEl = document.getElementById('output');

function log(msg) {
    outputEl.textContent += `${msg}\n`;
    console.log(msg);
}

(async () => {
    try {
        if (!('gpu' in navigator)) {
            statusEl.textContent = '‚ùå WebGPU not available';
            return;
        }
        
        statusEl.textContent = 'üîç WebGPU detected. Loading model...';
        
        // Use a small ONNX model for demo
        const modelUrl = 'https://huggingface.co/onnx/models/resolve/main/vision/classification/mnist-12/mnist-12.onnx';
        
        const session = await ort.InferenceSession.create(modelUrl, {
            executionProviders: ['webgpu']
        });
        
        log('‚úÖ ONNX Runtime session created with WebGPU');
        log(`üìä Input names: ${session.inputNames.join(', ')}`);
        log(`üìä Output names: ${session.outputNames.join(', ')}`);
        
        // Create dummy input (MNIST expects 1x1x28x28)
        const inputData = new Float32Array(1 * 1 * 28 * 28).fill(0.1);
        const input = new ort.Tensor('float32', inputData, [1, 1, 28, 28]);
        
        const feeds = {};
        feeds[session.inputNames[0]] = input;
        
        const results = await session.run(feeds);
        const output = results[session.outputNames[0]];
        
        // Find prediction (argmax)
        let maxIdx = 0;
        for (let i = 1; i < output.data.length; i++) {
            if (output.data[i] > output.data[maxIdx]) maxIdx = i;
        }
        
        statusEl.textContent = '‚úÖ WebGPU inference complete!';
        log(`üéØ Predicted class: ${maxIdx}`);
        log(`üìà Confidence scores: [${Array.from(output.data).map(x => x.toFixed(3)).join(', ')}]`);
        
    } catch (error) {
        statusEl.textContent = `‚ùå Error: ${error.message}`;
        log(`Error: ${error.message}`);
        console.error(error);
    }
})();
```

### –ö—Ä–æ–∫ 3: –ó–∞–ø—É—Å–∫ –¥–µ–º–æ

```cmd
# Create demo directory
mkdir samples\04\webgpu-demo
cd samples\04\webgpu-demo

# Save HTML and JS files, then serve
python -m http.server 5173

# Open browser to http://localhost:5173
```

## –ß–∞—Å—Ç–∏–Ω–∞ 6: –Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è Open WebUI

### –û–≥–ª—è–¥

Open WebUI –∑–∞–±–µ–∑–ø–µ—á—É—î –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–∏–π —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å, —Å—Ö–æ–∂–∏–π –Ω–∞ ChatGPT, —è–∫–∏–π –ø—ñ–¥–∫–ª—é—á–∞—î—Ç—å—Å—è –¥–æ OpenAI-—Å—É–º—ñ—Å–Ω–æ–≥–æ API Foundry Local.

### –ö—Ä–æ–∫ 1: –ü–æ–ø–µ—Ä–µ–¥–Ω—ñ –≤–∏–º–æ–≥–∏

```cmd
# Verify Foundry Local is running
foundry service status

# Start a model
foundry model run phi-4-mini

# Confirm API endpoint is accessible
curl http://localhost:51211/v1/models
```

### –ö—Ä–æ–∫ 2: –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è Docker (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ)

```cmd
# Pull Open WebUI image
docker pull ghcr.io/open-webui/open-webui:main

# Run with Foundry Local connection
docker run -d --name open-webui -p 3000:8080 ^
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 ^
  -e OPENAI_API_KEY=foundry-local-key ^
  -v open-webui-data:/app/backend/data ^
  ghcr.io/open-webui/open-webui:main
```

**–ü—Ä–∏–º—ñ—Ç–∫–∞:** `host.docker.internal` –¥–æ–∑–≤–æ–ª—è—î –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞–º Docker –æ—Ç—Ä–∏–º—É–≤–∞—Ç–∏ –¥–æ—Å—Ç—É–ø –¥–æ —Ö–æ—Å—Ç-–º–∞—à–∏–Ω–∏ –Ω–∞ Windows.

### –ö—Ä–æ–∫ 3: –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è

1. **–í—ñ–¥–∫—Ä–∏–π—Ç–µ –±—Ä–∞—É–∑–µ—Ä:** –ü–µ—Ä–µ–π–¥—ñ—Ç—å –∑–∞ –∞–¥—Ä–µ—Å–æ—é `http://localhost:3000`
2. **–ü–æ—á–∞—Ç–∫–æ–≤–µ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è:** –°—Ç–≤–æ—Ä—ñ—Ç—å –æ–±–ª—ñ–∫–æ–≤–∏–π –∑–∞–ø–∏—Å –∞–¥–º—ñ–Ω—ñ—Å—Ç—Ä–∞—Ç–æ—Ä–∞
3. **–ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è –º–æ–¥–µ–ª—ñ:**
   - –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è ‚Üí –ú–æ–¥–µ–ª—ñ ‚Üí OpenAI API  
   - –ë–∞–∑–æ–≤–∏–π URL: `http://host.docker.internal:51211/v1`
   - API-–∫–ª—é—á: `foundry-local-key` (–±—É–¥—å-—è–∫–µ –∑–Ω–∞—á–µ–Ω–Ω—è –ø—ñ–¥—ñ–π–¥–µ)
4. **–¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è:** –ú–æ–¥–µ–ª—ñ –ø–æ–≤–∏–Ω–Ω—ñ –∑'—è–≤–∏—Ç–∏—Å—è —É –≤–∏–ø–∞–¥–∞—é—á–æ–º—É —Å–ø–∏—Å–∫—É

### –í–∏—Ä—ñ—à–µ–Ω–Ω—è –ø—Ä–æ–±–ª–µ–º

**–ü–æ—à–∏—Ä–µ–Ω—ñ –ø—Ä–æ–±–ª–µ–º–∏:**

1. **–í—ñ–¥–º–æ–≤–∞ –≤ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—ñ:**
   ```cmd
   # Check Foundry Local status
   foundry service ps
   netstat -ano | findstr :51211
   ```

2. **–ú–æ–¥–µ–ª—ñ –Ω–µ –∑'—è–≤–ª—è—é—Ç—å—Å—è:**
   - –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ, —á–∏ –º–æ–¥–µ–ª—å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞: `foundry model list`
   - –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –≤—ñ–¥–ø–æ–≤—ñ–¥—å API: `curl http://localhost:51211/v1/models`
   - –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç—ñ—Ç—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä Open WebUI

## –ß–∞—Å—Ç–∏–Ω–∞ 7: –†–æ–∑–≥–æ—Ä—Ç–∞–Ω–Ω—è –≤ –ø—Ä–æ–¥–∞–∫—à–Ω

### –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞

**–ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –¥–ª—è —Ä–æ–∑—Ä–æ–±–∫–∏:**
```cmd
# Development with auto-reload and debugging
chainlit run samples\04\app.py -w --port 8080 --debug
```

**–†–æ–∑–≥–æ—Ä—Ç–∞–Ω–Ω—è –≤ –ø—Ä–æ–¥–∞–∫—à–Ω:**
```cmd
# Production mode with optimizations
chainlit run samples\04\app.py --host 0.0.0.0 --port 8080 --no-cache
```

### –ü–æ—à–∏—Ä–µ–Ω—ñ –ø—Ä–æ–±–ª–µ–º–∏ –∑ –ø–æ—Ä—Ç–∞–º–∏ —Ç–∞ —ó—Ö –≤–∏—Ä—ñ—à–µ–Ω–Ω—è

**–ó–∞–ø–æ–±—ñ–≥–∞–Ω–Ω—è –∫–æ–Ω—Ñ–ª—ñ–∫—Ç–∞–º –ø–æ—Ä—Ç—É 51211:**
```cmd
# Check what's using Foundry Local port
netstat -ano | findstr :51211

# Use different port for Chainlit
chainlit run samples\04\app.py -w --port 8080
```

### –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ

**–†–µ–∞–ª—ñ–∑–∞—Ü—ñ—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —Å—Ç–∞–Ω—É:**
```python
@cl.on_chat_start
async def health_check():
    try:
        # Test model availability
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": "test"}],
            max_tokens=1
        )
        return {"status": "healthy", "model": model_name}
    except Exception as e:
        return {"status": "unhealthy", "error": str(e)}
```

## –ü—ñ–¥—Å—É–º–æ–∫

–°–µ—Å—ñ—è 4 –æ—Ö–æ–ø–∏–ª–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –≥–æ—Ç–æ–≤–∏—Ö –¥–æ –ø—Ä–æ–¥–∞–∫—à–Ω –¥–æ–¥–∞—Ç–∫—ñ–≤ Chainlit –¥–ª—è —Ä–æ–∑–º–æ–≤–Ω–æ–≥–æ AI. –í–∏ –¥—ñ–∑–Ω–∞–ª–∏—Å—è –ø—Ä–æ:

- ‚úÖ **–§—Ä–µ–π–º–≤–æ—Ä–∫ Chainlit**: –°—É—á–∞—Å–Ω–∏–π UI —Ç–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∞ –ø–æ—Ç–æ–∫—ñ–≤ –¥–ª—è —á–∞—Ç-–¥–æ–¥–∞—Ç–∫—ñ–≤
- ‚úÖ **–Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è Foundry Local**: –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è SDK —Ç–∞ –ø–∞—Ç–µ—Ä–Ω–∏ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó  
- ‚úÖ **–Ü–Ω—Ñ–µ—Ä–µ–Ω—Å WebGPU**: AI —É –±—Ä–∞—É–∑–µ—Ä—ñ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä—ñ–≤–Ω—è –∫–æ–Ω—Ñ—ñ–¥–µ–Ω—Ü—ñ–π–Ω–æ—Å—Ç—ñ
- ‚úÖ **–ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è Open WebUI**: –†–æ–∑–≥–æ—Ä—Ç–∞–Ω–Ω—è –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–æ–≥–æ —á–∞—Ç-—ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É
- ‚úÖ **–ü—Ä–æ–¥–∞–∫—à–Ω-–ø–∞—Ç–µ—Ä–Ω–∏**: –û–±—Ä–æ–±–∫–∞ –ø–æ–º–∏–ª–æ–∫, –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ —ñ –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è

–ó—Ä–∞–∑–æ–∫ 04 –¥–µ–º–æ–Ω—Å—Ç—Ä—É—î –Ω–∞–π–∫—Ä–∞—â—ñ –ø—Ä–∞–∫—Ç–∏–∫–∏ –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–∞–¥—ñ–π–Ω–∏—Ö —á–∞—Ç-—ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ñ–≤, —è–∫—ñ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å –ª–æ–∫–∞–ª—å–Ω—ñ AI-–º–æ–¥–µ–ª—ñ —á–µ—Ä–µ–∑ Microsoft Foundry Local, –∑–∞–±–µ–∑–ø–µ—á—É—é—á–∏ —á—É–¥–æ–≤–∏–π –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–∏–π –¥–æ—Å–≤—ñ–¥.

## –†–µ—Å—É—Ä—Å–∏

- **[–ó—Ä–∞–∑–æ–∫ 04: –î–æ–¥–∞—Ç–æ–∫ Chainlit](samples/04/README.md)**: –ü–æ–≤–Ω–∏–π –¥–æ–¥–∞—Ç–æ–∫ —ñ–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—î—é
- **[–ù–∞–≤—á–∞–ª—å–Ω–∏–π Notebook Chainlit](samples/04/chainlit_app.ipynb)**: –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ñ –Ω–∞–≤—á–∞–ª—å–Ω—ñ –º–∞—Ç–µ—Ä—ñ–∞–ª–∏
- **[–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è Foundry Local](https://learn.microsoft.com/azure/ai-foundry/foundry-local/)**: –ü–æ–≤–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∏
- **[–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è Chainlit](https://docs.chainlit.io/)**: –û—Ñ—ñ—Ü—ñ–π–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è —Ñ—Ä–µ–π–º–≤–æ—Ä–∫—É
- **[–Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è –∑ —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—ó Open WebUI](https://github.com/microsoft/foundry-local/blob/main/docs/tutorials/chat-application-with-open-web-ui.md)**: –û—Ñ—ñ—Ü—ñ–π–Ω–∏–π –ø–æ—Å—ñ–±–Ω–∏–∫

---

**–í—ñ–¥–º–æ–≤–∞ –≤—ñ–¥ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞–ª—å–Ω–æ—Å—Ç—ñ**:  
–¶–µ–π –¥–æ–∫—É–º–µ–Ω—Ç –±—É–≤ –ø–µ—Ä–µ–∫–ª–∞–¥–µ–Ω–∏–π –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é —Å–µ—Ä–≤—ñ—Å—É –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ–≥–æ –ø–µ—Ä–µ–∫–ª–∞–¥—É [Co-op Translator](https://github.com/Azure/co-op-translator). –•–æ—á–∞ –º–∏ –ø—Ä–∞–≥–Ω–µ–º–æ –¥–æ —Ç–æ—á–Ω–æ—Å—Ç—ñ, –∑–≤–µ—Ä–Ω—ñ—Ç—å —É–≤–∞–≥—É, —â–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω—ñ –ø–µ—Ä–µ–∫–ª–∞–¥–∏ –º–æ–∂—É—Ç—å –º—ñ—Å—Ç–∏—Ç–∏ –ø–æ–º–∏–ª–∫–∏ –∞–±–æ –Ω–µ—Ç–æ—á–Ω–æ—Å—Ç—ñ. –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞ –π–æ–≥–æ —Ä—ñ–¥–Ω—ñ–π –º–æ–≤—ñ —Å–ª—ñ–¥ –≤–≤–∞–∂–∞—Ç–∏ –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω–∏–º –¥–∂–µ—Ä–µ–ª–æ–º. –î–ª—è –∫—Ä–∏—Ç–∏—á–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó —Ä–µ–∫–æ–º–µ–Ω–¥—É—î—Ç—å—Å—è –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–∏–π –ª—é–¥—Å—å–∫–∏–π –ø–µ—Ä–µ–∫–ª–∞–¥. –ú–∏ –Ω–µ –Ω–µ—Å–µ–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞–ª—å–Ω–æ—Å—Ç—ñ –∑–∞ –±—É–¥—å-—è–∫—ñ –Ω–µ–ø–æ—Ä–æ–∑—É–º—ñ–Ω–Ω—è –∞–±–æ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ñ —Ç–ª—É–º–∞—á–µ–Ω–Ω—è, —â–æ –≤–∏–Ω–∏–∫–∞—é—Ç—å –≤–Ω–∞—Å–ª—ñ–¥–æ–∫ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è —Ü—å–æ–≥–æ –ø–µ—Ä–µ–∫–ª–∞–¥—É.