<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8641f7baaf43de0f266276b64c5f5020",
  "translation_date": "2025-09-25T02:33:27+00:00",
  "source_file": "Module08/06.ModelsAsTools.md",
  "language_code": "uk"
}
-->
# ## –û–≥–ª—è–¥

–°—Ç–∞–≤—Ç–µ—Å—è –¥–æ –º–æ–¥–µ–ª–µ–π —à—Ç—É—á–Ω–æ–≥–æ —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É —è–∫ –¥–æ –º–æ–¥—É–ª—å–Ω–∏—Ö, –Ω–∞–ª–∞—à—Ç–æ–≤—É–≤–∞–Ω–∏—Ö —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ñ–≤, —è–∫—ñ –ø—Ä–∞—Ü—é—é—Ç—å –±–µ–∑–ø–æ—Å–µ—Ä–µ–¥–Ω—å–æ –Ω–∞ –ø—Ä–∏—Å—Ç—Ä–æ—ó –∑ Foundry Local. –¶—è —Å–µ—Å—ñ—è –∞–∫—Ü–µ–Ω—Ç—É—î —É–≤–∞–≥—É –Ω–∞ –ø—Ä–∞–∫—Ç–∏—á–Ω–∏—Ö —Ä–æ–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å–∞—Ö –¥–ª—è –∑–∞–±–µ–∑–ø–µ—á–µ–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–¥–µ–Ω—Ü—ñ–π–Ω–æ—Å—Ç—ñ, –Ω–∏–∑—å–∫–æ—ó –∑–∞—Ç—Ä–∏–º–∫–∏ –ø—Ä–∏ –≤–∏–∫–æ–Ω–∞–Ω–Ω—ñ –∑–∞–ø–∏—Ç—ñ–≤ —ñ —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—ó —Ü–∏—Ö —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ñ–≤ —á–µ—Ä–µ–∑ SDK, API –∞–±–æ CLI. –í–∏ —Ç–∞–∫–æ–∂ –¥—ñ–∑–Ω–∞—î—Ç–µ—Å—è, —è–∫ –º–∞—Å—à—Ç–∞–±—É–≤–∞—Ç–∏ –¥–æ Azure AI Foundry –∑–∞ –ø–æ—Ç—Ä–µ–±–∏.

> **üîÑ –û–Ω–æ–≤–ª–µ–Ω–æ –¥–ª—è —Å—É—á–∞—Å–Ω–æ–≥–æ SDK**: –¶–µ–π –º–æ–¥—É–ª—å —É–∑–≥–æ–¥–∂–µ–Ω–æ –∑ –æ—Å—Ç–∞–Ω–Ω—ñ–º–∏ —à–∞–±–ª–æ–Ω–∞–º–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ—é Microsoft Foundry-Local —ñ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—ó —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü—ñ—ó –≤ `samples/06/`. –ü—Ä–∏–∫–ª–∞–¥–∏ —Ç–µ–ø–µ—Ä –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å —Å—É—á–∞—Å–Ω–∏–π `foundry-local-sdk` —ñ –≤–¥–æ—Å–∫–æ–Ω–∞–ª–µ–Ω—ñ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—ó –≤–∏–±–æ—Ä—É –º–æ–¥–µ–ª–µ–π.

**üèóÔ∏è –û—Å–Ω–æ–≤–Ω—ñ –º–æ–º–µ–Ω—Ç–∏ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏:**
- **–Ü–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü—ñ—è –º–æ–¥–µ–ª–µ–π**: –í–∏–±—ñ—Ä –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤ –º—ñ–∂ –∑–∞–≥–∞–ª—å–Ω–∏–º–∏, –ª–æ–≥—ñ—á–Ω–∏–º–∏, –∫–æ–¥–æ–≤–∏–º–∏ —Ç–∞ —Ç–≤–æ—Ä—á–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏
- **–Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è —Å—É—á–∞—Å–Ω–æ–≥–æ SDK**: –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î `FoundryLocalManager` –∑ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–º –≤–∏—è–≤–ª–µ–Ω–Ω—è–º —Å–µ—Ä–≤—ñ—Å—ñ–≤
- **–ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞**: –ì–Ω—É—á–∫–µ –ø—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ –∑–º—ñ–Ω–Ω—ñ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞
- **–ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ —Å—Ç–∞–Ω—É**: –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Å–µ—Ä–≤—ñ—Å—ñ–≤ —ñ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—ñ –º–æ–¥–µ–ª–µ–π
- **–ì–æ—Ç–æ–≤–Ω—ñ—Å—Ç—å –¥–æ –≤–∏—Ä–æ–±–Ω–∏—Ü—Ç–≤–∞**: –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –ø–æ–º–∏–ª–æ–∫ —ñ –º–µ—Ö–∞–Ω—ñ–∑–º–∏ —Ä–µ–∑–µ—Ä–≤—É–≤–∞–Ω–Ω—è

**üìÅ –õ–æ–∫–∞–ª—å–Ω–∞ —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—è:**
- `samples/06/router.py` - –Ü–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω–∏–π –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ç–æ—Ä –º–æ–¥–µ–ª–µ–π –∑ –≤–∏–±–æ—Ä–æ–º –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤
- `samples/06/model_router.ipynb` - –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ñ –ø—Ä–∏–∫–ª–∞–¥–∏ —Ç–∞ –±–µ–Ω—á–º–∞—Ä–∫–∏
- `samples/06/README.md` - –Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó —Ç–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è

–†–µ—Å—É—Ä—Å–∏:
- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è Foundry Local: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
- –Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è –∑ SDK –¥–ª—è –≤–∏–∫–æ–Ω–∞–Ω–Ω—è –∑–∞–ø–∏—Ç—ñ–≤: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
- –ö–æ–º–ø—ñ–ª—è—Ü—ñ—è –º–æ–¥–µ–ª–µ–π Hugging Face: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models

## –û–≥–ª—è–¥

–°—Ç–∞–≤—Ç–µ—Å—è –¥–æ –º–æ–¥–µ–ª–µ–π —à—Ç—É—á–Ω–æ–≥–æ —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É —è–∫ –¥–æ –º–æ–¥—É–ª—å–Ω–∏—Ö, –Ω–∞–ª–∞—à—Ç–æ–≤—É–≤–∞–Ω–∏—Ö —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ñ–≤, —è–∫—ñ –ø—Ä–∞—Ü—é—é—Ç—å –±–µ–∑–ø–æ—Å–µ—Ä–µ–¥–Ω—å–æ –Ω–∞ –ø—Ä–∏—Å—Ç—Ä–æ—ó –∑ Foundry Local. –¶—è —Å–µ—Å—ñ—è –∞–∫—Ü–µ–Ω—Ç—É—î —É–≤–∞–≥—É –Ω–∞ –ø—Ä–∞–∫—Ç–∏—á–Ω–∏—Ö —Ä–æ–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å–∞—Ö –¥–ª—è –∑–∞–±–µ–∑–ø–µ—á–µ–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–¥–µ–Ω—Ü—ñ–π–Ω–æ—Å—Ç—ñ, –Ω–∏–∑—å–∫–æ—ó –∑–∞—Ç—Ä–∏–º–∫–∏ –ø—Ä–∏ –≤–∏–∫–æ–Ω–∞–Ω–Ω—ñ –∑–∞–ø–∏—Ç—ñ–≤ —ñ —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—ó —Ü–∏—Ö —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ñ–≤ —á–µ—Ä–µ–∑ SDK, API –∞–±–æ CLI. –í–∏ —Ç–∞–∫–æ–∂ –¥—ñ–∑–Ω–∞—î—Ç–µ—Å—è, —è–∫ –º–∞—Å—à—Ç–∞–±—É–≤–∞—Ç–∏ –¥–æ Azure AI Foundry –∑–∞ –ø–æ—Ç—Ä–µ–±–∏.

–†–µ—Å—É—Ä—Å–∏:
- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è Foundry Local: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
- –Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è –∑ SDK –¥–ª—è –≤–∏–∫–æ–Ω–∞–Ω–Ω—è –∑–∞–ø–∏—Ç—ñ–≤: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
- –ö–æ–º–ø—ñ–ª—è—Ü—ñ—è –º–æ–¥–µ–ª–µ–π Hugging Face: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models

## –¶—ñ–ª—ñ –Ω–∞–≤—á–∞–Ω–Ω—è
- –†–æ–∑—Ä–æ–±–∫–∞ —à–∞–±–ª–æ–Ω—ñ–≤ "–º–æ–¥–µ–ª—å —è–∫ —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç" –Ω–∞ –ø—Ä–∏—Å—Ç—Ä–æ—ó
- –Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è —á–µ—Ä–µ–∑ REST API, —Å—É–º—ñ—Å–Ω–∏–π –∑ OpenAI, –∞–±–æ SDK
- –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª–µ–π –¥–ª—è —Å–ø–µ—Ü–∏—Ñ—ñ—á–Ω–∏—Ö –≥–∞–ª—É–∑–µ–≤–∏—Ö –≤–∏–ø–∞–¥–∫—ñ–≤
- –ü–ª–∞–Ω—É–≤–∞–Ω–Ω—è –≥—ñ–±—Ä–∏–¥–Ω–æ–≥–æ –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è –¥–æ Azure AI Foundry

## –ß–∞—Å—Ç–∏–Ω–∞ 1: –Ü–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω–∏–π –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ç–æ—Ä –º–æ–¥–µ–ª–µ–π (—Å—É—á–∞—Å–Ω–∞ —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—è)

–ú–µ—Ç–∞: –†–µ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω–∏–π –≤–∏–±—ñ—Ä –º–æ–¥–µ–ª—ñ –∑ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ—é –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü—ñ—î—é –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∑–º—ñ—Å—Ç—É –∑–∞–ø–∏—Ç—É.

> **üìã –ü—Ä–∏–º—ñ—Ç–∫–∞**: –¶—è —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—è –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î —à–∞–±–ª–æ–Ω–∞–º, –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∏–º —É `samples/06/router.py`, –∑ –≤–¥–æ—Å–∫–æ–Ω–∞–ª–µ–Ω–∏–º –≤–∏–±–æ—Ä–æ–º –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤.

–ö—Ä–æ–∫ 1) –í–∏–∑–Ω–∞—á—Ç–µ —Å—É—á–∞—Å–Ω–∏–π –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ç–æ—Ä –º–æ–¥–µ–ª–µ–π –∑ FoundryLocalManager  
```python
# router/intelligent_router.py
from foundry_local import FoundryLocalManager
from openai import OpenAI
from typing import Dict, Any, Optional
import os
import json

class ModelRouter:
    """Intelligent model router that selects appropriate models for different task types."""
    
    def __init__(self):
        self.client = None
        self.base_url = None
        self.tools = self._load_tool_registry()
        self._initialize_client()
    
    def _load_tool_registry(self) -> Dict[str, Dict[str, Any]]:
        """Load tool registry from environment or use defaults."""
        default_tools = {
            "general": {
                "model": os.environ.get("GENERAL_MODEL", "phi-4-mini"),
                "notes": "Fast general-purpose chat and Q&A",
                "temperature": 0.7
            },
            "reasoning": {
                "model": os.environ.get("REASONING_MODEL", "deepseek-r1-distill-qwen-7b"),
                "notes": "Step-by-step analysis and logical reasoning",
                "temperature": 0.3
            },
            "code": {
                "model": os.environ.get("CODE_MODEL", "qwen2.5-7b-instruct"),
                "notes": "Code generation, debugging, and technical tasks",
                "temperature": 0.2
            },
            "creative": {
                "model": os.environ.get("CREATIVE_MODEL", "phi-4-mini"),
                "notes": "Creative writing and storytelling",
                "temperature": 0.9
            }
        }
        
        # Check for environment override
        tools_env = os.environ.get("TOOL_REGISTRY")
        if tools_env:
            try:
                return json.loads(tools_env)
            except json.JSONDecodeError:
                print("Warning: Invalid TOOL_REGISTRY JSON, using defaults")
        
        return default_tools
```
  
–ö—Ä–æ–∫ 2) –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É–π—Ç–µ –∫–ª—ñ—î–Ω—Ç —ñ–∑ —Å—É—á–∞—Å–Ω–∏–º SDK —ñ –≤–∏—è–≤–ª–µ–Ω–Ω—è–º —Å–µ—Ä–≤—ñ—Å—ñ–≤  
```python
    def _initialize_client(self):
        """Initialize OpenAI client with Foundry Local or fallback configuration."""
        try:
            from foundry_local import FoundryLocalManager
            # Try to use any available model for client initialization
            first_model = next(iter(self.tools.values()))["model"]
            manager = FoundryLocalManager(first_model)
            
            self.client = OpenAI(
                base_url=manager.endpoint,
                api_key=manager.api_key
            )
            self.base_url = manager.endpoint
            print(f"‚úÖ Foundry Local SDK initialized")
        except Exception as e:
            print(f"Warning: Could not use Foundry SDK ({e}), falling back to manual configuration")
            # Fallback to manual configuration
            self.base_url = os.environ.get("BASE_URL", "http://localhost:8000")
            api_key = os.environ.get("API_KEY", "")
            
            self.client = OpenAI(
                base_url=f"{self.base_url}/v1",
                api_key=api_key
            )
            print(f"Initialized manual configuration at {self.base_url}")
    
    def select_tool(self, user_query: str) -> str:
        """Select the most appropriate tool based on the user query."""
        query_lower = user_query.lower()
        
        # Code-related keywords
        code_keywords = ["code", "python", "function", "class", "method", "bug", "debug", 
                        "programming", "script", "algorithm", "implementation", "refactor"]
        if any(keyword in query_lower for keyword in code_keywords):
            return "code"
        
        # Reasoning keywords
        reasoning_keywords = ["why", "how", "explain", "step-by-step", "reason", "analyze", 
                             "think", "logic", "because", "cause", "compare", "evaluate"]
        if any(keyword in query_lower for keyword in reasoning_keywords):
            return "reasoning"
        
        # Creative keywords
        creative_keywords = ["story", "poem", "creative", "imagine", "write", "tale", 
                           "narrative", "fiction", "character", "plot"]
        if any(keyword in query_lower for keyword in creative_keywords):
            return "creative"
        
        # Default to general
        return "general"
    
    def chat(self, model: str, content: str, max_tokens: int = 300, temperature: Optional[float] = None) -> str:
        """Send chat completion request to the specified model."""
        try:
            params = {
                "model": model,
                "messages": [{"role": "user", "content": content}],
                "max_tokens": max_tokens
            }
            
            if temperature is not None:
                params["temperature"] = temperature
            
            response = self.client.chat.completions.create(**params)
            return response.choices[0].message.content
        except Exception as e:
            return f"Error generating response with model {model}: {str(e)}"
```
  
–ö—Ä–æ–∫ 3) –†–µ–∞–ª—ñ–∑—É–π—Ç–µ —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω—É –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü—ñ—é —Ç–∞ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è (–¥–∏–≤. `samples/06/router.py`)  
```python
    def route_and_run(self, prompt: str) -> Dict[str, Any]:
        """Route the prompt to the appropriate model and generate response."""
        tool_key = self.select_tool(prompt)
        tool_config = self.tools[tool_key]
        model = tool_config["model"]
        temperature = tool_config.get("temperature", 0.7)
        
        print(f"üéØ Selected tool: {tool_key} (model: {model})")
        
        answer = self.chat(
            model=model, 
            content=prompt, 
            max_tokens=400, 
            temperature=temperature
        )
        
        return {
            "tool": tool_key,
            "model": model,
            "tool_description": tool_config["notes"],
            "temperature": temperature,
            "answer": answer
        }
    
    def check_service_health(self) -> Dict[str, Any]:
        """Check Foundry Local service health and available models."""
        try:
            models_response = self.client.models.list()
            available_models = [model.id for model in models_response.data]
            
            return {
                "status": "healthy",
                "base_url": self.base_url,
                "available_models": available_models,
                "tools_configured": list(self.tools.keys())
            }
        except Exception as e:
            return {
                "status": "error",
                "base_url": self.base_url,
                "error": str(e)
            }

if __name__ == "__main__":
    # Ensure: foundry model run phi-4-mini
    router = ModelRouter()
    
    # Check health
    health = router.check_service_health()
    print(f"Service Health: {json.dumps(health, indent=2)}")
    
    # Test different query types
    queries = [
        "Write a Python function to calculate fibonacci numbers",  # -> code
        "Explain step-by-step why the sky is blue",  # -> reasoning
        "Tell me a creative story about AI",  # -> creative
        "What's the weather like today?"  # -> general
    ]
    
    for query in queries:
        result = router.route_and_run(query)
        print(f"\nQuery: {query}")
        print(f"Selected: {result['tool']} -> {result['model']}")
        print(f"Answer: {result['answer'][:100]}...")
```
  

## –ß–∞—Å—Ç–∏–Ω–∞ 2: –Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è —Å—É—á–∞—Å–Ω–æ–≥–æ SDK (–ø–æ–∫—Ä–æ–∫–æ–≤–æ)

–ú–µ—Ç–∞: –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ Foundry Local SDK —Ä–∞–∑–æ–º —ñ–∑ OpenAI Python SDK –¥–ª—è –±–µ–∑–ø–µ—Ä–µ–±—ñ–π–Ω–æ—ó —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—ó.

–ö—Ä–æ–∫ 1) –í—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ  
```cmd
cd Module08
.\.venv\Scripts\activate
pip install foundry-local-sdk openai
```
  
–ö—Ä–æ–∫ 2) –ù–∞–ª–∞—à—Ç—É–π—Ç–µ —Å–µ—Ä–µ–¥–æ–≤–∏—â–µ (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ - –¥–∏–≤. `samples/06/README.md`)  
```cmd
REM Override default models per tool
set GENERAL_MODEL=phi-4-mini
set REASONING_MODEL=deepseek-r1-distill-qwen-7b
set CODE_MODEL=qwen2.5-7b-instruct
REM Or provide a full JSON registry
set TOOL_REGISTRY={"general":{"model":"phi-4-mini"},"reasoning":{"model":"deepseek-r1-distill-qwen-7b"}}
```
  
–ö—Ä–æ–∫ 3) –Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è —Å—É—á–∞—Å–Ω–æ–≥–æ SDK  
```python
# modern_sdk_demo.py
from foundry_local import FoundryLocalManager
from openai import OpenAI
import sys

def main():
    """Demonstrate modern SDK integration."""
    try:
        # Initialize with FoundryLocalManager
        alias = "phi-4-mini"
        manager = FoundryLocalManager(alias)
        
        # Create OpenAI client using Foundry Local endpoint
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key
        )
        
        # Get model info
        model_info = manager.get_model_info(alias)
        print(f"Using model: {model_info.id}")
        
        # Make request with streaming
        stream = client.chat.completions.create(
            model=model_info.id,
            messages=[{"role": "user", "content": "Explain edge AI benefits in one paragraph."}],
            stream=True,
            max_tokens=200
        )
        
        print("Response: ", end="")
        for chunk in stream:
            if chunk.choices[0].delta.content:
                print(chunk.choices[0].delta.content, end="", flush=True)
        print()
        
    except Exception as e:
        print(f"Error: {e}")
        print("Ensure Foundry Local is running with: foundry model run phi-4-mini")
        sys.exit(1)

if __name__ == "__main__":
    main()
```
  

## –ß–∞—Å—Ç–∏–Ω–∞ 3: –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –¥–ª—è –≥–∞–ª—É–∑—ñ (–ø–æ–∫—Ä–æ–∫–æ–≤–æ)

–ú–µ—Ç–∞: –ê–¥–∞–ø—Ç—É–≤–∞—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –¥–ª—è –≥–∞–ª—É–∑—ñ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ —à–∞–±–ª–æ–Ω–∏ –ø—ñ–¥–∫–∞–∑–æ–∫ —ñ —Å—Ö–µ–º—É JSON.

–ö—Ä–æ–∫ 1) –°—Ç–≤–æ—Ä—ñ—Ç—å —à–∞–±–ª–æ–Ω –ø—ñ–¥–∫–∞–∑–∫–∏ –¥–ª—è –≥–∞–ª—É–∑—ñ  
```python
# domain/templates.py
BUSINESS_ANALYST_SYSTEM = """
You are a senior business analyst. Provide:
1) Key insights
2) Risks
3) Next steps
Respond in valid JSON with fields: insights, risks, next_steps.
"""
```
  
–ö—Ä–æ–∫ 2) –ó–∞–±–µ–∑–ø–µ—á—Ç–µ –≤–∏—Ö—ñ–¥ —É —Ñ–æ—Ä–º–∞—Ç—ñ JSON  
```python
# domain/analyst.py
import requests, os, json

BASE_URL = os.getenv("OPENAI_BASE_URL", "http://localhost:8000/v1")
API_KEY = os.getenv("OPENAI_API_KEY", "local-key")
HEADERS = {"Content-Type":"application/json","Authorization":f"Bearer {API_KEY}"}

from domain.templates import BUSINESS_ANALYST_SYSTEM

def analyze(text: str) -> dict:
    messages = [
        {"role":"system","content": BUSINESS_ANALYST_SYSTEM},
        {"role":"user","content": f"Analyze this business text:\n{text}"}
    ]
    r = requests.post(f"{BASE_URL}/chat/completions", json={
    "model":"phi-4-mini",
        "messages": messages,
        "response_format": {"type":"json_object"},
        "temperature": 0.3
    }, headers=HEADERS, timeout=60)
    r.raise_for_status()
    # Parse JSON content
    content = r.json()["choices"][0]["message"]["content"]
    return json.loads(content)

if __name__ == "__main__":
    print(analyze("Sales dipped 12% in Q3 due to supply constraints and marketing cuts."))
```
  

## –ß–∞—Å—Ç–∏–Ω–∞ 4: –û—Ñ–ª–∞–π–Ω-—Ä–µ–∂–∏–º —ñ –±–µ–∑–ø–µ–∫–∞ (–ø–æ–∫—Ä–æ–∫–æ–≤–æ)

–ú–µ—Ç–∞: –ó–∞–±–µ–∑–ø–µ—á–∏—Ç–∏ –∫–æ–Ω—Ñ—ñ–¥–µ–Ω—Ü—ñ–π–Ω—ñ—Å—Ç—å —ñ —Å—Ç—ñ–π–∫—ñ—Å—Ç—å –ø—Ä–∏ –ª–æ–∫–∞–ª—å–Ω–æ–º—É –∑–∞–ø—É—Å–∫—É –º–æ–¥–µ–ª–µ–π —è–∫ —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ñ–≤.

–ö—Ä–æ–∫ 1) –ü–æ–ø–µ—Ä–µ–¥–Ω—å–æ –∞–∫—Ç–∏–≤—É–π—Ç–µ —Ç–∞ –ø–µ—Ä–µ–≤—ñ—Ä—Ç–µ –ª–æ–∫–∞–ª—å–Ω—É –∫—ñ–Ω—Ü–µ–≤—É —Ç–æ—á–∫—É  
```cmd
foundry model run phi-4-mini
curl http://localhost:8000/v1/models
```
  
–ö—Ä–æ–∫ 2) –û—á–∏—Å—Ç—ñ—Ç—å –≤—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ  
```python
# security/sanitize.py
import re
EMAIL_RE = re.compile(r"[\w\.-]+@[\w\.-]+")
PHONE_RE = re.compile(r"\+?\d[\d\s\-]{7,}\d")

def sanitize(text: str) -> str:
    text = EMAIL_RE.sub("[REDACTED_EMAIL]", text)
    text = PHONE_RE.sub("[REDACTED_PHONE]", text)
    return text
```
  
–ö—Ä–æ–∫ 3) –£—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å –ø—Ä–∞–ø–æ—Ä–µ—Ü—å "—Ç—ñ–ª—å–∫–∏ –ª–æ–∫–∞–ª—å–Ω–æ" —Ç–∞ –≤–µ–¥—ñ—Ç—å –∂—É—Ä–Ω–∞–ª  
```python
# security/local_only.py
import os, json, time
LOG = os.getenv("MODELS_AS_TOOLS_LOG", "./tools_logs.jsonl")

def record(event: dict):
    with open(LOG, "a", encoding="utf-8") as f:
        f.write(json.dumps(event) + "\n")

# Usage before each call
def before_call(tool_name, payload):
    record({"ts": time.time(), "tool": tool_name, "event": "before_call"})

# After each call
def after_call(tool_name, result):
    record({"ts": time.time(), "tool": tool_name, "event": "after_call"})
```
  

## –ß–∞—Å—Ç–∏–Ω–∞ 5: –†–æ–∑–≥–æ—Ä—Ç–∞–Ω–Ω—è —É –≤–∏—Ä–æ–±–Ω–∏—Ü—Ç–≤—ñ —Ç–∞ –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è

–ú–µ—Ç–∞: –†–æ–∑–≥–æ—Ä–Ω—É—Ç–∏ —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω–∏–π –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ç–æ—Ä —ñ–∑ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥–æ–º —ñ —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—î—é Azure AI Foundry.

> **üìã –ü—Ä–∏–º—ñ—Ç–∫–∞**: –õ–æ–∫–∞–ª—å–Ω–∞ —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—è –≤ `samples/06/model_router.ipynb` –≤–∫–ª—é—á–∞—î –∫–æ–º–ø–ª–µ–∫—Å–Ω—ñ –ø—Ä–∏–∫–ª–∞–¥–∏ —à–∞–±–ª–æ–Ω—ñ–≤ —Ä–æ–∑–≥–æ—Ä—Ç–∞–Ω–Ω—è —É –≤–∏—Ä–æ–±–Ω–∏—Ü—Ç–≤—ñ.

–ö—Ä–æ–∫ 1) –í–∏—Ä–æ–±–Ω–∏—á–∏–π –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ç–æ—Ä —ñ–∑ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥–æ–º (–¥–∏–≤. `samples/06/router.py`)  
```python
# production/router.py
from router.intelligent_router import ModelRouter
import json
import time
import sys

class ProductionModelRouter(ModelRouter):
    """Production-ready model router with monitoring and logging."""
    
    def __init__(self):
        super().__init__()
        self.request_count = 0
        self.error_count = 0
        self.start_time = time.time()
    
    def route_and_run_with_monitoring(self, prompt: str) -> Dict[str, Any]:
        """Route with comprehensive monitoring and error handling."""
        start_time = time.time()
        self.request_count += 1
        
        try:
            result = self.route_and_run(prompt)
            processing_time = time.time() - start_time
            
            # Log successful request
            self._log_request({
                "status": "success",
                "tool": result["tool"],
                "model": result["model"],
                "processing_time": processing_time,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            })
            
            result["processing_time"] = processing_time
            return result
            
        except Exception as e:
            self.error_count += 1
            error_result = {
                "status": "error",
                "error": str(e),
                "processing_time": time.time() - start_time,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            }
            
            self._log_request(error_result)
            return error_result
    
    def _log_request(self, data: Dict[str, Any]):
        """Log request data for monitoring."""
        print(f"üìä {json.dumps(data)}")
    
    def get_stats(self) -> Dict[str, Any]:
        """Get router statistics."""
        uptime = time.time() - self.start_time
        return {
            "uptime_seconds": uptime,
            "total_requests": self.request_count,
            "error_count": self.error_count,
            "success_rate": (self.request_count - self.error_count) / max(1, self.request_count),
            "requests_per_minute": self.request_count / max(1, uptime / 60)
        }

def main():
    """Production router demo."""
    router = ProductionModelRouter()
    
    # Health check
    health = router.check_service_health()
    if health["status"] == "error":
        print(f"‚ùå Service health check failed: {health['error']}")
        sys.exit(1)
    
    print(f"‚úÖ Service healthy with {len(health['available_models'])} models")
    
    # Process user query
    user_prompt = " ".join(sys.argv[1:]) or "Write three benefits of on-device AI in JSON format."
    print(f"\nüéØ Processing: {user_prompt}")
    
    result = router.route_and_run_with_monitoring(user_prompt)
    
    if result.get("status") == "error":
        print(f"‚ùå Error: {result['error']}")
    else:
        print(f"\nüìã Result:")
        print(f"Tool: {result['tool']} -> Model: {result['model']}")
        print(f"Processing Time: {result['processing_time']:.2f}s")
        print(f"Answer: {result['answer']}")
    
    # Show stats
    stats = router.get_stats()
    print(f"\nüìä Statistics: {json.dumps(stats, indent=2)}")

if __name__ == "__main__":
    main()
```
  

## –ü—Ä–∞–∫—Ç–∏—á–Ω–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–∏–π —Å–ø–∏—Å–æ–∫
- [ ] –†–µ–∞–ª—ñ–∑—É–π—Ç–µ —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω–∏–π –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ç–æ—Ä –º–æ–¥–µ–ª–µ–π —ñ–∑ –≤–∏–±–æ—Ä–æ–º –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤ (`samples/06/router.py`)
- [ ] –ù–∞–ª–∞—à—Ç—É–π—Ç–µ –∫—ñ–ª—å–∫–∞ —Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π (–∑–∞–≥–∞–ª—å–Ω—ñ, –ª–æ–≥—ñ—á–Ω—ñ, –∫–æ–¥–æ–≤—ñ, —Ç–≤–æ—Ä—á—ñ)
- [ ] –ü—Ä–æ—Ç–µ—Å—Ç—É–π—Ç–µ —ñ–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏–π Jupyter notebook (`samples/06/model_router.ipynb`)
- [ ] –ù–∞–ª–∞—à—Ç—É–π—Ç–µ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞
- [ ] –†–µ–∞–ª—ñ–∑—É–π—Ç–µ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ —Å—Ç–∞–Ω—É —Å–µ—Ä–≤—ñ—Å—É —Ç–∞ –æ–±—Ä–æ–±–∫—É –ø–æ–º–∏–ª–æ–∫
- [ ] –†–æ–∑–≥–æ—Ä–Ω—ñ—Ç—å –≤–∏—Ä–æ–±–Ω–∏—á–∏–π –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ç–æ—Ä —ñ–∑ –∫–æ–º–ø–ª–µ–∫—Å–Ω–∏–º –≤–µ–¥–µ–Ω–Ω—è–º –∂—É—Ä–Ω–∞–ª—É

## –õ–æ–∫–∞–ª—å–Ω–∞ —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è –∑ –ø—Ä–∏–∫–ª–∞–¥–∞–º–∏

–ó–∞–ø—É—Å—Ç—ñ—Ç—å –ø–æ–≤–Ω—É —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—é:  
```cmd
cd Module08
.\.venv\Scripts\activate

REM Start required models
foundry model run phi-4-mini
foundry model run qwen2.5-7b-instruct
foundry model run deepseek-r1-distill-qwen-7b

REM Test the intelligent router
python samples\06\router.py "Write a Python function to sort a list"
python samples\06\router.py "Explain step-by-step how bubble sort works"
python samples\06\router.py "Tell me a creative story about robots"

REM Explore the interactive notebook
jupyter notebook samples/06/model_router.ipynb
```
  

## –†–µ—Å—É—Ä—Å–∏ —Ç–∞ –Ω–∞—Å—Ç—É–ø–Ω—ñ –∫—Ä–æ–∫–∏
- **–õ–æ–∫–∞–ª—å–Ω–∞ —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—è**: `samples/06/` - –ü–æ–≤–Ω–∏–π —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω–∏–π –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ç–æ—Ä —ñ–∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é –∫—ñ–ª—å–∫–æ—Ö –º–æ–¥–µ–ª–µ–π
- **–ü—Ä–∏–∫–ª–∞–¥–∏ Microsoft**: [Hello Foundry Local](https://github.com/microsoft/Foundry-Local/tree/main/samples/python/hello-foundry-local)
- **–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è –∑ —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—ó**: [–Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è –∑ SDK –¥–ª—è –≤–∏–∫–æ–Ω–∞–Ω–Ω—è –∑–∞–ø–∏—Ç—ñ–≤](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks)
- **–†–æ–∑—à–∏—Ä–µ–Ω—ñ —à–∞–±–ª–æ–Ω–∏**: –î–æ—Å–ª—ñ–¥–∂—É–π—Ç–µ –≤–∏–∫–ª–∏–∫ —Ñ—É–Ω–∫—Ü—ñ–π —ñ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü—ñ—é –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç—ñ–≤ —É –º–æ–¥—É–ª—ñ 5

## –ü—ñ–¥—Å—É–º–æ–∫

Foundry Local –∑–∞–±–µ–∑–ø–µ—á—É—î –Ω–∞–¥—ñ–π–Ω–∏–π —à—Ç—É—á–Ω–∏–π —ñ–Ω—Ç–µ–ª–µ–∫—Ç –Ω–∞ –ø—Ä–∏—Å—Ç—Ä–æ—ó, –¥–µ –º–æ–¥–µ–ª—ñ —Å—Ç–∞—é—Ç—å —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω–∏–º–∏, —Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–º–∏ —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏. –ó–∞–≤–¥—è–∫–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ–º—É –≤–∏–±–æ—Ä—É –º–æ–¥–µ–ª–µ–π, –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–º—É –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É —Ç–∞ —à–∞–±–ª–æ–Ω–∞–º, –≥–æ—Ç–æ–≤–∏–º –¥–æ –≤–∏—Ä–æ–±–Ω–∏—Ü—Ç–≤–∞, –∫–æ–º–∞–Ω–¥–∏ –º–æ–∂—É—Ç—å —Å—Ç–≤–æ—Ä—é–≤–∞—Ç–∏ —Å–∫–ª–∞–¥–Ω—ñ AI-–¥–æ–¥–∞—Ç–∫–∏, —è–∫—ñ –∞–¥–∞–ø—Ç—É—é—Ç—å—Å—è –¥–æ —Ä—ñ–∑–Ω–∏—Ö —Ç–∏–ø—ñ–≤ –∑–∞–≤–¥–∞–Ω—å, –∑–±–µ—Ä—ñ–≥–∞—é—á–∏ –∫–æ–Ω—Ñ—ñ–¥–µ–Ω—Ü—ñ–π–Ω—ñ—Å—Ç—å —ñ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å. –®–∞–±–ª–æ–Ω —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ç–æ—Ä–∞, –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–æ–≤–∞–Ω–∏–π —Ç—É—Ç, –∑–∞–±–µ–∑–ø–µ—á—É—î –æ—Å–Ω–æ–≤—É –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å–∫–ª–∞–¥–Ω–∏—Ö AI-—Å–∏—Å—Ç–µ–º, —è–∫—ñ –º–æ–∂—É—Ç—å –º–∞—Å—à—Ç–∞–±—É–≤–∞—Ç–∏—Å—è –≤—ñ–¥ –ª–æ–∫–∞–ª—å–Ω–æ—ó —Ä–æ–∑—Ä–æ–±–∫–∏ –¥–æ —Ä–æ–∑–≥–æ—Ä—Ç–∞–Ω–Ω—è —É –≤–∏—Ä–æ–±–Ω–∏—Ü—Ç–≤—ñ.

---

