<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f86e720f67bb196e2fb6625b2338a1fb",
  "translation_date": "2025-10-09T19:03:48+00:00",
  "source_file": "STUDY_GUIDE.md",
  "language_code": "ms"
}
-->
# EdgeAI untuk Pemula: Laluan Pembelajaran dan Jadual Kajian

### Laluan Pembelajaran Tumpuan (1 minggu)

| Hari | Fokus | Anggaran Jam |
|------|-------|--------------|
| Hari 0 | Modul 0: Pengenalan kepada EdgeAI | 1-2 jam |
| Hari 1 | Modul 1: Asas EdgeAI | 3 jam |
| Hari 2 | Modul 2: Asas SLM | 3 jam |
| Hari 3 | Modul 3: Penggunaan SLM | 2 jam |
| Hari 4-5 | Modul 4: Pengoptimuman Model (6 rangka kerja) | 4 jam |
| Hari 6 | Modul 5: SLMOps | 3 jam |
| Hari 7 | Modul 6-7: Ejen AI & Alat Pembangunan | 4 jam |
| Hari 8 | Modul 8: Toolkit Tempatan Foundry (Pelaksanaan Moden) | 1 jam |

### Laluan Pembelajaran Tumpuan (2 minggu)

| Hari | Fokus | Anggaran Jam |
|------|-------|--------------|
| Hari 1-2 | Modul 1: Asas EdgeAI | 3 jam |
| Hari 3-4 | Modul 2: Asas SLM | 3 jam |
| Hari 5-6 | Modul 3: Penggunaan SLM | 2 jam |
| Hari 7-8 | Modul 4: Pengoptimuman Model | 4 jam |
| Hari 9-10 | Modul 5: SLMOps | 3 jam |
| Hari 11-12 | Modul 6: Ejen AI | 2 jam |
| Hari 13-14 | Modul 7: Alat Pembangunan | 3 jam |

### Kajian Separuh Masa (4 minggu)

| Minggu | Fokus | Anggaran Jam |
|--------|-------|--------------|
| Minggu 1 | Modul 1-2: Asas & Asas SLM | 6 jam |
| Minggu 2 | Modul 3-4: Penggunaan & Pengoptimuman | 6 jam |
| Minggu 3 | Modul 5-6: SLMOps & Ejen AI | 5 jam |
| Minggu 4 | Modul 7: Alat Pembangunan & Integrasi | 3 jam |

| Hari | Fokus | Anggaran Jam |
|------|-------|--------------|
| Hari 0 | Modul 0: Pengenalan kepada EdgeAI | 1-2 jam |
| Hari 1-2 | Modul 1: Asas EdgeAI | 3 jam |
| Hari 3-4 | Modul 2: Asas SLM | 3 jam |
| Hari 5-6 | Modul 3: Penggunaan SLM | 2 jam |
| Hari 7-8 | Modul 4: Pengoptimuman Model | 4 jam |
| Hari 9-10 | Modul 5: SLMOps | 3 jam |
| Hari 11-12 | Modul 6: Sistem Ejen SLM | 2 jam |
| Hari 13-14 | Modul 7: Contoh Pelaksanaan EdgeAI | 2 jam |

| Modul | Tarikh Siap | Jam Dihabiskan | Pengajaran Utama |
|-------|------------|----------------|------------------|
| Modul 0: Pengenalan kepada EdgeAI | | | |
| Modul 1: Asas EdgeAI | | | |
| Modul 2: Asas SLM | | | |
| Modul 3: Penggunaan SLM | | | |
| Modul 4: Pengoptimuman Model (6 rangka kerja) | | | |
| Modul 5: SLMOps | | | |
| Modul 6: Sistem Ejen SLM | | | |
| Modul 7: Contoh Pelaksanaan EdgeAI | | | |
| Latihan Praktikal | | | |
| Mini-Projek | | | |

### Kajian Separuh Masa (4 minggu)

| Minggu | Fokus | Anggaran Jam |
|--------|-------|--------------|
| Minggu 1 | Modul 1-2: Asas & Asas SLM | 6 jam |
| Minggu 2 | Modul 3-4: Penggunaan & Pengoptimuman | 6 jam |
| Minggu 3 | Modul 5-6: SLMOps & Ejen AI | 5 jam |
| Minggu 4 | Modul 7: Alat Pembangunan & Integrasi | 3 jam |

## Pengenalan

Selamat datang ke panduan kajian EdgeAI untuk Pemula! Dokumen ini direka untuk membantu anda menavigasi bahan kursus dengan berkesan dan memaksimumkan pengalaman pembelajaran anda. Ia menyediakan laluan pembelajaran yang terstruktur, jadual kajian yang disyorkan, ringkasan konsep utama, dan sumber tambahan untuk memperdalam pemahaman anda tentang teknologi Edge AI.

Ini adalah kursus ringkas selama 20 jam yang menyampaikan pengetahuan penting tentang EdgeAI dalam format yang efisien masa, menjadikannya sesuai untuk profesional sibuk dan pelajar yang ingin memperoleh kemahiran praktikal dengan cepat dalam bidang yang sedang berkembang ini.

## Gambaran Keseluruhan Kursus

Kursus ini disusun dalam lapan modul komprehensif:

0. **Pengenalan kepada EdgeAI** - Asas dan penetapan konteks dengan aplikasi industri dan objektif pembelajaran
1. **Asas dan Transformasi EdgeAI** - Memahami konsep utama dan perubahan teknologi
2. **Asas Model Bahasa Kecil (SLM)** - Meneroka pelbagai keluarga SLM dan seni bina mereka
3. **Penggunaan Model Bahasa Kecil** - Melaksanakan strategi penggunaan praktikal
4. **Penukaran Format Model dan Kuantisasi** - Pengoptimuman lanjutan dengan 6 rangka kerja termasuk OpenVINO
5. **SLMOps - Operasi Model Bahasa Kecil** - Pengurusan kitaran hayat pengeluaran dan penggunaan
6. **Sistem Ejen SLM** - Ejen AI, panggilan fungsi, dan Protokol Konteks Model
7. **Contoh Pelaksanaan EdgeAI** - Toolkit AI, pembangunan Windows, dan pelaksanaan khusus platform
8. **Microsoft Foundry Local – Toolkit Pembangun Lengkap** - Pembangunan tempatan pertama dengan integrasi Azure hibrid (Modul 08)

## Cara Menggunakan Panduan Kajian Ini

- **Pembelajaran Progresif**: Ikuti modul secara berurutan untuk pengalaman pembelajaran yang paling koheren
- **Titik Pemeriksaan Pengetahuan**: Gunakan soalan penilaian diri selepas setiap bahagian
- **Latihan Praktikal**: Lengkapkan latihan yang disarankan untuk mengukuhkan konsep teori
- **Sumber Tambahan**: Terokai bahan tambahan untuk topik yang paling menarik minat anda

## Cadangan Jadual Kajian

### Laluan Pembelajaran Tumpuan (1 minggu)

| Hari | Fokus | Anggaran Jam |
|------|-------|--------------|
| Hari 0 | Modul 0: Pengenalan kepada EdgeAI | 1-2 jam |
| Hari 1-2 | Modul 1: Asas EdgeAI | 6 jam |
| Hari 3-4 | Modul 2: Asas SLM | 8 jam |
| Hari 5 | Modul 3: Penggunaan SLM | 3 jam |
| Hari 6 | Modul 8: Toolkit Tempatan Foundry | 3 jam |

### Kajian Separuh Masa (3 minggu)

| Minggu | Fokus | Anggaran Jam |
|--------|-------|--------------|
| Minggu 1 | Modul 0: Pengenalan + Modul 1: Asas EdgeAI | 7-9 jam |
| Minggu 2 | Modul 2: Asas SLM | 7-8 jam |
| Minggu 3 | Modul 3: Penggunaan SLM (3j) + Modul 8: Toolkit Tempatan Foundry (2-3j) | 5-6 jam |

## Modul 0: Pengenalan kepada EdgeAI

### Objektif Pembelajaran Utama

- Memahami apa itu Edge AI dan mengapa ia penting dalam landskap teknologi masa kini
- Mengenal pasti industri utama yang diubah oleh Edge AI dan kes penggunaan spesifik mereka
- Memahami kelebihan Model Bahasa Kecil (SLM) untuk penggunaan di edge
- Menetapkan jangkaan pembelajaran dan hasil yang jelas untuk keseluruhan kursus
- Mengenali peluang kerjaya dan keperluan kemahiran dalam bidang Edge AI

### Fokus Kajian

#### Bahagian 1: Paradigma dan Definisi Edge AI
- **Konsep Utama**: 
  - Edge AI vs. pemprosesan AI berasaskan awan tradisional
  - Konvergensi perkakasan, pengoptimuman model, dan permintaan perniagaan
  - Penggunaan AI secara masa nyata, privasi terpelihara, dan kos yang efisien

#### Bahagian 2: Aplikasi Industri
- **Konsep Utama**: 
  - Pembuatan & Industri 4.0: Penyelenggaraan ramalan dan kawalan kualiti
  - Penjagaan Kesihatan: Pengimejan diagnostik dan pemantauan pesakit
  - Sistem Autonomi: Kenderaan pandu sendiri dan pengangkutan
  - Bandar Pintar: Pengurusan trafik dan keselamatan awam
  - Teknologi Pengguna: Telefon pintar, peranti boleh pakai, dan rumah pintar

#### Bahagian 3: Asas Model Bahasa Kecil
- **Konsep Utama**: 
  - Ciri-ciri SLM dan perbandingan prestasi
  - Kecekapan parameter vs. kompromi keupayaan
  - Kekangan penggunaan edge dan strategi pengoptimuman

#### Bahagian 4: Rangka Pembelajaran dan Laluan Kerjaya
- **Konsep Utama**: 
  - Seni bina kursus dan pendekatan penguasaan progresif
  - Kemahiran teknikal dan matlamat pelaksanaan praktikal
  - Peluang kemajuan kerjaya dan aplikasi industri

### Soalan Penilaian Diri

1. Apakah tiga trend teknologi utama yang telah memungkinkan Edge AI?
2. Bandingkan kelebihan dan cabaran Edge AI vs. AI berasaskan awan.
3. Namakan tiga industri di mana Edge AI memberikan nilai perniagaan kritikal dan jelaskan mengapa.
4. Bagaimana Model Bahasa Kecil menjadikan Edge AI praktikal untuk penggunaan dunia nyata?
5. Apakah kemahiran teknikal utama yang akan anda kembangkan sepanjang kursus ini?
6. Terangkan pendekatan pembelajaran empat fasa yang digunakan dalam kursus ini.

### Latihan Praktikal

1. **Penyelidikan Industri**: Pilih satu aplikasi industri dan kaji pelaksanaan Edge AI dunia nyata (30 minit)
2. **Penerokaan Model**: Layari Model Bahasa Kecil yang tersedia di Hugging Face dan bandingkan jumlah parameter dan keupayaan mereka (30 minit)
3. **Perancangan Pembelajaran**: Semak struktur kursus lengkap dan buat jadual kajian peribadi anda (15 minit)

### Bahan Tambahan

- [Gambaran Keseluruhan Pasaran Edge AI - McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-age-of-ai)
- [Gambaran Keseluruhan Model Bahasa Kecil - Hugging Face](https://huggingface.co/blog/small-language-models)
- [Asas Pengkomputeran Edge](https://www.edgecomputing.org/)

## Modul 1: Asas dan Transformasi EdgeAI

### Objektif Pembelajaran Utama

- Memahami perbezaan antara AI berasaskan awan dan AI berasaskan edge
- Menguasai teknik pengoptimuman utama untuk persekitaran yang terhad sumber
- Menganalisis aplikasi dunia nyata teknologi EdgeAI
- Menyediakan persekitaran pembangunan untuk projek EdgeAI

### Fokus Kajian

#### Bahagian 1: Asas EdgeAI
- **Konsep Utama**: 
  - Paradigma pengkomputeran Edge vs. Awan
  - Teknik kuantisasi model
  - Pilihan pecutan perkakasan (NPU, GPU, CPU)
  - Kelebihan privasi dan keselamatan

- **Bahan Tambahan**:
  - [Dokumentasi TensorFlow Lite](https://www.tensorflow.org/lite)
  - [GitHub ONNX Runtime](https://github.com/microsoft/onnxruntime)
  - [Dokumentasi Edge Impulse](https://docs.edgeimpulse.com)

#### Bahagian 2: Kajian Kes Dunia Nyata
- **Konsep Utama**: 
  - Ekosistem model Microsoft Phi & Mu
  - Pelaksanaan praktikal merentasi industri
  - Pertimbangan penggunaan

#### Bahagian 3: Panduan Pelaksanaan Praktikal
- **Konsep Utama**: 
  - Penyediaan persekitaran pembangunan
  - Alat kuantisasi dan pengoptimuman
  - Kaedah penilaian untuk pelaksanaan EdgeAI

#### Bahagian 4: Perkakasan Penggunaan Edge
- **Konsep Utama**: 
  - Perbandingan platform perkakasan
  - Strategi pengoptimuman untuk perkakasan tertentu
  - Pertimbangan penggunaan

### Soalan Penilaian Diri

1. Bandingkan dan bezakan AI berasaskan awan dengan pelaksanaan AI berasaskan edge.
2. Terangkan tiga teknik utama untuk mengoptimumkan model untuk penggunaan edge.
3. Apakah kelebihan utama menjalankan model AI di edge?
4. Terangkan proses kuantisasi model dan bagaimana ia mempengaruhi prestasi.
5. Jelaskan bagaimana pecutan perkakasan yang berbeza (NPU, GPU, CPU) mempengaruhi penggunaan EdgeAI.

### Latihan Praktikal

1. **Penyediaan Persekitaran Cepat**: Konfigurasikan persekitaran pembangunan minimum dengan pakej penting (30 minit)
2. **Penerokaan Model**: Muat turun dan periksa model bahasa kecil yang telah dilatih (1 jam)
3. **Kuantisasi Asas**: Cuba kuantisasi mudah pada model kecil (1 jam)

## Modul 2: Asas Model Bahasa Kecil

### Objektif Pembelajaran Utama

- Memahami prinsip seni bina pelbagai keluarga SLM
- Membandingkan keupayaan model merentasi skala parameter yang berbeza
- Menilai model berdasarkan kecekapan, keupayaan, dan keperluan penggunaan
- Mengenali kes penggunaan yang sesuai untuk pelbagai keluarga model

### Fokus Kajian

#### Bahagian 1: Keluarga Model Microsoft Phi
- **Konsep Utama**: 
  - Evolusi falsafah reka bentuk
  - Seni bina kecekapan pertama
  - Keupayaan khusus

#### Bahagian 2: Keluarga Qwen
- **Konsep Utama**: 
  - Sumbangan sumber terbuka
  - Pilihan penggunaan yang boleh diskalakan
  - Seni bina penaakulan lanjutan

#### Bahagian 3: Keluarga Gemma
- **Konsep Utama**: 
  - Inovasi yang didorong oleh penyelidikan
  - Keupayaan multimodal
  - Pengoptimuman mudah alih

#### Bahagian 4: Keluarga BitNET
- **Konsep Utama**: 
  - Teknologi kuantisasi 1-bit
  - Rangka kerja pengoptimuman inferens
  - Pertimbangan kelestarian

#### Bahagian 5: Model Microsoft Mu
- **Konsep Utama**: 
  - Seni bina pertama peranti
  - Integrasi sistem dengan Windows
  - Operasi yang memelihara privasi

#### Bahagian 6: Phi-Silica
- **Konsep Utama**: 
  - Seni bina yang dioptimumkan NPU
  - Metrik prestasi
  - Integrasi pembangun

### Soalan Penilaian Diri

1. Bandingkan pendekatan seni bina keluarga model Phi dan Qwen.
2. Terangkan bagaimana teknologi kuantisasi BitNET berbeza daripada kuantisasi tradisional.
3. Apakah kelebihan unik model Mu untuk integrasi Windows?
4. Terangkan bagaimana Phi-Silica memanfaatkan perkakasan NPU untuk pengoptimuman prestasi.
5. Untuk aplikasi mudah alih dengan sambungan terhad, keluarga model mana yang paling sesuai dan mengapa?

### Latihan Praktikal

1. **Perbandingan Model**: Penanda aras pantas dua model SLM yang berbeza (1 jam)
2. **Penjanaan Teks Mudah**: Pelaksanaan asas penjanaan teks dengan model kecil (1 jam)
3. **Pengoptimuman Pantas**: Terapkan satu teknik pengoptimuman untuk meningkatkan kelajuan inferens (1 jam)

## Modul 3: Penggunaan Model Bahasa Kecil

### Objektif Pembelajaran Utama

- Memilih model yang sesuai berdasarkan kekangan penggunaan
- Menguasai teknik pengoptimuman untuk pelbagai senario penggunaan
- Melaksanakan SLM dalam persekitaran tempatan dan awan
- Merancang konfigurasi sedia pengeluaran untuk aplikasi EdgeAI

### Fokus Kajian

#### Seksyen 1: Pembelajaran Lanjutan SLM
- **Konsep Keutamaan**: 
  - Kerangka klasifikasi parameter
  - Teknik pengoptimuman lanjutan
  - Strategi pemerolehan model

#### Seksyen 2: Penggunaan Persekitaran Tempatan
- **Konsep Keutamaan**: 
  - Penggunaan platform Ollama
  - Penyelesaian tempatan Microsoft Foundry
  - Analisis perbandingan kerangka kerja

#### Seksyen 3: Penggunaan Awan Berkontena
- **Konsep Keutamaan**: 
  - Inferens berprestasi tinggi vLLM
  - Orkestrasi kontena
  - Pelaksanaan ONNX Runtime

### Soalan Penilaian Kendiri

1. Apakah faktor yang perlu dipertimbangkan semasa memilih antara penggunaan tempatan dan awan?
2. Bandingkan Ollama dan Microsoft Foundry Local sebagai pilihan penggunaan.
3. Terangkan manfaat kontena untuk penggunaan SLM.
4. Apakah metrik prestasi utama yang perlu dipantau untuk SLM yang digunakan di edge?
5. Huraikan aliran kerja penggunaan lengkap dari pemilihan model hingga pelaksanaan pengeluaran.

### Latihan Praktikal

1. **Penggunaan Tempatan Asas**: Gunakan SLM mudah dengan Ollama (1 jam)
2. **Semakan Prestasi**: Jalankan penanda aras pantas pada model yang digunakan (30 minit)
3. **Integrasi Mudah**: Cipta aplikasi minimal yang menggunakan model yang digunakan (1 jam)

## Modul 4: Penukaran Format Model dan Kuantisasi

### Objektif Pembelajaran Utama

- Kuasai teknik kuantisasi lanjutan dari ketepatan 1-bit hingga 8-bit
- Fahami strategi penukaran format (GGUF, ONNX)
- Laksanakan pengoptimuman merentasi enam kerangka kerja (Llama.cpp, Olive, OpenVINO, MLX, sintesis aliran kerja)
- Gunakan model yang dioptimumkan untuk persekitaran edge pengeluaran merentasi perkakasan Intel, Apple, dan pelbagai platform

### Fokus Kajian

#### Seksyen 1: Asas Kuantisasi
- **Konsep Keutamaan**: 
  - Kerangka klasifikasi ketepatan
  - Perdagangan antara prestasi dan ketepatan
  - Pengoptimuman jejak memori

#### Seksyen 2: Pelaksanaan Llama.cpp
- **Konsep Keutamaan**: 
  - Penggunaan merentas platform
  - Pengoptimuman format GGUF
  - Teknik pecutan perkakasan

#### Seksyen 3: Suite Microsoft Olive
- **Konsep Keutamaan**: 
  - Pengoptimuman yang sedar perkakasan
  - Penggunaan gred perusahaan
  - Aliran kerja pengoptimuman automatik

#### Seksyen 4: Toolkit OpenVINO
- **Konsep Keutamaan**: 
  - Pengoptimuman perkakasan Intel
  - Kerangka Pemampatan Rangkaian Neural (NNCF)
  - Penggunaan inferens merentas platform
  - OpenVINO GenAI untuk penggunaan LLM

#### Seksyen 5: Kerangka Apple MLX
- **Konsep Keutamaan**: 
  - Pengoptimuman Apple Silicon
  - Seni bina memori bersatu
  - Keupayaan penalaan halus LoRA

#### Seksyen 6: Sintesis Aliran Kerja Pembangunan Edge AI
- **Konsep Keutamaan**: 
  - Seni bina aliran kerja bersatu
  - Pokok keputusan pemilihan kerangka kerja
  - Pengesahan kesediaan pengeluaran
  - Strategi masa depan

### Soalan Penilaian Kendiri

1. Bandingkan strategi kuantisasi merentasi tahap ketepatan yang berbeza (1-bit hingga 8-bit).
2. Terangkan kelebihan format GGUF untuk penggunaan di edge.
3. Bagaimana pengoptimuman yang sedar perkakasan dalam Microsoft Olive meningkatkan kecekapan penggunaan?
4. Apakah manfaat utama NNCF OpenVINO untuk pemampatan model?
5. Huraikan bagaimana Apple MLX memanfaatkan seni bina memori bersatu untuk pengoptimuman.
6. Bagaimana sintesis aliran kerja membantu dalam memilih kerangka pengoptimuman yang optimum?

### Latihan Praktikal

1. **Kuantisasi Model**: Terapkan tahap kuantisasi yang berbeza pada model dan bandingkan hasilnya (1 jam)
2. **Pengoptimuman OpenVINO**: Gunakan NNCF untuk memampatkan model untuk perkakasan Intel (1 jam)
3. **Perbandingan Kerangka Kerja**: Uji model yang sama merentasi tiga kerangka pengoptimuman yang berbeza (1 jam)
4. **Penanda Aras Prestasi**: Ukur kesan pengoptimuman pada kelajuan inferens dan penggunaan memori (1 jam)

## Modul 5: SLMOps - Operasi Model Bahasa Kecil

### Objektif Pembelajaran Utama

- Fahami prinsip pengurusan kitaran hayat SLMOps
- Kuasai teknik distilasi dan penalaan halus untuk penggunaan di edge
- Laksanakan strategi penggunaan pengeluaran dengan pemantauan
- Bina aliran kerja operasi dan penyelenggaraan SLM gred perusahaan

### Fokus Kajian

#### Seksyen 1: Pengenalan kepada SLMOps
- **Konsep Keutamaan**: 
  - Peralihan paradigma SLMOps dalam operasi AI
  - Seni bina yang mengutamakan kos dan privasi
  - Kesan strategik perniagaan dan kelebihan daya saing

#### Seksyen 2: Distilasi Model
- **Konsep Keutamaan**: 
  - Teknik pemindahan pengetahuan
  - Pelaksanaan proses distilasi dua peringkat
  - Aliran kerja distilasi Azure ML

#### Seksyen 3: Strategi Penalaan Halus
- **Konsep Keutamaan**: 
  - Penalaan halus yang cekap parameter (PEFT)
  - Kaedah lanjutan LoRA dan QLoRA
  - Latihan multi-adapter dan pengoptimuman hiperparameter

#### Seksyen 4: Penggunaan Pengeluaran
- **Konsep Keutamaan**: 
  - Penukaran model dan kuantisasi untuk pengeluaran
  - Konfigurasi penggunaan Foundry Local
  - Penanda aras prestasi dan pengesahan kualiti

### Soalan Penilaian Kendiri

1. Bagaimana SLMOps berbeza daripada MLOps tradisional?
2. Terangkan manfaat distilasi model untuk penggunaan di edge.
3. Apakah pertimbangan utama untuk penalaan halus SLM dalam persekitaran yang terhad sumber?
4. Huraikan aliran kerja penggunaan pengeluaran lengkap untuk aplikasi AI di edge.

### Latihan Praktikal

1. **Distilasi Asas**: Cipta model yang lebih kecil daripada model guru yang lebih besar (1 jam)
2. **Eksperimen Penalaan Halus**: Talaan halus model untuk domain tertentu (1 jam)
3. **Aliran Kerja Penggunaan**: Sediakan aliran kerja CI/CD asas untuk penggunaan model (1 jam)

## Modul 6: Sistem Agentik SLM - Ejen AI dan Panggilan Fungsi

### Objektif Pembelajaran Utama

- Bina ejen AI pintar untuk persekitaran edge menggunakan Model Bahasa Kecil
- Laksanakan keupayaan panggilan fungsi dengan aliran kerja sistematik
- Kuasai integrasi Protokol Konteks Model (MCP) untuk interaksi alat yang standard
- Cipta sistem agentik yang canggih dengan campur tangan manusia yang minimum

### Fokus Kajian

#### Seksyen 1: Ejen AI dan Asas SLM
- **Konsep Keutamaan**: 
  - Kerangka klasifikasi ejen (refleks, berasaskan model, berasaskan matlamat, ejen pembelajaran)
  - Analisis perdagangan SLM vs LLM
  - Corak reka bentuk ejen khusus edge
  - Pengoptimuman sumber untuk ejen

#### Seksyen 2: Panggilan Fungsi dalam Model Bahasa Kecil
- **Konsep Keutamaan**: 
  - Pelaksanaan aliran kerja sistematik (pengesanan niat, output JSON, pelaksanaan luaran)
  - Pelaksanaan khusus platform (Phi-4-mini, model Qwen terpilih, Microsoft Foundry Local)
  - Contoh lanjutan (kerjasama multi-ejen, pemilihan alat dinamik)
  - Pertimbangan pengeluaran (had kadar, log audit, langkah keselamatan)

#### Seksyen 3: Integrasi Protokol Konteks Model (MCP)
- **Konsep Keutamaan**: 
  - Seni bina protokol dan reka bentuk sistem berlapis
  - Sokongan multi-backend (Ollama untuk pembangunan, vLLM untuk pengeluaran)
  - Protokol sambungan (mod STDIO dan SSE)
  - Aplikasi dunia sebenar (automasi web, pemprosesan data, integrasi API)

### Soalan Penilaian Kendiri

1. Apakah pertimbangan seni bina utama untuk ejen AI di edge?
2. Bagaimana panggilan fungsi meningkatkan keupayaan ejen?
3. Terangkan peranan Protokol Konteks Model dalam komunikasi ejen.

### Latihan Praktikal

1. **Ejen Mudah**: Bina ejen AI asas dengan panggilan fungsi (1 jam)
2. **Integrasi MCP**: Laksanakan MCP dalam aplikasi ejen (30 minit)

## Bengkel: Laluan Pembelajaran Praktikal

### Objektif Pembelajaran Utama

- Bina aplikasi AI sedia pengeluaran menggunakan SDK Foundry Local dan amalan terbaik
- Laksanakan pengendalian ralat yang komprehensif dan corak maklum balas pengguna
- Cipta aliran RAG dengan penilaian kualiti dan pemantauan prestasi
- Bangunkan sistem multi-ejen dengan corak penyelaras
- Kuasai penghalaan model pintar untuk pemilihan model berdasarkan tugas
- Gunakan penyelesaian AI tempatan dengan seni bina yang menjaga privasi

### Fokus Kajian

#### Sesi 01: Memulakan dengan Foundry Local
- **Konsep Keutamaan**:
  - Integrasi SDK FoundryLocalManager dan penemuan perkhidmatan automatik
  - Pelaksanaan sembang asas dan penstriman
  - Corak pengendalian ralat dan maklum balas pengguna
  - Konfigurasi berdasarkan persekitaran

#### Sesi 02: Membina Penyelesaian AI dengan RAG
- **Konsep Keutamaan**:
  - Penyisipan vektor dalam memori dengan sentence-transformers
  - Pelaksanaan aliran RAG (ambil → jana)
  - Penilaian kualiti dengan metrik RAGAS
  - Keselamatan import untuk kebergantungan pilihan

#### Sesi 03: Model Sumber Terbuka
- **Konsep Keutamaan**:
  - Strategi penanda aras multi-model
  - Pengukuran kependaman dan throughput
  - Kemerosotan yang anggun dan pemulihan ralat
  - Perbandingan prestasi merentasi keluarga model

#### Sesi 04: Model Terkini
- **Konsep Keutamaan**:
  - Metodologi perbandingan SLM vs LLM
  - Petunjuk jenis dan pemformatan output yang komprehensif
  - Pengendalian ralat per model
  - Hasil berstruktur untuk analisis

#### Sesi 05: Ejen Berkuasa AI
- **Konsep Keutamaan**:
  - Orkestrasi multi-ejen dengan corak penyelaras
  - Pengurusan memori ejen dan penjejakan keadaan
  - Pengendalian ralat aliran dan log peringkat
  - Pemantauan prestasi dan statistik

#### Sesi 06: Model sebagai Alat
- **Konsep Keutamaan**:
  - Pengesanan niat dan padanan corak
  - Algoritma penghalaan model berdasarkan kata kunci
  - Aliran kerja berbilang langkah (rancang → laksanakan → perbaiki)
  - Dokumentasi fungsi yang komprehensif

### Soalan Penilaian Kendiri

1. Bagaimana FoundryLocalManager mempermudah pengurusan perkhidmatan berbanding panggilan REST manual?
2. Terangkan kepentingan pengawal import untuk kebergantungan pilihan seperti sentence-transformers.
3. Apakah strategi yang memastikan kemerosotan yang anggun dalam penanda aras multi-model?
4. Bagaimana corak penyelaras mengatur ejen pakar berganda?
5. Huraikan komponen penghala model pintar.
6. Apakah elemen utama pengendalian ralat sedia pengeluaran?

### Latihan Praktikal

1. **Aplikasi Sembang**: Laksanakan sembang penstriman dengan pengendalian ralat (45 minit)
2. **Aliran RAG**: Bina RAG minimal dengan penilaian kualiti (1 jam)
3. **Penanda Aras Model**: Bandingkan 3+ model berdasarkan prestasi (1 jam)
4. **Sistem Multi-Ejen**: Cipta penyelaras dengan 2 ejen pakar (1.5 jam)
5. **Penghala Pintar**: Bina pemilihan model berdasarkan tugas (1 jam)
6. **Penggunaan Pengeluaran**: Tambah pemantauan dan pengendalian ralat yang komprehensif (45 minit)

### Peruntukan Masa

**Pembelajaran Tertumpu (1 minggu)**:
- Hari 1: Sesi 01-02 (Sembang + RAG) - 3 jam
- Hari 2: Sesi 03-04 (Penanda Aras + Perbandingan) - 3 jam
- Hari 3: Sesi 05-06 (Ejen + Penghalaan) - 3 jam
- Hari 4: Latihan praktikal dan pengesahan - 2 jam

**Kajian Separuh Masa (2 minggu)**:
- Minggu 1: Sesi 01-03 (6 jam keseluruhan)
- Minggu 2: Sesi 04-06 + latihan (5 jam keseluruhan)

## Modul 7: Contoh Pelaksanaan EdgeAI

### Objektif Pembelajaran Utama

- Kuasai AI Toolkit untuk Visual Studio Code untuk aliran kerja pembangunan EdgeAI yang komprehensif
- Dapatkan kepakaran dalam platform Windows AI Foundry dan strategi pengoptimuman NPU
- Laksanakan EdgeAI merentasi pelbagai platform perkakasan dan senario penggunaan
- Bina aplikasi EdgeAI sedia pengeluaran dengan pengoptimuman khusus platform

### Fokus Kajian

#### Seksyen 1: AI Toolkit untuk Visual Studio Code
- **Konsep Keutamaan**: 
  - Persekitaran pembangunan Edge AI yang komprehensif dalam VS Code
  - Katalog model dan penemuan untuk penggunaan di edge
  - Ujian tempatan, pengoptimuman, dan aliran kerja pembangunan ejen
  - Pemantauan prestasi dan penilaian untuk senario edge

#### Seksyen 2: Panduan Pembangunan Windows EdgeAI
- **Konsep Keutamaan**: 
  - Gambaran keseluruhan platform Windows AI Foundry yang komprehensif
  - API Phi Silica untuk inferens NPU yang cekap
  - API Penglihatan Komputer untuk pemprosesan imej dan OCR
  - CLI Foundry Local untuk pembangunan dan ujian tempatan

#### Seksyen 3: Pelaksanaan Khusus Platform
- **Konsep Keutamaan**: 
  - Penggunaan NVIDIA Jetson Orin Nano (67 TOPS prestasi AI)
  - Aplikasi mudah alih dengan .NET MAUI dan ONNX Runtime GenAI
  - Penyelesaian Azure EdgeAI dengan seni bina hibrid awan-edge
  - Pengoptimuman Windows ML dengan sokongan perkakasan sejagat
  - Aplikasi Foundry Local dengan pelaksanaan RAG yang menjaga privasi

### Soalan Penilaian Kendiri

1. Bagaimana AI Toolkit mempermudah aliran kerja pembangunan EdgeAI?
2. Bandingkan strategi penggunaan merentasi pelbagai platform perkakasan.
3. Apakah kelebihan Windows AI Foundry untuk pembangunan di edge?
4. Jelaskan peranan pengoptimuman NPU dalam aplikasi AI tepi moden.
5. Bagaimana API Phi Silica memanfaatkan perkakasan NPU untuk pengoptimuman prestasi?
6. Bandingkan manfaat pelaksanaan tempatan vs. awan untuk aplikasi yang sensitif terhadap privasi.

### Latihan Praktikal

1. **Persediaan Alat AI**: Konfigurasi Alat AI dan optimumkan model (1 jam)
2. **Windows AI Foundry**: Bina aplikasi AI Windows mudah menggunakan API Phi Silica (1 jam)
3. **Pelaksanaan Merentas Platform**: Laksanakan model yang sama pada dua platform berbeza (1 jam)
4. **Pengoptimuman NPU**: Uji prestasi NPU dengan alat Windows AI Foundry (30 minit)

## Modul 8: Microsoft Foundry Local – Alat Pembangun Lengkap (Moden)

### Objektif Pembelajaran Utama

- Pasang dan konfigurasi Foundry Local dengan integrasi SDK moden
- Laksanakan sistem multi-ejen maju dengan corak penyelaras
- Bina penghala model pintar dengan pemilihan automatik berdasarkan tugas
- Laksanakan penyelesaian AI sedia pengeluaran dengan pemantauan menyeluruh
- Integrasi dengan Azure AI Foundry untuk senario pelaksanaan hibrid
- Kuasai corak SDK moden dengan FoundryLocalManager dan klien OpenAI

### Kawasan Fokus Kajian

#### Seksyen 1: Pemasangan dan Konfigurasi Moden
- **Konsep Keutamaan**: 
  - Integrasi SDK FoundryLocalManager
  - Penemuan perkhidmatan automatik dan pemantauan kesihatan
  - Corak konfigurasi berdasarkan persekitaran
  - Pertimbangan pelaksanaan pengeluaran

#### Seksyen 2: Sistem Multi-Ejen Maju
- **Konsep Keutamaan**: 
  - Corak penyelaras dengan ejen pakar
  - Pengkhususan ejen untuk pengambilan, penaakulan, dan pelaksanaan
  - Mekanisme gelung maklum balas untuk penambahbaikan
  - Pemantauan prestasi dan penjejakan statistik

#### Seksyen 3: Penghala Model Pintar
- **Konsep Keutamaan**: 
  - Algoritma pemilihan model berdasarkan kata kunci
  - Sokongan pelbagai model (umum, penaakulan, kod, kreatif)
  - Konfigurasi pemboleh ubah persekitaran untuk fleksibiliti
  - Pemeriksaan kesihatan perkhidmatan dan pengendalian ralat

#### Seksyen 4: Pelaksanaan Sedia Pengeluaran
- **Konsep Keutamaan**: 
  - Pengendalian ralat menyeluruh dan mekanisme sandaran
  - Pemantauan permintaan dan penjejakan prestasi
  - Contoh interaktif Jupyter notebook dengan penanda aras
  - Corak integrasi dengan aplikasi sedia ada

### Soalan Penilaian Kendiri

1. Bagaimana pendekatan FoundryLocalManager moden berbeza daripada panggilan REST manual?
2. Jelaskan corak penyelaras dan bagaimana ia mengatur ejen pakar.
3. Bagaimana penghala pintar memilih model yang sesuai berdasarkan kandungan pertanyaan?
4. Apakah komponen utama sistem ejen AI sedia pengeluaran?
5. Bagaimana anda melaksanakan pemantauan kesihatan menyeluruh untuk perkhidmatan Foundry Local?
6. Bandingkan manfaat pendekatan moden vs. corak pelaksanaan tradisional.

### Latihan Praktikal

1. **Persediaan SDK Moden**: Konfigurasi FoundryLocalManager dengan penemuan perkhidmatan automatik (30 minit)
2. **Sistem Multi-Ejen**: Jalankan penyelaras maju dengan ejen pakar (30 minit)
3. **Penghala Pintar**: Uji penghala model dengan jenis pertanyaan yang berbeza (30 minit)
4. **Eksplorasi Interaktif**: Gunakan Jupyter notebook untuk meneroka ciri-ciri maju (45 minit)
5. **Pelaksanaan Pengeluaran**: Laksanakan corak pemantauan dan pengendalian ralat (30 minit)
6. **Integrasi Hibrid**: Konfigurasi senario sandaran Azure AI Foundry (30 minit)

## Panduan Peruntukan Masa

Untuk membantu anda memanfaatkan garis masa kursus 30 jam yang diperluaskan (termasuk Bengkel), berikut adalah cadangan pecahan masa:

| Aktiviti | Peruntukan Masa | Penerangan |
|----------|----------------|-------------|
| Membaca Bahan Teras | 12 jam | Fokus pada konsep penting dalam setiap modul |
| Latihan Praktikal | 10 jam | Pelaksanaan praktikal teknik utama (termasuk Bengkel) |
| Penilaian Kendiri | 3 jam | Uji pemahaman anda melalui soalan dan refleksi |
| Projek Mini | 5 jam | Terapkan pengetahuan kepada pelaksanaan praktikal kecil |

### Kawasan Fokus Utama Berdasarkan Kekangan Masa

**Jika anda hanya mempunyai 10 jam:**
- Lengkapkan Modul 0 (Pengenalan) dan Modul 1, 2, dan 3 (konsep teras EdgeAI)
- Lakukan sekurang-kurangnya satu latihan praktikal setiap modul
- Fokus pada memahami konsep teras daripada butiran pelaksanaan

**Jika anda boleh meluangkan masa penuh 20 jam:**
- Lengkapkan semua lapan modul (termasuk Pengenalan)
- Lakukan latihan praktikal utama dari setiap modul
- Lengkapkan satu projek mini dari Modul 7
- Terokai sekurang-kurangnya 2-3 sumber tambahan

**Jika anda mempunyai lebih daripada 20 jam:**
- Lengkapkan semua modul (termasuk Pengenalan) dengan latihan terperinci
- Bina pelbagai projek mini
- Terokai teknik pengoptimuman maju dalam Modul 4
- Laksanakan pelaksanaan pengeluaran dari Modul 5

## Sumber Penting

Sumber yang dipilih dengan teliti ini memberikan nilai paling tinggi untuk masa belajar anda yang terhad:

### Dokumentasi Wajib Baca
- [ONNX Runtime Getting Started](https://onnxruntime.ai/docs/get-started/with-python.html) - Alat pengoptimuman model paling efisien
- [Ollama Quick Start](https://github.com/ollama/ollama#get-started) - Cara terpantas untuk melaksanakan SLM secara tempatan
- [Microsoft Phi Model Card](https://huggingface.co/microsoft/phi-2) - Rujukan untuk model yang dioptimumkan untuk tepi
- [OpenVINO Documentation](https://docs.openvino.ai/2025/index.html) - Kit alat pengoptimuman komprehensif Intel
- [AI Toolkit for VS Code](https://code.visualstudio.com/docs/intelligentapps/overview) - Persekitaran pembangunan EdgeAI bersepadu
- [Windows AI Foundry](https://docs.microsoft.com/en-us/windows/ai/) - Platform pembangunan EdgeAI khusus Windows

### Alat Penjimat Masa
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Akses model dan pelaksanaan pantas
- [Gradio](https://www.gradio.app/docs/interface) - Pembangunan UI pantas untuk demo AI
- [Microsoft Olive](https://github.com/microsoft/Olive) - Pengoptimuman model yang dipermudahkan
- [Llama.cpp](https://github.com/ggml-ai/llama.cpp) - Inferens CPU yang efisien
- [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf) - Rangka kerja pemampatan rangkaian neural
- [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai) - Kit alat pelaksanaan model bahasa besar

## Templat Penjejakan Kemajuan

Gunakan templat ringkas ini untuk menjejaki kemajuan pembelajaran anda melalui kursus 20 jam:

| Modul | Tarikh Selesai | Masa Diluangkan | Pengajaran Utama |
|--------|----------------|-------------|---------------|
| Modul 0: Pengenalan kepada EdgeAI | | | |
| Modul 1: Asas EdgeAI | | | |
| Modul 2: Asas SLM | | | |
| Modul 3: Pelaksanaan SLM | | | |
| Modul 4: Pengoptimuman Model | | | |
| Modul 5: SLMOps | | | |
| Modul 6: Ejen AI | | | |
| Modul 7: Alat Pembangunan | | | |
| Bengkel: Pembelajaran Praktikal | | | |
| Modul 8: Alat Foundry Local | | | |
| Latihan Praktikal | | | |
| Projek Mini | | | |

## Idea Projek Mini

Pertimbangkan untuk melengkapkan salah satu projek ini untuk mengamalkan konsep EdgeAI (setiap satu direka untuk mengambil masa 2-4 jam):

### Projek Pemula (2-3 jam setiap satu)
1. **Pembantu Teks Tepi**: Cipta alat pelengkap teks luar talian mudah menggunakan model bahasa kecil
2. **Papan Pemuka Perbandingan Model**: Bina visualisasi asas metrik prestasi merentas SLM yang berbeza
3. **Eksperimen Pengoptimuman**: Ukur kesan tahap kuantisasi yang berbeza pada model asas yang sama

### Projek Pertengahan (3-4 jam setiap satu)
4. **Aliran Kerja Alat AI**: Gunakan Alat AI VS Code untuk mengoptimumkan dan melaksanakan model dari awal hingga akhir
5. **Aplikasi Windows AI Foundry**: Cipta aplikasi Windows menggunakan API Phi Silica dan pengoptimuman NPU
6. **Pelaksanaan Merentas Platform**: Laksanakan model yang dioptimumkan yang sama pada Windows (OpenVINO) dan mudah alih (.NET MAUI)
7. **Ejen Panggilan Fungsi**: Bina ejen AI dengan keupayaan panggilan fungsi untuk senario tepi

### Projek Integrasi Lanjutan (4-5 jam setiap satu)
8. **Saluran Pengoptimuman OpenVINO**: Laksanakan pengoptimuman model lengkap menggunakan NNCF dan kit alat GenAI
9. **Saluran SLMOps**: Laksanakan kitaran hayat model lengkap dari latihan hingga pelaksanaan tepi
10. **Sistem Tepi Multi-Model**: Laksanakan pelbagai model khusus yang bekerjasama pada perkakasan tepi
11. **Sistem Integrasi MCP**: Bina sistem ejen menggunakan Protokol Konteks Model untuk interaksi alat

## Rujukan

- Microsoft Learn (Foundry Local)
  - Gambaran Keseluruhan: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
  - Memulakan: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
  - Rujukan CLI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
  - Integrasi dengan SDK inferens: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
  - Cara membuka WebUI: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui
  - Kompilasi model Hugging Face: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- Azure AI Foundry
  - Gambaran Keseluruhan: https://learn.microsoft.com/en-us/azure/ai-foundry/
  - Ejen (gambaran keseluruhan): https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- Alat Pengoptimuman dan Inferens
  - Microsoft Olive (dokumen): https://microsoft.github.io/Olive/
  - Microsoft Olive (GitHub): https://github.com/microsoft/Olive
  - ONNX Runtime (memulakan): https://onnxruntime.ai/docs/get-started/with-python.html
  - Integrasi ONNX Runtime Olive: https://onnxruntime.ai/docs/performance/olive.html
  - OpenVINO (dokumen): https://docs.openvino.ai/2025/index.html
  - Apple MLX (dokumen): https://ml-explore.github.io/mlx/build/html/index.html
- Rangka Kerja Pelaksanaan dan Model
  - Llama.cpp: https://github.com/ggml-ai/llama.cpp
  - Hugging Face Transformers: https://huggingface.co/docs/transformers/index
  - vLLM (dokumen): https://docs.vllm.ai/
  - Ollama (memulakan): https://github.com/ollama/ollama#get-started
- Alat Pembangun (Windows dan VS Code)
  - Alat AI untuk VS Code: https://learn.microsoft.com/en-us/azure/ai-toolkit/overview
  - Windows ML (gambaran keseluruhan): https://learn.microsoft.com/en-us/windows/ai/new-windows-ml/overview

## Komuniti Pembelajaran

Sertai perbincangan dan berhubung dengan pelajar lain:
- Perbincangan GitHub di [repositori EdgeAI untuk Pemula](https://github.com/microsoft/edgeai-for-beginners/discussions)
- [Komuniti Teknologi Microsoft](https://techcommunity.microsoft.com/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/edge-ai)

## Kesimpulan

EdgeAI mewakili sempadan pelaksanaan kecerdasan buatan, membawa keupayaan yang kuat terus ke peranti sambil menangani kebimbangan kritikal tentang privasi, kependaman, dan sambungan. Kursus 20 jam ini menyediakan anda dengan pengetahuan penting dan kemahiran praktikal untuk mula bekerja dengan teknologi EdgeAI dengan segera.

Kursus ini sengaja ringkas dan fokus pada konsep paling penting, membolehkan anda memperoleh kepakaran yang bernilai dengan cepat tanpa komitmen masa yang berlebihan. Ingat bahawa latihan praktikal, walaupun dengan contoh mudah, adalah kunci untuk mengukuhkan apa yang telah anda pelajari.

Selamat belajar!

---

**Penafian**:  
Dokumen ini telah diterjemahkan menggunakan perkhidmatan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Walaupun kami berusaha untuk ketepatan, sila ambil perhatian bahawa terjemahan automatik mungkin mengandungi kesilapan atau ketidaktepatan. Dokumen asal dalam bahasa asalnya harus dianggap sebagai sumber yang berwibawa. Untuk maklumat penting, terjemahan manusia profesional adalah disyorkan. Kami tidak bertanggungjawab atas sebarang salah faham atau salah tafsir yang timbul daripada penggunaan terjemahan ini.