<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1c8c05964be6fb235b026feed0bf066e",
  "translation_date": "2025-10-01T21:47:45+00:00",
  "source_file": "Module02/02.QwenFamily.md",
  "language_code": "bg"
}
-->
# –†–∞–∑–¥–µ–ª 2: –û—Å–Ω–æ–≤–∏ –Ω–∞ —Å–µ–º–µ–π—Å—Ç–≤–æ—Ç–æ Qwen

–ú–æ–¥–µ–ª–Ω–æ—Ç–æ —Å–µ–º–µ–π—Å—Ç–≤–æ Qwen –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–≤–∞ —Ü—è–ª–æ—Å—Ç–Ω–∏—è –ø–æ–¥—Ö–æ–¥ –Ω–∞ Alibaba Cloud –∫—ä–º –≥–æ–ª–µ–º–∏—Ç–µ –µ–∑–∏–∫–æ–≤–∏ –º–æ–¥–µ–ª–∏ –∏ –º—É–ª—Ç–∏–º–æ–¥–∞–ª–Ω–∏—è AI, –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–∞–π–∫–∏, —á–µ –æ—Ç–≤–æ—Ä–µ–Ω–∏—Ç–µ –º–æ–¥–µ–ª–∏ –º–æ–≥–∞—Ç –¥–∞ –ø–æ—Å—Ç–∏–≥–Ω–∞—Ç –∑–∞–±–µ–ª–µ–∂–∏—Ç–µ–ª–Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç, –∫–∞—Ç–æ —Å—ä—â–µ–≤—Ä–µ–º–µ–Ω–Ω–æ —Å–∞ –¥–æ—Å—Ç—ä–ø–Ω–∏ –∑–∞ —Ä–∞–∑–ª–∏—á–Ω–∏ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –Ω–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ. –í–∞–∂–Ω–æ –µ –¥–∞ —Ä–∞–∑–±–µ—Ä–µ–º –∫–∞–∫ —Å–µ–º–µ–π—Å—Ç–≤–æ—Ç–æ Qwen –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—è –º–æ—â–Ω–∏ AI –≤—ä–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å –≥—ä–≤–∫–∞–≤–∏ –æ–ø—Ü–∏–∏ –∑–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ, –∫–∞—Ç–æ —Å—ä—â–µ–≤—Ä–µ–º–µ–Ω–Ω–æ –ø–æ–¥–¥—ä—Ä–∂–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç –ø—Ä–∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–∏ –∑–∞–¥–∞—á–∏.

## –†–µ—Å—É—Ä—Å–∏ –∑–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏—Ü–∏

### –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏ –Ω–∞ –º–æ–¥–µ–ª–∏ –≤ Hugging Face
–ò–∑–±—Ä–∞–Ω–∏ –º–æ–¥–µ–ª–∏ –æ—Ç —Å–µ–º–µ–π—Å—Ç–≤–æ—Ç–æ Qwen —Å–∞ –¥–æ—Å—Ç—ä–ø–Ω–∏ —á—Ä–µ–∑ [Hugging Face](https://huggingface.co/models?search=qwen), –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—è–π–∫–∏ –¥–æ—Å—Ç—ä–ø –¥–æ –Ω—è–∫–æ–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∏ –Ω–∞ —Ç–µ–∑–∏ –º–æ–¥–µ–ª–∏. –ú–æ–∂–µ—Ç–µ –¥–∞ —Ä–∞–∑–≥–ª–µ–¥–∞—Ç–µ –Ω–∞–ª–∏—á–Ω–∏—Ç–µ –≤–∞—Ä–∏–∞–Ω—Ç–∏, –¥–∞ –≥–∏ –∞–¥–∞–ø—Ç–∏—Ä–∞—Ç–µ –∑–∞ –≤–∞—à–∏—Ç–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∏ –Ω—É–∂–¥–∏ –∏ –¥–∞ –≥–∏ –≤–Ω–µ–¥—Ä–∏—Ç–µ —á—Ä–µ–∑ —Ä–∞–∑–ª–∏—á–Ω–∏ —Ä–∞–º–∫–∏.

### –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏ –∑–∞ –ª–æ–∫–∞–ª–Ω–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞
–ó–∞ –ª–æ–∫–∞–ª–Ω–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∏ —Ç–µ—Å—Ç–≤–∞–Ω–µ –º–æ–∂–µ—Ç–µ –¥–∞ –∏–∑–ø–æ–ª–∑–≤–∞—Ç–µ [Microsoft Foundry Local](https://github.com/microsoft/foundry-local), –∑–∞ –¥–∞ —Å—Ç–∞—Ä—Ç–∏—Ä–∞—Ç–µ –Ω–∞–ª–∏—á–Ω–∏—Ç–µ –º–æ–¥–µ–ª–∏ Qwen –Ω–∞ –≤–∞—à–∞—Ç–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–≤–∞—â–∞ –º–∞—à–∏–Ω–∞ —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç.

### –†–µ—Å—É—Ä—Å–∏ –∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
- [–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∑–∞ –º–æ–¥–µ–ª–∏—Ç–µ Qwen](https://huggingface.co/docs/transformers/model_doc/qwen)
- [–û–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω–µ –Ω–∞ –º–æ–¥–µ–ª–∏—Ç–µ Qwen –∑–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–Ω–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞](https://github.com/microsoft/olive)

## –í—ä–≤–µ–¥–µ–Ω–∏–µ

–í —Ç–æ–∑–∏ —É—Ä–æ–∫ —â–µ —Ä–∞–∑–≥–ª–µ–¥–∞–º–µ —Å–µ–º–µ–π—Å—Ç–≤–æ—Ç–æ –º–æ–¥–µ–ª–∏ Qwen –Ω–∞ Alibaba –∏ –Ω–µ–≥–æ–≤–∏—Ç–µ –æ—Å–Ω–æ–≤–Ω–∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏. –©–µ –æ–±—Ö–≤–∞–Ω–µ–º –µ–≤–æ–ª—é—Ü–∏—è—Ç–∞ –Ω–∞ —Å–µ–º–µ–π—Å—Ç–≤–æ—Ç–æ Qwen, –∏–Ω–æ–≤–∞—Ç–∏–≤–Ω–∏—Ç–µ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ –∑–∞ –æ–±—É—á–µ–Ω–∏–µ, –∫–æ–∏—Ç–æ –ø—Ä–∞–≤—è—Ç –º–æ–¥–µ–ª–∏—Ç–µ Qwen –µ—Ñ–µ–∫—Ç–∏–≤–Ω–∏, –∫–ª—é—á–æ–≤–∏—Ç–µ –≤–∞—Ä–∏–∞–Ω—Ç–∏ –≤ —Å–µ–º–µ–π—Å—Ç–≤–æ—Ç–æ –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤ —Ä–∞–∑–ª–∏—á–Ω–∏ —Å—Ü–µ–Ω–∞—Ä–∏–∏.

## –¶–µ–ª–∏ –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ—Ç–æ

–î–æ –∫—Ä–∞—è –Ω–∞ —Ç–æ–∑–∏ —É—Ä–æ–∫ —â–µ –º–æ–∂–µ—Ç–µ:

- –î–∞ —Ä–∞–∑–±–µ—Ä–µ—Ç–µ —Ñ–∏–ª–æ—Å–æ—Ñ–∏—è—Ç–∞ –Ω–∞ –¥–∏–∑–∞–π–Ω–∞ –∏ –µ–≤–æ–ª—é—Ü–∏—è—Ç–∞ –Ω–∞ —Å–µ–º–µ–π—Å—Ç–≤–æ—Ç–æ –º–æ–¥–µ–ª–∏ Qwen –Ω–∞ Alibaba
- –î–∞ –∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–∞—Ç–µ –∫–ª—é—á–æ–≤–∏—Ç–µ –∏–Ω–æ–≤–∞—Ü–∏–∏, –∫–æ–∏—Ç–æ –ø–æ–∑–≤–æ–ª—è–≤–∞—Ç –Ω–∞ –º–æ–¥–µ–ª–∏—Ç–µ Qwen –¥–∞ –ø–æ—Å—Ç–∏–≥–∞—Ç –≤–∏—Å–æ–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç –ø—Ä–∏ —Ä–∞–∑–ª–∏—á–Ω–∏ —Ä–∞–∑–º–µ—Ä–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
- –î–∞ —Ä–∞–∑–ø–æ–∑–Ω–∞–µ—Ç–µ –ø—Ä–µ–¥–∏–º—Å—Ç–≤–∞—Ç–∞ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è—Ç–∞ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω–∏—Ç–µ –≤–∞—Ä–∏–∞–Ω—Ç–∏ –Ω–∞ –º–æ–¥–µ–ª–∏—Ç–µ Qwen
- –î–∞ –ø—Ä–∏–ª–æ–∂–∏—Ç–µ –∑–Ω–∞–Ω–∏—è—Ç–∞ –∑–∞ –º–æ–¥–µ–ª–∏—Ç–µ Qwen, –∑–∞ –¥–∞ –∏–∑–±–µ—Ä–µ—Ç–µ –ø–æ–¥—Ö–æ–¥—è—â–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∏ –∑–∞ —Ä–µ–∞–ª–Ω–∏ —Å—Ü–µ–Ω–∞—Ä–∏–∏

## –†–∞–∑–±–∏—Ä–∞–Ω–µ –Ω–∞ —Å—ä–≤—Ä–µ–º–µ–Ω–Ω–∏—è –ø–µ–π–∑–∞–∂ –Ω–∞ AI –º–æ–¥–µ–ª–∏

–ü–µ–π–∑–∞–∂—ä—Ç –Ω–∞ AI —Å–µ –µ —Ä–∞–∑–≤–∏–ª –∑–Ω–∞—á–∏—Ç–µ–ª–Ω–æ, –∫–∞—Ç–æ —Ä–∞–∑–ª–∏—á–Ω–∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –ø—Ä–µ—Å–ª–µ–¥–≤–∞—Ç —Ä–∞–∑–ª–∏—á–Ω–∏ –ø–æ–¥—Ö–æ–¥–∏ –∫—ä–º —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞—Ç–∞ –Ω–∞ –µ–∑–∏–∫–æ–≤–∏ –º–æ–¥–µ–ª–∏. –î–æ–∫–∞—Ç–æ –Ω—è–∫–æ–∏ —Å–µ —Ñ–æ–∫—É—Å–∏—Ä–∞—Ç –≤—ä—Ä—Ö—É –∑–∞—Ç–≤–æ—Ä–µ–Ω–∏ –º–æ–¥–µ–ª–∏, –¥—Ä—É–≥–∏ –∞–∫—Ü–µ–Ω—Ç–∏—Ä–∞—Ç –≤—ä—Ä—Ö—É –¥–æ—Å—Ç—ä–ø–Ω–æ—Å—Ç—Ç–∞ –∏ –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—Ç–∞ –Ω–∞ –æ—Ç–≤–æ—Ä–µ–Ω–∏—Ç–µ –º–æ–¥–µ–ª–∏. –¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–∏—è—Ç –ø–æ–¥—Ö–æ–¥ –≤–∫–ª—é—á–≤–∞ –∏–ª–∏ –º–∞—Å–∏–≤–Ω–∏ –∑–∞—Ç–≤–æ—Ä–µ–Ω–∏ –º–æ–¥–µ–ª–∏, –¥–æ—Å—Ç—ä–ø–Ω–∏ —Å–∞–º–æ —á—Ä–µ–∑ API, –∏–ª–∏ –æ—Ç–≤–æ—Ä–µ–Ω–∏ –º–æ–¥–µ–ª–∏, –∫–æ–∏—Ç–æ –º–æ–∂–µ –¥–∞ –∏–∑–æ—Å—Ç–∞–≤–∞—Ç –≤ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏—Ç–µ —Å–∏.

–¢–∞–∑–∏ –ø–∞—Ä–∞–¥–∏–≥–º–∞ —Å—ä–∑–¥–∞–≤–∞ –ø—Ä–µ–¥–∏–∑–≤–∏–∫–∞—Ç–µ–ª—Å—Ç–≤–∞ –∑–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏—Ç–µ, –∫–æ–∏—Ç–æ —Ç—ä—Ä—Å—è—Ç –º–æ—â–Ω–∏ AI –≤—ä–∑–º–æ–∂–Ω–æ—Å—Ç–∏, –∫–∞—Ç–æ —Å—ä—â–µ–≤—Ä–µ–º–µ–Ω–Ω–æ –∑–∞–ø–∞–∑–≤–∞—Ç –∫–æ–Ω—Ç—Ä–æ–ª –≤—ä—Ä—Ö—É —Å–≤–æ–∏—Ç–µ –¥–∞–Ω–Ω–∏, —Ä–∞–∑—Ö–æ–¥–∏ –∏ –≥—ä–≤–∫–∞–≤–æ—Å—Ç –Ω–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ. –¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–∏—è—Ç –ø–æ–¥—Ö–æ–¥ —á–µ—Å—Ç–æ –∏–∑–∏—Å–∫–≤–∞ –∏–∑–±–æ—Ä –º–µ–∂–¥—É –≤—ä—Ä—Ö–æ–≤–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ —Å—ä–æ–±—Ä–∞–∂–µ–Ω–∏—è –∑–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ.

## –ü—Ä–µ–¥–∏–∑–≤–∏–∫–∞—Ç–µ–ª—Å—Ç–≤–æ—Ç–æ –∑–∞ –¥–æ—Å—Ç—ä–ø–Ω–æ AI —Å—ä–≤—ä—Ä—à–µ–Ω—Å—Ç–≤–æ

–ù–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—Ç–∞ –æ—Ç –≤–∏—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω, –¥–æ—Å—Ç—ä–ø–µ–Ω AI —Å—Ç–∞–≤–∞ –≤—Å–µ –ø–æ-–≤–∞–∂–Ω–∞ –≤ —Ä–∞–∑–ª–∏—á–Ω–∏ —Å—Ü–µ–Ω–∞—Ä–∏–∏. –ü–æ–º–∏—Å–ª–µ—Ç–µ –∑–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, –∫–æ–∏—Ç–æ –∏–∑–∏—Å–∫–≤–∞—Ç –≥—ä–≤–∫–∞–≤–∏ –æ–ø—Ü–∏–∏ –∑–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ –∑–∞ —Ä–∞–∑–ª–∏—á–Ω–∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω–∏ –Ω—É–∂–¥–∏, –∏–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏, –∫—ä–¥–µ—Ç–æ —Ä–∞–∑—Ö–æ–¥–∏—Ç–µ –∑–∞ API –º–æ–≥–∞—Ç –¥–∞ —Å—Ç–∞–Ω–∞—Ç –∑–Ω–∞—á–∏—Ç–µ–ª–Ω–∏, –º–Ω–æ–≥–æ–µ–∑–∏—á–Ω–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∑–∞ –≥–ª–æ–±–∞–ª–Ω–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∏–ª–∏ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω–∞ –µ–∫—Å–ø–µ—Ä—Ç–∏–∑–∞ –≤ –æ–±–ª–∞—Å—Ç–∏ –∫–∞—Ç–æ –ø—Ä–æ–≥—Ä–∞–º–∏—Ä–∞–Ω–µ –∏ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∞.

### –û—Å–Ω–æ–≤–Ω–∏ –∏–∑–∏—Å–∫–≤–∞–Ω–∏—è –∑–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ

–°—ä–≤—Ä–µ–º–µ–Ω–Ω–∏—Ç–µ AI –≤–Ω–µ–¥—Ä–µ–Ω–∏—è —Å–µ —Å–±–ª—ä—Å–∫–≤–∞—Ç —Å –Ω—è–∫–æ–ª–∫–æ –æ—Å–Ω–æ–≤–Ω–∏ –∏–∑–∏—Å–∫–≤–∞–Ω–∏—è, –∫–æ–∏—Ç–æ –æ–≥—Ä–∞–Ω–∏—á–∞–≤–∞—Ç –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—Ç–∞ –ø—Ä–∏–ª–æ–∂–∏–º–æ—Å—Ç:

- **–î–æ—Å—Ç—ä–ø–Ω–æ—Å—Ç**: –ù–∞–ª–∏—á–Ω–æ—Å—Ç –Ω–∞ –æ—Ç–≤–æ—Ä–µ–Ω –∫–æ–¥ –∑–∞ –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç –∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è
- **–ò–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∞ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç**: –†–∞–∑—É–º–Ω–∏ –∏–∑–∏—Å–∫–≤–∞–Ω–∏—è –∑–∞ –∏–∑—á–∏—Å–ª–∏—Ç–µ–ª–Ω–∏ —Ä–µ—Å—É—Ä—Å–∏ –∑–∞ —Ä–∞–∑–ª–∏—á–Ω–∏ –±—é–¥–∂–µ—Ç–∏
- **–ì—ä–≤–∫–∞–≤–æ—Å—Ç**: –†–∞–∑–ª–∏—á–Ω–∏ —Ä–∞–∑–º–µ—Ä–∏ –Ω–∞ –º–æ–¥–µ–ª–∏ –∑–∞ —Ä–∞–∑–ª–∏—á–Ω–∏ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –Ω–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ
- **–ì–ª–æ–±–∞–ª–µ–Ω –æ–±—Ö–≤–∞—Ç**: –°–∏–ª–Ω–∏ –º–Ω–æ–≥–æ–µ–∑–∏—á–Ω–∏ –∏ –º–µ–∂–¥—É–∫—É–ª—Ç—É—Ä–Ω–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏
- **–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è**: –í–∞—Ä–∏–∞–Ω—Ç–∏, —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∏ –∑–∞ –¥–æ–º–µ–π–Ω–∞, –∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏ —Å–ª—É—á–∞–∏ –Ω–∞ —É–ø–æ—Ç—Ä–µ–±–∞

## –§–∏–ª–æ—Å–æ—Ñ–∏—è—Ç–∞ –Ω–∞ –º–æ–¥–µ–ª–∏—Ç–µ Qwen

–°–µ–º–µ–π—Å—Ç–≤–æ—Ç–æ –º–æ–¥–µ–ª–∏ Qwen –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–≤–∞ —Ü—è–ª–æ—Å—Ç–µ–Ω –ø–æ–¥—Ö–æ–¥ –∫—ä–º —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞—Ç–∞ –Ω–∞ AI –º–æ–¥–µ–ª–∏, –∫–∞—Ç–æ –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä–∞ –¥–æ—Å—Ç—ä–ø–Ω–æ—Å—Ç—Ç–∞ –Ω–∞ –æ—Ç–≤–æ—Ä–µ–Ω–∏—è –∫–æ–¥, –º–Ω–æ–≥–æ–µ–∑–∏—á–Ω–∏—Ç–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ—Ç–æ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ, –∫–∞—Ç–æ —Å—ä—â–µ–≤—Ä–µ–º–µ–Ω–Ω–æ –ø–æ–¥–¥—ä—Ä–∂–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç. –ú–æ–¥–µ–ª–∏—Ç–µ Qwen –ø–æ—Å—Ç–∏–≥–∞—Ç —Ç–æ–≤–∞ —á—Ä–µ–∑ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–∏ —Ä–∞–∑–º–µ—Ä–∏ –Ω–∞ –º–æ–¥–µ–ª–∏, –≤–∏—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–∏ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ –∑–∞ –æ–±—É—á–µ–Ω–∏–µ –∏ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∏ –∑–∞ —Ä–∞–∑–ª–∏—á–Ω–∏ –¥–æ–º–µ–π–Ω–∏.

–°–µ–º–µ–π—Å—Ç–≤–æ—Ç–æ Qwen –æ–±—Ö–≤–∞—â–∞ —Ä–∞–∑–ª–∏—á–Ω–∏ –ø–æ–¥—Ö–æ–¥–∏, –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–∏ –¥–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—è—Ç –æ–ø—Ü–∏–∏ –≤ —Å–ø–µ–∫—Ç—ä—Ä–∞ –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç-–µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç, –ø–æ–∑–≤–æ–ª—è–≤–∞–π–∫–∏ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ –æ—Ç –º–æ–±–∏–ª–Ω–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –¥–æ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∏ —Å—ä—Ä–≤—ä—Ä–∏, –∫–∞—Ç–æ —Å—ä—â–µ–≤—Ä–µ–º–µ–Ω–Ω–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—è –∑–Ω–∞—á–∏–º–∏ AI –≤—ä–∑–º–æ–∂–Ω–æ—Å—Ç–∏. –¶–µ–ª—Ç–∞ –µ –¥–∞ —Å–µ –¥–µ–º–æ–∫—Ä–∞—Ç–∏–∑–∏—Ä–∞ –¥–æ—Å—Ç—ä–ø—ä—Ç –¥–æ –≤–∏—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω AI, –∫–∞—Ç–æ —Å–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—è –≥—ä–≤–∫–∞–≤–æ—Å—Ç –ø—Ä–∏ –∏–∑–±–æ—Ä–∞ –Ω–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ.

### –û—Å–Ω–æ–≤–Ω–∏ –ø—Ä–∏–Ω—Ü–∏–ø–∏ –Ω–∞ –¥–∏–∑–∞–π–Ω–∞ –Ω–∞ Qwen

–ú–æ–¥–µ–ª–∏—Ç–µ Qwen —Å–∞ –∏–∑–≥—Ä–∞–¥–µ–Ω–∏ –≤—ä—Ä—Ö—É –Ω—è–∫–æ–ª–∫–æ –æ—Å–Ω–æ–≤–Ω–∏ –ø—Ä–∏–Ω—Ü–∏–ø–∞, –∫–æ–∏—Ç–æ –≥–∏ –æ—Ç–ª–∏—á–∞–≤–∞—Ç –æ—Ç –¥—Ä—É–≥–∏ —Å–µ–º–µ–π—Å—Ç–≤–∞ –µ–∑–∏–∫–æ–≤–∏ –º–æ–¥–µ–ª–∏:

- **–û—Ç–≤–æ—Ä–µ–Ω –∫–æ–¥ –Ω–∞ –ø—ä—Ä–≤–æ –º—è—Å—Ç–æ**: –ü—ä–ª–Ω–∞ –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç –∏ –¥–æ—Å—Ç—ä–ø–Ω–æ—Å—Ç –∑–∞ –∏–∑—Å–ª–µ–¥–≤–∞–Ω–∏—è –∏ —Ç—ä—Ä–≥–æ–≤—Å–∫–∞ —É–ø–æ—Ç—Ä–µ–±–∞
- **–¶—è–ª–æ—Å—Ç–Ω–æ –æ–±—É—á–µ–Ω–∏–µ**: –û–±—É—á–µ–Ω–∏–µ –≤—ä—Ä—Ö—É –º–∞—Å–∏–≤–Ω–∏, —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–∏ –Ω–∞–±–æ—Ä–∏ –æ—Ç –¥–∞–Ω–Ω–∏, –æ–±—Ö–≤–∞—â–∞—â–∏ –º–Ω–æ–∂–µ—Å—Ç–≤–æ –µ–∑–∏—Ü–∏ –∏ –¥–æ–º–µ–π–Ω–∏
- **–ú–∞—â–∞–±–∏—Ä—É–µ–º–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**: –†–∞–∑–ª–∏—á–Ω–∏ —Ä–∞–∑–º–µ—Ä–∏ –Ω–∞ –º–æ–¥–µ–ª–∏, —Å—ä–æ—Ç–≤–µ—Ç—Å—Ç–≤–∞—â–∏ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω–∏ –∏–∑—á–∏—Å–ª–∏—Ç–µ–ª–Ω–∏ –∏–∑–∏—Å–∫–≤–∞–Ω–∏—è
- **–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω–æ —Å—ä–≤—ä—Ä—à–µ–Ω—Å—Ç–≤–æ**: –í–∞—Ä–∏–∞–Ω—Ç–∏, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω–∏ –∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏ –∑–∞–¥–∞—á–∏

## –ö–ª—é—á–æ–≤–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, –∫–æ–∏—Ç–æ –ø–æ–∑–≤–æ–ª—è–≤–∞—Ç —Å–µ–º–µ–π—Å—Ç–≤–æ—Ç–æ Qwen

### –ú–∞—Å–∏–≤–Ω–æ –º–∞—â–∞–±–Ω–æ –æ–±—É—á–µ–Ω–∏–µ

–ï–¥–∏–Ω –æ—Ç –æ–ø—Ä–µ–¥–µ–ª—è—â–∏—Ç–µ –∞—Å–ø–µ–∫—Ç–∏ –Ω–∞ —Å–µ–º–µ–π—Å—Ç–≤–æ—Ç–æ Qwen –µ –º–∞—â–∞–±—ä—Ç –Ω–∞ –æ–±—É—á–∏—Ç–µ–ª–Ω–∏—Ç–µ –¥–∞–Ω–Ω–∏ –∏ –∏–∑—á–∏—Å–ª–∏—Ç–µ–ª–Ω–∏—Ç–µ —Ä–µ—Å—É—Ä—Å–∏, –∏–Ω–≤–µ—Å—Ç–∏—Ä–∞–Ω–∏ –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞—Ç–∞ –Ω–∞ –º–æ–¥–µ–ª–∏. –ú–æ–¥–µ–ª–∏—Ç–µ Qwen –∏–∑–ø–æ–ª–∑–≤–∞—Ç –≤–Ω–∏–º–∞—Ç–µ–ª–Ω–æ –ø–æ–¥–±—Ä–∞–Ω–∏, –º–Ω–æ–≥–æ–µ–∑–∏—á–Ω–∏ –Ω–∞–±–æ—Ä–∏ –æ—Ç –¥–∞–Ω–Ω–∏, –æ–±—Ö–≤–∞—â–∞—â–∏ —Ç—Ä–∏–ª–∏–æ–Ω–∏ —Ç–æ–∫–µ–Ω–∏, –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–∏ –¥–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—è—Ç —Ü—è–ª–æ—Å—Ç–Ω–∏ –∑–Ω–∞–Ω–∏—è –∑–∞ —Å–≤–µ—Ç–∞ –∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∑–∞ —Ä–∞–∑—Å—ä–∂–¥–µ–Ω–∏–µ.

–¢–æ–∑–∏ –ø–æ–¥—Ö–æ–¥ —Ä–∞–±–æ—Ç–∏ —á—Ä–µ–∑ –∫–æ–º–±–∏–Ω–∏—Ä–∞–Ω–µ –Ω–∞ –≤–∏—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–æ —É–µ–± —Å—ä–¥—ä—Ä–∂–∞–Ω–∏–µ, –∞–∫–∞–¥–µ–º–∏—á–Ω–∞ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞, —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ —Å –∫–æ–¥ –∏ –º–Ω–æ–≥–æ–µ–∑–∏—á–Ω–∏ —Ä–µ—Å—É—Ä—Å–∏. –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è—Ç–∞ –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ –∞–∫—Ü–µ–Ω—Ç–∏—Ä–∞ –∫–∞–∫—Ç–æ –≤—ä—Ä—Ö—É —à–∏—Ä–æ—á–∏–Ω–∞—Ç–∞ –Ω–∞ –∑–Ω–∞–Ω–∏—è—Ç–∞, —Ç–∞–∫–∞ –∏ –≤—ä—Ä—Ö—É –¥—ä–ª–±–æ—á–∏–Ω–∞—Ç–∞ –Ω–∞ —Ä–∞–∑–±–∏—Ä–∞–Ω–µ—Ç–æ –≤ —Ä–∞–∑–ª–∏—á–Ω–∏ –¥–æ–º–µ–π–Ω–∏ –∏ –µ–∑–∏—Ü–∏.

### –ù–∞–ø—Ä–µ–¥–Ω–∞–ª–æ —Ä–∞–∑—Å—ä–∂–¥–µ–Ω–∏–µ –∏ –º–∏—Å–ª–µ–Ω–µ

–ü–æ—Å–ª–µ–¥–Ω–∏—Ç–µ –º–æ–¥–µ–ª–∏ Qwen –≤–∫–ª—é—á–≤–∞—Ç —Å–ª–æ–∂–Ω–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∑–∞ —Ä–∞–∑—Å—ä–∂–¥–µ–Ω–∏–µ, –∫–æ–∏—Ç–æ –ø–æ–∑–≤–æ–ª—è–≤–∞—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ —Ä–µ—à–∞–≤–∞–Ω–µ –Ω–∞ –ø—Ä–æ–±–ª–µ–º–∏ –Ω–∞ –Ω—è–∫–æ–ª–∫–æ —Å—Ç—ä–ø–∫–∏:

**–†–µ–∂–∏–º –Ω–∞ –º–∏—Å–ª–µ–Ω–µ (Qwen3)**: –ú–æ–¥–µ–ª–∏—Ç–µ –º–æ–≥–∞—Ç –¥–∞ —Å–µ –∞–Ω–≥–∞–∂–∏—Ä–∞—Ç —Å –¥–µ—Ç–∞–π–ª–Ω–æ —Ä–∞–∑—Å—ä–∂–¥–µ–Ω–∏–µ —Å—Ç—ä–ø–∫–∞ –ø–æ —Å—Ç—ä–ø–∫–∞, –ø—Ä–µ–¥–∏ –¥–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—è—Ç –æ–∫–æ–Ω—á–∞—Ç–µ–ª–Ω–∏ –æ—Ç–≥–æ–≤–æ—Ä–∏, –ø–æ–¥–æ–±–Ω–æ –Ω–∞ —á–æ–≤–µ—à–∫–∏ –ø–æ–¥—Ö–æ–¥–∏ –∑–∞ —Ä–µ—à–∞–≤–∞–Ω–µ –Ω–∞ –ø—Ä–æ–±–ª–µ–º–∏.

**–î–≤—É-—Ä–µ–∂–∏–º–µ–Ω —Ä–µ–∂–∏–º**: –°–ø–æ—Å–æ–±–Ω–æ—Å—Ç –∑–∞ –ø—Ä–µ–≤–∫–ª—é—á–≤–∞–Ω–µ –º–µ–∂–¥—É —Ä–µ–∂–∏–º –∑–∞ –±—ä—Ä–∑ –æ—Ç–≥–æ–≤–æ—Ä –∑–∞ –ø—Ä–æ—Å—Ç–∏ –∑–∞–ø–∏—Ç–≤–∞–Ω–∏—è –∏ —Ä–µ–∂–∏–º –∑–∞ –¥—ä–ª–±–æ–∫–æ –º–∏—Å–ª–µ–Ω–µ –∑–∞ —Å–ª–æ–∂–Ω–∏ –ø—Ä–æ–±–ª–µ–º–∏.

**–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –Ω–∞ –≤–µ—Ä–∏–≥–∏ –æ—Ç –º–∏—Å–ª–∏**: –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–æ –≤–∫–ª—é—á–≤–∞–Ω–µ –Ω–∞ —Å—Ç—ä–ø–∫–∏ –∑–∞ —Ä–∞–∑—Å—ä–∂–¥–µ–Ω–∏–µ, –∫–æ–∏—Ç–æ –ø–æ–¥–æ–±—Ä—è–≤–∞—Ç –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—Ç–∞ –∏ —Ç–æ—á–Ω–æ—Å—Ç—Ç–∞ –ø—Ä–∏ —Å–ª–æ–∂–Ω–∏ –∑–∞–¥–∞—á–∏.

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∏ –∏–Ω–æ–≤–∞—Ü–∏–∏

–°–µ–º–µ–π—Å—Ç–≤–æ—Ç–æ Qwen –≤–∫–ª—é—á–≤–∞ –Ω—è–∫–æ–ª–∫–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏, –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–∏ –∫–∞–∫—Ç–æ –∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç, —Ç–∞–∫–∞ –∏ –∑–∞ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç:

**–ú–∞—â–∞–±–∏—Ä—É–µ–º –¥–∏–∑–∞–π–Ω**: –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –≤ —Ä–∞–∑–ª–∏—á–Ω–∏ —Ä–∞–∑–º–µ—Ä–∏ –Ω–∞ –º–æ–¥–µ–ª–∏, –ø–æ–∑–≤–æ–ª—è–≤–∞—â–∞ –ª–µ—Å–Ω–æ –º–∞—â–∞–±–∏—Ä–∞–Ω–µ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ.

**–ú—É–ª—Ç–∏–º–æ–¥–∞–ª–Ω–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è**: –ë–µ–∑–ø—Ä–æ–±–ª–µ–º–Ω–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –Ω–∞ —Ç–µ–∫—Å—Ç, –≤–∏–∑–∏—è –∏ –∞—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–∞–Ω–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∏.

**–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ**: –†–∞–∑–ª–∏—á–Ω–∏ –æ–ø—Ü–∏–∏ –∑–∞ –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è –∏ —Ñ–æ—Ä–º–∞—Ç–∏ –∑–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ –∑–∞ —Ä–∞–∑–ª–∏—á–Ω–∏ —Ö–∞—Ä–¥—É–µ—Ä–Ω–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏.

## –†–∞–∑–º–µ—Ä–∏ –Ω–∞ –º–æ–¥–µ–ª–∏ –∏ –æ–ø—Ü–∏–∏ –∑–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ

–°—ä–≤—Ä–µ–º–µ–Ω–Ω–∏—Ç–µ —Å—Ä–µ–¥–∏ –∑–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ —Å–µ –≤—ä–∑–ø–æ–ª–∑–≤–∞—Ç –æ—Ç –≥—ä–≤–∫–∞–≤–æ—Å—Ç—Ç–∞ –Ω–∞ –º–æ–¥–µ–ª–∏—Ç–µ Qwen –ø—Ä–∏ —Ä–∞–∑–ª–∏—á–Ω–∏ –∏–∑—á–∏—Å–ª–∏—Ç–µ–ª–Ω–∏ –∏–∑–∏—Å–∫–≤–∞–Ω–∏—è:

### –ú–∞–ª–∫–∏ –º–æ–¥–µ–ª–∏ (0.5B-3B)

Qwen –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—è –µ—Ñ–µ–∫—Ç–∏–≤–Ω–∏ –º–∞–ª–∫–∏ –º–æ–¥–µ–ª–∏, –ø–æ–¥—Ö–æ–¥—è—â–∏ –∑–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–Ω–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞, –º–æ–±–∏–ª–Ω–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∏ —Å—Ä–µ–¥–∏ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏ —Ä–µ—Å—É—Ä—Å–∏, –∫–∞—Ç–æ —Å—ä—â–µ–≤—Ä–µ–º–µ–Ω–Ω–æ –ø–æ–¥–¥—ä—Ä–∂–∞ –≤–ø–µ—á–∞—Ç–ª—è–≤–∞—â–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏.

### –°—Ä–µ–¥–Ω–∏ –º–æ–¥–µ–ª–∏ (7B-32B)

–°—Ä–µ–¥–Ω–∏—Ç–µ –º–æ–¥–µ–ª–∏ –ø—Ä–µ–¥–ª–∞–≥–∞—Ç –ø–æ–¥–æ–±—Ä–µ–Ω–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∑–∞ –ø—Ä–æ—Ñ–µ—Å–∏–æ–Ω–∞–ª–Ω–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, –æ—Å–∏–≥—É—Ä—è–≤–∞–π–∫–∏ –æ—Ç–ª–∏—á–µ–Ω –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç –∏ –∏–∑—á–∏—Å–ª–∏—Ç–µ–ª–Ω–∏ –∏–∑–∏—Å–∫–≤–∞–Ω–∏—è.

### –ì–æ–ª–µ–º–∏ –º–æ–¥–µ–ª–∏ (72B+)

–ú–æ–¥–µ–ª–∏ –≤ –ø—ä–ª–µ–Ω –º–∞—â–∞–± –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—è—Ç –≤—ä—Ä—Ö–æ–≤–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç –∑–∞ –≤–∑–∏—Å–∫–∞—Ç–µ–ª–Ω–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, –∏–∑—Å–ª–µ–¥–≤–∞–Ω–∏—è –∏ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∏ –≤–Ω–µ–¥—Ä–µ–Ω–∏—è, –∏–∑–∏—Å–∫–≤–∞—â–∏ –º–∞–∫—Å–∏–º–∞–ª–Ω–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏.

## –ü—Ä–µ–¥–∏–º—Å—Ç–≤–∞ –Ω–∞ —Å–µ–º–µ–π—Å—Ç–≤–æ—Ç–æ –º–æ–¥–µ–ª–∏ Qwen

### –î–æ—Å—Ç—ä–ø–Ω–æ—Å—Ç –Ω–∞ –æ—Ç–≤–æ—Ä–µ–Ω–∏—è –∫–æ–¥

–ú–æ–¥–µ–ª–∏—Ç–µ Qwen –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—è—Ç –ø—ä–ª–Ω–∞ –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç –∏ –≤—ä–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è, –ø–æ–∑–≤–æ–ª—è–≤–∞–π–∫–∏ –Ω–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏—Ç–µ –¥–∞ —Ä–∞–∑–±–∏—Ä–∞—Ç, –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–∞—Ç –∏ –∞–¥–∞–ø—Ç–∏—Ä–∞—Ç –º–æ–¥–µ–ª–∏—Ç–µ –∫—ä–º —Å–≤–æ–∏—Ç–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∏ –Ω—É–∂–¥–∏ –±–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç –æ—Ç –¥–æ—Å—Ç–∞–≤—á–∏—Ü–∏.

### –ì—ä–≤–∫–∞–≤–æ—Å—Ç –Ω–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ

–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ—Ç–æ –æ—Ç —Ä–∞–∑–º–µ—Ä–∏ –Ω–∞ –º–æ–¥–µ–ª–∏ –ø–æ–∑–≤–æ–ª—è–≤–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ –≤ —Ä–∞–∑–ª–∏—á–Ω–∏ —Ö–∞—Ä–¥—É–µ—Ä–Ω–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏, –æ—Ç –º–æ–±–∏–ª–Ω–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –¥–æ –≤–∏—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–∏ —Å—ä—Ä–≤—ä—Ä–∏, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—è–π–∫–∏ –Ω–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏—Ç–µ –≥—ä–≤–∫–∞–≤–æ—Å—Ç –≤ –∏–∑–±–æ—Ä–∞ –Ω–∞ AI –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞.

### –ú–Ω–æ–≥–æ–µ–∑–∏—á–Ω–æ —Å—ä–≤—ä—Ä—à–µ–Ω—Å—Ç–≤–æ

–ú–æ–¥–µ–ª–∏—Ç–µ Qwen —Å–µ –æ—Ç–ª–∏—á–∞–≤–∞—Ç –≤ –º–Ω–æ–≥–æ–µ–∑–∏—á–Ω–æ—Ç–æ —Ä–∞–∑–±–∏—Ä–∞–Ω–µ –∏ –≥–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ, –ø–æ–¥–¥—ä—Ä–∂–∞–π–∫–∏ –¥–µ—Å–µ—Ç–∫–∏ –µ–∑–∏—Ü–∏ —Å—ä—Å —Å–ø–µ—Ü–∏–∞–ª–Ω–∞ —Å–∏–ª–∞ –≤ –∞–Ω–≥–ª–∏–π—Å–∫–∏ –∏ –∫–∏—Ç–∞–π—Å–∫–∏, –∫–æ–µ—Ç–æ –≥–∏ –ø—Ä–∞–≤–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏ –∑–∞ –≥–ª–æ–±–∞–ª–Ω–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.

### –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç

–ú–æ–¥–µ–ª–∏—Ç–µ Qwen –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–Ω–æ –ø–æ—Å—Ç–∏–≥–∞—Ç –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏ –≤ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤–µ, –∫–∞—Ç–æ —Å—ä—â–µ–≤—Ä–µ–º–µ–Ω–Ω–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—è—Ç –¥–æ—Å—Ç—ä–ø–Ω–æ—Å—Ç –Ω–∞ –æ—Ç–≤–æ—Ä–µ–Ω–∏—è –∫–æ–¥, –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–∞–π–∫–∏, —á–µ –æ—Ç–≤–æ—Ä–µ–Ω–∏—Ç–µ –º–æ–¥–µ–ª–∏ –º–æ–≥–∞—Ç –¥–∞ —Å–µ –∫–æ–Ω–∫—É—Ä–∏—Ä–∞—Ç —Å –∑–∞—Ç–≤–æ—Ä–µ–Ω–∏—Ç–µ –∞–ª—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∏.

### –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏

–í–∞—Ä–∏–∞–Ω—Ç–∏, —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∏ –∑–∞ –¥–æ–º–µ–π–Ω–∞, –∫–∞—Ç–æ Qwen-Coder –∏ Qwen-Math, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—è—Ç —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω–∞ –µ–∫—Å–ø–µ—Ä—Ç–∏–∑–∞, –∫–∞—Ç–æ —Å—ä—â–µ–≤—Ä–µ–º–µ–Ω–Ω–æ –ø–æ–¥–¥—ä—Ä–∂–∞—Ç –æ–±—â–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∑–∞ –µ–∑–∏–∫–æ–≤–æ —Ä–∞–∑–±–∏—Ä–∞–Ω–µ.

## –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏–º–µ—Ä–∏ –∏ —Å–ª—É—á–∞–∏ –Ω–∞ —É–ø–æ—Ç—Ä–µ–±–∞

–ü—Ä–µ–¥–∏ –¥–∞ —Å–µ –ø–æ—Ç–æ–ø–∏–º –≤ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ç–µ –¥–µ—Ç–∞–π–ª–∏, –Ω–µ–∫–∞ —Ä–∞–∑–≥–ª–µ–¥–∞–º–µ –Ω—è–∫–æ–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏ –ø—Ä–∏–º–µ—Ä–∏ –∑–∞ —Ç–æ–≤–∞, –∫–æ–µ—Ç–æ –º–æ–¥–µ–ª–∏—Ç–µ Qwen –º–æ–≥–∞—Ç –¥–∞ –ø–æ—Å—Ç–∏–≥–Ω–∞—Ç:

### –ü—Ä–∏–º–µ—Ä –∑–∞ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ —Ä–∞–∑—Å—ä–∂–¥–µ–Ω–∏–µ

Qwen-Math —Å–µ –æ—Ç–ª–∏—á–∞–≤–∞ –≤ —Ä–µ—à–∞–≤–∞–Ω–µ—Ç–æ –Ω–∞ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ–±–ª–µ–º–∏ —Å—Ç—ä–ø–∫–∞ –ø–æ —Å—Ç—ä–ø–∫–∞. –ù–∞–ø—Ä–∏–º–µ—Ä, –∫–æ–≥–∞—Ç–æ –±—ä–¥–µ –ø–æ–ø–∏—Ç–∞–Ω –¥–∞ —Ä–µ—à–∏ —Å–ª–æ–∂–µ–Ω –ø—Ä–æ–±–ª–µ–º —Å –∏–Ω—Ç–µ–≥—Ä–∞–ª–∏:

```
User: Find the derivative of f(x) = x¬≥ + 2x¬≤ - 5x + 3

Qwen-Math: I'll solve this step by step using the power rule for derivatives.

For f(x) = x¬≥ + 2x¬≤ - 5x + 3, I need to find f'(x).

Using the power rule: d/dx(x‚Åø) = n¬∑x‚Åø‚Åª¬π

Breaking down each term:
- d/dx(x¬≥) = 3x¬≤
- d/dx(2x¬≤) = 2 ¬∑ 2x¬π = 4x  
- d/dx(-5x) = -5
- d/dx(3) = 0 (constant term)

Therefore: f'(x) = 3x¬≤ + 4x - 5
```

### –ü—Ä–∏–º–µ—Ä –∑–∞ –º–Ω–æ–≥–æ–µ–∑–∏—á–Ω–∞ –ø–æ–¥–¥—Ä—ä–∂–∫–∞

–ú–æ–¥–µ–ª–∏—Ç–µ Qwen –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–∞—Ç —Å–∏–ª–Ω–∏ –º–Ω–æ–≥–æ–µ–∑–∏—á–Ω–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –≤ —Ä–∞–∑–ª–∏—á–Ω–∏ –µ–∑–∏—Ü–∏:

```
User: Explain the concept of artificial intelligence in both English and Chinese.

Qwen: **English:**
Artificial Intelligence (AI) refers to the simulation of human intelligence processes by machines, especially computer systems. These processes include learning, reasoning, problem-solving, perception, and language understanding. AI enables machines to perform tasks that typically require human cognitive abilities.

**‰∏≠Êñá:**
‰∫∫Â∑•Êô∫ËÉΩÔºàAIÔºâÊòØÊåáÊú∫Âô®ÔºàÁâπÂà´ÊòØËÆ°ÁÆóÊú∫Á≥ªÁªüÔºâÂØπ‰∫∫Á±ªÊô∫ËÉΩËøáÁ®ãÁöÑÊ®°Êãü„ÄÇËøô‰∫õËøáÁ®ãÂåÖÊã¨Â≠¶‰π†„ÄÅÊé®ÁêÜ„ÄÅËß£ÂÜ≥ÈóÆÈ¢ò„ÄÅÊÑüÁü•ÂíåËØ≠Ë®ÄÁêÜËß£„ÄÇ‰∫∫Â∑•Êô∫ËÉΩ‰ΩøÊú∫Âô®ËÉΩÂ§üÊâßË°åÈÄöÂ∏∏ÈúÄË¶Å‰∫∫Á±ªËÆ§Áü•ËÉΩÂäõÁöÑ‰ªªÂä°„ÄÇ
```

### –ü—Ä–∏–º–µ—Ä –∑–∞ –º—É–ª—Ç–∏–º–æ–¥–∞–ª–Ω–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏

Qwen-VL –º–æ–∂–µ –¥–∞ –æ–±—Ä–∞–±–æ—Ç–≤–∞ —Ç–µ–∫—Å—Ç –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –µ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ:

```
User: [Image of a chart showing sales data] What trends do you see in this sales chart?

Qwen-VL: Looking at this sales chart, I can identify several key trends:

1. **Seasonal Pattern**: There's a clear seasonal cycle with peaks typically occurring in Q4, likely due to holiday sales.

2. **Overall Growth**: Despite fluctuations, there's an upward trend over the time period shown, indicating business growth.

3. **Quarterly Variations**: Q1 and Q3 show consistently lower performance compared to Q2 and Q4.

4. **Recent Acceleration**: The most recent data points suggest accelerating growth, with steeper increases than historical averages.

5. **Volatility Changes**: Earlier periods show more stability, while recent periods display increased volatility, possibly indicating market expansion or increased competition.
```

### –ü—Ä–∏–º–µ—Ä –∑–∞ –≥–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ –∫–æ–¥

Qwen-Coder —Å–µ –æ—Ç–ª–∏—á–∞–≤–∞ –≤ –≥–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ—Ç–æ –∏ –æ–±—è—Å–Ω–µ–Ω–∏–µ—Ç–æ –Ω–∞ –∫–æ–¥ –≤ –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø—Ä–æ–≥—Ä–∞–º–Ω–∏ –µ–∑–∏—Ü–∏:

```
User: Create a Python function to implement a binary search algorithm with detailed comments.

Qwen-Coder: Here's a Python implementation of binary search with comprehensive comments:

```python
def binary_search(arr, target):
    """
    Perform binary search on a sorted array to find the target value.
    
    Args:
        arr (list): A sorted list of comparable elements
        target: The value to search for
        
    Returns:
        int: Index of target if found, -1 if not found
        
    Time Complexity: O(log n)
    Space Complexity: O(1)
    """
    # Initialize left and right pointers
    left, right = 0, len(arr) - 1
    
    # Continue searching while the search space is valid
    while left <= right:
        # Calculate middle index to avoid integer overflow
        mid = left + (right - left) // 2
        
        # Check if we found the target
        if arr[mid] == target:
            return mid
        
        # If target is smaller, search left half
        elif arr[mid] > target:
            right = mid - 1
        
        # If target is larger, search right half
        else:
            left = mid + 1
    
    # Target not found
    return -1

# Example usage:
sorted_list = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]
result = binary_search(sorted_list, 7)
print(f"Index of 7: {result}")  # Output: Index of 7: 3
```

–¢–∞–∑–∏ –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏—è —Å–ª–µ–¥–≤–∞ –Ω–∞–π-–¥–æ–±—Ä–∏—Ç–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ —Å —è—Å–Ω–∏ –∏–º–µ–Ω–∞ –Ω–∞ –ø—Ä–æ–º–µ–Ω–ª–∏–≤–∏, –∏–∑—á–µ—Ä–ø–∞—Ç–µ–ª–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–∞ –ª–æ–≥–∏–∫–∞.
```

### Edge Deployment Example

Qwen models can be deployed on various edge devices with optimized configurations:

```
# –ü—Ä–∏–º–µ—Ä –∑–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ –Ω–∞ –º–æ–±–∏–ª–Ω–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ —Å –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# –ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ –∫–≤–∞–Ω—Ç–∏–∑–∏—Ä–∞–Ω –º–æ–¥–µ–ª –∑–∞ –º–æ–±–∏–ª–Ω–æ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ

```
model = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen2.5-1.5B-Instruct",
    torch_dtype=torch.float16,
    device_map="auto",
    load_in_8bit=True  # 8-bit quantization for efficiency
)

tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2.5-1.5B-Instruct")

# Mobile-optimized inference
def mobile_inference(prompt):
    inputs = tokenizer(prompt, return_tensors="pt", max_length=512, truncation=True)
    
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=100,
            do_sample=True,
            temperature=0.7,
            pad_token_id=tokenizer.eos_token_id
        )
    
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return response.replace(prompt, "").strip()
```

## –ï–≤–æ–ª—é—Ü–∏—è—Ç–∞ –Ω–∞ —Å–µ–º–µ–π—Å—Ç–≤–æ—Ç–æ Qwen

### Qwen 1.0 –∏ 1.5: –û—Å–Ω–æ–≤–Ω–∏ –º–æ–¥–µ–ª–∏

–†–∞–Ω–Ω–∏—Ç–µ –º–æ–¥–µ–ª–∏ Qwen —É—Å—Ç–∞–Ω–æ–≤–∏—Ö–∞ –æ—Å–Ω–æ–≤–Ω–∏—Ç–µ –ø—Ä–∏–Ω—Ü–∏–ø–∏ –Ω–∞ —Ü—è–ª–æ—Å—Ç–Ω–æ –æ–±—É—á–µ–Ω–∏–µ –∏ –¥–æ—Å—Ç—ä–ø–Ω–æ—Å—Ç –Ω–∞ –æ—Ç–≤–æ—Ä–µ–Ω–∏—è –∫–æ–¥:

- **Qwen-7B (7B –ø–∞—Ä–∞–º–µ—Ç—Ä–∏)**: –ü—ä—Ä–≤–æ–Ω–∞—á–∞–ª–Ω–æ –∏–∑–¥–∞–Ω–∏–µ, —Ñ–æ–∫—É—Å–∏—Ä–∞–Ω–æ –≤—ä—Ä—Ö—É —Ä–∞–∑–±–∏—Ä–∞–Ω–µ –Ω–∞ –∫–∏—Ç–∞–π—Å–∫–∏ –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏ –µ–∑–∏–∫
- **Qwen-14B (14B –ø–∞—Ä–∞–º–µ—Ç—Ä–∏)**: –ü–æ–¥–æ–±—Ä–µ–Ω–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —Å –ø–æ–¥–æ–±—Ä–µ–Ω–æ —Ä–∞–∑—Å—ä–∂–¥–µ–Ω–∏–µ –∏ –∑–Ω–∞–Ω–∏—è
- **Qwen-72B (72B –ø–∞—Ä–∞–º–µ—Ç—Ä–∏)**: –ì–æ–ª—è–º –º–∞—â–∞–±–µ–Ω –º–æ–¥–µ–ª, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—è—â –≤—ä—Ä—Ö–æ–≤–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç
- **–°–µ—Ä–∏—è Qwen1.5**: –†–∞–∑—à–∏—Ä–µ–Ω–∞ –¥–æ –º–Ω–æ–∂–µ—Å—Ç–≤–æ —Ä–∞–∑–º–µ—Ä–∏ (0.5B –¥–æ 110B) —Å –ø–æ–¥–æ–±—Ä–µ–Ω–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ –¥—ä–ª–≥–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∏

### –°–µ–º–µ–π—Å—Ç–≤–æ Qwen2: –ú—É–ª—Ç–∏–º–æ–¥–∞–ª–Ω–æ —Ä–∞–∑—à–∏—Ä–µ–Ω–∏–µ

–°–µ—Ä–∏—è—Ç–∞ Qwen2 –æ—Ç–±–µ–ª—è–∑–∞ –∑–Ω–∞—á–∏—Ç–µ–ª–µ–Ω –Ω–∞–ø—Ä–µ–¥—ä–∫ –∫–∞–∫—Ç–æ –≤ –µ–∑–∏–∫–æ–≤–∏—Ç–µ, —Ç–∞–∫–∞ –∏ –≤ –º—É–ª—Ç–∏–º–æ–¥–∞–ª–Ω–∏—Ç–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏:

- **Qwen2-0.5B –¥–æ 72B**: –¶—è–ª–æ—Å—Ç–µ–Ω –¥–∏–∞–ø–∞–∑–æ–Ω –æ—Ç –µ–∑–∏–∫–æ–≤–∏ –º–æ–¥–µ–ª–∏ –∑–∞ —Ä–∞–∑–ª–∏—á–Ω–∏ –Ω—É–∂–¥–∏ –æ—Ç –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ
- **Qwen2-57B-A14B (MoE)**: –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å –º–∏–∫—Å –æ—Ç –µ–∫—Å–ø–µ—Ä—Ç–∏ –∑–∞ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –∏–∑–ø–æ–ª–∑–≤–∞–Ω–µ –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
- **Qwen2-VL**: –ù–∞–ø—Ä–µ–¥–Ω–∞–ª–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∑–∞ –≤–∏–∑–∏—è –∏ –µ–∑–∏–∫ –∑–∞ —Ä–∞–∑–±–∏—Ä–∞–Ω–µ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
- **Qwen2-Audio**: –°–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∑–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —Ä–∞–∑–±–∏—Ä–∞–Ω–µ –Ω–∞ –∞—É–¥–∏–æ
- **Qwen2-Math**: –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω–æ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ —Ä–∞–∑—Å—ä–∂–¥–µ–Ω–∏–µ –∏ —Ä–µ—à–∞–≤–∞–Ω–µ –Ω–∞ –ø—Ä–æ–±–ª–µ–º–∏

### –°–µ–º–µ–π—Å—Ç–≤–æ Qwen2.5: –ü–æ–¥–æ–±—Ä–µ–Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç

–°–µ—Ä–∏—è—Ç–∞ Qwen2.5 –¥–æ–Ω–µ—Å–µ –∑–Ω–∞—á–∏—Ç–µ–ª–Ω–∏ –ø–æ–¥–æ–±—Ä–µ–Ω–∏—è –≤—ä–≤ –≤—Å–∏—á–∫–∏ –∏–∑–º–µ—Ä–µ–Ω–∏—è:

- **–†–∞–∑—à–∏—Ä–µ–Ω–æ –æ–±—É—á–µ–Ω–∏–µ**: 18 —Ç—Ä–∏–ª–∏–æ–Ω–∞ —Ç–æ–∫–µ–Ω–∏ –æ–±—É—á–∏—Ç–µ–ª–Ω–∏ –¥–∞–Ω–Ω–∏ –∑–∞ –ø–æ–¥–æ–±—Ä–µ–Ω–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏
- **–†–∞–∑—à–∏—Ä–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç**: –î–æ 128K —Ç–æ–∫–µ–Ω–∏ –¥—ä–ª–∂–∏–Ω–∞ –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, —Å Turbo –≤–∞—Ä–∏–∞–Ω—Ç, –ø–æ–¥–¥—ä—Ä–∂–∞—â 1M —Ç–æ–∫–µ–Ω–∏
- **–ü–æ–¥–æ–±—Ä–µ–Ω–∞ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è**: –ü–æ–¥–æ–±—Ä–µ–Ω–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∏ Qwen2.5-Coder –∏ Qwen2.5-Math
- **–ü–æ-–¥–æ–±—Ä–∞ –º–Ω–æ–≥–æ–µ–∑–∏—á–Ω–∞ –ø–æ–¥–¥—Ä—ä–∂–∫–∞**: –ü–æ–¥–æ–±—Ä–µ–Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç –≤ 27+ –µ–∑–∏–∫–∞

### –°–µ–º–µ–π—Å—Ç–≤–æ Qwen3: –ù–∞–ø—Ä–µ–¥–Ω–∞–ª–æ —Ä–∞–∑—Å—ä–∂–¥–µ–Ω–∏–µ

–ü–æ—Å–ª–µ–¥–Ω–æ—Ç–æ –ø–æ–∫–æ–ª–µ–Ω–∏–µ —Ä–∞–∑—à–∏—Ä—è–≤–∞ –≥—Ä–∞–Ω–∏—Ü–∏—Ç–µ –Ω–∞ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏—Ç–µ –∑–∞ —Ä–∞–∑—Å—ä–∂–¥–µ–Ω–∏–µ –∏ –º–∏—Å–ª–µ–Ω–µ:

- **Qwen3-235B-A22B**: –í–æ–¥–µ—â –º–æ–¥–µ–ª —Å –º–∏–∫—Å –æ—Ç –µ–∫—Å–ø–µ—Ä—Ç–∏ —Å –æ–±—â–æ 235B –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
- **Qwen3-30B-A3B**: –ï—Ñ–µ–∫—Ç–∏–≤–µ–Ω MoE –º–æ–¥–µ–ª —Å—ä—Å —Å–∏–ª–Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç –Ω–∞ –∞–∫—Ç–∏–≤–µ–Ω –ø–∞—Ä–∞–º–µ—Ç—ä—Ä
- **–ü–ª—ä—Ç–Ω–∏ –º–æ–¥–µ–ª–∏**: Qwen3-32B, 14B, 8B, 4B, 1.7B, 0.6B –∑–∞ —Ä–∞–∑–ª–∏—á–Ω–∏ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –Ω–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ
- **–†–µ–∂–∏–º –Ω–∞ –º–∏—Å–ª–µ–Ω–µ**: –•–∏–±—Ä–∏–¥–µ–Ω –ø–æ–¥—Ö–æ–¥ –∑–∞ —Ä–∞–∑—Å—ä–∂–¥–µ–Ω–∏–µ, –ø–æ–¥–¥—ä—Ä–∂–∞—â –∫–∞–∫—Ç–æ –±—ä—Ä–∑–∏ –æ—Ç–≥–æ–≤–æ—Ä–∏, —Ç–∞–∫–∞ –∏ –¥—ä–ª–±–æ–∫–æ –º–∏—Å–ª–µ–Ω–µ
- **–ú–Ω–æ–≥–æ–µ–∑–∏—á–Ω–æ —Å—ä–≤—ä—Ä—à–µ–Ω—Å—Ç–≤–æ**: –ü–æ–¥–¥—Ä—ä–∂–∫–∞ –Ω–∞ 119 –µ–∑–∏–∫–∞ –∏ –¥–∏–∞–ª–µ–∫—Ç–∏
- **–ü–æ–¥–æ–±—Ä–µ–Ω–æ –æ–±—É—á–µ–Ω–∏–µ**: 36 —Ç—Ä–∏–ª–∏–æ–Ω–∞ —Ç–æ–∫–µ–Ω–∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–∏, –≤–∏—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–∏ –æ–±—É—á–∏—Ç–µ–ª–Ω–∏ –¥–∞–Ω–Ω–∏

## –ü—Ä–∏–ª–æ–∂–µ–Ω–∏—è –Ω–∞ –º–æ–¥–µ–ª–∏—Ç–µ Qwen

### –ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏—Ç–µ –∏–∑–ø–æ–ª–∑–≤–∞—Ç –º–æ–¥–µ–ª–∏—Ç–µ Qwen –∑–∞ –∞–Ω–∞–ª–∏–∑ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∏, –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –Ω–∞ –æ–±—Å–ª—É–∂–≤–∞–Ω–µ—Ç–æ –Ω–∞ –∫–ª–∏–µ–Ω—Ç–∏, –ø–æ–º–æ—â –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ –∫–æ–¥ –∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∑–∞ –±–∏–∑–Ω–µ—Å –∏–Ω—Ç–µ–ª–∏–≥–µ–Ω—Ç–Ω–æ—Å—Ç. –û—Ç–≤–æ—Ä–µ–Ω–∏—è—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä –ø–æ–∑–≤–æ–ª—è–≤–∞ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∏ –±–∏–∑–Ω–µ—Å –Ω—É–∂–¥–∏, –∫–∞—Ç–æ —Å—ä—â–µ–≤—Ä–µ–º–µ–Ω–Ω–æ –∑–∞–ø–∞–∑–≤–∞ –ø–æ–≤–µ—Ä–∏—Ç–µ–ª–Ω–æ—Å—Ç—Ç–∞ –∏ –∫–æ–Ω—Ç—Ä–æ–ª–∞ –≤—ä—Ä—Ö—É –¥–∞–Ω–Ω–∏—Ç–µ.

### –ú–æ–±–∏–ª–Ω–∏ –∏ –ø–µ—Ä–∏—Ñ–µ—Ä–Ω–∏ –∏–∑—á–∏—Å–ª–µ–Ω–∏—è

–ú–æ–±–∏–ª–Ω–∏—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∏–∑–ø–æ–ª–∑–≤–∞—Ç –º–æ–¥–µ–ª–∏—Ç–µ Qwen –∑–∞ –ø—Ä–µ–≤–æ–¥ –≤ —Ä–µ–∞–ª–Ω–æ –≤—Ä–µ–º–µ, –∏–Ω—Ç–µ–ª–∏–≥–µ–Ω—Ç–Ω–∏ –∞—Å–∏—Å—Ç–µ–Ω—Ç–∏, –≥–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ —Å—ä–¥—ä—Ä–∂–∞–Ω–∏–µ –∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–∏ –ø—Ä–µ–ø–æ—Ä—ä–∫–∏. –î–∏–∞–ø–∞–∑–æ–Ω—ä—Ç –æ—Ç —Ä–∞–∑–º–µ—Ä–∏ –Ω–∞ –º–æ–¥–µ–ª–∏ –ø–æ–∑–≤–æ–ª—è–≤–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ –æ—Ç –º–æ–±–∏–ª–Ω–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –¥–æ –ø–µ—Ä–∏—Ñ–µ—Ä–Ω–∏ —Å—ä—Ä–≤—ä—Ä–∏.

### –û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª–Ω–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏

–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª–Ω–∏—Ç–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∏ –∏–∑–ø–æ–ª–∑–≤–∞—Ç –º–æ–¥–µ–ª–∏—Ç–µ Qwen –∑–∞ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–æ –æ–±—É—á–µ–Ω–∏–µ, –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–∞–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ —Å—ä–¥—ä—Ä–∂–∞–Ω–∏–µ, –ø–æ–º–æ—â –ø—Ä–∏ –∏–∑—É—á–∞–≤–∞–Ω–µ –Ω–∞ –µ–∑–∏—Ü–∏ –∏ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª–Ω–∏ –ø—Ä–µ–∂–∏–≤—è–≤–∞–Ω–∏—è. –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω–∏ –º–æ–¥–µ–ª–∏ –∫–∞—Ç–æ Qwen-M
- Qwen3-235B-A22B –ø–æ—Å—Ç–∏–≥–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏ –≤ –æ—Ü–µ–Ω–∫–∏—Ç–µ –Ω–∞ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤–µ –∑–∞ –∫–æ–¥–∏—Ä–∞–Ω–µ, –º–∞—Ç–µ–º–∞—Ç–∏–∫–∞ –∏ –æ–±—â–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –¥—Ä—É–≥–∏ –≤–æ–¥–µ—â–∏ –º–æ–¥–µ–ª–∏ –∫–∞—Ç–æ DeepSeek-R1, o1, o3-mini, Grok-3 –∏ Gemini-2.5-Pro.  
- Qwen3-30B-A3B –ø—Ä–µ–≤—ä–∑—Ö–æ–∂–¥–∞ QwQ-32B —Å 10 –ø—ä—Ç–∏ –ø–æ–≤–µ—á–µ –∞–∫—Ç–∏–≤–∏—Ä–∞–Ω–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏.  
- Qwen3-4B –º–æ–∂–µ –¥–∞ —Å–µ –∫–æ–Ω–∫—É—Ä–∏—Ä–∞ —Å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç—Ç–∞ –Ω–∞ Qwen2.5-72B-Instruct.  

**–ü–æ—Å—Ç–∏–∂–µ–Ω–∏—è –≤ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—Ç–∞:**  
- –ë–∞–∑–æ–≤–∏—Ç–µ –º–æ–¥–µ–ª–∏ Qwen3-MoE –ø–æ—Å—Ç–∏–≥–∞—Ç —Å—Ö–æ–¥–Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç —Å –ø–ª—ä—Ç–Ω–∏—Ç–µ –±–∞–∑–æ–≤–∏ –º–æ–¥–µ–ª–∏ Qwen2.5, –∏–∑–ø–æ–ª–∑–≤–∞–π–∫–∏ —Å–∞–º–æ 10% –æ—Ç –∞–∫—Ç–∏–≤–Ω–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏.  
- –ó–Ω–∞—á–∏—Ç–µ–ª–Ω–∏ –∏–∫–æ–Ω–æ–º–∏–∏ –Ω–∞ —Ä–∞–∑—Ö–æ–¥–∏ –∫–∞–∫—Ç–æ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–µ, —Ç–∞–∫–∞ –∏ –ø—Ä–∏ –∏–∑–≤–æ–¥–∏ –≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø–ª—ä—Ç–Ω–∏—Ç–µ –º–æ–¥–µ–ª–∏.  

**–ú–Ω–æ–≥–æ–µ–∑–∏—á–Ω–∏ –≤—ä–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**  
- –ú–æ–¥–µ–ª–∏—Ç–µ Qwen3 –ø–æ–¥–¥—ä—Ä–∂–∞—Ç 119 –µ–∑–∏–∫–∞ –∏ –¥–∏–∞–ª–µ–∫—Ç–∞.  
- –°–∏–ª–Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç –≤ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–∏ –µ–∑–∏–∫–æ–≤–∏ –∏ –∫—É–ª—Ç—É—Ä–Ω–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∏.  

**–ú–∞—â–∞–± –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ:**  
- Qwen3 –∏–∑–ø–æ–ª–∑–≤–∞ –ø–æ—á—Ç–∏ –¥–≤–∞ –ø—ä—Ç–∏ –ø–æ–≤–µ—á–µ –¥–∞–Ω–Ω–∏, —Å –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª–Ω–æ 36 —Ç—Ä–∏–ª–∏–æ–Ω–∞ —Ç–æ–∫–µ–Ω–∞, –æ–±—Ö–≤–∞—â–∞—â–∏ 119 –µ–∑–∏–∫–∞ –∏ –¥–∏–∞–ª–µ–∫—Ç–∞, –≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å 18 —Ç—Ä–∏–ª–∏–æ–Ω–∞ —Ç–æ–∫–µ–Ω–∞ –Ω–∞ Qwen2.5.  

### –ú–∞—Ç—Ä–∏—Ü–∞ –∑–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–∞ –º–æ–¥–µ–ª–∏  

| –°–µ—Ä–∏—è –º–æ–¥–µ–ª–∏ | –î–∏–∞–ø–∞–∑–æ–Ω –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—Ç–µ | –î—ä–ª–∂–∏–Ω–∞ –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ | –û—Å–Ω–æ–≤–Ω–∏ –ø—Ä–µ–¥–∏–º—Å—Ç–≤–∞ | –ù–∞–π-–¥–æ–±—Ä–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è |  
|--------------|--------------------------|----------------------|--------------------|-----------------------|  
| **Qwen2.5** | 0.5B-72B | 32K-128K | –ë–∞–ª–∞–Ω—Å–∏—Ä–∞–Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç, –º–Ω–æ–≥–æ–µ–∑–∏—á–Ω–æ—Å—Ç | –û–±—â–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ –≤ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ |  
| **Qwen2.5-Coder** | 1.5B-32B | 128K | –ì–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ –∫–æ–¥, –ø—Ä–æ–≥—Ä–∞–º–∏—Ä–∞–Ω–µ | –°–æ—Ñ—Ç—É–µ—Ä–Ω–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞, –ø–æ–º–æ—â –ø—Ä–∏ –∫–æ–¥–∏—Ä–∞–Ω–µ |  
| **Qwen2.5-Math** | 1.5B-72B | 4K-128K | –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ —Ä–∞–∑—Å—ä–∂–¥–µ–Ω–∏–µ | –û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª–Ω–∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∏, STEM –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è |  
| **Qwen2.5-VL** | –†–∞–∑–ª–∏—á–Ω–∏ | –ü—Ä–æ–º–µ–Ω–ª–∏–≤–∞ | –†–∞–∑–±–∏—Ä–∞–Ω–µ –Ω–∞ –≤–∏–∑–∏—è –∏ –µ–∑–∏–∫ | –ú—É–ª—Ç–∏–º–æ–¥–∞–ª–Ω–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, –∞–Ω–∞–ª–∏–∑ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è |  
| **Qwen3** | 0.6B-235B | –ü—Ä–æ–º–µ–Ω–ª–∏–≤–∞ | –ù–∞–ø—Ä–µ–¥–Ω–∞–ª–æ —Ä–∞–∑—Å—ä–∂–¥–µ–Ω–∏–µ, —Ä–µ–∂–∏–º –Ω–∞ –º–∏—Å–ª–µ–Ω–µ | –°–ª–æ–∂–Ω–æ —Ä–∞–∑—Å—ä–∂–¥–µ–Ω–∏–µ, –∏–∑—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—Å–∫–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è |  
| **Qwen3 MoE** | 30B-235B –æ–±—â–æ | –ü—Ä–æ–º–µ–Ω–ª–∏–≤–∞ | –ï—Ñ–µ–∫—Ç–∏–≤–Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç –≤ –≥–æ–ª—è–º –º–∞—â–∞–± | –ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, –Ω—É–∂–¥–∏ –æ—Ç –≤–∏—Å–æ–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç |  

## –†—ä–∫–æ–≤–æ–¥—Å—Ç–≤–æ –∑–∞ –∏–∑–±–æ—Ä –Ω–∞ –º–æ–¥–µ–ª  

### –ó–∞ –æ—Å–Ω–æ–≤–Ω–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è  
- **Qwen2.5-0.5B/1.5B**: –ú–æ–±–∏–ª–Ω–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, –∫—Ä–∞–π–Ω–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞, –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤ —Ä–µ–∞–ª–Ω–æ –≤—Ä–µ–º–µ.  
- **Qwen2.5-3B/7B**: –û–±—â–∏ —á–∞—Ç–±–æ—Ç–æ–≤–µ, –≥–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ —Å—ä–¥—ä—Ä–∂–∞–Ω–∏–µ, —Å–∏—Å—Ç–µ–º–∏ –∑–∞ –≤—ä–ø—Ä–æ—Å–∏ –∏ –æ—Ç–≥–æ–≤–æ—Ä–∏.  

### –ó–∞ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏ –ª–æ–≥–∏—á–µ—Å–∫–∏ –∑–∞–¥–∞—á–∏  
- **Qwen2.5-Math**: –†–µ—à–∞–≤–∞–Ω–µ –Ω–∞ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ–±–ª–µ–º–∏ –∏ STEM –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ.  
- **Qwen3 —Å —Ä–µ–∂–∏–º –Ω–∞ –º–∏—Å–ª–µ–Ω–µ**: –°–ª–æ–∂–Ω–æ —Ä–∞–∑—Å—ä–∂–¥–µ–Ω–∏–µ, –∏–∑–∏—Å–∫–≤–∞—â–æ –∞–Ω–∞–ª–∏–∑ —Å—Ç—ä–ø–∫–∞ –ø–æ —Å—Ç—ä–ø–∫–∞.  

### –ó–∞ –ø—Ä–æ–≥—Ä–∞–º–∏—Ä–∞–Ω–µ –∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞  
- **Qwen2.5-Coder**: –ì–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ –∫–æ–¥, –¥–µ–±—ä–≥–∏–Ω–≥, –ø–æ–º–æ—â –ø—Ä–∏ –ø—Ä–æ–≥—Ä–∞–º–∏—Ä–∞–Ω–µ.  
- **Qwen3**: –ù–∞–ø—Ä–µ–¥–Ω–∞–ª–∏ –∑–∞–¥–∞—á–∏ –∑–∞ –ø—Ä–æ–≥—Ä–∞–º–∏—Ä–∞–Ω–µ —Å –ª–æ–≥–∏—á–µ—Å–∫–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏.  

### –ó–∞ –º—É–ª—Ç–∏–º–æ–¥–∞–ª–Ω–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è  
- **Qwen2.5-VL**: –†–∞–∑–±–∏—Ä–∞–Ω–µ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –≤–∏–∑—É–∞–ª–Ω–∏ –≤—ä–ø—Ä–æ—Å–∏ –∏ –æ—Ç–≥–æ–≤–æ—Ä–∏.  
- **Qwen-Audio**: –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ –∞—É–¥–∏–æ –∏ —Ä–∞–∑–±–∏—Ä–∞–Ω–µ –Ω–∞ —Ä–µ—á.  

### –ó–∞ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ  
- **Qwen2.5-32B/72B**: –í–∏—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ –µ–∑–∏–∫–æ–≤–æ —Ä–∞–∑–±–∏—Ä–∞–Ω–µ.  
- **Qwen3-235B-A22B**: –ú–∞–∫—Å–∏–º–∞–ª–Ω–∏ –≤—ä–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞ –≤–∑–∏—Å–∫–∞—Ç–µ–ª–Ω–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.  

## –ü–ª–∞—Ç—Ñ–æ—Ä–º–∏ –∑–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ –∏ –¥–æ—Å—Ç—ä–ø–Ω–æ—Å—Ç  

### –û–±–ª–∞—á–Ω–∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∏  
- **Hugging Face Hub**: –û–±—à–∏—Ä–Ω–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∑–∞ –º–æ–¥–µ–ª–∏ —Å –ø–æ–¥–∫—Ä–µ–ø–∞ –æ—Ç –æ–±—â–Ω–æ—Å—Ç—Ç–∞.  
- **ModelScope**: –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞ –∑–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ Alibaba —Å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏ –∑–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è.  
- **–†–∞–∑–ª–∏—á–Ω–∏ –æ–±–ª–∞—á–Ω–∏ –¥–æ—Å—Ç–∞–≤—á–∏—Ü–∏**: –ü–æ–¥–¥—Ä—ä–∂–∫–∞ —á—Ä–µ–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏ ML –ø–ª–∞—Ç—Ñ–æ—Ä–º–∏.  

### –õ–æ–∫–∞–ª–Ω–∏ —Ä–∞–º–∫–∏ –∑–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞  
- **Transformers**: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –Ω–∞ Hugging Face –∑–∞ –ª–µ—Å–Ω–æ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ.  
- **vLLM**: –í–∏—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ –æ–±—Å–ª—É–∂–≤–∞–Ω–µ –∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–∏ —Å—Ä–µ–¥–∏.  
- **Ollama**: –û–ø—Ä–æ—Å—Ç–µ–Ω–æ –ª–æ–∫–∞–ª–Ω–æ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ.  
- **ONNX Runtime**: –ö—Ä–æ—Å–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞ —Ä–∞–∑–ª–∏—á–µ–Ω —Ö–∞—Ä–¥—É–µ—Ä.  
- **llama.cpp**: –ï—Ñ–µ–∫—Ç–∏–≤–Ω–∞ C++ –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏—è –∑–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∏.  

### –û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª–Ω–∏ —Ä–µ—Å—É—Ä—Å–∏  
- **–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–∞ Qwen**: –û—Ñ–∏—Ü–∏–∞–ª–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏ –∫–∞—Ä—Ç–∏ –Ω–∞ –º–æ–¥–µ–ª–∏.  
- **Hugging Face Model Hub**: –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –∏ –ø—Ä–∏–º–µ—Ä–∏ –æ—Ç –æ–±—â–Ω–æ—Å—Ç—Ç–∞.  
- **–ù–∞—É—á–Ω–∏ —Å—Ç–∞—Ç–∏–∏**: –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤ arxiv –∑–∞ –∑–∞–¥—ä–ª–±–æ—á–µ–Ω–æ —Ä–∞–∑–±–∏—Ä–∞–Ω–µ.  
- **–§–æ—Ä—É–º–∏ –Ω–∞ –æ–±—â–Ω–æ—Å—Ç—Ç–∞**: –ê–∫—Ç–∏–≤–Ω–∞ –ø–æ–¥–∫—Ä–µ–ø–∞ –∏ –¥–∏—Å–∫—É—Å–∏–∏ –≤ –æ–±—â–Ω–æ—Å—Ç—Ç–∞.  

### –ó–∞–ø–æ—á–≤–∞–Ω–µ —Å –º–æ–¥–µ–ª–∏—Ç–µ Qwen  

#### –ü–ª–∞—Ç—Ñ–æ—Ä–º–∏ –∑–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞  
1. **Hugging Face Transformers**: –ó–∞–ø–æ—á–Ω–µ—Ç–µ —Å—ä—Å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞ Python –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è.  
2. **ModelScope**: –ò–∑—Å–ª–µ–¥–≤–∞–π—Ç–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω–∏—Ç–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏ –∑–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ –Ω–∞ Alibaba.  
3. **–õ–æ–∫–∞–ª–Ω–æ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ**: –ò–∑–ø–æ–ª–∑–≤–∞–π—Ç–µ Ollama –∏–ª–∏ –¥–∏—Ä–µ–∫—Ç–Ω–∏ transformers –∑–∞ –ª–æ–∫–∞–ª–Ω–æ —Ç–µ—Å—Ç–≤–∞–Ω–µ.  

#### –ü—ä—Ç –∑–∞ –æ–±—É—á–µ–Ω–∏–µ  
1. **–†–∞–∑–±–µ—Ä–µ—Ç–µ –æ—Å–Ω–æ–≤–Ω–∏—Ç–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏**: –ò–∑—É—á–µ—Ç–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞—Ç–∞ –∏ –≤—ä–∑–º–æ–∂–Ω–æ—Å—Ç–∏—Ç–µ –Ω–∞ —Å–µ–º–µ–π—Å—Ç–≤–æ—Ç–æ Qwen.  
2. **–ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–∞–π—Ç–µ —Å –≤–∞—Ä–∏–∞–Ω—Ç–∏**: –û–ø–∏—Ç–∞–π—Ç–µ —Ä–∞–∑–ª–∏—á–Ω–∏ —Ä–∞–∑–º–µ—Ä–∏ –Ω–∞ –º–æ–¥–µ–ª–∏, –∑–∞ –¥–∞ —Ä–∞–∑–±–µ—Ä–µ—Ç–µ –∫–æ–º–ø—Ä–æ–º–∏—Å–∏—Ç–µ –≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç—Ç–∞.  
3. **–ü—Ä–∞–∫—Ç–∏–∫—É–≤–∞–π—Ç–µ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ**: –í–Ω–µ–¥—Ä–µ—Ç–µ –º–æ–¥–µ–ª–∏ –≤ —Å—Ä–µ–¥–∏ –∑–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞.  
4. **–û–ø—Ç–∏–º–∏–∑–∏—Ä–∞–π—Ç–µ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ—Ç–æ**: –§–∏–Ω–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–∏ —Å–ª—É—á–∞–∏.  

#### –ù–∞–π-–¥–æ–±—Ä–∏ –ø—Ä–∞–∫—Ç–∏–∫–∏  
- **–ó–∞–ø–æ—á–Ω–µ—Ç–µ —Å –º–∞–ª–∫–∏ –º–æ–¥–µ–ª–∏**: –ó–∞–ø–æ—á–Ω–µ—Ç–µ —Å –ø–æ-–º–∞–ª–∫–∏ –º–æ–¥–µ–ª–∏ (1.5B-7B) –∑–∞ –ø—ä—Ä–≤–æ–Ω–∞—á–∞–ª–Ω–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞.  
- **–ò–∑–ø–æ–ª–∑–≤–∞–π—Ç–µ —à–∞–±–ª–æ–Ω–∏ –∑–∞ —á–∞—Ç**: –ü—Ä–∏–ª–∞–≥–∞–π—Ç–µ –ø—Ä–∞–≤–∏–ª–Ω–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–∞–Ω–µ –∑–∞ –æ–ø—Ç–∏–º–∞–ª–Ω–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏.  
- **–°–ª–µ–¥–µ—Ç–µ —Ä–µ—Å—É—Ä—Å–∏—Ç–µ**: –ü—Ä–æ—Å–ª–µ–¥—è–≤–∞–π—Ç–µ –∏–∑–ø–æ–ª–∑–≤–∞–Ω–µ—Ç–æ –Ω–∞ –ø–∞–º–µ—Ç—Ç–∞ –∏ —Å–∫–æ—Ä–æ—Å—Ç—Ç–∞ –Ω–∞ –∏–∑–≤–æ–¥–∞.  
- **–û–±–º–∏—Å–ª–µ—Ç–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è**: –ò–∑–±–µ—Ä–µ—Ç–µ –≤–∞—Ä–∏–∞–Ω—Ç–∏, —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∏ –∑–∞ –¥–æ–º–µ–π–Ω–∞, –∫–æ–≥–∞—Ç–æ –µ –ø–æ–¥—Ö–æ–¥—è—â–æ.  

## –ú–æ–¥–µ–ª–∏ –∑–∞ –Ω–∞–ø—Ä–µ–¥–Ω–∞–ª–∞ —É–ø–æ—Ç—Ä–µ–±–∞  

### –ü—Ä–∏–º–µ—Ä–∏ –∑–∞ —Ñ–∏–Ω–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞  

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig, get_peft_model
from trl import SFTTrainer
from datasets import load_dataset

# Load base model for fine-tuning
model_name = "Qwen/Qwen2.5-7B-Instruct"
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.bfloat16,
    device_map="auto"
)

tokenizer = AutoTokenizer.from_pretrained(model_name)
tokenizer.pad_token = tokenizer.eos_token

# Configure LoRA for efficient fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.1,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj"]
)

# Apply LoRA to model
model = get_peft_model(model, peft_config)

# Training configuration
training_args = TrainingArguments(
    output_dir="./qwen-finetuned",
    learning_rate=5e-5,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,
    num_train_epochs=3,
    warmup_steps=100,
    logging_steps=10,
    save_steps=500,
    evaluation_strategy="steps",
    eval_steps=500,
    bf16=True,
    remove_unused_columns=False
)

# Load and prepare dataset
def format_instruction(example):
    return f"<|im_start|>user\n{example['instruction']}<|im_end|>\n<|im_start|>assistant\n{example['output']}<|im_end|>"

dataset = load_dataset("your-custom-dataset")
dataset = dataset.map(
    lambda x: {"text": format_instruction(x)},
    remove_columns=dataset["train"].column_names
)

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_args,
    train_dataset=dataset["train"],
    eval_dataset=dataset["validation"],
    tokenizer=tokenizer,
    max_seq_length=2048,
    packing=True
)

# Start fine-tuning
trainer.train()
```
  
### –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω–æ –∏–Ω–∂–µ–Ω–µ—Ä—Å—Ç–≤–æ –Ω–∞ –ø–æ–¥—Å–∫–∞–∑–∫–∏  

**–ó–∞ —Å–ª–æ–∂–Ω–∏ –∑–∞–¥–∞—á–∏ –∑–∞ —Ä–∞–∑—Å—ä–∂–¥–µ–Ω–∏–µ:**  
```python
def create_reasoning_prompt(problem, context=""):
    """Create structured prompt for complex reasoning"""
    prompt = f"""<|im_start|>system
You are Qwen, a helpful AI assistant. When solving complex problems, break down your reasoning into clear steps.

Instructions:
1. Analyze the problem carefully
2. Identify key components and relationships
3. Work through the solution step by step
4. Verify your answer
5. Provide a clear final answer

{context}
<|im_end|>
<|im_start|>user
{problem}

Please solve this step by step, showing your reasoning process.
<|im_end|>
<|im_start|>assistant"""
    
    return prompt

# Example usage
complex_problem = """
A company's revenue grows by 15% each year. If they had $2 million in revenue in 2020, 
and they want to reach $5 million by 2025, will they achieve this goal? 
If not, what growth rate would they need?
"""

reasoning_prompt = create_reasoning_prompt(complex_problem)
```
  
**–ó–∞ –≥–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ –∫–æ–¥ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç:**  
```python
def create_coding_prompt(task, language="Python", context="", constraints=""):
    """Create structured prompt for code generation"""
    prompt = f"""<|im_start|>system
You are Qwen-Coder, an expert programming assistant. Generate clean, efficient, and well-documented code.

Requirements:
- Use {language} programming language
- Include comprehensive docstrings
- Add type hints where appropriate
- Follow best practices and conventions
- Include example usage

{context}
<|im_end|>
<|im_start|>user
Task: {task}

{f"Constraints: {constraints}" if constraints else ""}

Please provide a complete, production-ready solution.
<|im_end|>
<|im_start|>assistant"""
    
    return prompt

# Example usage
coding_task = """
Create a class that manages a simple in-memory cache with TTL (time-to-live) support.
The cache should support get, set, delete operations and automatically expire entries.
"""

constraints = """
- Thread-safe operations
- Configurable default TTL
- Memory-efficient cleanup of expired entries
- Support for custom serialization
"""

coding_prompt = create_coding_prompt(coding_task, "Python", constraints=constraints)
```
  
### –ú–Ω–æ–≥–æ–µ–∑–∏—á–Ω–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è  

```python
def create_multilingual_prompt(query, target_languages=["en", "zh", "es"]):
    """Create prompt for multilingual responses"""
    language_names = {
        "en": "English",
        "zh": "Chinese (‰∏≠Êñá)",
        "es": "Spanish (Espa√±ol)",
        "fr": "French (Fran√ßais)",
        "de": "German (Deutsch)",
        "ja": "Japanese (Êó•Êú¨Ë™û)"
    }
    
    lang_list = [language_names.get(lang, lang) for lang in target_languages]
    lang_str = ", ".join(lang_list)
    
    prompt = f"""<|im_start|>system
You are Qwen, a multilingual AI assistant. Provide responses in multiple languages as requested.
Ensure cultural appropriateness and natural expression in each language.
<|im_end|>
<|im_start|>user
Please answer the following question in {lang_str}:

{query}

Provide clear, culturally appropriate responses in each requested language.
<|im_end|>
<|im_start|>assistant"""
    
    return prompt

# Example usage
multilingual_query = "What are the benefits of renewable energy for the environment?"
multilingual_prompt = create_multilingual_prompt(
    multilingual_query, 
    target_languages=["en", "zh", "es"]
)
```
  
### üîß –ú–æ–¥–µ–ª–∏ –∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–æ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ  

```python
import asyncio
from typing import List, Dict, Optional
from dataclasses import dataclass
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

@dataclass
class GenerationConfig:
    max_tokens: int = 512
    temperature: float = 0.7
    top_p: float = 0.9
    repetition_penalty: float = 1.05
    do_sample: bool = True

class QwenService:
    """Production-ready Qwen model service"""
    
    def __init__(self, model_name: str, device: str = "auto"):
        self.model_name = model_name
        self.device = device
        self.model = None
        self.tokenizer = None
        self._load_model()
    
    def _load_model(self):
        """Load model and tokenizer"""
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModelForCausalLM.from_pretrained(
            self.model_name,
            torch_dtype=torch.bfloat16,
            device_map=self.device,
            trust_remote_code=True
        )
        
        # Optimize for inference
        self.model.eval()
        if hasattr(self.model, 'generation_config'):
            self.model.generation_config.pad_token_id = self.tokenizer.eos_token_id
    
    def format_chat(self, messages: List[Dict[str, str]]) -> str:
        """Format messages using chat template"""
        return self.tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )
    
    async def generate_async(
        self, 
        messages: List[Dict[str, str]], 
        config: GenerationConfig = GenerationConfig()
    ) -> str:
        """Async generation for high-throughput applications"""
        formatted_prompt = self.format_chat(messages)
        
        # Tokenize input
        inputs = self.tokenizer(
            formatted_prompt,
            return_tensors="pt",
            truncation=True,
            max_length=4096
        ).to(self.model.device)
        
        # Generate response
        with torch.no_grad():
            outputs = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.model.generate(
                    **inputs,
                    max_new_tokens=config.max_tokens,
                    temperature=config.temperature,
                    top_p=config.top_p,
                    repetition_penalty=config.repetition_penalty,
                    do_sample=config.do_sample,
                    pad_token_id=self.tokenizer.eos_token_id
                )
            )
        
        # Extract generated text
        generated_text = self.tokenizer.decode(
            outputs[0][inputs.input_ids.shape[1]:],
            skip_special_tokens=True
        )
        
        return generated_text.strip()
    
    def generate_batch(
        self, 
        batch_messages: List[List[Dict[str, str]]], 
        config: GenerationConfig = GenerationConfig()
    ) -> List[str]:
        """Batch generation for efficiency"""
        formatted_prompts = [self.format_chat(messages) for messages in batch_messages]
        
        # Tokenize batch
        inputs = self.tokenizer(
            formatted_prompts,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=4096
        ).to(self.model.device)
        
        # Generate responses
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=config.max_tokens,
                temperature=config.temperature,
                top_p=config.top_p,
                repetition_penalty=config.repetition_penalty,
                do_sample=config.do_sample,
                pad_token_id=self.tokenizer.eos_token_id
            )
        
        # Extract all generated texts
        responses = []
        for i, output in enumerate(outputs):
            generated_text = self.tokenizer.decode(
                output[inputs.input_ids[i].shape[0]:],
                skip_special_tokens=True
            )
            responses.append(generated_text.strip())
        
        return responses

# Example usage
async def main():
    # Initialize service
    qwen_service = QwenService("Qwen/Qwen2.5-7B-Instruct")
    
    # Single generation
    messages = [
        {"role": "user", "content": "Explain machine learning in simple terms"}
    ]
    response = await qwen_service.generate_async(messages)
    print("Single Response:", response)
    
    # Batch generation
    batch_messages = [
        [{"role": "user", "content": "What is artificial intelligence?"}],
        [{"role": "user", "content": "How does deep learning work?"}],
        [{"role": "user", "content": "What are neural networks?"}]
    ]
    
    batch_responses = qwen_service.generate_batch(batch_messages)
    for i, response in enumerate(batch_responses):
        print(f"Batch Response {i+1}:", response)

# Run the example
# asyncio.run(main())
```
  

## –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∑–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç—Ç–∞  

### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–∞ –ø–∞–º–µ—Ç—Ç–∞  

```python
# Memory-efficient loading strategies
from transformers import AutoModelForCausalLM, BitsAndBytesConfig

# 8-bit quantization for memory efficiency
quantization_config = BitsAndBytesConfig(
    load_in_8bit=True,
    llm_int8_threshold=6.0,
    llm_int8_has_fp16_weight=False
)

model = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen2.5-7B-Instruct",
    quantization_config=quantization_config,
    device_map="auto",
    torch_dtype=torch.float16
)

# 4-bit quantization for maximum efficiency
quantization_config_4bit = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.bfloat16,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4"
)

efficient_model = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen2.5-7B-Instruct",
    quantization_config=quantization_config_4bit,
    device_map="auto"
)
```
  
### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–∞ –∏–∑–≤–æ–¥–∞  

```python
import torch
from torch.nn.attention import SDPABackend, sdpa_kernel

# Optimized inference configuration
def optimized_inference_setup():
    """Configure optimizations for inference"""
    
    # Enable optimized attention mechanisms
    torch.backends.cuda.enable_flash_sdp(True)
    torch.backends.cuda.enable_math_sdp(True)
    torch.backends.cuda.enable_mem_efficient_sdp(True)
    
    # Set optimal threading
    torch.set_num_threads(4)  # Adjust based on your CPU
    
    # Enable JIT compilation for repeated patterns
    torch.jit.set_fusion_strategy([('STATIC', 3), ('DYNAMIC', 20)])

def fast_generate(model, tokenizer, prompt, max_tokens=256):
    """Optimized generation function"""
    with torch.no_grad():
        # Use optimized attention backend
        with sdpa_kernel(SDPABackend.FLASH_ATTENTION):
            inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
            
            # Generate with optimizations
            outputs = model.generate(
                **inputs,
                max_new_tokens=max_tokens,
                do_sample=True,
                temperature=0.7,
                use_cache=True,  # Enable KV caching
                pad_token_id=tokenizer.eos_token_id,
                early_stopping=True
            )
            
            response = tokenizer.decode(
                outputs[0][inputs.input_ids.shape[1]:],
                skip_special_tokens=True
            )
            
    return response.strip()
```
  

## –ù–∞–π-–¥–æ–±—Ä–∏ –ø—Ä–∞–∫—Ç–∏–∫–∏ –∏ –Ω–∞—Å–æ–∫–∏  

### –°–∏–≥—É—Ä–Ω–æ—Å—Ç –∏ –ø–æ–≤–µ—Ä–∏—Ç–µ–ª–Ω–æ—Å—Ç  

```python
import hashlib
import time
from typing import Optional

class SecureQwenService:
    """Security-focused Qwen service implementation"""
    
    def __init__(self, model_name: str):
        self.model_name = model_name
        self.model = None
        self.tokenizer = None
        self.request_logs = {}
        self._load_model()
    
    def _sanitize_input(self, text: str) -> str:
        """Sanitize user input to prevent injection attacks"""
        # Remove or escape potentially harmful patterns
        dangerous_patterns = [
            "<script>", "</script>", 
            "javascript:", "data:",
            "<iframe>", "</iframe>"
        ]
        
        sanitized = text
        for pattern in dangerous_patterns:
            sanitized = sanitized.replace(pattern, "")
        
        return sanitized
    
    def _rate_limit_check(self, user_id: str, max_requests: int = 100, window: int = 3600) -> bool:
        """Simple rate limiting implementation"""
        current_time = time.time()
        
        if user_id not in self.request_logs:
            self.request_logs[user_id] = []
        
        # Clean old requests
        self.request_logs[user_id] = [
            req_time for req_time in self.request_logs[user_id]
            if current_time - req_time < window
        ]
        
        # Check rate limit
        if len(self.request_logs[user_id]) >= max_requests:
            return False
        
        # Log current request
        self.request_logs[user_id].append(current_time)
        return True
    
    def _hash_sensitive_data(self, data: str) -> str:
        """Hash sensitive data for logging"""
        return hashlib.sha256(data.encode()).hexdigest()[:16]
    
    def secure_generate(
        self, 
        messages: List[Dict[str, str]], 
        user_id: str,
        max_tokens: int = 512
    ) -> Optional[str]:
        """Generate with security measures"""
        
        # Rate limiting
        if not self._rate_limit_check(user_id):
            return "Rate limit exceeded. Please try again later."
        
        # Input sanitization
        sanitized_messages = []
        for message in messages:
            sanitized_content = self._sanitize_input(message.get("content", ""))
            sanitized_messages.append({
                "role": message.get("role", "user"),
                "content": sanitized_content
            })
        
        # Content length validation
        total_content_length = sum(len(msg["content"]) for msg in sanitized_messages)
        if total_content_length > 8192:  # Reasonable limit
            return "Input too long. Please reduce the content length."
        
        # Log request (with hashed sensitive data)
        content_hash = self._hash_sensitive_data(str(sanitized_messages))
        print(f"Processing request from user {user_id[:8]}... Content hash: {content_hash}")
        
        # Generate response
        try:
            formatted_prompt = self.tokenizer.apply_chat_template(
                sanitized_messages,
                tokenize=False,
                add_generation_prompt=True
            )
            
            inputs = self.tokenizer(formatted_prompt, return_tensors="pt").to(self.model.device)
            
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=min(max_tokens, 1024),  # Enforce reasonable limits
                    temperature=0.7,
                    top_p=0.9,
                    repetition_penalty=1.05,
                    do_sample=True,
                    pad_token_id=self.tokenizer.eos_token_id
                )
            
            response = self.tokenizer.decode(
                outputs[0][inputs.input_ids.shape[1]:],
                skip_special_tokens=True
            )
            
            return response.strip()
            
        except Exception as e:
            print(f"Generation error for user {user_id[:8]}...: {str(e)}")
            return "An error occurred while processing your request."
```
  
### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –æ—Ü–µ–Ω–∫–∞  

```python
import time
import psutil
import torch
from dataclasses import dataclass
from typing import List, Dict, Any

@dataclass
class PerformanceMetrics:
    """Performance metrics for monitoring"""
    response_time: float
    memory_usage: float
    gpu_usage: float
    token_count: int
    tokens_per_second: float

class QwenMonitor:
    """Monitor Qwen model performance and health"""
    
    def __init__(self):
        self.metrics_history = []
    
    def measure_performance(self, model, tokenizer, prompt: str) -> PerformanceMetrics:
        """Measure comprehensive performance metrics"""
        start_time = time.time()
        start_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        
        # GPU metrics (if available)
        gpu_usage = 0
        if torch.cuda.is_available():
            torch.cuda.reset_peak_memory_stats()
            gpu_usage = torch.cuda.memory_allocated() / 1024 / 1024  # MB
        
        # Generate response
        inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
        
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=256,
                temperature=0.7,
                do_sample=True,
                pad_token_id=tokenizer.eos_token_id
            )
        
        # Calculate metrics
        end_time = time.time()
        end_memory = psutil.Process().memory_info().rss / 1024 / 1024
        
        response_time = end_time - start_time
        memory_usage = end_memory - start_memory
        
        if torch.cuda.is_available():
            gpu_usage = torch.cuda.max_memory_allocated() / 1024 / 1024
        
        token_count = outputs.shape[1] - inputs.input_ids.shape[1]
        tokens_per_second = token_count / response_time if response_time > 0 else 0
        
        metrics = PerformanceMetrics(
            response_time=response_time,
            memory_usage=memory_usage,
            gpu_usage=gpu_usage,
            token_count=token_count,
            tokens_per_second=tokens_per_second
        )
        
        self.metrics_history.append(metrics)
        return metrics
    
    def get_average_metrics(self, last_n: int = 10) -> Dict[str, float]:
        """Get average metrics from recent measurements"""
        if not self.metrics_history:
            return {}
        
        recent_metrics = self.metrics_history[-last_n:]
        
        return {
            "avg_response_time": sum(m.response_time for m in recent_metrics) / len(recent_metrics),
            "avg_memory_usage": sum(m.memory_usage for m in recent_metrics) / len(recent_metrics),
            "avg_gpu_usage": sum(m.gpu_usage for m in recent_metrics) / len(recent_metrics),
            "avg_tokens_per_second": sum(m.tokens_per_second for m in recent_metrics) / len(recent_metrics)
        }
    
    def health_check(self, model, tokenizer) -> Dict[str, Any]:
        """Perform comprehensive health check"""
        health_status = {
            "status": "healthy",
            "checks": {},
            "recommendations": []
        }
        
        try:
            # Test basic functionality
            test_prompt = "Hello, how are you?"
            metrics = self.measure_performance(model, tokenizer, test_prompt)
            
            # Check response time
            if metrics.response_time > 10.0:  # seconds
                health_status["checks"]["response_time"] = "slow"
                health_status["recommendations"].append("Consider model optimization or hardware upgrade")
            else:
                health_status["checks"]["response_time"] = "good"
            
            # Check memory usage
            if metrics.memory_usage > 1000:  # MB
                health_status["checks"]["memory_usage"] = "high"
                health_status["recommendations"].append("Monitor memory usage and consider cleanup")
            else:
                health_status["checks"]["memory_usage"] = "good"
            
            # Check token generation rate
            if metrics.tokens_per_second < 5:
                health_status["checks"]["generation_speed"] = "slow"
                health_status["recommendations"].append("Optimize inference configuration")
            else:
                health_status["checks"]["generation_speed"] = "good"
            
            # Overall status
            if any(check in ["slow", "high"] for check in health_status["checks"].values()):
                health_status["status"] = "degraded"
            
        except Exception as e:
            health_status["status"] = "unhealthy"
            health_status["error"] = str(e)
            health_status["recommendations"].append("Check model loading and configuration")
        
        return health_status

# Example usage
monitor = QwenMonitor()

# Regular performance monitoring
def monitor_model_performance(model, tokenizer, test_prompts: List[str]):
    """Monitor model performance with various prompts"""
    for prompt in test_prompts:
        metrics = monitor.measure_performance(model, tokenizer, prompt)
        print(f"Prompt: {prompt[:50]}...")
        print(f"Response time: {metrics.response_time:.2f}s")
        print(f"Tokens/sec: {metrics.tokens_per_second:.1f}")
        print(f"Memory usage: {metrics.memory_usage:.1f}MB")
        print("-" * 50)
    
    # Show average metrics
    avg_metrics = monitor.get_average_metrics()
    print("Average Performance Metrics:")
    for metric, value in avg_metrics.items():
        print(f"{metric}: {value:.2f}")
```
  

## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ  

–°–µ–º–µ–π—Å—Ç–≤–æ—Ç–æ –º–æ–¥–µ–ª–∏ Qwen –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–≤–∞ —Ü—è–ª–æ—Å—Ç–µ–Ω –ø–æ–¥—Ö–æ–¥ –∫—ä–º –¥–µ–º–æ–∫—Ä–∞—Ç–∏–∑–∞—Ü–∏—è—Ç–∞ –Ω–∞ AI —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏—Ç–µ, –∫–∞—Ç–æ —Å—ä—â–µ–≤—Ä–µ–º–µ–Ω–Ω–æ –ø–æ–¥–¥—ä—Ä–∂–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç –≤ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è. –ß—Ä–µ–∑ –∞–Ω–≥–∞–∂–∏–º–µ–Ω—Ç–∞ —Å–∏ –∫—ä–º –¥–æ—Å—Ç—ä–ø–Ω–æ—Å—Ç —Å –æ—Ç–≤–æ—Ä–µ–Ω –∫–æ–¥, –º–Ω–æ–≥–æ–µ–∑–∏—á–Ω–∏ –≤—ä–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∏ –≥—ä–≤–∫–∞–≤–∏ –æ–ø—Ü–∏–∏ –∑–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ, Qwen –ø–æ–∑–≤–æ–ª—è–≤–∞ –Ω–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏—Ç–µ –∏ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏—Ü–∏—Ç–µ –¥–∞ –∏–∑–ø–æ–ª–∑–≤–∞—Ç –º–æ—â–Ω–∏ AI –≤—ä–∑–º–æ–∂–Ω–æ—Å—Ç–∏, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Ç–µ—Ö–Ω–∏—Ç–µ —Ä–µ—Å—É—Ä—Å–∏ –∏–ª–∏ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∏ –∏–∑–∏—Å–∫–≤–∞–Ω–∏—è.  

### –û—Å–Ω–æ–≤–Ω–∏ –∏–∑–≤–æ–¥–∏  

**–û—Ç–ª–∏—á–∏–µ —Å –æ—Ç–≤–æ—Ä–µ–Ω –∫–æ–¥**: Qwen –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–∞, —á–µ –º–æ–¥–µ–ª–∏—Ç–µ —Å –æ—Ç–≤–æ—Ä–µ–Ω –∫–æ–¥ –º–æ–≥–∞—Ç –¥–∞ –ø–æ—Å—Ç–∏–≥–Ω–∞—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç, –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–∞ –Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–∏—Ç–µ –∞–ª—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∏, –∫–∞—Ç–æ —Å—ä—â–µ–≤—Ä–µ–º–µ–Ω–Ω–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—è—Ç –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç, –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∫–æ–Ω—Ç—Ä–æ–ª.  

**–ú–∞—â–∞–±–∏—Ä—É–µ–º–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**: –î–∏–∞–ø–∞–∑–æ–Ω—ä—Ç –æ—Ç 0.5B –¥–æ 235B –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –ø–æ–∑–≤–æ–ª—è–≤–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ –≤ —Ü–µ–ª–∏—è —Å–ø–µ–∫—Ç—ä—Ä –æ—Ç –∏–∑—á–∏—Å–ª–∏—Ç–µ–ª–Ω–∏ —Å—Ä–µ–¥–∏, –æ—Ç –º–æ–±–∏–ª–Ω–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –¥–æ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∏ –∫–ª—ä—Å—Ç–µ—Ä–∏.  

**–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω–∏ –≤—ä–∑–º–æ–∂–Ω–æ—Å—Ç–∏**: –í–∞—Ä–∏–∞–Ω—Ç–∏, —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∏ –∑–∞ –¥–æ–º–µ–π–Ω–∞, –∫–∞—Ç–æ Qwen-Coder, Qwen-Math –∏ Qwen-VL, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—è—Ç —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω–∞ –µ–∫—Å–ø–µ—Ä—Ç–∏–∑–∞, –∫–∞—Ç–æ —Å—ä—â–µ–≤—Ä–µ–º–µ–Ω–Ω–æ –ø–æ–¥–¥—ä—Ä–∂–∞—Ç –æ–±—â–æ –µ–∑–∏–∫–æ–≤–æ —Ä–∞–∑–±–∏—Ä–∞–Ω–µ.  

**–ì–ª–æ–±–∞–ª–Ω–∞ –¥–æ—Å—Ç—ä–ø–Ω–æ—Å—Ç**: –°–∏–ª–Ω–∞—Ç–∞ –º–Ω–æ–≥–æ–µ–∑–∏—á–Ω–∞ –ø–æ–¥–¥—Ä—ä–∂–∫–∞ –Ω–∞ –Ω–∞–¥ 119 –µ–∑–∏–∫–∞ –ø—Ä–∞–≤–∏ Qwen –ø–æ–¥—Ö–æ–¥—è—â –∑–∞ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–∏ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—Å–∫–∏ –±–∞–∑–∏.  

**–ù–µ–ø—Ä–µ–∫—ä—Å–Ω–∞—Ç–∏ –∏–Ω–æ–≤–∞—Ü–∏–∏**: –ï–≤–æ–ª—é—Ü–∏—è—Ç–∞ –æ—Ç Qwen 1.0 –¥–æ Qwen3 –ø–æ–∫–∞–∑–≤–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–Ω–æ –ø–æ–¥–æ–±—Ä–µ–Ω–∏–µ –Ω–∞ –≤—ä–∑–º–æ–∂–Ω–æ—Å—Ç–∏—Ç–µ, –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—Ç–∞ –∏ –æ–ø—Ü–∏–∏—Ç–µ –∑–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ.  

### –ë—ä–¥–µ—â–∏ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–∏  

–° —Ä–∞–∑–≤–∏—Ç–∏–µ—Ç–æ –Ω–∞ —Å–µ–º–µ–π—Å—Ç–≤–æ—Ç–æ Qwen –º–æ–∂–µ–º –¥–∞ –æ—á–∞–∫–≤–∞–º–µ:  
- **–ü–æ–¥–æ–±—Ä–µ–Ω–∞ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç**: –ü—Ä–æ–¥—ä–ª–∂–∞–≤–∞—â–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞ –ø–æ-–¥–æ–±—Ä–∏ —Å—ä–æ—Ç–Ω–æ—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç-–ø–∞—Ä–∞–º–µ—Ç—Ä–∏.  
- **–†–∞–∑—à–∏—Ä–µ–Ω–∏ –º—É–ª—Ç–∏–º–æ–¥–∞–ª–Ω–∏ –≤—ä–∑–º–æ–∂–Ω–æ—Å—Ç–∏**: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –Ω–∞ –ø–æ-—Å–ª–æ–∂–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ –≤–∏–∑–∏—è, –∞—É–¥–∏–æ –∏ —Ç–µ–∫—Å—Ç.  
- **–ü–æ–¥–æ–±—Ä–µ–Ω–æ —Ä–∞–∑—Å—ä–∂–¥–µ–Ω–∏–µ**: –ù–∞–ø—Ä–µ–¥–Ω–∞–ª–∏ –º–µ—Ö–∞–Ω–∏–∑–º–∏ –∑–∞ –º–∏—Å–ª–µ–Ω–µ –∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∑–∞ —Ä–µ—à–∞–≤–∞–Ω–µ –Ω–∞ –º–Ω–æ–≥–æ–µ—Ç–∞–ø–Ω–∏ –ø—Ä–æ–±–ª–µ–º–∏.  
- **–ü–æ-–¥–æ–±—Ä–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏ –∑–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ**: –ü–æ–¥–æ–±—Ä–µ–Ω–∏ —Ä–∞–º–∫–∏ –∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏ –∑–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–∏ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –Ω–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ.  
- **–†–∞—Å—Ç–µ–∂ –Ω–∞ –æ–±—â–Ω–æ—Å—Ç—Ç–∞**: –†–∞–∑—à–∏—Ä–µ–Ω–∞ –µ–∫–æ—Å–∏—Å—Ç–µ–º–∞ –æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏, –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∏ –ø—Ä–∏–Ω–æ—Å–∏ –æ—Ç –æ–±—â–Ω–æ—Å—Ç—Ç–∞.  

### –°–ª–µ–¥–≤–∞—â–∏ —Å—Ç—ä–ø–∫–∏  

–ù–µ–∑–∞–≤–∏—Å–∏–º–æ –¥–∞–ª–∏ —Å—ä–∑–¥–∞–≤–∞—Ç–µ —á–∞—Ç–±–æ—Ç, —Ä–∞–∑—Ä–∞–±–æ—Ç–≤–∞—Ç–µ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª–Ω–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏, —Å—ä–∑–¥–∞–≤–∞—Ç–µ –ø–æ–º–æ—â–Ω–∏—Ü–∏ –∑–∞ –∫–æ–¥–∏—Ä–∞–Ω–µ –∏–ª–∏ —Ä–∞–±–æ—Ç–∏—Ç–µ –≤—ä—Ä—Ö—É –º–Ω–æ–≥–æ–µ–∑–∏—á–Ω–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, —Å–µ–º–µ–π—Å—Ç–≤–æ—Ç–æ Qwen –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—è –º–∞—â–∞–±–∏—Ä—É–µ–º–∏ —Ä–µ—à–µ–Ω–∏—è —Å—ä—Å —Å–∏–ª–Ω–∞ –ø–æ–¥–∫—Ä–µ–ø–∞ –æ—Ç –æ–±—â–Ω–æ—Å—Ç—Ç–∞ –∏ –∏–∑—á–µ—Ä–ø–∞—Ç–µ–ª–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è.  

–ó–∞ –Ω–∞–π-–Ω–æ–≤–∏—Ç–µ –∞–∫—Ç—É–∞–ª–∏–∑–∞—Ü–∏–∏, –∏–∑–¥–∞–Ω–∏—è –Ω–∞ –º–æ–¥–µ–ª–∏ –∏ –ø–æ–¥—Ä–æ–±–Ω–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è, –ø–æ—Å–µ—Ç–µ—Ç–µ –æ—Ñ–∏—Ü–∏–∞–ª–Ω–∏—Ç–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –Ω–∞ Qwen –≤ Hugging Face –∏ –∏–∑—Å–ª–µ–¥–≤–∞–π—Ç–µ –∞–∫—Ç–∏–≤–Ω–∏—Ç–µ –¥–∏—Å–∫—É—Å–∏–∏ –∏ –ø—Ä–∏–º–µ—Ä–∏ –æ—Ç –æ–±—â–Ω–æ—Å—Ç—Ç–∞.  

–ë—ä–¥–µ—â–µ—Ç–æ –Ω–∞ AI —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞—Ç–∞ —Å–µ –∫—Ä–∏–µ –≤ –¥–æ—Å—Ç—ä–ø–Ω–∏, –ø—Ä–æ–∑—Ä–∞—á–Ω–∏ –∏ –º–æ—â–Ω–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏, –∫–æ–∏—Ç–æ –ø–æ–∑–≤–æ–ª—è–≤–∞—Ç –∏–Ω–æ–≤–∞—Ü–∏–∏ –≤—ä–≤ –≤—Å–∏—á–∫–∏ —Å–µ–∫—Ç–æ—Ä–∏ –∏ –º–∞—â–∞–±–∏. –°–µ–º–µ–π—Å—Ç–≤–æ—Ç–æ Qwen –≤—ä–ø–ª—ä—â–∞–≤–∞ —Ç–∞–∑–∏ –≤–∏–∑–∏—è, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—è–π–∫–∏ –Ω–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏—Ç–µ –∏ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏—Ü–∏—Ç–µ –æ—Å–Ω–æ–≤–∞—Ç–∞ –∑–∞ –∏–∑–≥—Ä–∞–∂–¥–∞–Ω–µ –Ω–∞ —Å–ª–µ–¥–≤–∞—â–æ—Ç–æ –ø–æ–∫–æ–ª–µ–Ω–∏–µ AI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.  

## –î–æ–ø—ä–ª–Ω–∏—Ç–µ–ª–Ω–∏ —Ä–µ—Å—É—Ä—Å–∏  

- **–û—Ñ–∏—Ü–∏–∞–ª–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è**: [–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–∞ Qwen](https://qwen.readthedocs.io/)  
- **–•—Ä–∞–Ω–∏–ª–∏—â–µ –Ω–∞ –º–æ–¥–µ–ª–∏**: [–ö–æ–ª–µ–∫—Ü–∏–∏ –Ω–∞ Qwen –≤ Hugging Face](https://huggingface.co/collections/Qwen/)  
- **–ù–∞—É—á–Ω–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏**: [–ù–∞—É—á–Ω–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –∑–∞ Qwen](https://arxiv.org/search/?query=Qwen&searchtype=all)  
- **–û–±—â–Ω–æ—Å—Ç**: [–î–∏—Å–∫—É—Å–∏–∏ –∏ –ø—Ä–æ–±–ª–µ–º–∏ –≤ GitHub](https://github.com/QwenLM/)  
- **–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞ ModelScope**: [ModelScope –Ω–∞ Alibaba](https://modelscope.cn/models?page=1&tasks=natural-language-processing&type=1)  

## –†–µ–∑—É–ª—Ç–∞—Ç–∏ –æ—Ç –æ–±—É—á–µ–Ω–∏–µ—Ç–æ  

–°–ª–µ–¥ –∑–∞–≤—ä—Ä—à–≤–∞–Ω–µ –Ω–∞ —Ç–æ–∑–∏ –º–æ–¥—É–ª —â–µ –º–æ–∂–µ—Ç–µ:  
1. –î–∞ –æ–±—è—Å–Ω–∏—Ç–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∏—Ç–µ –ø—Ä–µ–¥–∏–º—Å—Ç–≤–∞ –Ω–∞ —Å–µ–º–µ–π—Å—Ç–≤–æ—Ç–æ –º–æ–¥–µ–ª–∏ Qwen –∏ –ø–æ–¥—Ö–æ–¥–∞ –º—É —Å –æ—Ç–≤–æ—Ä–µ–Ω –∫–æ–¥.  
2. –î–∞ –∏–∑–±–µ—Ä–µ—Ç–µ –ø–æ–¥—Ö–æ–¥—è—â–∏—è –≤–∞—Ä–∏–∞–Ω—Ç –Ω–∞ Qwen –≤—ä–∑ –æ—Å–Ω–æ–≤–∞ –Ω–∞ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∏ –∏–∑–∏—Å–∫–≤–∞–Ω–∏—è –∑–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ —Ä–µ—Å—É—Ä—Å–∏—Ç–µ.  
3. –î–∞ –≤–Ω–µ–¥—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏ Qwen –≤ —Ä–∞–∑–ª–∏—á–Ω–∏ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –Ω–∞ –≤–Ω–µ–¥—Ä—è–≤–∞–Ω–µ —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏.  
4. –î–∞ –ø—Ä–∏–ª–æ–∂–∏—Ç–µ —Ç–µ—Ö–Ω–∏–∫–∏ –∑–∞ –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞ –ø–æ–¥–æ–±—Ä—è–≤–∞–Ω–µ –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç—Ç–∞ –Ω–∞ –º–æ–¥–µ–ª–∏—Ç–µ Qwen.  
5. –î–∞ –æ—Ü–µ–Ω–∏—Ç–µ –∫–æ–º–ø—Ä–æ–º–∏—Å–∏—Ç–µ –º–µ–∂–¥—É —Ä–∞–∑–º–µ—Ä –Ω–∞ –º–æ–¥–µ–ª–∞, –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç –∏ –≤—ä–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≤ —Å–µ–º–µ–π—Å—Ç–≤–æ—Ç–æ Qwen.  

## –ö–∞–∫–≤–æ —Å–ª–µ–¥–≤–∞  

- [03: –û—Å–Ω–æ–≤–∏ –Ω–∞ —Å–µ–º–µ–π—Å—Ç–≤–æ—Ç–æ Gemma](03.GemmaFamily.md)  

---

**–û—Ç–∫–∞–∑ –æ—Ç –æ—Ç–≥–æ–≤–æ—Ä–Ω–æ—Å—Ç**:  
–¢–æ–∑–∏ –¥–æ–∫—É–º–µ–Ω—Ç –µ –ø—Ä–µ–≤–µ–¥–µ–Ω —Å –ø–æ–º–æ—â—Ç–∞ –Ω–∞ AI —É—Å–ª—É–≥–∞ –∑–∞ –ø—Ä–µ–≤–æ–¥ [Co-op Translator](https://github.com/Azure/co-op-translator). –í—ä–ø—Ä–µ–∫–∏ —á–µ —Å–µ —Å—Ç—Ä–µ–º–∏–º –∫—ä–º —Ç–æ—á–Ω–æ—Å—Ç, –º–æ–ª—è, –∏–º–∞–π—Ç–µ –ø—Ä–µ–¥–≤–∏–¥, —á–µ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–∞–Ω–∏—Ç–µ –ø—Ä–µ–≤–æ–¥–∏ –º–æ–∂–µ –¥–∞ —Å—ä–¥—ä—Ä–∂–∞—Ç –≥—Ä–µ—à–∫–∏ –∏–ª–∏ –Ω–µ—Ç–æ—á–Ω–æ—Å—Ç–∏. –û—Ä–∏–≥–∏–Ω–∞–ª–Ω–∏—è—Ç –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞ –Ω–µ–≥–æ–≤–∏—è —Ä–æ–¥–µ–Ω –µ–∑–∏–∫ —Ç—Ä—è–±–≤–∞ –¥–∞ —Å–µ —Å—á–∏—Ç–∞ –∑–∞ –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–µ–Ω –∏–∑—Ç–æ—á–Ω–∏–∫. –ó–∞ –∫—Ä–∏—Ç–∏—á–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å–µ –ø—Ä–µ–ø–æ—Ä—ä—á–≤–∞ –ø—Ä–æ—Ñ–µ—Å–∏–æ–Ω–∞–ª–µ–Ω —á–æ–≤–µ—à–∫–∏ –ø—Ä–µ–≤–æ–¥. –ù–∏–µ –Ω–µ –Ω–æ—Å–∏–º –æ—Ç–≥–æ–≤–æ—Ä–Ω–æ—Å—Ç –∑–∞ –Ω–µ–¥–æ—Ä–∞–∑—É–º–µ–Ω–∏—è –∏–ª–∏ –ø–æ–≥—Ä–µ—à–Ω–∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏, –ø—Ä–æ–∏–∑—Ç–∏—á–∞—â–∏ –æ—Ç –∏–∑–ø–æ–ª–∑–≤–∞–Ω–µ—Ç–æ –Ω–∞ —Ç–æ–∑–∏ –ø—Ä–µ–≤–æ–¥.