<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20892f7994d9e5d2473ad19dfa93cf6d",
  "translation_date": "2025-09-17T14:52:43+00:00",
  "source_file": "Module02/01.PhiFamily.md",
  "language_code": "pl"
}
-->
# Sekcja 1: Podstawy rodziny modeli Microsoft Phi

Rodzina modeli Microsoft Phi stanowi przeÅ‚om w sztucznej inteligencji, pokazujÄ…c, Å¼e kompaktowe i wydajne modele mogÄ… osiÄ…gaÄ‡ niezwykÅ‚Ä… wydajnoÅ›Ä‡, jednoczeÅ›nie zuÅ¼ywajÄ…c znacznie mniej zasobÃ³w niÅ¼ tradycyjne duÅ¼e modele jÄ™zykowe. WaÅ¼ne jest, aby zrozumieÄ‡, jak rodzina Phi umoÅ¼liwia potÄ™Å¼ne moÅ¼liwoÅ›ci AI przy zmniejszonych wymaganiach obliczeniowych, zachowujÄ…c wysokÄ… wydajnoÅ›Ä‡ w rÃ³Å¼nych zadaniach.

## Zasoby dla programistÃ³w

### Katalog modeli Azure AI Foundry
Rodzina modeli Phi (z wyjÄ…tkiem Phi-silica) jest dostÄ™pna w [katalogu modeli Azure AI Foundry](https://ai.azure.com/explore/models?q=phi), co uÅ‚atwia programistom dostÄ™p, dostrajanie i wdraÅ¼anie tych modeli w swoich aplikacjach. Katalog zapewnia uproszczony sposÃ³b eksperymentowania z rÃ³Å¼nymi wariantami Phi i ich integracji z projektami.

### Azure AI Foundry
MoÅ¼esz wdraÅ¼aÄ‡ i eksperymentowaÄ‡ z modelami Phi za pomocÄ… [Azure AI Foundry](https://ai.azure.com), ktÃ³re oferuje kompleksowe Å›rodowisko do budowy, testowania i wdraÅ¼ania rozwiÄ…zaÅ„ AI przy minimalnej konfiguracji.

### Foundry Local
Do lokalnego rozwoju i wdraÅ¼ania sprawdÅº [Microsoft Foundry Local](https://github.com/microsoft/foundry-local), ktÃ³re umoÅ¼liwia uruchamianie modeli Phi na komputerze deweloperskim z zoptymalizowanymi konfiguracjami.

### Zasoby dokumentacyjne
- [Microsoft Research: Raporty techniczne modeli Phi](https://ai.azure.com/labs/projects/phi-4)
- [Phi Cookbook](https://aka.ms/phicookbook)

## Wprowadzenie

W tej lekcji przyjrzymy siÄ™ rodzinie modeli Microsoft Phi i jej podstawowym koncepcjom. OmÃ³wimy ewolucjÄ™ rodziny Phi, innowacyjne metody treningowe, ktÃ³re czyniÄ… modele Phi wydajnymi, kluczowe warianty w rodzinie oraz praktyczne zastosowania w rÃ³Å¼nych scenariuszach.

## Cele nauki

Po ukoÅ„czeniu tej lekcji bÄ™dziesz w stanie:

- ZrozumieÄ‡ filozofiÄ™ projektowania i ewolucjÄ™ rodziny modeli Microsoft Phi.
- ZidentyfikowaÄ‡ kluczowe innowacje, ktÃ³re pozwalajÄ… modelom Phi osiÄ…gaÄ‡ wysokÄ… wydajnoÅ›Ä‡ przy mniejszej liczbie parametrÃ³w.
- RozpoznaÄ‡ korzyÅ›ci i ograniczenia rÃ³Å¼nych wariantÃ³w modeli Phi.
- WykorzystaÄ‡ wiedzÄ™ o modelach Phi do wyboru odpowiednich wariantÃ³w w rzeczywistych scenariuszach.

## Zrozumienie tradycyjnego paradygmatu modeli AI

Tradycyjnie, osiÄ…gniÄ™cie wysokiej wydajnoÅ›ci w przetwarzaniu jÄ™zyka naturalnego wymagaÅ‚o ogromnych modeli jÄ™zykowych z miliardami lub setkami miliardÃ³w parametrÃ³w. Organizacje zazwyczaj wdraÅ¼ajÄ… te modele na potÄ™Å¼nych klastrach GPU, korzystajÄ…c z ich moÅ¼liwoÅ›ci za poÅ›rednictwem interfejsÃ³w API lub specjalistycznej infrastruktury sprzÄ™towej.

PodejÅ›cie to sprawdza siÄ™ w wielu zastosowaniach, ale ma wrodzone ograniczenia w kontekÅ›cie praktycznych scenariuszy wdroÅ¼eniowych. Tradycyjna metoda wymaga modeli, ktÃ³re potrzebujÄ… znacznych zasobÃ³w obliczeniowych, duÅ¼ej iloÅ›ci pamiÄ™ci i znacznego zuÅ¼ycia energii. ChociaÅ¼ podejÅ›cie to zapewnia dostÄ™p do najnowoczeÅ›niejszych moÅ¼liwoÅ›ci, tworzy zaleÅ¼noÅ›ci od kosztownego sprzÄ™tu, wprowadza wysokie koszty operacyjne i ogranicza elastycznoÅ›Ä‡ wdroÅ¼enia.

## Wyzwanie efektywnego wdraÅ¼ania AI

Potrzeba bardziej efektywnej AI staje siÄ™ coraz waÅ¼niejsza w rÃ³Å¼nych scenariuszach. WeÅºmy pod uwagÄ™ aplikacje wymagajÄ…ce lokalnego wdroÅ¼enia ze wzglÄ™dÃ³w prywatnoÅ›ci, implementacje wraÅ¼liwe na koszty, gdzie koszty API w chmurze stajÄ… siÄ™ zaporowe, scenariusze obliczeÅ„ brzegowych z ograniczonymi zasobami sprzÄ™towymi lub aplikacje czasu rzeczywistego, gdzie kluczowe jest niskie opÃ³Åºnienie.

### Kluczowe ograniczenia wdroÅ¼eniowe

Tradycyjne wdroÅ¼enia duÅ¼ych modeli napotykajÄ… kilka fundamentalnych ograniczeÅ„, ktÃ³re ograniczajÄ… ich praktyczne zastosowanie:

- **Ograniczenia kosztowe**: Wysokie koszty obliczeniowe sprawiajÄ…, Å¼e ciÄ…gÅ‚e wdroÅ¼enie jest drogie dla wielu organizacji.
- **Ograniczenia zasobÃ³w**: Ograniczony dostÄ™p do zaawansowanej infrastruktury GPU ogranicza moÅ¼liwoÅ›ci wdroÅ¼enia.
- **Wymagania dotyczÄ…ce prywatnoÅ›ci**: WraÅ¼liwe aplikacje wymagajÄ… lokalnego przetwarzania, aby zachowaÄ‡ prywatnoÅ›Ä‡ danych.
- **WraÅ¼liwoÅ›Ä‡ na opÃ³Åºnienia**: Aplikacje czasu rzeczywistego potrzebujÄ… natychmiastowych odpowiedzi bez opÃ³ÅºnieÅ„ wynikajÄ…cych z przesyÅ‚ania danych do chmury i z powrotem.

## Filozofia modeli Microsoft Phi

Rodzina modeli Microsoft Phi reprezentuje fundamentalnÄ… zmianÄ™ w filozofii projektowania modeli AI, kÅ‚adÄ…c nacisk na efektywnoÅ›Ä‡ i praktyczne wdroÅ¼enie przy jednoczesnym zachowaniu silnych cech wydajnoÅ›ciowych. Modele Phi osiÄ…gajÄ… to dziÄ™ki innowacyjnym architekturom, wysokiej jakoÅ›ci metodom treningowym i specjalistycznym technikom optymalizacyjnym.

Rodzina Phi obejmuje rÃ³Å¼ne podejÅ›cia zaprojektowane w celu maksymalizacji wydajnoÅ›ci na parametr, umoÅ¼liwiajÄ…c wdroÅ¼enie na standardowym sprzÄ™cie przy jednoczesnym zapewnieniu znaczÄ…cych moÅ¼liwoÅ›ci AI. Celem jest utrzymanie konkurencyjnej wydajnoÅ›ci przy jednoczesnym drastycznym zmniejszeniu wymagaÅ„ obliczeniowych, zuÅ¼ycia pamiÄ™ci i kosztÃ³w operacyjnych.

### Podstawowe zasady projektowania Phi

Modele Phi opierajÄ… siÄ™ na kilku fundamentalnych zasadach, ktÃ³re odrÃ³Å¼niajÄ… je od tradycyjnych duÅ¼ych modeli jÄ™zykowych:

- **EfektywnoÅ›Ä‡ przede wszystkim**: Optymalizacja pod kÄ…tem maksymalnej wydajnoÅ›ci na parametr, a nie absolutnej skali.
- **JakoÅ›Ä‡ treningu**: Skupienie na wysokiej jakoÅ›ci, starannie dobranych danych treningowych zamiast ogromnych zbiorÃ³w danych.
- **ElastycznoÅ›Ä‡ wdroÅ¼enia**: Zaprojektowane tak, aby dziaÅ‚aÅ‚y efektywnie na rÃ³Å¼nych konfiguracjach sprzÄ™towych.
- **Specjalistyczne moÅ¼liwoÅ›ci**: CzÄ™sto optymalizowane pod kÄ…tem konkretnych zadaÅ„ lub dziedzin, aby maksymalizowaÄ‡ skutecznoÅ›Ä‡.

## Kluczowe technologie umoÅ¼liwiajÄ…ce rozwÃ³j rodziny Phi

### PodejÅ›cie "PodrÄ™cznikowe" do treningu

Jednym z najbardziej rewolucyjnych aspektÃ³w rodziny Phi jest metodologia treningu "jakoÅ›ci podrÄ™cznikowej". Zamiast trenowaÄ‡ na ogromnych iloÅ›ciach nieprzefiltrowanych danych z internetu, modele Phi wykorzystujÄ… starannie dobrane, wysokiej jakoÅ›ci treÅ›ci edukacyjne, zaprojektowane tak, aby skutecznie uczyÄ‡ rozumowania, matematyki, kodowania i ogÃ³lnej wiedzy.

PodejÅ›cie to polega na tworzeniu syntetycznych treÅ›ci edukacyjnych, ktÃ³re odzwierciedlajÄ… wysokiej jakoÅ›ci podrÄ™czniki i materiaÅ‚y akademickie. Dane treningowe sÄ… specjalnie zaprojektowane, aby byÄ‡ pedagogicznie poprawne, koncentrujÄ…c siÄ™ na jasnych wyjaÅ›nieniach, krok po kroku rozumowaniu i uporzÄ…dkowanej prezentacji wiedzy.

### Zaawansowane treningi rozumowania

Nowsze modele Phi wprowadzajÄ… zaawansowane metody treningu rozumowania, ktÃ³re umoÅ¼liwiajÄ… rozwiÄ…zywanie zÅ‚oÅ¼onych problemÃ³w wieloetapowych. Techniki te obejmujÄ…:

**Trening "Chain-of-Thought"**: Modele uczÄ… siÄ™ rozkÅ‚adaÄ‡ zÅ‚oÅ¼one problemy na poÅ›rednie kroki rozumowania, co czyni proces rozwiÄ…zywania bardziej przejrzystym i niezawodnym.

**Skalowanie w czasie wnioskowania**: Modele generujÄ… szczegÃ³Å‚owe Å‚aÅ„cuchy rozumowania, ktÃ³re wykorzystujÄ… dodatkowe zasoby obliczeniowe podczas generowania odpowiedzi, aby poprawiÄ‡ dokÅ‚adnoÅ›Ä‡.

**Trening na granicy moÅ¼liwoÅ›ci**: Dane treningowe sÄ… specjalnie dobierane, aby rzucaÄ‡ wyzwanie modelowi na granicy jego obecnych moÅ¼liwoÅ›ci, promujÄ…c naukÄ™ zÅ‚oÅ¼onych wzorcÃ³w rozumowania.

### Innowacje architektoniczne

Rodzina Phi wprowadza kilka optymalizacji architektonicznych zaprojektowanych specjalnie pod kÄ…tem efektywnoÅ›ci:

**EfektywnoÅ›Ä‡ parametrÃ³w**: Starannie dobrane rozwiÄ…zania architektoniczne, ktÃ³re maksymalizujÄ… wpÅ‚yw kaÅ¼dego parametru w modelu.

**Integracja multimodalna**: Efektywna integracja przetwarzania tekstu, obrazu i mowy w kompaktowych architekturach.

**Optymalizacja sprzÄ™towa**: Specjalistyczne warianty zoptymalizowane pod kÄ…tem konkretnych platform sprzÄ™towych i scenariuszy wdroÅ¼eniowych.

## Optymalizacja sprzÄ™towa dla modeli Phi

WspÃ³Å‚czesne Å›rodowiska wdroÅ¼eniowe korzystajÄ… z efektywnoÅ›ci modeli Phi na rÃ³Å¼nych konfiguracjach sprzÄ™towych:

### WdroÅ¼enie zoptymalizowane pod kÄ…tem CPU

Modele Phi sÄ… zaprojektowane tak, aby dziaÅ‚aÅ‚y efektywnie na sprzÄ™cie opartym wyÅ‚Ä…cznie na CPU, co czyni je dostÄ™pnymi do wdroÅ¼enia na standardowej infrastrukturze obliczeniowej bez potrzeby specjalistycznych akceleratorÃ³w AI.

### Przyspieszenie GPU

ChociaÅ¼ modele Phi nie wymagajÄ… potÄ™Å¼nych GPU, mogÄ… korzystaÄ‡ z dostÄ™pnych zasobÃ³w GPU, aby zwiÄ™kszyÄ‡ wydajnoÅ›Ä‡, zapewniajÄ…c elastycznoÅ›Ä‡ w konfiguracjach wdroÅ¼eniowych.

### Integracja z urzÄ…dzeniami brzegowymi

Specjalistyczne warianty, takie jak Phi-3-Silica, sÄ… zoptymalizowane pod kÄ…tem konkretnych platform obliczeÅ„ brzegowych, osiÄ…gajÄ…c niezwykÅ‚e wskaÅºniki efektywnoÅ›ci, takie jak 650 tokenÃ³w na sekundÄ™ przy zuÅ¼yciu zaledwie 1,5 W mocy.

## KorzyÅ›ci z rodziny modeli Phi

### EfektywnoÅ›Ä‡ kosztowa

Modele Phi znacznie obniÅ¼ajÄ… koszty operacyjne, wymagajÄ…c znacznie mniej infrastruktury obliczeniowej przy jednoczesnym zachowaniu konkurencyjnej wydajnoÅ›ci. DziÄ™ki temu AI staje siÄ™ dostÄ™pne dla organizacji z ograniczonym budÅ¼etem lub aplikacji o duÅ¼ej skali, gdzie koszt na jedno wnioskowanie ma znaczenie.

### ElastycznoÅ›Ä‡ wdroÅ¼enia

EfektywnoÅ›Ä‡ modeli Phi umoÅ¼liwia wdroÅ¼enie na szerokiej gamie konfiguracji sprzÄ™towych, od laptopÃ³w osobistych po serwery korporacyjne, zapewniajÄ…c organizacjom wiÄ™kszÄ… elastycznoÅ›Ä‡ w wyborze infrastruktury AI.

### PrywatnoÅ›Ä‡ i bezpieczeÅ„stwo

EfektywnoÅ›Ä‡ modeli Phi umoÅ¼liwia lokalne wdroÅ¼enie w aplikacjach wraÅ¼liwych na prywatnoÅ›Ä‡, zapewniajÄ…c, Å¼e dane nie opuszczajÄ… organizacji, jednoczeÅ›nie oferujÄ…c potÄ™Å¼ne moÅ¼liwoÅ›ci AI.

### WydajnoÅ›Ä‡ w czasie rzeczywistym

Zmniejszone wymagania obliczeniowe przekÅ‚adajÄ… siÄ™ na szybsze czasy wnioskowania, umoÅ¼liwiajÄ…c aplikacje czasu rzeczywistego, ktÃ³re wymagajÄ… natychmiastowych odpowiedzi bez kompromisÃ³w w jakoÅ›ci moÅ¼liwoÅ›ci AI.

### DostÄ™pnoÅ›Ä‡ AI

DziÄ™ki obniÅ¼eniu barier wdroÅ¼eniowych, modele Phi sprawiajÄ…, Å¼e zaawansowane moÅ¼liwoÅ›ci AI sÄ… dostÄ™pne dla organizacji z ograniczonymi zasobami, umoÅ¼liwiajÄ…c mniejszym zespoÅ‚om i indywidualnym programistom korzystanie z zaawansowanego rozumienia jÄ™zyka.

## Praktyczne przykÅ‚ady i przypadki uÅ¼ycia

Przed zagÅ‚Ä™bieniem siÄ™ w technicznÄ… ewolucjÄ™, przyjrzyjmy siÄ™ kilku konkretnym przykÅ‚adom moÅ¼liwoÅ›ci modeli Phi:

### PrzykÅ‚ad rozumowania matematycznego

Phi-4-mini-reasoning doskonale radzi sobie z krok po kroku rozwiÄ…zywaniem problemÃ³w matematycznych. Na przykÅ‚ad, zapytany "Jak rozwiÄ…zaÄ‡ 3*x^2+4*x+5=1?", model dostarcza szczegÃ³Å‚owe kroki rozumowania:

```
<|system|>Your name is Phi, an AI math expert developed by Microsoft.<|end|>
<|user|>How to solve 3*x^2+4*x+5=1?<|end|>
<|assistant|>
I need to solve the quadratic equation 3xÂ² + 4x + 5 = 1.

First, let me rearrange this to standard form:
3xÂ² + 4x + 5 = 1
3xÂ² + 4x + 5 - 1 = 0  
3xÂ² + 4x + 4 = 0

Now I can use the quadratic formula: x = (-b Â± âˆš(bÂ² - 4ac)) / (2a)
Where a = 3, b = 4, c = 4

Let me calculate the discriminant:
bÂ² - 4ac = 4Â² - 4(3)(4) = 16 - 48 = -32

Since the discriminant is negative (-32), this equation has no real solutions.
The solutions are complex: x = (-4 Â± âˆš(-32)) / 6 = (-4 Â± 4iâˆš2) / 6 = (-2 Â± 2iâˆš2) / 3
```

### PrzykÅ‚ad wsparcia wielojÄ™zycznego

Phi-3.5-mini-instruct wykazuje silne moÅ¼liwoÅ›ci wielojÄ™zyczne w rÃ³Å¼nych jÄ™zykach. Oto przykÅ‚ad formatu zapytania:

```
<|system|>You are a helpful assistant.<|end|>
<|user|>How to explain Internet for a medieval knight?<|end|>
<|assistant|>
Imagine, good sir knight, a vast network of invisible roads that span the entire realm and beyond. The Internet is like a magical system of messenger birds that can carry any message - be it text, images, or even moving pictures - instantly to any castle, village, or hamlet in the world.

Think of it as if every scribe's work could be copied and shared with thousands of people simultaneously, as if you could visit any library in any kingdom without leaving your chambers, or as if you could hold council with knights from distant lands as if they were sitting at your very table.

This "Internet" allows people to:
- Send messages faster than the swiftest horse
- Access knowledge from scholars across all kingdoms
- Trade goods without traveling to distant markets
- Share stories and news from lands you've never seen

'Tis like having a thousand scribes, merchants, and storytellers all working for you at once, good knight!
```

### PrzykÅ‚ad moÅ¼liwoÅ›ci multimodalnych

Phi-4-multimodal potrafi jednoczeÅ›nie przetwarzaÄ‡ tekst, obrazy i mowÄ™. Oto kilka praktycznych zastosowaÅ„:

**Planowanie podrÃ³Å¼y z wejÅ›ciem audio:**
Zobacz, jak Phi-4 Multimodal analizuje mowÄ™, aby pomÃ³c w planowaniu podrÃ³Å¼y do Seattle, demonstrujÄ…c zaawansowane moÅ¼liwoÅ›ci przetwarzania dÅºwiÄ™ku i rekomendacji.

**RozwiÄ…zywanie problemÃ³w matematycznych z obrazÃ³w:**
Zobacz, jak Phi-4 Multimodal rozwiÄ…zuje zÅ‚oÅ¼one problemy matematyczne na podstawie wizualnych danych wejÅ›ciowych, demonstrujÄ…c zdolnoÅ›Ä‡ do przetwarzania i rozwiÄ…zywania rÃ³wnaÅ„ przedstawionych na obrazach.

**PrzykÅ‚ad wywoÅ‚ywania funkcji:**
DziÄ™ki wywoÅ‚ywaniu funkcji, Phi-4-mini i Phi-4-multimodal mogÄ… rozszerzaÄ‡ swoje moÅ¼liwoÅ›ci przetwarzania tekstu, integrujÄ…c wyszukiwarki, Å‚Ä…czÄ…c rÃ³Å¼ne narzÄ™dzia i nie tylko. Jak pokazano, model moÅ¼e pobieraÄ‡ informacje o meczach Premier League za pomocÄ… Phi-4-mini, demonstrujÄ…c zdolnoÅ›Ä‡ do bezproblemowej interakcji z zewnÄ™trznymi ÅºrÃ³dÅ‚ami danych.

### PrzykÅ‚ad generowania kodu

Phi-4-multimodal potrafi generowaÄ‡ struktury kodu projektowego na podstawie zarÃ³wno treÅ›ci obrazÃ³w, jak i dostarczonych zapytaÅ„, jak pokazano w tym praktycznym przepÅ‚ywie pracy:

1. PrzeÅ›lij obrazek z wireframe'em lub projektem
2. Podaj kontekst dotyczÄ…cy wymagaÅ„ projektu
3. Model generuje kompletne, funkcjonalne struktury kodu
4. Kod moÅ¼na dostosowaÄ‡ do konkretnych frameworkÃ³w lub jÄ™zykÃ³w

### PrzykÅ‚ad wdroÅ¼enia na urzÄ…dzeniach brzegowych

MoÅ¼emy wdroÅ¼yÄ‡ model skwantyzowany na urzÄ…dzeniach brzegowych. ÅÄ…czÄ…c Microsoft Olive i ONNX GenAI Runtime, moÅ¼emy wdroÅ¼yÄ‡ Phi-4-mini na Windows, iPhone, Android i innych urzÄ…dzeniach. Oto przykÅ‚ad dziaÅ‚ania na iPhone 12 Pro.

Proces wdroÅ¼enia obejmuje:
- KwantyzacjÄ™ modelu w celu optymalizacji mobilnej
- IntegracjÄ™ z ONNX Runtime dla kompatybilnoÅ›ci miÄ™dzyplatformowej
- LokalnÄ… inferencjÄ™ bez poÅ‚Ä…czenia z internetem
- WydajnoÅ›Ä‡ w czasie rzeczywistym przy minimalnym zuÅ¼yciu energii

## Ewolucja rodziny Phi

### Phi-1 i Phi-2: Modele podstawowe

Wczesne modele Phi ustanowiÅ‚y podstawowe zasady wysokiej jakoÅ›ci danych treningowych i wydajnych architektur:

- **Phi-1 (1,3B parametrÃ³w)**: WprowadziÅ‚ koncepcjÄ™ starannie dobranych danych treningowych dla podstawowego rozumienia jÄ™zyka i generowania kodu.
- **Phi-2 (2,7B parametrÃ³w)**: UlepszyÅ‚ zdolnoÅ›ci rozumowania dziÄ™ki syntetycznym danym NLP i starannie przefiltrowanym treÅ›ciom internetowym.

### Rodzina Phi-3: GÅ‚Ã³wne przyjÄ™cie

Seria Phi-3 oznaczaÅ‚a przeÅ‚om w moÅ¼liwoÅ›ciach SLM dziÄ™ki wielu specjalistycznym wariantom:

- **Phi-3-mini (3,8B parametrÃ³w)**: Zadania ogÃ³lnojÄ™zykowe z wyjÄ…tkowÄ… efektywnoÅ›ciÄ…, przewyÅ¼szajÄ…c modele dwukrotnie wiÄ™ksze.
- **Phi-3-small (7B parametrÃ³w)**: Zaawansowana wydajnoÅ›Ä‡ przewyÅ¼szajÄ…ca GPT-3.5 Turbo w rÃ³Å¼nych benchmarkach.
- **Phi-3-medium (14B parametrÃ³w)**: WydajnoÅ›Ä‡ na poziomie korporacyjnym przewyÅ¼szajÄ…ca Gemini 1.0 Pro.
- **Phi-3-vision (4,2B parametrÃ³w)**: MoÅ¼liwoÅ›ci multimodalne dla przetwarzania obrazÃ³w i tekstu.
- **Phi-3-Silica (3,3B parametrÃ³w)**: Specjalistyczna optymalizacja dla wbudowanego wdroÅ¼enia w Windows 11.

### Rodzina Phi-4: Zaawansowane rozumowanie

Najnowsza generacja przesuwa granice moÅ¼liwoÅ›ci rozumowania:

- **Phi-4 (14B parametrÃ³w)**: Specjalizacja w zÅ‚oÅ¼onym rozumowaniu, szczegÃ³lnie w matematyce.
- **Phi-4-mini (3,8B parametrÃ³w)**: Ulepszone rozumowanie z wywoÅ‚ywaniem funkcji i wsparciem dla dÅ‚ugiego kontekstu.
- **Phi-4-multimodal**: Jednoczesne przetwarzanie mowy, obrazu i tekstu.
- **Phi-4-reasoning (14B parametrÃ³w)**: Specjalizacja w zÅ‚oÅ¼onych zadaniach rozumowania wieloetapowego.
- **Phi-4-reasoning-plus (14B parametrÃ³w)**: ZwiÄ™kszona dokÅ‚adnoÅ›Ä‡ dziÄ™ki dodatkowej nauce przez wzmocnienie.
- **Phi-4-mini-reason
Rodzina modeli Phi pokazuje, Å¼e przyszÅ‚oÅ›Ä‡ wdraÅ¼ania sztucznej inteligencji nie polega jedynie na budowaniu wiÄ™kszych modeli, ale na tworzeniu inteligentniejszych, bardziej efektywnych, ktÃ³re mogÄ… dziaÅ‚aÄ‡ skutecznie w rÃ³Å¼nych Å›rodowiskach sprzÄ™towych, jednoczeÅ›nie utrzymujÄ…c wysokie standardy wydajnoÅ›ci.

## PrzykÅ‚ady rozwoju i integracji

### Szybki start z Transformers

Oto jak rozpoczÄ…Ä‡ pracÄ™ z modelami Phi, korzystajÄ…c z biblioteki Hugging Face Transformers:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load Phi-4-mini-instruct
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    attn_implementation="flash_attention_2"  # For optimized performance
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")

# Format your prompt using the chat template
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Explain quantum computing in simple terms."}
]

# Apply chat template
input_text = tokenizer.apply_chat_template(messages, tokenize=False)
inputs = tokenizer(input_text, return_tensors="pt")

# Generate response
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)
    
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### PrzykÅ‚ad dostrajania

PoniÅ¼szy przykÅ‚ad pokazuje, jak dostroiÄ‡ Phi-4-mini-instruct do konkretnych zadaÅ„:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig
from trl import SFTTrainer
from datasets import load_dataset

# Configuration for LoRA fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules="all-linear"
)

# Training configuration optimized for efficiency
training_config = TrainingArguments(
    output_dir="./phi-4-mini-finetuned",
    learning_rate=5.0e-06,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=1,
    num_train_epochs=1,
    bf16=True,
    gradient_checkpointing=True,
    warmup_ratio=0.2,
    save_steps=100
)

# Load model and tokenizer
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")
tokenizer.pad_token = tokenizer.unk_token
tokenizer.padding_side = 'right'

# Load and process dataset
train_dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_config,
    peft_config=peft_config,
    train_dataset=train_dataset,
    max_seq_length=2048,
    tokenizer=tokenizer,
    packing=True
)

# Start fine-tuning
trainer.train()
```

### Specjalistyczne formaty promptÃ³w

**Do zadaÅ„ wymagajÄ…cych rozumowania (Phi-4-reasoning-plus):**  
```
<|im_start|>system<|im_sep|>
You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions.

Please structure your response into two main sections:
<think>
{Thought section}
</think>
{Solution section}
<|im_end|>
<|im_start|>user<|im_sep|>
What is the derivative of x^2?
<|im_end|>
<|im_start|>assistant<|im_sep|>
```

**Do zadaÅ„ matematycznych (Phi-4-mini-reasoning):**  
```
<|system|>
Your name is Phi, an AI math expert developed by Microsoft.
<|end|>
<|user|>
Solve this calculus problem: Find the integral of 2x + 3
<|end|>
<|assistant|>
```

### WdroÅ¼enie mobilne z ONNX

```python
import onnxruntime as ort
import numpy as np

# Load ONNX model for mobile deployment
session = ort.InferenceSession("phi-4-mini-quantized.onnx")

# Prepare input
input_ids = tokenizer.encode("Hello, how are you?", return_tensors="np")

# Run inference
outputs = session.run(None, {"input_ids": input_ids})
predicted_ids = outputs[0]

# Decode response
response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)
```

## Benchmarki wydajnoÅ›ci i osiÄ…gniÄ™cia

Rodzina modeli Phi osiÄ…gnÄ™Å‚a niezwykÅ‚e wyniki w rÃ³Å¼nych benchmarkach, czÄ™sto przewyÅ¼szajÄ…c znacznie wiÄ™ksze modele:

### Kluczowe osiÄ…gniÄ™cia wydajnoÅ›ci

**DoskonaÅ‚oÅ›Ä‡ w rozumowaniu matematycznym:**
- Phi-4 osiÄ…ga 82,5% dokÅ‚adnoÅ›ci na AIME 2025 (kwalifikacje do Olimpiady Matematycznej)
- Phi-4-reasoning (14B) przewyÅ¼sza DeepSeek-R1-Distill-70B (5x wiÄ™kszy) w benchmarkach rozumowania
- Phi-4-mini-reasoning (3,8B) dorÃ³wnuje modelom dwa razy wiÄ™kszym w zadaniach matematycznych

**OsiÄ…gniÄ™cia w efektywnoÅ›ci:**
- Phi-3-Silica osiÄ…ga 650 tokenÃ³w na sekundÄ™ przy zuÅ¼yciu zaledwie 1,5W mocy
- Phi-4-mini (3,8B) osiÄ…ga podobnÄ… wydajnoÅ›Ä‡ co znacznie wiÄ™ksze modele

**Wyniki benchmarkÃ³w:**
- **MMLU (Massive Multitask Language Understanding):** Konkurencyjna wydajnoÅ›Ä‡ w 57 przedmiotach akademickich
- **HumanEval:** Silne moÅ¼liwoÅ›ci generowania kodu, szczegÃ³lnie w Pythonie
- **MGSM:** RozwiÄ…zywanie wielojÄ™zycznych zadaÅ„ matematycznych na poziomie szkoÅ‚y podstawowej
- **DROP:** ZÅ‚oÅ¼one zadania zwiÄ…zane z rozumieniem i wnioskowaniem
- **SimpleQA:** DokÅ‚adnoÅ›Ä‡ w udzielaniu odpowiedzi na pytania faktograficzne

### ğŸ“Š Macierz porÃ³wnawcza modeli

| Model | Parametry | DÅ‚ugoÅ›Ä‡ kontekstu | Kluczowe mocne strony | Najlepsze zastosowania |
|-------|-----------|-------------------|-----------------------|------------------------|
| **Phi-3-mini** | 3,8B | 4K/128K | OgÃ³lna efektywnoÅ›Ä‡ | Aplikacje mobilne, podstawowe chatboty |
| **Phi-3.5-mini** | 3,8B | 128K | Wsparcie wielojÄ™zyczne | Aplikacje miÄ™dzynarodowe |
| **Phi-4-mini** | 3,8B | 128K | Ulepszone rozumowanie, wywoÅ‚ywanie funkcji | Automatyzacja biznesowa |
| **Phi-4-mini-reasoning** | 3,8B | 128K | Rozumowanie matematyczne | Platformy edukacyjne |
| **Phi-4** | 14B | 32K | ZÅ‚oÅ¼one rozumowanie | Badania, zaawansowana analiza |
| **Phi-4-reasoning** | 14B | 32K/64K | Rozumowanie wieloetapowe | Obliczenia naukowe |
| **Phi-4-reasoning-plus** | 14B | 32K | Maksymalna dokÅ‚adnoÅ›Ä‡ w rozumowaniu | Krytyczne podejmowanie decyzji |
| **Phi-4-multimodal** | 5,6B | Zmienna | Mowa, wizja, tekst | Aplikacje multimedialne |

## Przewodnik po wyborze modelu

### Do podstawowych zastosowaÅ„
- **Phi-3-mini:** Prosta generacja tekstu, podstawowe pytania i odpowiedzi, szybkie odpowiedzi
- **Phi-4-mini:** Ulepszone rozumowanie z moÅ¼liwoÅ›ciÄ… wywoÅ‚ywania funkcji

### Do zadaÅ„ matematycznych i rozumowania
- **Phi-4:** ZÅ‚oÅ¼one rozwiÄ…zywanie problemÃ³w matematycznych i rozumowanie
- **Phi-4-reasoning:** Rozumowanie wieloetapowe z szczegÃ³Å‚owymi wyjaÅ›nieniami
- **Phi-4-reasoning-plus:** Maksymalna dokÅ‚adnoÅ›Ä‡ w zastosowaniach wymagajÄ…cych rozumowania
- **Phi-4-mini-reasoning:** Efektywne rozumowanie matematyczne w Å›rodowiskach o ograniczonych zasobach

### Do zastosowaÅ„ multimodalnych
- **Phi-3-vision:** PoÅ‚Ä…czenie przetwarzania obrazu i tekstu
- **Phi-4-multimodal:** Kompleksowe moÅ¼liwoÅ›ci w zakresie mowy, wizji i tekstu

### Do wdroÅ¼eÅ„ w przedsiÄ™biorstwach
- **Phi-3-medium:** Zaawansowane rozumienie jÄ™zyka dla zastosowaÅ„ biznesowych
- **Phi-3-Silica:** Optymalizacja dla specyficznych platform sprzÄ™towych

## Platformy wdroÅ¼eniowe i dostÄ™pnoÅ›Ä‡

### Platformy chmurowe
- **Azure AI Foundry:** PeÅ‚ne wdroÅ¼enie z narzÄ™dziami dla przedsiÄ™biorstw
- **Hugging Face:** Repozytorium modeli open-source i zasoby spoÅ‚ecznoÅ›ciowe
- **NVIDIA API Catalog:** Opcje wdroÅ¼enia jako mikrousÅ‚ugi

### Lokalne frameworki deweloperskie
- **Ollama:** Lekki framework do lokalnego wdraÅ¼ania modeli
- **ONNX Runtime:** Optymalizacja dla rÃ³Å¼nych konfiguracji sprzÄ™towych  
- **DirectML:** Optymalizacja dla systemÃ³w Windows
- **llama.cpp:** Silnik inferencyjny dziaÅ‚ajÄ…cy na rÃ³Å¼nych platformach

### Zasoby edukacyjne
- **Phi Portal:** Oficjalna dokumentacja Microsoft Phi
- **Phi Cookbook:** Kompleksowe przykÅ‚ady i samouczki
- **Raporty techniczne:** SzczegÃ³Å‚owe artykuÅ‚y badawcze na arxiv
- **Przestrzenie spoÅ‚ecznoÅ›ciowe:** Interaktywne dema na Hugging Face

### RozpoczÄ™cie pracy z modelami Phi

#### Platformy deweloperskie
1. **Azure AI Foundry:** Prosty lokalny interfejs CLI i zarzÄ…dzanie modelami.
2. **Hugging Face Transformers:** Szybkie eksperymenty lokalne
3. **Ollama:** Proste lokalne wdraÅ¼anie do testÃ³w

#### ÅšcieÅ¼ka nauki
1. **Zrozum podstawowe pojÄ™cia:** Przestudiuj fundamentalne zasady projektowania
2. **Eksperymentuj z wariantami:** WyprÃ³buj rÃ³Å¼ne modele Phi, aby zrozumieÄ‡ ich moÅ¼liwoÅ›ci
3. **Ä†wicz wdraÅ¼anie:** WdraÅ¼aj modele w Å›rodowiskach testowych
4. **Skaluj wdroÅ¼enie:** Stopniowo rozszerzaj uÅ¼ycie na podstawie udanych pilotaÅ¼y

#### Najlepsze praktyki
- **Zacznij od maÅ‚ych modeli:** Rozpocznij od modeli Phi-mini do poczÄ…tkowego rozwoju
- **Optymalizuj prompty:** UÅ¼ywaj odpowiedniego formatowania rozmÃ³w dla najlepszych wynikÃ³w
- **Monitoruj wydajnoÅ›Ä‡:** ÅšledÅº szybkoÅ›Ä‡ inferencji i metryki dokÅ‚adnoÅ›ci
- **Dopasuj sprzÄ™t:** Dopasuj rozmiar modelu do dostÄ™pnych zasobÃ³w obliczeniowych

## Podsumowanie

Rodzina modeli Microsoft Phi reprezentuje rewolucyjne podejÅ›cie do projektowania modeli AI, pokazujÄ…c, Å¼e mniejsze, bardziej efektywne modele mogÄ… osiÄ…gaÄ‡ niezwykÅ‚e wyniki w rÃ³Å¼nych zadaniach. DziÄ™ki skupieniu na wysokiej jakoÅ›ci danych treningowych i optymalizacjach architektonicznych, rodzina Phi oferuje wyjÄ…tkowe moÅ¼liwoÅ›ci przy znacznie mniejszych wymaganiach obliczeniowych w porÃ³wnaniu do tradycyjnych duÅ¼ych modeli jÄ™zykowych.

## Kluczowe cele nauki

1. Zrozum filozofiÄ™ projektowania i ewolucjÄ™ rodziny modeli Microsoft Phi od Phi-1 do Phi-4
2. Zidentyfikuj kluczowe innowacje, w tym szkolenie na "jakoÅ›ci podrÄ™cznikowej" danych i optymalizacje architektoniczne
3. Rozpoznaj korzyÅ›ci i ograniczenia rÃ³Å¼nych wariantÃ³w Phi w rÃ³Å¼nych scenariuszach wdroÅ¼eniowych
4. Wybierz odpowiednie modele Phi do konkretnych przypadkÃ³w uÅ¼ycia i ograniczeÅ„ sprzÄ™towych
5. WdroÅ¼ techniki optymalizacji do wdraÅ¼ania modeli Phi na urzÄ…dzeniach o ograniczonych zasobach
6. WyjaÅ›nij przewagi architektoniczne rodziny modeli Phi nad tradycyjnymi duÅ¼ymi modelami jÄ™zykowymi
7. Wybierz odpowiedni wariant Phi na podstawie specyficznych wymagaÅ„ aplikacji i ograniczeÅ„ sprzÄ™towych
8. WdroÅ¼ modele Phi zarÃ³wno w scenariuszach chmurowych, jak i brzegowych z zoptymalizowanymi konfiguracjami
9. Zastosuj techniki kwantyzacji i optymalizacji, aby poprawiÄ‡ wydajnoÅ›Ä‡ modeli Phi na docelowych urzÄ…dzeniach
10. OceÅ„ kompromisy miÄ™dzy rozmiarem modelu, wydajnoÅ›ciÄ… i moÅ¼liwoÅ›ciami w rodzinie Phi

## Co dalej

- [02: Podstawy rodziny Qwen](02.QwenFamily.md)

---

**ZastrzeÅ¼enie**:  
Ten dokument zostaÅ‚ przetÅ‚umaczony za pomocÄ… usÅ‚ugi tÅ‚umaczeniowej AI [Co-op Translator](https://github.com/Azure/co-op-translator). ChociaÅ¼ dokÅ‚adamy wszelkich staraÅ„, aby tÅ‚umaczenie byÅ‚o precyzyjne, prosimy pamiÄ™taÄ‡, Å¼e automatyczne tÅ‚umaczenia mogÄ… zawieraÄ‡ bÅ‚Ä™dy lub nieÅ›cisÅ‚oÅ›ci. Oryginalny dokument w jego rodzimym jÄ™zyku powinien byÄ‡ uznawany za wiarygodne ÅºrÃ³dÅ‚o. W przypadku informacji krytycznych zaleca siÄ™ skorzystanie z profesjonalnego tÅ‚umaczenia wykonanego przez czÅ‚owieka. Nie ponosimy odpowiedzialnoÅ›ci za jakiekolwiek nieporozumienia lub bÅ‚Ä™dne interpretacje wynikajÄ…ce z korzystania z tego tÅ‚umaczenia.