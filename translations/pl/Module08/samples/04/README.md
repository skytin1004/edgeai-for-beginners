<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "562ac0eae12d808c9f45fbb77eb5c84f",
  "translation_date": "2025-09-24T12:33:25+00:00",
  "source_file": "Module08/samples/04/README.md",
  "language_code": "pl"
}
-->
# PrzykÅ‚ad 04: Produkcyjne aplikacje czatowe z Chainlit

Kompleksowy przykÅ‚ad prezentujÄ…cy rÃ³Å¼ne podejÅ›cia do budowy gotowych do produkcji aplikacji czatowych z wykorzystaniem Microsoft Foundry Local, z nowoczesnymi interfejsami webowymi, strumieniowymi odpowiedziami i najnowszymi technologiami przeglÄ…darkowymi.

## Co zawiera

- **ðŸš€ Aplikacja czatowa Chainlit** (`app.py`): Gotowa do produkcji aplikacja czatowa ze strumieniowaniem
- **ðŸŒ Demo WebGPU** (`webgpu-demo/`): Wnioskowanie AI w przeglÄ…darce z akceleracjÄ… sprzÄ™towÄ…
- **ðŸŽ¨ Integracja Open WebUI** (`open-webui-guide.md`): Profesjonalny interfejs podobny do ChatGPT
- **ðŸ“š Edukacyjny notebook** (`chainlit_app.ipynb`): Interaktywne materiaÅ‚y edukacyjne

## Szybki start

### 1. Aplikacja czatowa Chainlit

```cmd
# Navigate to Module08 directory
cd Module08

# Start your model
foundry model run phi-4-mini

# Run Chainlit app (using port 8080 to avoid conflicts)
chainlit run samples\04\app.py -w --port 8080
```
  
Otwiera siÄ™ pod: `http://localhost:8080`

### 2. Demo WebGPU w przeglÄ…darce

```cmd
# Navigate to WebGPU demo
cd Module08\samples\04\webgpu-demo

# Serve the demo
python -m http.server 5173
```
  
Otwiera siÄ™ pod: `http://localhost:5173`

### 3. Konfiguracja Open WebUI

```cmd
# Run Open WebUI with Docker
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```
  
Otwiera siÄ™ pod: `http://localhost:3000`

## Wzorce architektury

### Lokalna vs chmurowa macierz decyzyjna

| Scenariusz | Rekomendacja | PowÃ³d |
|------------|--------------|-------|
| **Dane wraÅ¼liwe na prywatnoÅ›Ä‡** | ðŸ  Lokalnie (Foundry) | Dane nigdy nie opuszczajÄ… urzÄ…dzenia |
| **ZÅ‚oÅ¼one rozumowanie** | â˜ï¸ Chmura (Azure OpenAI) | DostÄ™p do wiÄ™kszych modeli |
| **Czat w czasie rzeczywistym** | ðŸ  Lokalnie (Foundry) | NiÅ¼sze opÃ³Åºnienia, szybsze odpowiedzi |
| **Analiza dokumentÃ³w** | ðŸ”„ Hybrydowo | Lokalnie dla ekstrakcji, w chmurze dla analizy |
| **Generowanie kodu** | ðŸ  Lokalnie (Foundry) | PrywatnoÅ›Ä‡ + wyspecjalizowane modele |
| **Zadania badawcze** | â˜ï¸ Chmura (Azure OpenAI) | Potrzebna szeroka baza wiedzy |

### PorÃ³wnanie technologii

| Technologia | Zastosowanie | Zalety | Wady |
|-------------|--------------|--------|------|
| **Chainlit** | Dla programistÃ³w Python, szybkie prototypowanie | Åatwa konfiguracja, wsparcie strumieniowe | Tylko Python |
| **WebGPU** | Maksymalna prywatnoÅ›Ä‡, scenariusze offline | Natywne dla przeglÄ…darki, brak potrzeby serwera | Ograniczony rozmiar modelu |
| **Open WebUI** | WdroÅ¼enia produkcyjne, zespoÅ‚y | Profesjonalny UI, zarzÄ…dzanie uÅ¼ytkownikami | Wymaga Dockera |

## Wymagania wstÄ™pne

- **Foundry Local**: Zainstalowany i uruchomiony ([Pobierz](https://aka.ms/foundry-local-installer))
- **Python**: 3.10+ z wirtualnym Å›rodowiskiem
- **Model**: Przynajmniej jeden zaÅ‚adowany (`foundry model run phi-4-mini`)
- **PrzeglÄ…darka**: Chrome/Edge z obsÅ‚ugÄ… WebGPU dla demo
- **Docker**: Dla Open WebUI (opcjonalnie)

## Instalacja i konfiguracja

### 1. Konfiguracja Å›rodowiska Python

```cmd
# Navigate to Module08 directory
cd Module08

# Create and activate virtual environment
py -m venv .venv
.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```
  
### 2. Konfiguracja Foundry Local

```cmd
# Verify Foundry Local installation
foundry --version

# Start the service
foundry service start

# Load a model
foundry model run phi-4-mini

# Verify model is running
foundry service ps
```
  
## PrzykÅ‚adowe aplikacje

### Aplikacja czatowa Chainlit

**Funkcje:**
- ðŸš€ **Strumieniowanie w czasie rzeczywistym**: Tokeny pojawiajÄ… siÄ™ w miarÄ™ ich generowania
- ðŸ›¡ï¸ **Solidne zarzÄ…dzanie bÅ‚Ä™dami**: Åagodne degradacje i odzyskiwanie
- ðŸŽ¨ **Nowoczesny UI**: Profesjonalny interfejs czatu od razu gotowy
- ðŸ”§ **Elastyczna konfiguracja**: Zmienne Å›rodowiskowe i automatyczne wykrywanie
- ðŸ“± **Responsywny design**: DziaÅ‚a na komputerach i urzÄ…dzeniach mobilnych

**Szybki start:**  
```cmd
# Run with default settings (recommended)
chainlit run samples\04\app.py -w --port 8080

# Use specific model
set MODEL=qwen2.5-7b-instruct
chainlit run samples\04\app.py -w --port 8080

# Manual endpoint configuration
set BASE_URL=http://localhost:51211
set API_KEY=your-api-key
chainlit run samples\04\app.py -w --port 8080
```
  
### Demo WebGPU w przeglÄ…darce

**Funkcje:**
- ðŸŒ **Natywne AI w przeglÄ…darce**: Brak potrzeby serwera, dziaÅ‚a caÅ‚kowicie w przeglÄ…darce
- âš¡ **Akceleracja WebGPU**: Przyspieszenie sprzÄ™towe, gdy dostÄ™pne
- ðŸ”’ **Maksymalna prywatnoÅ›Ä‡**: Dane nigdy nie opuszczajÄ… urzÄ…dzenia
- ðŸŽ¯ **Zero instalacji**: DziaÅ‚a w kaÅ¼dej kompatybilnej przeglÄ…darce
- ðŸ”„ **Åagodne przejÅ›cie**: Automatyczne przejÅ›cie na CPU, jeÅ›li WebGPU niedostÄ™pne

**Uruchamianie:**  
```cmd
cd samples\04\webgpu-demo
python -m http.server 5173
# Open http://localhost:5173
```
  
### Integracja Open WebUI

**Funkcje:**
- ðŸŽ¨ **Interfejs podobny do ChatGPT**: Profesjonalny, znajomy UI
- ðŸ‘¥ **Wsparcie dla wielu uÅ¼ytkownikÃ³w**: Konta uÅ¼ytkownikÃ³w i historia rozmÃ³w
- ðŸ“ **Przetwarzanie plikÃ³w**: PrzesyÅ‚anie i analiza dokumentÃ³w
- ðŸ”„ **PrzeÅ‚Ä…czanie modeli**: Åatwe przeÅ‚Ä…czanie miÄ™dzy rÃ³Å¼nymi modelami
- ðŸ³ **WdroÅ¼enie w Dockerze**: Gotowa do produkcji konfiguracja kontenerowa

**Szybka konfiguracja:**  
```cmd
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```
  
## Referencje konfiguracji

### Zmienne Å›rodowiskowe

| Zmienna | Opis | DomyÅ›lna wartoÅ›Ä‡ | PrzykÅ‚ad |
|---------|------|------------------|----------|
| `MODEL` | Alias modelu do uÅ¼ycia | `phi-4-mini` | `qwen2.5-7b-instruct` |
| `BASE_URL` | Endpoint Foundry Local | Automatyczne wykrywanie | `http://localhost:51211` |
| `API_KEY` | Klucz API (opcjonalny dla lokalnego) | `""` | `your-api-key` |

## RozwiÄ…zywanie problemÃ³w

### Typowe problemy

**Aplikacja Chainlit:**

1. **UsÅ‚uga niedostÄ™pna:**  
   ```cmd
   # Check Foundry Local status
   foundry service status
   foundry service ps
   
   # Validate API endpoint (note: port 51211)
   curl http://localhost:51211/v1/models
   ```
  
2. **Konflikty portÃ³w:**  
   ```cmd
   # Check what's using port 8080
   netstat -ano | findstr :8080
   
   # Use different port if needed
   chainlit run samples\04\app.py -w --port 3000
   ```
  
3. **Problemy ze Å›rodowiskiem Python:**  
   ```cmd
   # Verify correct interpreter in VS Code
   # Ctrl+Shift+P â†’ Python: Select Interpreter
   # Choose: Module08/.venv/Scripts/python.exe
   
   # Reinstall dependencies
   pip install -r requirements.txt
   ```
  
**Demo WebGPU:**

1. **Brak wsparcia dla WebGPU:**
   - Zaktualizuj do Chrome/Edge 113+
   - WÅ‚Ä…cz WebGPU: `chrome://flags/#enable-unsafe-webgpu`
   - SprawdÅº status GPU: `chrome://gpu`
   - Demo automatycznie przejdzie na CPU

2. **BÅ‚Ä™dy Å‚adowania modelu:**
   - Upewnij siÄ™, Å¼e masz poÅ‚Ä…czenie z internetem do pobrania modelu
   - SprawdÅº konsolÄ™ przeglÄ…darki pod kÄ…tem bÅ‚Ä™dÃ³w CORS
   - Zweryfikuj, Å¼e serwujesz przez HTTP (nie file://)

**Open WebUI:**

1. **Odmowa poÅ‚Ä…czenia:**  
   ```cmd
   # Check Docker is running
   docker --version
   
   # Check container status
   docker ps | findstr open-webui
   
   # View container logs
   docker logs open-webui
   ```
  
2. **Modele nie pojawiajÄ… siÄ™:**  
   ```cmd
   # Verify Foundry Local endpoint
   curl http://localhost:51211/v1/models
   
   # Restart Open WebUI
   docker restart open-webui
   ```
  
### Lista kontrolna walidacji

```cmd
# âœ… 1. Foundry Local Setup
foundry --version                    # Should show version
foundry service status               # Should show "running"
foundry model list                   # Should show loaded models
curl http://localhost:51211/v1/models  # Should return JSON

# âœ… 2. Python Environment  
python --version                     # Should be 3.10+
pip list | findstr chainlit         # Should show chainlit package
pip list | findstr openai           # Should show openai package

# âœ… 3. Application Testing
chainlit run samples\04\app.py -w --port 8080  # Should open browser
# Test WebGPU demo at localhost:5173
# Test Open WebUI at localhost:3000
```
  
## Zaawansowane uÅ¼ycie

### Optymalizacja wydajnoÅ›ci

**Chainlit:**
- UÅ¼ywaj strumieniowania dla lepszej percepcji wydajnoÅ›ci
- Implementuj pooling poÅ‚Ä…czeÅ„ dla wysokiej rÃ³wnoczesnoÅ›ci
- Cache'uj odpowiedzi modelu dla powtarzajÄ…cych siÄ™ zapytaÅ„
- Monitoruj uÅ¼ycie pamiÄ™ci przy duÅ¼ych historiach rozmÃ³w

**WebGPU:**
- UÅ¼ywaj WebGPU dla maksymalnej prywatnoÅ›ci i szybkoÅ›ci
- Implementuj kwantyzacjÄ™ modelu dla mniejszych modeli
- UÅ¼ywaj Web Workers do przetwarzania w tle
- Cache'uj skompilowane modele w pamiÄ™ci przeglÄ…darki

**Open WebUI:**
- UÅ¼ywaj trwaÅ‚ych woluminÃ³w dla historii rozmÃ³w
- Konfiguruj limity zasobÃ³w dla kontenera Dockera
- Implementuj strategie backupu dla danych uÅ¼ytkownikÃ³w
- Konfiguruj reverse proxy dla zakoÅ„czenia SSL

### Wzorce integracji

**Hybrydowe lokalne/chmurowe:**  
```python
# Route based on complexity and privacy requirements
async def intelligent_routing(prompt: str, metadata: dict):
    if metadata.get("contains_pii"):
        return await foundry_local_completion(prompt)  # Privacy-sensitive
    elif len(prompt.split()) > 200:
        return await azure_openai_completion(prompt)   # Complex reasoning
    else:
        return await foundry_local_completion(prompt)  # Default local
```
  
**Pipeline wielomodalny:**  
```python
# Combine different AI capabilities
async def analyze_document(file_path: str):
    # 1. OCR with WebGPU (browser-based)
    text = await webgpu_ocr(file_path)
    
    # 2. Analysis with Foundry Local (private)
    summary = await foundry_local_analyze(text)
    
    # 3. Enhancement with cloud (if needed)
    if summary.confidence < 0.8:
        summary = await azure_openai_enhance(summary)
    
    return summary
```
  
## WdroÅ¼enie produkcyjne

### RozwaÅ¼ania dotyczÄ…ce bezpieczeÅ„stwa

- **Klucze API**: UÅ¼ywaj zmiennych Å›rodowiskowych, nigdy nie zapisuj na staÅ‚e
- **SieÄ‡**: UÅ¼ywaj HTTPS w produkcji, rozwaÅ¼ VPN dla dostÄ™pu zespoÅ‚u
- **Kontrola dostÄ™pu**: Implementuj uwierzytelnianie dla Open WebUI
- **PrywatnoÅ›Ä‡ danych**: Audytuj, ktÃ³re dane pozostajÄ… lokalne, a ktÃ³re trafiajÄ… do chmury
- **Aktualizacje**: Utrzymuj Foundry Local i kontenery w aktualnym stanie

### Monitorowanie i utrzymanie

- **Kontrole zdrowia**: Implementuj monitorowanie endpointÃ³w
- **Logowanie**: Centralizuj logi ze wszystkich komponentÃ³w
- **Metryki**: ÅšledÅº czasy odpowiedzi, wskaÅºniki bÅ‚Ä™dÃ³w, uÅ¼ycie zasobÃ³w
- **Backup**: Regularne kopie zapasowe danych rozmÃ³w i konfiguracji

## Referencje i zasoby

### Dokumentacja
- [Dokumentacja Chainlit](https://docs.chainlit.io/) - Kompletny przewodnik po frameworku
- [Dokumentacja Foundry Local](https://learn.microsoft.com/azure/ai-foundry/foundry-local/) - Oficjalne dokumenty Microsoft
- [ONNX Runtime Web](https://onnxruntime.ai/docs/get-started/with-javascript/web.html) - Integracja WebGPU
- [Dokumentacja Open WebUI](https://docs.openwebui.com/) - Zaawansowana konfiguracja

### Pliki przykÅ‚adowe
- [`app.py`](../../../../../Module08/samples/04/app.py) - Produkcyjna aplikacja Chainlit
- [`chainlit_app.ipynb`](./chainlit_app.ipynb) - Edukacyjny notebook
- [`webgpu-demo/`](../../../../../Module08/samples/04/webgpu-demo) - Wnioskowanie AI w przeglÄ…darce
- [`open-webui-guide.md`](./open-webui-guide.md) - Kompletny przewodnik po Open WebUI

### PowiÄ…zane przykÅ‚ady
- [Dokumentacja sesji 4](../../04.CuttingEdgeModels.md) - Kompletny przewodnik po sesji
- [PrzykÅ‚ady Foundry Local](https://github.com/microsoft/foundry-local/tree/main/samples) - Oficjalne przykÅ‚ady

---

