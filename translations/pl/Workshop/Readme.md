<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8b994c57f1207012e4d7f58b7c0d1ae7",
  "translation_date": "2025-10-17T09:35:58+00:00",
  "source_file": "Workshop/Readme.md",
  "language_code": "pl"
}
-->
# EdgeAI dla PoczÄ…tkujÄ…cych - Warsztaty

> **Praktyczna Å›cieÅ¼ka nauki budowania gotowych do produkcji aplikacji Edge AI**
>
> Opanuj lokalne wdraÅ¼anie AI z Microsoft Foundry Local, od pierwszego ukoÅ„czenia czatu po orkiestracjÄ™ wieloagentowÄ… w 6 progresywnych sesjach.

---

## ğŸ¯ Wprowadzenie

Witamy na **Warsztatach EdgeAI dla PoczÄ…tkujÄ…cych** - praktycznym przewodniku po budowaniu inteligentnych aplikacji dziaÅ‚ajÄ…cych caÅ‚kowicie na lokalnym sprzÄ™cie. Te warsztaty przeksztaÅ‚cajÄ… teoretyczne koncepcje Edge AI w umiejÄ™tnoÅ›ci praktyczne poprzez coraz bardziej wymagajÄ…ce Ä‡wiczenia z uÅ¼yciem Microsoft Foundry Local i MaÅ‚ych Modeli JÄ™zykowych (SLM).

### Dlaczego te warsztaty?

**Rewolucja Edge AI juÅ¼ trwa**

Organizacje na caÅ‚ym Å›wiecie przechodzÄ… od AI zaleÅ¼nego od chmury do obliczeÅ„ brzegowych z trzech kluczowych powodÃ³w:

1. **PrywatnoÅ›Ä‡ i zgodnoÅ›Ä‡** - Przetwarzaj wraÅ¼liwe dane lokalnie bez przesyÅ‚ania ich do chmury (HIPAA, GDPR, regulacje finansowe)
2. **WydajnoÅ›Ä‡** - Wyeliminuj opÃ³Åºnienia sieciowe (50-500ms lokalnie vs 500-2000ms w chmurze)
3. **Kontrola kosztÃ³w** - UsuÅ„ koszty API za token i skaluj bez wydatkÃ³w na chmurÄ™

**Ale Edge AI jest inne**

Uruchamianie AI na miejscu wymaga nowych umiejÄ™tnoÅ›ci:
- WybÃ³r i optymalizacja modeli pod kÄ…tem ograniczeÅ„ zasobÃ³w
- ZarzÄ…dzanie lokalnymi usÅ‚ugami i przyspieszenie sprzÄ™towe
- InÅ¼ynieria promptÃ³w dla mniejszych modeli
- Wzorce wdraÅ¼ania produkcyjnego dla urzÄ…dzeÅ„ brzegowych

**Te warsztaty dostarczÄ… tych umiejÄ™tnoÅ›ci**

W 6 skoncentrowanych sesjach (~3 godziny Å‚Ä…cznie) przejdziesz od "Hello World" do wdroÅ¼enia gotowych do produkcji systemÃ³w wieloagentowych - wszystko dziaÅ‚ajÄ…ce lokalnie na Twoim komputerze.

---

## ğŸ“š Cele nauki

Po ukoÅ„czeniu tych warsztatÃ³w bÄ™dziesz w stanie:

### Kluczowe kompetencje
1. **WdraÅ¼anie i zarzÄ…dzanie lokalnymi usÅ‚ugami AI**
   - Instalacja i konfiguracja Microsoft Foundry Local
   - WybÃ³r odpowiednich modeli do wdroÅ¼enia brzegowego
   - ZarzÄ…dzanie cyklem Å¼ycia modelu (pobieranie, Å‚adowanie, buforowanie)
   - Monitorowanie wykorzystania zasobÃ³w i optymalizacja wydajnoÅ›ci

2. **Budowanie aplikacji zasilanych AI**
   - Implementacja lokalnych ukoÅ„czeÅ„ czatu kompatybilnych z OpenAI
   - Projektowanie skutecznych promptÃ³w dla MaÅ‚ych Modeli JÄ™zykowych
   - ObsÅ‚uga strumieniowych odpowiedzi dla lepszego UX
   - Integracja lokalnych modeli z istniejÄ…cymi aplikacjami

3. **Tworzenie systemÃ³w RAG (Retrieval Augmented Generation)**
   - Budowanie wyszukiwania semantycznego z uÅ¼yciem osadzeÅ„
   - Ugruntowanie odpowiedzi LLM w wiedzy specyficznej dla domeny
   - Ocena jakoÅ›ci RAG za pomocÄ… standardowych metryk branÅ¼owych
   - Skalowanie od prototypu do produkcji

4. **Optymalizacja wydajnoÅ›ci modeli**
   - Benchmarking wielu modeli dla Twojego przypadku uÅ¼ycia
   - Pomiar opÃ³Åºnienia, przepustowoÅ›ci i czasu pierwszego tokena
   - WybÃ³r optymalnych modeli na podstawie kompromisÃ³w szybkoÅ›Ä‡/jakoÅ›Ä‡
   - PorÃ³wnanie SLM vs LLM w rzeczywistych scenariuszach

5. **Orkiestracja systemÃ³w wieloagentowych**
   - Projektowanie wyspecjalizowanych agentÃ³w do rÃ³Å¼nych zadaÅ„
   - Implementacja pamiÄ™ci agentÃ³w i zarzÄ…dzania kontekstem
   - Koordynacja agentÃ³w w zÅ‚oÅ¼onych przepÅ‚ywach pracy
   - Inteligentne kierowanie Å¼Ä…daÅ„ miÄ™dzy wieloma modelami

6. **WdraÅ¼anie rozwiÄ…zaÅ„ gotowych do produkcji**
   - Implementacja obsÅ‚ugi bÅ‚Ä™dÃ³w i logiki ponownego prÃ³bowania
   - Monitorowanie uÅ¼ycia tokenÃ³w i zasobÃ³w systemowych
   - Budowanie skalowalnych architektur z wzorcami model-as-tools
   - Planowanie Å›cieÅ¼ek migracji z edge do hybrydowych (edge + chmura)

---

## ğŸ“ Rezultaty nauki

### Co zbudujesz

Na koniec warsztatÃ³w stworzysz:

| Sesja | Rezultat | Demonstrowane umiejÄ™tnoÅ›ci |
|-------|----------|---------------------------|
| **1** | Aplikacja czatu ze strumieniowaniem | Konfiguracja usÅ‚ugi, podstawowe ukoÅ„czenia, UX strumieniowy |
| **2** | System RAG z ocenÄ… | Osadzenia, wyszukiwanie semantyczne, metryki jakoÅ›ci |
| **3** | Zestaw benchmarkÃ³w dla wielu modeli | Pomiar wydajnoÅ›ci, porÃ³wnanie modeli |
| **4** | PorÃ³wnywarka SLM vs LLM | Analiza kompromisÃ³w, strategie optymalizacji |
| **5** | Orkiestrator wieloagentowy | Projektowanie agentÃ³w, zarzÄ…dzanie pamiÄ™ciÄ…, koordynacja |
| **6** | Inteligentny system routingu | Wykrywanie intencji, wybÃ³r modelu, skalowalnoÅ›Ä‡ |

### Matryca kompetencji

| Poziom umiejÄ™tnoÅ›ci | Sesja 1-2 | Sesja 3-4 | Sesja 5-6 |
|---------------------|-----------|-----------|-----------|
| **PoczÄ…tkujÄ…cy** | âœ… Konfiguracja i podstawy | âš ï¸ Wyzwanie | âŒ Zbyt zaawansowane |
| **Åšredniozaawansowany** | âœ… Szybki przeglÄ…d | âœ… Kluczowa nauka | âš ï¸ Cele rozwojowe |
| **Zaawansowany** | âœ… Bez problemu | âœ… Doskonalenie | âœ… Wzorce produkcyjne |

### UmiejÄ™tnoÅ›ci gotowe na karierÄ™

**Po tych warsztatach bÄ™dziesz gotowy do:**

âœ… **Budowania aplikacji z priorytetem prywatnoÅ›ci**
- Aplikacje zdrowotne obsÅ‚ugujÄ…ce PHI/PII lokalnie
- UsÅ‚ugi finansowe z wymaganiami zgodnoÅ›ci
- Systemy rzÄ…dowe z potrzebÄ… suwerennoÅ›ci danych

âœ… **Optymalizacji dla Å›rodowisk brzegowych**
- UrzÄ…dzenia IoT z ograniczonymi zasobami
- Aplikacje mobilne dziaÅ‚ajÄ…ce offline
- Systemy czasu rzeczywistego o niskim opÃ³Åºnieniu

âœ… **Projektowania inteligentnych architektur**
- Systemy wieloagentowe dla zÅ‚oÅ¼onych przepÅ‚ywÃ³w pracy
- Hybrydowe wdroÅ¼enia edge-chmura
- Infrastruktura AI zoptymalizowana pod kÄ…tem kosztÃ³w

âœ… **Prowadzenia inicjatyw Edge AI**
- Ocena wykonalnoÅ›ci Edge AI dla projektÃ³w
- WybÃ³r odpowiednich modeli i frameworkÃ³w
- Projektowanie skalowalnych lokalnych rozwiÄ…zaÅ„ AI

---

## ğŸ—ºï¸ Struktura warsztatÃ³w

### PrzeglÄ…d sesji (6 sesji Ã— 30 minut = 3 godziny)

| Sesja | Temat | Skupienie | Czas trwania |
|-------|-------|-----------|--------------|
| **1** | RozpoczÄ™cie pracy z Foundry Local | Instalacja, weryfikacja, pierwsze ukoÅ„czenia | 30 min |
| **2** | Budowanie rozwiÄ…zaÅ„ AI z RAG | InÅ¼ynieria promptÃ³w, osadzenia, ocena | 30 min |
| **3** | Modele open source | Odkrywanie modeli, benchmarking, wybÃ³r | 30 min |
| **4** | NajnowoczeÅ›niejsze modele | SLM vs LLM, optymalizacja, frameworki | 30 min |
| **5** | Agenci zasilani AI | Projektowanie agentÃ³w, orkiestracja, pamiÄ™Ä‡ | 30 min |
| **6** | Modele jako narzÄ™dzia | Routing, Å‚aÅ„czenie, strategie skalowania | 30 min |

---

## ğŸš€ Szybki start

### Wymagania wstÄ™pne

**Wymagania systemowe:**
- **OS**: Windows 10/11, macOS 11+ lub Linux (Ubuntu 20.04+)
- **RAM**: Minimum 8GB, zalecane 16GB+
- **Dysk**: 10GB+ wolnego miejsca na modele
- **CPU**: Nowoczesny procesor z obsÅ‚ugÄ… AVX2
- **GPU** (opcjonalnie): Kompatybilny z CUDA lub Qualcomm NPU dla przyspieszenia

**Wymagania dotyczÄ…ce oprogramowania:**
- **Python 3.8+** ([Pobierz](https://www.python.org/downloads/))
- **Microsoft Foundry Local** ([Przewodnik instalacji](../../../Workshop))
- **Git** ([Pobierz](https://git-scm.com/downloads))
- **Visual Studio Code** (zalecane) ([Pobierz](https://code.visualstudio.com/))

### Konfiguracja w 3 krokach

#### 1. Zainstaluj Foundry Local

**Windows:**
```powershell
winget install Microsoft.FoundryLocal
```

**macOS:**
```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

**Weryfikacja instalacji:**
```bash
foundry --version
foundry service status
```

**Upewnij siÄ™, Å¼e Azure AI Foundry Local dziaÅ‚a z ustalonym portem**

```bash
# Set FoundryLocal to use port 58123 (default)
foundry service set --port 58123 --show

# Or use a different port
foundry service set --port 58000 --show
```

**SprawdÅº dziaÅ‚anie:**
```bash
# Check service status
foundry service status

# Test the endpoint
curl http://127.0.0.1:58123/v1/models
```
**Znajdowanie dostÄ™pnych modeli**
Aby zobaczyÄ‡, ktÃ³re modele sÄ… dostÄ™pne w Twojej instancji Foundry Local, moÅ¼esz zapytaÄ‡ endpoint modeli:

```bash
# cmd/bash/powershell
foundry model list
```

Korzystanie z endpointu Web 

```bash
# Windows PowerShell
powershell -Command "Invoke-RestMethod -Uri 'http://127.0.0.1:58123/v1/models' -Method Get"

# Or using curl (if available)
curl http://127.0.0.1:58123/v1/models
```

#### 2. Sklonuj repozytorium i zainstaluj zaleÅ¼noÅ›ci

```bash
# Clone repository
git clone https://github.com/microsoft/edgeai-for-beginners.git
cd edgeai-for-beginners/Workshop

# Create virtual environment
python -m venv .venv

# Activate virtual environment
# Windows:
.\.venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

#### 3. Uruchom swÃ³j pierwszy przykÅ‚ad

```bash
# Start Foundry Local and load a model
foundry model run phi-4-mini

# Run the chat bootstrap sample
cd samples/session01
python chat_bootstrap.py "What is edge AI?"
```

**âœ… Sukces!** PowinieneÅ› zobaczyÄ‡ strumieniowÄ… odpowiedÅº dotyczÄ…cÄ… edge AI.

---

## ğŸ“¦ Zasoby warsztatowe

### PrzykÅ‚ady w Pythonie

Progresywne przykÅ‚ady praktyczne demonstrujÄ…ce kaÅ¼dÄ… koncepcjÄ™:

| Sesja | PrzykÅ‚ad | Opis | Czas wykonania |
|-------|---------|------|----------------|
| 1 | [`chat_bootstrap.py`](../../../Workshop/samples/session01/chat_bootstrap.py) | Podstawowy czat i strumieniowanie | ~30s |
| 2 | [`rag_pipeline.py`](../../../Workshop/samples/session02/rag_pipeline.py) | RAG z osadzeniami | ~45s |
| 2 | [`rag_eval_ragas.py`](../../../Workshop/samples/session02/rag_eval_ragas.py) | Ocena jakoÅ›ci RAG | ~60s |
| 3 | [`benchmark_oss_models.py`](../../../Workshop/samples/session03/benchmark_oss_models.py) | Benchmarking wielu modeli | ~2-3m |
| 4 | [`model_compare.py`](../../../Workshop/samples/session04/model_compare.py) | PorÃ³wnanie SLM vs LLM | ~45s |
| 5 | [`agents_orchestrator.py`](../../../Workshop/samples/session05/agents_orchestrator.py) | System wieloagentowy | ~60s |
| 6 | [`models_router.py`](../../../Workshop/samples/session06/models_router.py) | Routing oparty na intencjach | ~45s |
| 6 | [`models_pipeline.py`](../../../Workshop/samples/session06/models_pipeline.py) | Pipeline wieloetapowy | ~60s |

### Notatniki Jupyter

Interaktywna eksploracja z wyjaÅ›nieniami i wizualizacjami:

| Sesja | Notatnik | Opis | TrudnoÅ›Ä‡ |
|-------|----------|------|----------|
| 1 | [`session01_chat_bootstrap.ipynb`](./notebooks/session01_chat_bootstrap.ipynb) | Podstawy czatu i strumieniowanie | â­ PoczÄ…tkujÄ…cy |
| 2 | [`session02_rag_pipeline.ipynb`](./notebooks/session02_rag_pipeline.ipynb) | Budowanie systemu RAG | â­â­ Åšredniozaawansowany |
| 2 | [`session02_rag_eval_ragas.ipynb`](./notebooks/session02_rag_eval_ragas.ipynb) | Ocena jakoÅ›ci RAG | â­â­ Åšredniozaawansowany |
| 3 | [`session03_benchmark_oss_models.ipynb`](./notebooks/session03_benchmark_oss_models.ipynb) | Benchmarking modeli | â­â­ Åšredniozaawansowany |
| 4 | [`session04_model_compare.ipynb`](./notebooks/session04_model_compare.ipynb) | PorÃ³wnanie modeli | â­â­ Åšredniozaawansowany |
| 5 | [`session05_agents_orchestrator.ipynb`](./notebooks/session05_agents_orchestrator.ipynb) | Orkiestracja agentÃ³w | â­â­â­ Zaawansowany |
| 6 | [`session06_models_router.ipynb`](./notebooks/session06_models_router.ipynb) | Routing intencji | â­â­â­ Zaawansowany |
| 6 | [`session06_models_pipeline.ipynb`](./notebooks/session06_models_pipeline.ipynb) | Orkiestracja pipeline | â­â­â­ Zaawansowany |

### Dokumentacja

Kompleksowe przewodniki i odniesienia:

| Dokument | Opis | UÅ¼yj, gdy |
|----------|------|----------|
| [QUICK_START.md](./QUICK_START.md) | Przewodnik szybkiej konfiguracji | Zaczynasz od zera |
| [QUICK_REFERENCE.md](./QUICK_REFERENCE.md) | SkrÃ³cona lista poleceÅ„ i API | Potrzebujesz szybkich odpowiedzi |
| [FOUNDRY_SDK_QUICKREF.md](./FOUNDRY_SDK_QUICKREF.md) | Wzorce SDK i przykÅ‚ady | Piszesz kod |
| [ENV_CONFIGURATION.md](./ENV_CONFIGURATION.md) | Przewodnik po zmiennych Å›rodowiskowych | Konfigurujesz przykÅ‚ady |
| [SAMPLES_UPDATE_SUMMARY.md](./SAMPLES_UPDATE_SUMMARY.md) | Najnowsze ulepszenia przykÅ‚adÃ³w | Rozumiesz zmiany |
| [SDK_MIGRATION_NOTES.md](./SDK_MIGRATION_NOTES.md) | Przewodnik migracji | Aktualizujesz kod |
| [notebooks/TROUBLESHOOTING.md](./notebooks/TROUBLESHOOTING.md) | Typowe problemy i rozwiÄ…zania | RozwiÄ…zujesz problemy |

---

## ğŸ“ Rekomendacje Å›cieÅ¼ki nauki

### Dla poczÄ…tkujÄ…cych (3-4 godziny)
1. âœ… Sesja 1: RozpoczÄ™cie pracy (skup siÄ™ na konfiguracji i podstawowym czacie)
2. âœ… Sesja 2: Podstawy RAG (na poczÄ…tku pomiÅ„ ocenÄ™)
3. âœ… Sesja 3: Prosty benchmarking (tylko 2 modele)
4. â­ï¸ Na razie pomiÅ„ sesje 4-6
5. ğŸ”„ WrÃ³Ä‡ do sesji 4-6 po zbudowaniu pierwszej aplikacji

### Dla Å›redniozaawansowanych (3 godziny)
1. âš¡ Sesja 1: Szybka weryfikacja konfiguracji
2. âœ… Sesja 2: Kompletny pipeline RAG z ocenÄ…
3. âœ… Sesja 3: PeÅ‚ny zestaw benchmarkÃ³w
4. âœ… Sesja 4: Optymalizacja modeli
5. âœ… Sesje 5-6: Skup siÄ™ na wzorcach architektury

### Dla zaawansowanych (2-3 godziny)
1. âš¡ Sesje 1-3: Szybki przeglÄ…d i weryfikacja
2. âœ… Sesja 4: DogÅ‚Ä™bna optymalizacja
3. âœ… Sesja 5: Architektura wieloagentowa
4. âœ… Sesja 6: Wzorce produkcyjne i skalowanie
5. ğŸš€ Rozszerz: Zbuduj wÅ‚asnÄ… logikÄ™ routingu i wdroÅ¼enia hybrydowe

---

## Pakiet sesji warsztatowych (Skoncentrowane 30â€‘minutowe laboratoria)

JeÅ›li podÄ…Å¼asz za skondensowanym formatem warsztatÃ³w 6-sesyjnych, uÅ¼yj tych dedykowanych przewodnikÃ³w (kaÅ¼dy odpowiada i uzupeÅ‚nia szersze moduÅ‚y dokumentacji powyÅ¼ej):

| Sesja warsztatowa | Przewodnik | GÅ‚Ã³wne skupienie |
|-------------------|-----------|------------------|
| 1 | [Session01-GettingStartedFoundryLocal](./Session01-GettingStartedFoundryLocal.md) | Instalacja, weryfikacja, uruchomienie phi & GPT-OSS-20B, przyspieszenie |
| 2 | [Session02-BuildAISolutionsRAG](./Session02-BuildAISolutionsRAG.md) | InÅ¼ynieria promptÃ³w, wzorce RAG, ugruntowanie CSV i dokumentÃ³w, migracja |
| 3 | [Session03-OpenSourceModels](./Session03-OpenSourceModels.md) | Integracja Hugging Face, benchmarking, wybÃ³r modeli |
| 4 | [Session04-CuttingEdgeModels](./Session04-CuttingEdgeModels.md) | SLM vs LLM, WebGPU, Chainlit RAG, przyspieszenie ONNX |
| 5 | [Session05-AIPoweredAgents](./Session05-AIPoweredAgents.md) | Role agentÃ³w, pamiÄ™Ä‡, narzÄ™dzia, orkiestracja |
| 6 | [Session06-ModelsAsTools](./Session06-ModelsAsTools.md) | Routing, Å‚Ä…czenie, skalowanie na Azure |

KaÅ¼dy plik sesji zawiera: streszczenie, cele nauki, 30-minutowy przebieg demonstracji, projekt startowy, listÄ™ kontrolnÄ… walidacji, rozwiÄ…zywanie problemÃ³w oraz odniesienia do oficjalnego Foundry Local Python SDK.

### PrzykÅ‚adowe skrypty

Instalacja zaleÅ¼noÅ›ci warsztatowych (Windows):

```powershell
cd Workshop
py -m venv .venv
.\.venv\Scripts\activate
pip install -r requirements.txt
```

macOS / Linux:

```bash
cd Workshop
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

JeÅ›li usÅ‚uga Foundry Local dziaÅ‚a na innym komputerze (Windows) lub maszynie wirtualnej niÅ¼ macOS, wyeksportuj punkt koÅ„cowy:

```bash
export FOUNDRY_LOCAL_ENDPOINT=http://<windows-host>:5273/v1
```

| Sesja | Skrypt(y) | Opis |
|-------|-----------|------|
| 1 | `samples/session01/chat_bootstrap.py` | Uruchomienie usÅ‚ugi i czat strumieniowy |
| 2 | `samples/session02/rag_pipeline.py` | Minimalny RAG (w pamiÄ™ci) |
|   | `samples/session02/rag_eval_ragas.py` | Ocena RAG za pomocÄ… metryk ragas |
| 3 | `samples/session03/benchmark_oss_models.py` | Benchmarking opÃ³ÅºnieÅ„ i przepustowoÅ›ci dla wielu modeli |
| 4 | `samples/session04/model_compare.py` | PorÃ³wnanie SLM vs LLM (opÃ³Åºnienia i przykÅ‚adowe wyniki) |
| 5 | `samples/session05/agents_orchestrator.py` | Pipeline badawczy dwÃ³ch agentÃ³w â†’ redakcja |
| 6 | `samples/session06/models_router.py` | Demonstracja routingu opartego na intencjach |
|   | `samples/session06/models_pipeline.py` | ÅaÅ„cuch planowania/wykonania/poprawy w wielu krokach |

### Zmienne Å›rodowiskowe (wspÃ³lne dla wszystkich przykÅ‚adÃ³w)

| Zmienna | Cel | PrzykÅ‚ad |
|---------|-----|---------|
| `FOUNDRY_LOCAL_ALIAS` | DomyÅ›lny alias pojedynczego modelu dla podstawowych przykÅ‚adÃ³w | `phi-4-mini` |
| `SLM_ALIAS` / `LLM_ALIAS` | WyraÅºne SLM vs wiÄ™kszy model do porÃ³wnania | `phi-4-mini` / `gpt-oss-20b` |
| `BENCH_MODELS` | Lista aliasÃ³w do benchmarku | `qwen2.5-0.5b,gemma-2-2b,mistral-7b` |
| `BENCH_ROUNDS` | PowtÃ³rzenia benchmarku na model | `3` |
| `BENCH_PROMPT` | Prompt uÅ¼ywany w benchmarku | `Explain retrieval augmented generation briefly.` |
| `EMBED_MODEL` | Model embeddingu sentence-transformers | `sentence-transformers/all-MiniLM-L6-v2` |
| `RAG_QUESTION` | Nadpisanie zapytania testowego dla pipeline RAG | `Why use RAG with local inference?` |
| `AGENT_QUESTION` | Nadpisanie zapytania dla pipeline agentÃ³w | `Explain why edge AI matters for compliance.` |
| `AGENT_MODEL_PRIMARY` | Alias modelu dla agenta badawczego | `phi-4-mini` |
| `AGENT_MODEL_EDITOR` | Alias modelu dla agenta redakcyjnego (moÅ¼e siÄ™ rÃ³Å¼niÄ‡) | `gpt-oss-20b` |
| `SHOW_USAGE` | JeÅ›li `1`, drukuje uÅ¼ycie tokenÃ³w na zakoÅ„czenie | `1` |
| `RETRY_ON_FAIL` | JeÅ›li `1`, ponawia prÃ³bÄ™ w przypadku bÅ‚Ä™dÃ³w czatu | `1` |
| `RETRY_BACKOFF` | Czas oczekiwania przed ponownÄ… prÃ³bÄ… | `1.0` |

JeÅ›li zmienna nie jest ustawiona, skrypty korzystajÄ… z rozsÄ…dnych wartoÅ›ci domyÅ›lnych. W przypadku demonstracji z jednym modelem zazwyczaj wystarczy `FOUNDRY_LOCAL_ALIAS`.

### ModuÅ‚ pomocniczy

Wszystkie przykÅ‚ady korzystajÄ… teraz z pomocniczego `samples/workshop_utils.py`, ktÃ³ry oferuje:

* BuforowanÄ… obsÅ‚ugÄ™ `FoundryLocalManager` + klienta OpenAI
* Pomocnik `chat_once()` z opcjonalnym ponawianiem prÃ³b + drukowaniem uÅ¼ycia
* Proste raportowanie uÅ¼ycia tokenÃ³w (wÅ‚Ä…czane przez `SHOW_USAGE=1`)

To zmniejsza duplikacjÄ™ i podkreÅ›la najlepsze praktyki efektywnej orkiestracji lokalnych modeli.

## Opcjonalne ulepszenia (miÄ™dzy sesjami)

| Temat | Ulepszenie | Sesje | Åšrodowisko / PrzeÅ‚Ä…cznik |
|-------|------------|-------|--------------------------|
| Determinizm | StaÅ‚a temperatura + stabilne zestawy promptÃ³w | 1â€“6 | Ustaw `temperature=0`, `top_p=1` |
| WidocznoÅ›Ä‡ uÅ¼ycia tokenÃ³w | Nauka kosztÃ³w/efektywnoÅ›ci | 1â€“6 | `SHOW_USAGE=1` |
| Strumieniowanie pierwszego tokena | Metryka postrzeganego opÃ³Åºnienia | 1,3,4,6 | `BENCH_STREAM=1` (benchmark) |
| OdpornoÅ›Ä‡ na bÅ‚Ä™dy | ObsÅ‚uga zimnego startu | Wszystkie | `RETRY_ON_FAIL=1` + `RETRY_BACKOFF` |
| Wielomodelowi agenci | Specjalizacja rÃ³l | 5 | `AGENT_MODEL_PRIMARY`, `AGENT_MODEL_EDITOR` |
| Adaptacyjny routing | Intencje + heurystyki kosztowe | 6 | Rozszerz router o logikÄ™ eskalacji |
| PamiÄ™Ä‡ wektorowa | DÅ‚ugoterminowe przypomnienie semantyczne | 2,5,6 | Integracja indeksu embeddingu FAISS/Chroma |
| Eksport Å›ladÃ³w | Audyt i ocena | 2,5,6 | Dodawanie linii JSON na krok |
| Rubryki jakoÅ›ci | Åšledzenie jakoÅ›ci | 3â€“6 | Dodatkowe prompty oceniajÄ…ce |
| Testy wstÄ™pne | Szybka walidacja przed warsztatem | Wszystkie | `python Workshop/tests/smoke.py` |

### Deterministyczny szybki start

```powershell
set FOUNDRY_LOCAL_ALIAS=phi-4-mini
set SHOW_USAGE=1
python Workshop\tests\smoke.py
```

Oczekuj stabilnej liczby tokenÃ³w dla powtarzajÄ…cych siÄ™ identycznych wejÅ›Ä‡.

### Ocena RAG (Sesja 2)

UÅ¼yj `rag_eval_ragas.py`, aby obliczyÄ‡ trafnoÅ›Ä‡ odpowiedzi, wiernoÅ›Ä‡ i precyzjÄ™ kontekstu na maÅ‚ym syntetycznym zbiorze danych:

```powershell
python samples/session02/rag_eval_ragas.py
```

Rozszerz, dostarczajÄ…c wiÄ™kszy JSONL z pytaniami, kontekstami i prawdziwymi odpowiedziami, a nastÄ™pnie konwertujÄ…c na `Dataset` Hugging Face.

## Dodatek do dokÅ‚adnoÅ›ci poleceÅ„ CLI

Warsztat celowo uÅ¼ywa tylko aktualnie udokumentowanych/stabilnych poleceÅ„ CLI Foundry Local.

### Stabilne polecenia referencyjne

| Kategoria | Polecenie | Cel |
|-----------|-----------|-----|
| Podstawowe | `foundry --version` | PokaÅ¼ zainstalowanÄ… wersjÄ™ |
| Podstawowe | `foundry init` | Inicjalizacja konfiguracji |
| UsÅ‚uga | `foundry service start` | Uruchom lokalnÄ… usÅ‚ugÄ™ (jeÅ›li nie automatycznie) |
| UsÅ‚uga | `foundry status` | PokaÅ¼ status usÅ‚ugi |
| Modele | `foundry model list` | Lista katalogu/dostÄ™pnych modeli |
| Modele | `foundry model download <alias>` | Pobierz wagi modelu do pamiÄ™ci podrÄ™cznej |
| Modele | `foundry model run <alias>` | Uruchom (zaÅ‚aduj) model lokalnie; poÅ‚Ä…cz z `--prompt` dla jednorazowego uÅ¼ycia |
| Modele | `foundry model unload <alias>` / `foundry model stop <alias>` | WyÅ‚aduj model z pamiÄ™ci (jeÅ›li obsÅ‚ugiwane) |
| PamiÄ™Ä‡ podrÄ™czna | `foundry cache list` | Lista modeli w pamiÄ™ci podrÄ™cznej |
| System | `foundry system info` | Migawka sprzÄ™tu i moÅ¼liwoÅ›ci akceleracji |
| System | `foundry system gpu-info` | Diagnostyka GPU |
| Konfiguracja | `foundry config list` | PokaÅ¼ bieÅ¼Ä…ce wartoÅ›ci konfiguracji |
| Konfiguracja | `foundry config set <key> <value>` | Aktualizacja konfiguracji |

### Wzorzec jednorazowego promptu

Zamiast przestarzaÅ‚ego podpolecenia `model chat`, uÅ¼yj:

```powershell
foundry model run <alias> --prompt "Your question here"
```

To wykonuje pojedynczy cykl prompt/odpowiedÅº, a nastÄ™pnie koÅ„czy dziaÅ‚anie.

### UsuniÄ™te/unikane wzorce

| PrzestarzaÅ‚e/Niedokumentowane | ZastÄ™pstwo/Zalecenia |
|-------------------------------|----------------------|
| `foundry model chat <model> "..."` | `foundry model run <model> --prompt "..."` |
| `foundry model list --running` | UÅ¼yj zwykÅ‚ego `foundry model list` + ostatnia aktywnoÅ›Ä‡/logi |
| `foundry model list --cached` | `foundry cache list` |
| `foundry model stats <model>` | UÅ¼yj skryptu benchmarkowego + narzÄ™dzi systemowych (Task Manager / `nvidia-smi`) |
| `foundry model benchmark ...` | `samples/session03/benchmark_oss_models.py` |

### Benchmarking i telemetria

- OpÃ³Åºnienia, p95, tokeny/sek.: `samples/session03/benchmark_oss_models.py`
- OpÃ³Åºnienie pierwszego tokena (strumieniowanie): ustaw `BENCH_STREAM=1`
- UÅ¼ycie zasobÃ³w: Monitory systemowe (Task Manager, Activity Monitor, `nvidia-smi`) + `foundry system info`.

Gdy nowe polecenia telemetrii CLI zostanÄ… ustabilizowane, moÅ¼na je Å‚atwo wÅ‚Ä…czyÄ‡ do markdownÃ³w sesji.

### Automatyczna kontrola skÅ‚adni

Automatyczny linter zapobiega ponownemu wprowadzeniu przestarzaÅ‚ych wzorcÃ³w CLI w blokach kodu markdown:

Skrypt: `Workshop/scripts/lint_markdown_cli.py`

PrzestarzaÅ‚e wzorce sÄ… blokowane w blokach kodu.

Zalecane zamienniki:
| PrzestarzaÅ‚e | ZastÄ™pstwo |
|--------------|-----------|
| `foundry model chat <a> "..."` | `foundry model run <a> --prompt "..."` |
| `model list --running` | `model list` |
| `model list --cached` | `cache list` |
| `model stats` | Skrypt benchmarkowy + narzÄ™dzia systemowe |
| `model benchmark` | `samples/session03/benchmark_oss_models.py` |
| `model list --available` | `model list` |

Uruchom lokalnie:
```powershell
python Workshop\scripts\lint_markdown_cli.py --verbose
```

GitHub Action: `.github/workflows/markdown-cli-lint.yml` uruchamia siÄ™ przy kaÅ¼dym pushu i PR.

Opcjonalny hook pre-commit:
```bash
echo "python Workshop/scripts/lint_markdown_cli.py" > .git/hooks/pre-commit
chmod +x .git/hooks/pre-commit
```

## Szybka tabela migracji CLI â†’ SDK

| Zadanie | Jednolinijkowe CLI | RÃ³wnowaÅ¼nik SDK (Python) | Uwagi |
|---------|--------------------|--------------------------|-------|
| Uruchom model raz (prompt) | `foundry model run phi-4-mini --prompt "Hello"` | `manager=FoundryLocalManager("phi-4-mini"); client=OpenAI(base_url=manager.endpoint, api_key=manager.api_key or "not-needed"); client.chat.completions.create(model=manager.get_model_info("phi-4-mini").id, messages=[{"role":"user","content":"Hello"}])` | SDK automatycznie uruchamia usÅ‚ugÄ™ i pamiÄ™Ä‡ podrÄ™cznÄ… |
| Pobierz (cache) model | `foundry model download qwen2.5-0.5b` | `FoundryLocalManager("qwen2.5-0.5b")  # triggers download/load` | Manager wybiera najlepszy wariant, jeÅ›li alias odnosi siÄ™ do wielu wersji |
| Lista katalogu | `foundry model list` | `# uÅ¼yj managera dla kaÅ¼dego aliasu lub utrzymuj znanÄ… listÄ™` | CLI agreguje; SDK obecnie instancja per-alias |
| Lista modeli w pamiÄ™ci podrÄ™cznej | `foundry cache list` | `manager.list_cached_models()` | Po inicjalizacji managera (dowolny alias) |
| WÅ‚Ä…cz akceleracjÄ™ GPU | `foundry config set compute.onnx.enable_gpu true` | `# Akcja CLI; SDK zakÅ‚ada, Å¼e konfiguracja zostaÅ‚a juÅ¼ zastosowana` | Konfiguracja jest efektem zewnÄ™trznym |
| Pobierz URL punktu koÅ„cowego | (implicit) | `manager.endpoint` | UÅ¼ywane do tworzenia klienta kompatybilnego z OpenAI |
| Rozgrzej model | `foundry model run <alias>` a nastÄ™pnie pierwszy prompt | `chat_once(alias, messages=[...])` (utility) | NarzÄ™dzia obsÅ‚ugujÄ… poczÄ…tkowe opÃ³Åºnienie zimnego startu |
| Zmierz opÃ³Åºnienie | `python benchmark_oss_models.py` | `import benchmark_oss_models` (lub nowy skrypt eksportera) | Preferuj skrypt dla spÃ³jnych metryk |
| Zatrzymaj/wyÅ‚aduj model | `foundry model unload <alias>` | (Nie udostÄ™pnione â€“ restart usÅ‚ugi/procesu) | Zazwyczaj nie wymagane w warsztacie |
| Pobierz uÅ¼ycie tokenÃ³w | (zobacz output) | `resp.usage.total_tokens` | Dostarczane, jeÅ›li backend zwraca obiekt uÅ¼ycia |

## Eksport markdown benchmarku

UÅ¼yj skryptu `Workshop/scripts/export_benchmark_markdown.py`, aby uruchomiÄ‡ Å›wieÅ¼y benchmark (ta sama logika co `samples/session03/benchmark_oss_models.py`) i wygenerowaÄ‡ tabelÄ™ Markdown przyjaznÄ… dla GitHub oraz surowy JSON.

### PrzykÅ‚ad

```powershell
python Workshop\scripts\export_benchmark_markdown.py --models "qwen2.5-0.5b,gemma-2-2b,mistral-7b" --prompt "Explain retrieval augmented generation briefly." --rounds 3 --output benchmark_report.md
```

Wygenerowane pliki:
| Plik | ZawartoÅ›Ä‡ |
|------|-----------|
| `benchmark_report.md` | Tabela Markdown + wskazÃ³wki interpretacyjne |
| `benchmark_report.json` | Surowa tablica metryk (do porÃ³wnywania/trendÃ³w) |

Ustaw `BENCH_STREAM=1` w Å›rodowisku, aby uwzglÄ™dniÄ‡ opÃ³Åºnienie pierwszego tokena, jeÅ›li obsÅ‚ugiwane.

---

**ZastrzeÅ¼enie**:  
Ten dokument zostaÅ‚ przetÅ‚umaczony za pomocÄ… usÅ‚ugi tÅ‚umaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). ChociaÅ¼ staramy siÄ™ zapewniÄ‡ dokÅ‚adnoÅ›Ä‡, prosimy pamiÄ™taÄ‡, Å¼e automatyczne tÅ‚umaczenia mogÄ… zawieraÄ‡ bÅ‚Ä™dy lub nieÅ›cisÅ‚oÅ›ci. Oryginalny dokument w jego rodzimym jÄ™zyku powinien byÄ‡ uznawany za autorytatywne ÅºrÃ³dÅ‚o. W przypadku informacji krytycznych zaleca siÄ™ skorzystanie z profesjonalnego tÅ‚umaczenia przez czÅ‚owieka. Nie ponosimy odpowiedzialnoÅ›ci za jakiekolwiek nieporozumienia lub bÅ‚Ä™dne interpretacje wynikajÄ…ce z uÅ¼ycia tego tÅ‚umaczenia.