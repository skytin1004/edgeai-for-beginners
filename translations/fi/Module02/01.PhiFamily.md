<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20892f7994d9e5d2473ad19dfa93cf6d",
  "translation_date": "2025-09-18T09:32:28+00:00",
  "source_file": "Module02/01.PhiFamily.md",
  "language_code": "fi"
}
-->
# Osa 1: Microsoft Phi -malliperheen perusteet

Microsoft Phi -malliperhe edustaa merkitt√§v√§√§ muutosta teko√§lyn kehityksess√§, osoittaen, ett√§ kompaktit ja tehokkaat mallit voivat saavuttaa vaikuttavaa suorituskyky√§ samalla, kun ne ovat huomattavasti resurssitehokkaampia kuin perinteiset suuret kielimallit. On t√§rke√§√§ ymm√§rt√§√§, miten Phi-perhe mahdollistaa tehokkaat teko√§lyominaisuudet pienemmill√§ laskentavaatimuksilla s√§ilytt√§en korkean suorituskyvyn monenlaisissa teht√§viss√§.

## Resurssit kehitt√§jille

### Azure AI Foundry Model Catalog
Phi-malliperhe (lukuun ottamatta Phi-silicaa) on saatavilla [Azure AI Foundry Model Catalog](https://ai.azure.com/explore/models?q=phi) -katalogin kautta, mik√§ tekee kehitt√§jille helpoksi k√§ytt√§√§, hienos√§√§t√§√§ ja ottaa k√§ytt√∂√∂n n√§it√§ malleja sovelluksissaan. Katalogi tarjoaa sujuvan tavan kokeilla eri Phi-mallivaihtoehtoja ja integroida ne projekteihisi.

### Azure AI Foundry
Voit ottaa Phi-mallit k√§ytt√∂√∂n ja kokeilla niit√§ [Azure AI Foundry](https://ai.azure.com) -ymp√§rist√∂ss√§, joka tarjoaa kattavan alustan teko√§lyratkaisujen rakentamiseen, testaamiseen ja k√§ytt√∂√∂nottoon minimaalisella asetusty√∂ll√§.

### Foundry Local
Paikallista kehityst√§ ja k√§ytt√∂√∂nottoa varten tutustu [Microsoft Foundry Local](https://github.com/microsoft/foundry-local) -ty√∂kaluun, joka mahdollistaa Phi-mallien ajamisen kehityskoneellasi optimoiduilla asetuksilla.

### Dokumentaatioresurssit
- [Microsoft Research: Phi Model Technical Reports](https://ai.azure.com/labs/projects/phi-4)
- [Phi Cookbook](https://aka.ms/phicookbook)

## Johdanto

T√§ss√§ oppitunnissa tutustumme Microsoftin Phi-malliperheeseen ja sen perusk√§sitteisiin. K√§ymme l√§pi Phi-perheen kehityksen, innovatiiviset koulutusmenetelm√§t, jotka tekev√§t Phi-malleista tehokkaita, perheen keskeiset variantit ja k√§yt√§nn√∂n sovellukset eri tilanteissa.

## Oppimistavoitteet

Oppitunnin lopussa osaat:

- Ymm√§rt√§√§ Microsoftin Phi-malliperheen suunnittelufilosofian ja kehityksen.
- Tunnistaa keskeiset innovaatiot, jotka mahdollistavat Phi-mallien korkean suorituskyvyn pienemmill√§ parametreilla.
- Tunnistaa eri Phi-mallivaihtoehtojen hy√∂dyt ja rajoitukset.
- Soveltaa Phi-mallien tiet√§myst√§ valitaksesi sopivat variantit todellisiin k√§ytt√∂tapauksiin.

## Perinteisen teko√§lymallin paradigma

Perinteisesti korkean suorituskyvyn saavuttaminen luonnollisen kielen k√§sittelyss√§ on vaatinut massiivisia kielimalleja, joissa on miljardeja tai satoja miljardeja parametreja. Organisaatiot k√§ytt√§v√§t tyypillisesti n√§it√§ malleja tehokkailla GPU-klustereilla, hy√∂dynt√§en niiden ominaisuuksia API-rajapintojen tai erikoistuneen laitteiston kautta.

T√§m√§ l√§hestymistapa toimii hyvin monissa sovelluksissa, mutta sill√§ on luontaisia rajoituksia k√§yt√§nn√∂n k√§ytt√∂√∂notossa. Perinteinen menetelm√§ sis√§lt√§√§ malleja, jotka vaativat huomattavia laskentaresursseja, suuria m√§√§ri√§ muistia ja merkitt√§v√§√§ energiankulutusta. Vaikka t√§m√§ l√§hestymistapa tarjoaa p√§√§syn huipputason ominaisuuksiin, se luo riippuvuuksia kalliista laitteistosta, lis√§√§ operatiivisia kustannuksia ja rajoittaa k√§ytt√∂√∂noton joustavuutta.

## Tehokkaan teko√§lyn k√§ytt√∂√∂noton haasteet

Tehokkaamman teko√§lyn tarve on tullut yh√§ t√§rke√§mm√§ksi eri tilanteissa. Esimerkiksi sovellukset, jotka vaativat paikallista k√§ytt√∂√∂nottoa yksityisyyssyist√§, kustannusherk√§t toteutukset, joissa pilvi-API-kustannukset ovat liian korkeita, reunalaskennan skenaariot, joissa laitteistoresurssit ovat rajalliset, tai reaaliaikaiset sovellukset, joissa viive on kriittinen.

### Keskeiset k√§ytt√∂√∂noton rajoitteet

Perinteiset suuret mallien k√§ytt√∂√∂notot kohtaavat useita perustavanlaatuisia rajoitteita, jotka rajoittavat niiden k√§yt√§nn√∂n soveltuvuutta:

- **Kustannusrajoitteet**: Korkeat laskentakustannukset tekev√§t jatkuvasta k√§ytt√∂√∂notosta kallista monille organisaatioille.
- **Resurssirajoitteet**: Rajoitettu p√§√§sy huippuluokan GPU-infrastruktuuriin rajoittaa k√§ytt√∂√∂noton vaihtoehtoja.
- **Yksityisyysvaatimukset**: Herk√§t sovellukset vaativat paikallista k√§sittely√§ tietosuojan yll√§pit√§miseksi.
- **Viiveherkkyys**: Reaaliaikaiset sovellukset tarvitsevat v√§litt√∂mi√§ vastauksia ilman pilvikierroksen viivett√§.

## Microsoft Phi -mallien filosofia

Microsoft Phi -malliperhe edustaa perustavanlaatuista muutosta teko√§lymallien suunnittelufilosofiassa, jossa etusijalla ovat tehokkuus ja k√§yt√§nn√∂n k√§ytt√∂√∂notto samalla, kun s√§ilytet√§√§n vahvat suorituskykyominaisuudet. Phi-mallit saavuttavat t√§m√§n innovatiivisten arkkitehtuurien, korkealaatuisten koulutusmenetelmien ja erikoistuneiden optimointitekniikoiden avulla.

Phi-perhe kattaa erilaisia l√§hestymistapoja, jotka on suunniteltu maksimoimaan suorituskyky parametria kohden, mahdollistaen k√§ytt√∂√∂noton tavallisella laitteistolla samalla, kun tarjotaan merkitt√§vi√§ teko√§lyominaisuuksia. Tavoitteena on s√§ilytt√§√§ kilpailukykyinen suorituskyky samalla, kun laskentavaatimukset, muistink√§ytt√∂ ja operatiiviset kustannukset v√§henev√§t merkitt√§v√§sti.

### Phi-mallien keskeiset suunnitteluperiaatteet

Phi-mallit perustuvat useisiin perusperiaatteisiin, jotka erottavat ne perinteisist√§ suurista kielimalleista:

- **Tehokkuus etusijalla**: Optimoitu maksimaaliseen suorituskykyyn parametria kohden absoluuttisen skaalan sijaan.
- **Laadukas koulutus**: Keskittyminen korkealaatuiseen, kuratoituun koulutusdataan massiivisten datasetien sijaan.
- **K√§ytt√∂√∂noton joustavuus**: Suunniteltu toimimaan tehokkaasti erilaisilla laitteistokokoonpanoilla.
- **Erikoistuneet ominaisuudet**: Usein optimoitu tiettyihin teht√§viin tai aloihin maksimaalisen tehokkuuden saavuttamiseksi.

## Phi-perheen mahdollistavat keskeiset teknologiat

### "Oppikirjamainen" koulutusmenetelm√§

Yksi Phi-perheen vallankumouksellisimmista piirteist√§ on "oppikirjalaatuinen" koulutusmenetelm√§. Sen sijaan, ett√§ malleja koulutettaisiin massiivisilla m√§√§rill√§ suodattamatonta internetdataa, Phi-mallit k√§ytt√§v√§t huolellisesti kuratoitua, korkealaatuista opetusmateriaalia, joka on suunniteltu opettamaan p√§√§ttely√§, matematiikkaa, koodausta ja yleist√§ tietoa tehokkaasti.

T√§m√§ l√§hestymistapa toimii luomalla synteettist√§ opetusmateriaalia, joka j√§ljittelee korkealaatuisia oppikirjoja ja akateemisia materiaaleja. Koulutusdata on erityisesti suunniteltu pedagogisesti j√§rkev√§ksi, keskittyen selkeisiin selityksiin, vaiheittaisiin p√§√§ttelyihin ja j√§senneltyyn tiedon esitt√§miseen.

### Kehittynyt p√§√§ttelykoulutus

Uusimmat Phi-mallit sis√§lt√§v√§t kehittyneit√§ p√§√§ttelykoulutusmenetelmi√§, jotka mahdollistavat monimutkaisten monivaiheisten ongelmien ratkaisemisen. N√§ihin tekniikoihin kuuluu:

**Chain-of-Thought Training**: Mallit oppivat jakamaan monimutkaiset ongelmat v√§livaiheisiin, mik√§ tekee niiden p√§√§ttelyprosessista l√§pin√§kyv√§mm√§n ja luotettavamman.

**Inference-Time Scaling**: Mallit tuottavat yksityiskohtaisia p√§√§ttelyketjuja, jotka hy√∂dynt√§v√§t lis√§laskentaresursseja vastauksen tuottamisen aikana parantaakseen tarkkuutta.

**Edge-of-Capability Training**: Koulutusdata valitaan erityisesti haastamaan mallia sen nykyisten kykyjen rajoilla, edist√§en monimutkaisten p√§√§ttelymallien oppimista.

### Arkkitehtuuriset innovaatiot

Phi-perhe sis√§lt√§√§ useita arkkitehtuurisia optimointeja, jotka on suunniteltu erityisesti tehokkuutta varten:

**Parametrien tehokkuus**: Huolelliset arkkitehtuurivalinnat, jotka maksimoivat jokaisen parametrin vaikutuksen mallissa.

**Monimodaalinen integrointi**: Tehokas tekstin, kuvan ja puheen k√§sittelykykyjen integrointi kompakteihin arkkitehtuureihin.

**Laitteisto-optimointi**: Erikoistuneet variantit, jotka on optimoitu tiettyj√§ laitteistoalustoja ja k√§ytt√∂√∂noton skenaarioita varten.

## Phi-mallien laitteisto-optimointi

Nykyaikaiset k√§ytt√∂√∂nottoymp√§rist√∂t hy√∂tyv√§t Phi-mallien tehokkuudesta eri laitteistokokoonpanoissa:

### CPU-optimoitu k√§ytt√∂√∂notto

Phi-mallit on suunniteltu toimimaan tehokkaasti pelk√§st√§√§n CPU-laitteistolla, mik√§ tekee niist√§ helposti saatavilla tavallisella laskentainfrastruktuurilla ilman erikoistuneita teko√§lykiihdyttimi√§.

### GPU-kiihdytys

Vaikka Phi-mallit eiv√§t vaadi tehokkaita GPU:ita, ne voivat hy√∂dynt√§√§ saatavilla olevia GPU-resursseja parantaakseen suorituskyky√§, tarjoten joustavuutta k√§ytt√∂√∂noton kokoonpanoissa.

### Reunalaitteiden integrointi

Erikoistuneet variantit, kuten Phi-3-Silica, on optimoitu tiettyj√§ reunalaskenta-alustoja varten, saavuttaen vaikuttavia tehokkuusmittareita, kuten 650 tokenia sekunnissa vain 1,5 W:n virrankulutuksella.

## Phi-malliperheen hy√∂dyt

### Kustannustehokkuus

Phi-mallit v√§hent√§v√§t operatiivisia kustannuksia merkitt√§v√§sti, koska ne vaativat huomattavasti v√§hemm√§n laskentainfrastruktuuria s√§ilytt√§en kilpailukykyisen suorituskyvyn. T√§m√§ tekee teko√§lyst√§ saavutettavaa organisaatioille, joilla on rajalliset budjetit tai suurivolyymiset sovellukset, joissa kustannus per inferenssi on t√§rke√§.

### K√§ytt√∂√∂noton joustavuus

Phi-mallien tehokkuus mahdollistaa k√§ytt√∂√∂noton laajalla valikoimalla laitteistokokoonpanoja, henkil√∂kohtaisista kannettavista tietokoneista yrityspalvelimiin, tarjoten organisaatioille enemm√§n joustavuutta teko√§lyinfrastruktuurin valinnoissa.

### Yksityisyys ja turvallisuus

Phi-mallien tehokkuus mahdollistaa paikallisen k√§ytt√∂√∂noton yksityisyytt√§ vaativissa sovelluksissa, varmistaen, ett√§ arkaluontoinen data ei koskaan poistu organisaation hallinnasta samalla, kun tarjotaan tehokkaita teko√§lyominaisuuksia.

### Reaaliaikainen suorituskyky

V√§hentyneet laskentavaatimukset tarkoittavat nopeampia inferenssiaikoja, mahdollistaen reaaliaikaiset sovellukset, jotka vaativat v√§litt√∂mi√§ vastauksia tinkim√§tt√§ teko√§lyominaisuuksien laadusta.

### Saavutettava teko√§ly

V√§hent√§m√§ll√§ teko√§lyn k√§ytt√∂√∂noton esteit√§ Phi-mallit tekev√§t kehittyneist√§ teko√§lyominaisuuksista saavutettavia organisaatioille, joilla on rajalliset resurssit, mahdollistaen pienemm√§t tiimit ja yksitt√§iset kehitt√§j√§t hy√∂dynt√§m√§√§n kehittynytt√§ kielen ymm√§rryst√§.

## K√§yt√§nn√∂n esimerkit ja k√§ytt√∂tapaukset

Ennen tekniseen kehitykseen sukeltamista, tutustutaan joihinkin konkreettisiin esimerkkeihin siit√§, mit√§ Phi-mallit voivat saavuttaa:

### Matemaattisen p√§√§ttelyn esimerkki

Phi-4-mini-reasoning on erinomainen vaiheittaisessa matemaattisten ongelmien ratkaisemisessa. Esimerkiksi kysytt√§ess√§ "Kuinka ratkaista 3*x^2+4*x+5=1?", malli tarjoaa yksityiskohtaiset p√§√§ttelyvaiheet:

```
<|system|>Your name is Phi, an AI math expert developed by Microsoft.<|end|>
<|user|>How to solve 3*x^2+4*x+5=1?<|end|>
<|assistant|>
I need to solve the quadratic equation 3x¬≤ + 4x + 5 = 1.

First, let me rearrange this to standard form:
3x¬≤ + 4x + 5 = 1
3x¬≤ + 4x + 5 - 1 = 0  
3x¬≤ + 4x + 4 = 0

Now I can use the quadratic formula: x = (-b ¬± ‚àö(b¬≤ - 4ac)) / (2a)
Where a = 3, b = 4, c = 4

Let me calculate the discriminant:
b¬≤ - 4ac = 4¬≤ - 4(3)(4) = 16 - 48 = -32

Since the discriminant is negative (-32), this equation has no real solutions.
The solutions are complex: x = (-4 ¬± ‚àö(-32)) / 6 = (-4 ¬± 4i‚àö2) / 6 = (-2 ¬± 2i‚àö2) / 3
```

### Monikielinen tuki

Phi-3.5-mini-instruct osoittaa vahvoja monikielisi√§ kykyj√§ eri kielill√§. T√§ss√§ esimerkki kehotusmuodosta:

```
<|system|>You are a helpful assistant.<|end|>
<|user|>How to explain Internet for a medieval knight?<|end|>
<|assistant|>
Imagine, good sir knight, a vast network of invisible roads that span the entire realm and beyond. The Internet is like a magical system of messenger birds that can carry any message - be it text, images, or even moving pictures - instantly to any castle, village, or hamlet in the world.

Think of it as if every scribe's work could be copied and shared with thousands of people simultaneously, as if you could visit any library in any kingdom without leaving your chambers, or as if you could hold council with knights from distant lands as if they were sitting at your very table.

This "Internet" allows people to:
- Send messages faster than the swiftest horse
- Access knowledge from scholars across all kingdoms
- Trade goods without traveling to distant markets
- Share stories and news from lands you've never seen

'Tis like having a thousand scribes, merchants, and storytellers all working for you at once, good knight!
```

### Monimodaaliset ominaisuudet

Phi-4-multimodal pystyy k√§sittelem√§√§n teksti√§, kuvia ja puhetta samanaikaisesti. T√§ss√§ joitakin k√§yt√§nn√∂n sovelluksia:

**Matkasuunnittelu √§√§ni-inputilla:**
Katso, kuinka Phi-4 Multimodal analysoi puhuttua kielt√§ auttaakseen suunnittelemaan matkaa Seattleen, osoittaen sen kehittyneet √§√§nenk√§sittely- ja suositusominaisuudet.

**Matemaattisten ongelmien ratkaisu kuvista:**
Katso, kuinka Phi-4 Multimodal k√§sittelee monimutkaisia matemaattisia ongelmia visuaalisten sy√∂tteiden avulla, osoittaen sen kyvyn k√§sitell√§ ja ratkaista kuvissa esitettyj√§ yht√§l√∂it√§.

**Funktiokutsujen esimerkki:**
Funktiokutsujen avulla Phi-4-mini ja Phi-4-multimodal voivat laajentaa tekstink√§sittelyominaisuuksiaan integroimalla hakukoneita, yhdist√§m√§ll√§ erilaisia ty√∂kaluja ja paljon muuta. Kuten esimerkiss√§, malli voi hakea Valioliigan ottelutietoja Phi-4-minin avulla, osoittaen sen kyvyn olla vuorovaikutuksessa ulkoisten tietol√§hteiden kanssa saumattomasti.

### Koodin generointi

Phi-4-multimodal voi tuottaa j√§sennelty√§ projektikoodia sek√§ kuvasis√§ll√∂n ett√§ annettujen kehotusten perusteella, kuten t√§ss√§ k√§yt√§nn√∂n ty√∂nkulussa:

1. Lataa kuva wireframesta tai suunnittelusta
2. Anna konteksti projektivaatimuksista
3. Malli tuottaa t√§ydelliset, toimivat koodirakenteet
4. Koodi voidaan mukauttaa tiettyjen kehysten tai kielten mukaan

### Reunak√§ytt√∂√∂noton esimerkki

Voimme ottaa kvantisoidun mallin k√§ytt√∂√∂n reunalaitteilla. Yhdist√§m√§ll√§ Microsoft Olive ja ONNX GenAI Runtime, voimme ottaa Phi-4-minin k√§ytt√∂√∂n Windows-, iPhone-, Android- ja muilla laitteilla. T√§ss√§ esimerkki iPhone 12 Pro:lla.

K√§ytt√∂√∂notto sis√§lt√§√§:
- Mallin kvantisoinnin mobiilioptimointia varten
- ONNX-runtime-integraation alustojen v√§liseen yhteensopivuuteen
- Paikallisen inferenssin ilman internetyhteytt√§
- Reaaliaikaisen suorituskyvyn minimaalisella virrankulutuksella

## Phi-perheen kehitys

### Phi-1 ja Phi-2: Perusmallit

Varhaiset Phi-mallit loivat perustan korkealaatuiselle koulutusdatalle ja tehokkaille arkkitehtuureille:

- **Phi-1 (1.3B parametria)**: Esitteli kuratoidun koulutusdatan konseptin peruskielen ymm√§rt√§miseen ja koodin generointiin.
- **Phi-2 (2.7B parametria)**: Paransi p√§√§ttelykykyj√§ synteettisen NLP-datan ja huolellisesti suodatetun verkkosis√§ll√∂n avulla.

### Phi-3-perhe: Yleis√∂n suosio

Phi-3-sarja merkitsi l√§pimurtoa SLM-ominaisuuksissa useilla erikoistuneilla varianteilla:

- **Phi-3-mini (3.8B parametria)**: Yleiset kieliteht√§v√§t poikkeuksellisella tehokkuudella, ylitt√§en kaksi kertaa suuremmat mallit.
- **Phi-3-small (7B parametria)**: Edistynyt suorituskyky, joka voittaa GPT-3.5 Turbon eri vertailuissa.
- **Phi-3-medium (14B parametria)**: Yritystason suorituskyky, joka ylitt√§√§ Gemini 1.0 Pron.
- **Phi-3-vision (4.2B parametria)**: Monimodaaliset ominaisuudet kuvan ja tekstin k√§sittelyyn.
- **Phi-3-Silica (3.3B parametria)**: Erikoistunut optimointi Windows 11:n sis√§√§nrakennettuun k√§ytt√∂√∂nottoon.

### Phi-4-perhe: Kehittynyt p√§√§ttely

Uusin sukupolvi vie p√§√§ttelykyvyt √§√§rirajoille:

- **Phi-4 (14B parametria)**: Monimutkaisten p√§√§ttelyteht√§vien erikoistuminen, erityisesti matematiikassa.
- **Phi-4-mini (3.8B
Phi-perhe osoittaa, ett√§ teko√§lyn tulevaisuus ei perustu pelk√§st√§√§n suurempien mallien rakentamiseen, vaan √§lykk√§√§mpien ja tehokkaampien mallien kehitt√§miseen, jotka toimivat tehokkaasti monenlaisissa laiteymp√§rist√∂iss√§ s√§ilytt√§en korkean suorituskyvyn.

## Kehitys- ja integrointiesimerkit

### Nopea aloitus Transformers-kirjastolla

N√§in p√§√§set alkuun Phi-mallien kanssa Hugging Face Transformers -kirjastoa k√§ytt√§en:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load Phi-4-mini-instruct
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    attn_implementation="flash_attention_2"  # For optimized performance
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")

# Format your prompt using the chat template
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Explain quantum computing in simple terms."}
]

# Apply chat template
input_text = tokenizer.apply_chat_template(messages, tokenize=False)
inputs = tokenizer(input_text, return_tensors="pt")

# Generate response
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)
    
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### Hienos√§√§t√∂esimerkki

Seuraava esimerkki n√§ytt√§√§, kuinka Phi-4-mini-instruct-mallia hienos√§√§det√§√§n tiettyj√§ teht√§vi√§ varten:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig
from trl import SFTTrainer
from datasets import load_dataset

# Configuration for LoRA fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules="all-linear"
)

# Training configuration optimized for efficiency
training_config = TrainingArguments(
    output_dir="./phi-4-mini-finetuned",
    learning_rate=5.0e-06,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=1,
    num_train_epochs=1,
    bf16=True,
    gradient_checkpointing=True,
    warmup_ratio=0.2,
    save_steps=100
)

# Load model and tokenizer
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")
tokenizer.pad_token = tokenizer.unk_token
tokenizer.padding_side = 'right'

# Load and process dataset
train_dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_config,
    peft_config=peft_config,
    train_dataset=train_dataset,
    max_seq_length=2048,
    tokenizer=tokenizer,
    packing=True
)

# Start fine-tuning
trainer.train()
```

### Erikoistuneet kehotemuodot

**P√§√§ttelyteht√§viin (Phi-4-reasoning-plus):**
```
<|im_start|>system<|im_sep|>
You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions.

Please structure your response into two main sections:
<think>
{Thought section}
</think>
{Solution section}
<|im_end|>
<|im_start|>user<|im_sep|>
What is the derivative of x^2?
<|im_end|>
<|im_start|>assistant<|im_sep|>
```

**Matemaattisiin teht√§viin (Phi-4-mini-reasoning):**
```
<|system|>
Your name is Phi, an AI math expert developed by Microsoft.
<|end|>
<|user|>
Solve this calculus problem: Find the integral of 2x + 3
<|end|>
<|assistant|>
```

### Mobiilijulkaisu ONNX:ll√§

```python
import onnxruntime as ort
import numpy as np

# Load ONNX model for mobile deployment
session = ort.InferenceSession("phi-4-mini-quantized.onnx")

# Prepare input
input_ids = tokenizer.encode("Hello, how are you?", return_tensors="np")

# Run inference
outputs = session.run(None, {"input_ids": input_ids})
predicted_ids = outputs[0]

# Decode response
response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)
```

## Suorituskykyvertailut ja saavutukset

Phi-malliperhe on saavuttanut merkitt√§vi√§ tuloksia monilla vertailualueilla, usein ylitt√§en paljon suuremmat mallit:

### Keskeiset suorituskykykohokohdat

**Matemaattisen p√§√§ttelyn huippuosaaminen:**
- Phi-4 saavuttaa 82,5 % tarkkuuden AIME 2025 -testiss√§ (matematiikkaolympialaisten karsinta)
- Phi-4-reasoning (14B) ylitt√§√§ DeepSeek-R1-Distill-70B:n (5x suurempi) p√§√§ttelytesteiss√§
- Phi-4-mini-reasoning (3.8B) kilpailee kaksinkertaisesti suurempien mallien kanssa matemaattisessa p√§√§ttelyss√§

**Tehokkuussaavutukset:**
- Phi-3-Silica k√§sittelee 650 tokenia sekunnissa vain 1,5 W tehonkulutuksella
- Phi-4-mini (3.8B) saavuttaa vastaavan suorituskyvyn kuin paljon suuremmat mallit

**Vertailutulokset:**
- **MMLU (Massive Multitask Language Understanding)**: Kilpailukykyinen suorituskyky 57 akateemisessa aiheessa
- **HumanEval**: Vahvat koodin generointikyvyt, erityisesti Pythonissa
- **MGSM**: Monikielinen peruskoulutason matematiikan ongelmanratkaisu
- **DROP**: Monimutkaiset ymm√§rrys- ja p√§√§ttelyteht√§v√§t
- **SimpleQA**: Faktoihin perustuva vastaustarkkuus

### üìä Mallivertailutaulukko

| Malli | Parametrit | Kontekstin pituus | Keskeiset vahvuudet | Parhaat k√§ytt√∂tapaukset |
|-------|------------|-------------------|---------------------|-------------------------|
| **Phi-3-mini** | 3.8B | 4K/128K | Yleinen tehokkuus | Mobiilisovellukset, perus chatbotit |
| **Phi-3.5-mini** | 3.8B | 128K | Monikielinen tuki | Kansainv√§liset sovellukset |
| **Phi-4-mini** | 3.8B | 128K | Parannettu p√§√§ttely, funktiokutsut | Liiketoiminnan automaatio |
| **Phi-4-mini-reasoning** | 3.8B | 128K | Matemaattinen p√§√§ttely | Koulutusalustat |
| **Phi-4** | 14B | 32K | Monimutkainen p√§√§ttely | Tutkimus, edistynyt analyysi |
| **Phi-4-reasoning** | 14B | 32K/64K | Monivaiheinen p√§√§ttely | Tieteellinen laskenta |
| **Phi-4-reasoning-plus** | 14B | 32K | Maksimaalinen tarkkuus p√§√§ttelyss√§ | Kriittinen p√§√§t√∂ksenteko |
| **Phi-4-multimodal** | 5.6B | Vaihteleva | Puhe, visio, teksti | Multimediasovellukset |

## Mallin valintaopas

### Perussovelluksiin
- **Phi-3-mini**: Yksinkertainen tekstin generointi, perus Q&A, nopeat vastaukset
- **Phi-4-mini**: Parannettu p√§√§ttely funktiokutsujen kanssa

### Matemaattisiin ja p√§√§ttelyteht√§viin
- **Phi-4**: Monimutkainen matemaattinen ongelmanratkaisu ja p√§√§ttely
- **Phi-4-reasoning**: Monivaiheinen p√§√§ttely yksityiskohtaisilla selityksill√§
- **Phi-4-reasoning-plus**: Maksimaalinen tarkkuus kriittisiss√§ p√§√§ttelyteht√§viss√§
- **Phi-4-mini-reasoning**: Tehokas matemaattinen p√§√§ttely resurssirajoitteisissa ymp√§rist√∂iss√§

### Multimodaalisovelluksiin
- **Phi-3-vision**: Kuvan ja tekstin k√§sittelyn yhdistelm√§t
- **Phi-4-multimodal**: Kattavat puhe-, visio- ja tekstikyvyt

### Yritysjulkaisuun
- **Phi-3-medium**: Edistynyt kielen ymm√§rrys liiketoimintasovelluksiin
- **Phi-3-Silica**: Optimoitu tietyille laitealustoille

## Julkaisualustat ja saavutettavuus

### Pilvialustat
- **Azure AI Foundry**: T√§ysin varusteltu julkaisu yritysty√∂kaluilla
- **Hugging Face**: Avoimen l√§hdekoodin mallivarasto ja yhteis√∂resurssit
- **NVIDIA API Catalog**: Mikropalvelujen julkaisuvaihtoehdot

### Paikalliset kehityskehykset
- **Ollama**: Kevyt kehys paikalliseen mallijulkaisuun
- **ONNX Runtime**: Optimoitu eri laitekokoonpanoille  
- **DirectML**: Windows-optimoitu suorituskyky
- **llama.cpp**: Alustojen v√§linen inferenssimoottori

### Oppimisresurssit
- **Phi Portal**: Microsoft Phi -mallien virallinen dokumentaatio
- **Phi Cookbook**: Kattavat esimerkit ja opetusohjelmat
- **Tekniset raportit**: Syv√§lliset tutkimuspaperit arxivissa
- **Yhteis√∂tilat**: Hugging Face -interaktiiviset demot

### Phi-mallien k√§yt√∂n aloittaminen

#### Kehitysalustat
1. **Azure AI Foundry**: Yksinkertainen paikallinen CLI ja mallien hallinta.
2. **Hugging Face Transformers**: Nopea paikallinen kokeilu
3. **Ollama**: Yksinkertainen paikallinen julkaisu testaukseen

#### Oppimispolku
1. **Ymm√§rr√§ peruskonseptit**: Tutustu suunnitteluperiaatteisiin
2. **Kokeile eri versioita**: Testaa eri Phi-malleja ymm√§rt√§√§ksesi niiden kyvyt
3. **Harjoittele toteutusta**: Julkaise malleja testausymp√§rist√∂iss√§
4. **Laajenna k√§ytt√∂√§**: Laajenna k√§ytt√∂√§ onnistuneiden pilottien perusteella

#### Parhaat k√§yt√§nn√∂t
- **Aloita pienest√§**: K√§yt√§ Phi-mini-malleja alkuvaiheen kehitykseen
- **Optimoi kehotteet**: K√§yt√§ oikeaa chat-muotoilua parhaan tuloksen saavuttamiseksi
- **Seuraa suorituskyky√§**: Tarkkaile inferenssinopeutta ja tarkkuusmittareita
- **Huomioi laitteisto**: Sovita mallin koko k√§ytett√§viss√§ oleviin laskentaresursseihin

## Yhteenveto

Microsoftin Phi-malliperhe edustaa vallankumouksellista l√§hestymistapaa teko√§lymallien suunnittelussa, osoittaen, ett√§ pienemm√§t ja tehokkaammat mallit voivat saavuttaa merkitt√§vi√§ tuloksia monenlaisissa teht√§viss√§. Keskittym√§ll√§ korkealaatuiseen koulutusdataan ja arkkitehtuurin optimointeihin Phi-perhe tarjoaa poikkeuksellisia kykyj√§ merkitt√§v√§sti pienemmill√§ laskentavaatimuksilla verrattuna perinteisiin suuriin kielimalleihin.

## Keskeiset oppimistavoitteet

1. Ymm√§rr√§ Microsoftin Phi-malliperheen suunnittelufilosofia ja kehitys Phi-1:st√§ Phi-4:√§√§n
2. Tunnista keskeiset innovaatiot, kuten "oppikirjatason" koulutus ja arkkitehtuurin optimoinnit
3. Tunnista eri Phi-versioiden hy√∂dyt ja rajoitukset eri julkaisuskenaarioissa
4. Sovella tietoa valitaksesi sopivat Phi-mallit tiettyihin k√§ytt√∂tapauksiin ja laiterajoituksiin
5. Toteuta optimointitekniikoita Phi-mallien julkaisemiseksi resurssirajoitteisilla laitteilla
6. Selit√§ Phi-malliperheen arkkitehtuurin edut perinteisiin suuriin kielimalleihin verrattuna
7. Valitse sopiva Phi-versio tiettyjen sovellustarpeiden ja laiterajoitusten perusteella
8. Toteuta Phi-malleja sek√§ pilvi- ett√§ reunajulkaisuymp√§rist√∂iss√§ optimoiduilla kokoonpanoilla
9. Sovella kvantisointi- ja optimointitekniikoita Phi-mallien suorituskyvyn parantamiseksi kohdelaitteilla
10. Arvioi mallin koon, suorituskyvyn ja kykyjen v√§lisi√§ kompromisseja Phi-perheen sis√§ll√§

## Mit√§ seuraavaksi

- [02: Qwen Family Fundamentals](02.QwenFamily.md)

---

**Vastuuvapauslauseke**:  
T√§m√§ asiakirja on k√§√§nnetty k√§ytt√§m√§ll√§ teko√§lypohjaista k√§√§nn√∂spalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, huomioithan, ett√§ automaattiset k√§√§nn√∂kset voivat sis√§lt√§√§ virheit√§ tai ep√§tarkkuuksia. Alkuper√§ist√§ asiakirjaa sen alkuper√§isell√§ kielell√§ tulisi pit√§√§ ensisijaisena l√§hteen√§. Kriittisen tiedon osalta suositellaan ammattimaista ihmisk√§√§nn√∂st√§. Emme ole vastuussa v√§√§rink√§sityksist√§ tai virhetulkinnoista, jotka johtuvat t√§m√§n k√§√§nn√∂ksen k√§yt√∂st√§.