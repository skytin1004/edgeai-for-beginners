<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2f1754a482b6a84e07287a5b775e65b6",
  "translation_date": "2025-10-01T00:46:07+00:00",
  "source_file": "Module08/samples/04/README.md",
  "language_code": "fi"
}
-->
# Esimerkki 04: Tuotantovalmiit chat-sovellukset ChainlitillÃ¤

Kattava esimerkki, joka esittelee useita lÃ¤hestymistapoja tuotantovalmiiden chat-sovellusten rakentamiseen Microsoft Foundry Localin avulla. Mukana modernit verkkokÃ¤yttÃ¶liittymÃ¤t, suoratoistovastaukset ja huippuluokan selainteknologiat.

## SisÃ¤ltÃ¶

- **ðŸš€ Chainlit Chat -sovellus** (`app.py`): Tuotantovalmiit chat-sovellukset suoratoistolla
- **ðŸŒ WebGPU Demo** (`webgpu-demo/`): Selaimessa toimiva AI-pÃ¤Ã¤ttely laitteistokiihdytyksellÃ¤
- **ðŸŽ¨ Open WebUI -integraatio** (`open-webui-guide.md`): Ammattimainen ChatGPT-tyylinen kÃ¤yttÃ¶liittymÃ¤
- **ðŸ“š Opetuksellinen muistikirja** (`chainlit_app.ipynb`): Interaktiiviset oppimateriaalit

## Pika-aloitus

### 1. Chainlit Chat -sovellus

```cmd
# Navigate to Module08 directory
cd Module08

# Start your model
foundry model run phi-4-mini

# Run Chainlit app (using port 8080 to avoid conflicts)
chainlit run samples\04\app.py -w --port 8080
```

Avautuu osoitteessa: `http://localhost:8080`

### 2. WebGPU-selaindemo

```cmd
# Navigate to WebGPU demo
cd Module08\samples\04\webgpu-demo

# Serve the demo
python -m http.server 5173
```

Avautuu osoitteessa: `http://localhost:5173`

### 3. Open WebUI -asennus

```cmd
# Run Open WebUI with Docker
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

Avautuu osoitteessa: `http://localhost:3000`

## Arkkitehtuurimallit

### Paikallinen vs pilvipohjainen pÃ¤Ã¤tÃ¶smatriisi

| Tilanne | Suositus | Peruste |
|---------|----------|---------|
| **Tietosensitiiviset tiedot** | ðŸ  Paikallinen (Foundry) | Tiedot eivÃ¤t koskaan poistu laitteelta |
| **Monimutkainen pÃ¤Ã¤ttely** | â˜ï¸ Pilvi (Azure OpenAI) | PÃ¤Ã¤sy suurempiin malleihin |
| **Reaaliaikainen chat** | ðŸ  Paikallinen (Foundry) | Alhaisempi viive, nopeammat vastaukset |
| **Dokumenttianalyysi** | ðŸ”„ Hybridi | Paikallinen tiedon poimintaan, pilvi analyysiin |
| **Koodin generointi** | ðŸ  Paikallinen (Foundry) | Yksityisyys + erikoistuneet mallit |
| **TutkimustehtÃ¤vÃ¤t** | â˜ï¸ Pilvi (Azure OpenAI) | Laaja tietopohja tarpeen |

### Teknologiavertailu

| Teknologia | KÃ¤yttÃ¶tapaus | Edut | Haitat |
|------------|--------------|------|--------|
| **Chainlit** | Python-kehittÃ¤jÃ¤t, nopea prototyyppaus | Helppo asennus, suoratoistotuki | Vain Python |
| **WebGPU** | Maksimaalinen yksityisyys, offline-tilanteet | Selaimen oma, ei palvelinta tarvitaan | Rajoitettu mallikoko |
| **Open WebUI** | TuotantokÃ¤yttÃ¶, tiimit | Ammattimainen kÃ¤yttÃ¶liittymÃ¤, kÃ¤yttÃ¤jÃ¤hallinta | Vaatii Dockerin |

## Esivaatimukset

- **Foundry Local**: Asennettu ja kÃ¤ynnissÃ¤ ([Lataa](https://aka.ms/foundry-local-installer))
- **Python**: Versio 3.10+ virtuaaliympÃ¤ristÃ¶llÃ¤
- **Malli**: VÃ¤hintÃ¤Ã¤n yksi ladattu (`foundry model run phi-4-mini`)
- **Selain**: Chrome/Edge WebGPU-tuella demoja varten
- **Docker**: Open WebUI:lle (valinnainen)

## Asennus ja kÃ¤yttÃ¶Ã¶notto

### 1. Python-ympÃ¤ristÃ¶n asennus

```cmd
# Navigate to Module08 directory
cd Module08

# Create and activate virtual environment
py -m venv .venv
.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Foundry Local -asennus

```cmd
# Verify Foundry Local installation
foundry --version

# Start the service
foundry service start

# Load a model
foundry model run phi-4-mini

# Verify model is running
foundry service ps
```

## Esimerkkisovellukset

### Chainlit Chat -sovellus

**Ominaisuudet:**
- ðŸš€ **Reaaliaikainen suoratoisto**: Tokenit nÃ¤kyvÃ¤t niiden generoinnin aikana
- ðŸ›¡ï¸ **Vahva virheenkÃ¤sittely**: Sulava heikentyminen ja palautuminen
- ðŸŽ¨ **Moderni kÃ¤yttÃ¶liittymÃ¤**: Ammattimainen chat-kÃ¤yttÃ¶liittymÃ¤ valmiina
- ðŸ”§ **Joustava konfigurointi**: YmpÃ¤ristÃ¶muuttujat ja automaattinen tunnistus
- ðŸ“± **Responsiivinen suunnittelu**: Toimii sekÃ¤ tyÃ¶pÃ¶ydÃ¤llÃ¤ ettÃ¤ mobiililaitteilla

**Pika-aloitus:**
```cmd
# Run with default settings (recommended)
chainlit run samples\04\app.py -w --port 8080

# Use specific model
set MODEL=qwen2.5-7b
chainlit run samples\04\app.py -w --port 8080

# Manual endpoint configuration
set BASE_URL=http://localhost:51211
set API_KEY=your-api-key
chainlit run samples\04\app.py -w --port 8080
```

### WebGPU-selaindemo

**Ominaisuudet:**
- ðŸŒ **Selaimen oma AI**: Ei palvelinta tarvitaan, toimii tÃ¤ysin selaimessa
- âš¡ **WebGPU-kiihdytys**: Laitteistokiihdytys, kun saatavilla
- ðŸ”’ **Maksimaalinen yksityisyys**: Tiedot eivÃ¤t koskaan poistu laitteeltasi
- ðŸŽ¯ **Ei asennusta**: Toimii missÃ¤ tahansa yhteensopivassa selaimessa
- ðŸ”„ **Sulava varajÃ¤rjestelmÃ¤**: Siirtyy CPU:lle, jos WebGPU ei ole saatavilla

**KÃ¤ynnistys:**
```cmd
cd samples\04\webgpu-demo
python -m http.server 5173
# Open http://localhost:5173
```

### Open WebUI -integraatio

**Ominaisuudet:**
- ðŸŽ¨ **ChatGPT-tyylinen kÃ¤yttÃ¶liittymÃ¤**: Ammattimainen, tuttu UI
- ðŸ‘¥ **Monen kÃ¤yttÃ¤jÃ¤n tuki**: KÃ¤yttÃ¤jÃ¤tilit ja keskusteluhistoria
- ðŸ“ **Tiedostojen kÃ¤sittely**: Lataa ja analysoi dokumentteja
- ðŸ”„ **Mallin vaihto**: Helppo vaihto eri mallien vÃ¤lillÃ¤
- ðŸ³ **Docker-asennus**: Tuotantovalmis konttiasennus

**Pika-asennus:**
```cmd
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

## Konfigurointiviite

### YmpÃ¤ristÃ¶muuttujat

| Muuttuja | Kuvaus | Oletus | Esimerkki |
|----------|--------|--------|-----------|
| `MODEL` | KÃ¤ytettÃ¤vÃ¤ mallialias | `phi-4-mini` | `qwen2.5-7b` |
| `BASE_URL` | Foundry Local -pÃ¤Ã¤tepiste | Automaattisesti tunnistettu | `http://localhost:51211` |
| `API_KEY` | API-avain (valinnainen paikalliselle) | `""` | `your-api-key` |

## VianmÃ¤Ã¤ritys

### Yleiset ongelmat

**Chainlit-sovellus:**

1. **Palvelu ei ole kÃ¤ytettÃ¤vissÃ¤:**
   ```cmd
   # Check Foundry Local status
   foundry service status
   foundry service ps
   
   # Validate API endpoint (note: port 51211)
   curl http://localhost:51211/v1/models
   ```

2. **Porttikonfliktit:**
   ```cmd
   # Check what's using port 8080
   netstat -ano | findstr :8080
   
   # Use different port if needed
   chainlit run samples\04\app.py -w --port 3000
   ```

3. **Python-ympÃ¤ristÃ¶n ongelmat:**
   ```cmd
   # Verify correct interpreter in VS Code
   # Ctrl+Shift+P â†’ Python: Select Interpreter
   # Choose: Module08/.venv/Scripts/python.exe
   
   # Reinstall dependencies
   pip install -r requirements.txt
   ```

**WebGPU-demo:**

1. **WebGPU ei tuettu:**
   - PÃ¤ivitÃ¤ Chrome/Edge versioon 113+
   - Ota WebGPU kÃ¤yttÃ¶Ã¶n: `chrome://flags/#enable-unsafe-webgpu`
   - Tarkista GPU-tila: `chrome://gpu`
   - Demo siirtyy automaattisesti CPU:lle

2. **Mallin latausvirheet:**
   - Varmista internet-yhteys mallin latausta varten
   - Tarkista selaimen konsoli CORS-virheiden varalta
   - Varmista, ettÃ¤ palvelet HTTP:n kautta (ei file://)

**Open WebUI:**

1. **Yhteys kielletty:**
   ```cmd
   # Check Docker is running
   docker --version
   
   # Check container status
   docker ps | findstr open-webui
   
   # View container logs
   docker logs open-webui
   ```

2. **Mallit eivÃ¤t nÃ¤y:**
   ```cmd
   # Verify Foundry Local endpoint
   curl http://localhost:51211/v1/models
   
   # Restart Open WebUI
   docker restart open-webui
   ```

### Vahvistuslista

```cmd
# âœ… 1. Foundry Local Setup
foundry --version                    # Should show version
foundry service status               # Should show "running"
foundry model list                   # Should show loaded models
curl http://localhost:51211/v1/models  # Should return JSON

# âœ… 2. Python Environment  
python --version                     # Should be 3.10+
pip list | findstr chainlit         # Should show chainlit package
pip list | findstr openai           # Should show openai package

# âœ… 3. Application Testing
chainlit run samples\04\app.py -w --port 8080  # Should open browser
# Test WebGPU demo at localhost:5173
# Test Open WebUI at localhost:3000
```

## Edistynyt kÃ¤yttÃ¶

### Suorituskyvyn optimointi

**Chainlit:**
- KÃ¤ytÃ¤ suoratoistoa paremman koetun suorituskyvyn saavuttamiseksi
- Toteuta yhteyspoolaus korkeaan samanaikaisuuteen
- VÃ¤limuistita mallivastaukset toistuvia kyselyitÃ¤ varten
- Seuraa muistinkÃ¤yttÃ¶Ã¤ suurten keskusteluhistorioiden kanssa

**WebGPU:**
- KÃ¤ytÃ¤ WebGPU:ta maksimaalisen yksityisyyden ja nopeuden saavuttamiseksi
- Toteuta mallin kvantisointi pienempiÃ¤ malleja varten
- KÃ¤ytÃ¤ Web Workers -tyÃ¶ntekijÃ¶itÃ¤ taustaprosessointiin
- VÃ¤limuistita kÃ¤Ã¤nnetyt mallit selaimen tallennustilaan

**Open WebUI:**
- KÃ¤ytÃ¤ pysyviÃ¤ volyymeja keskusteluhistorian tallentamiseen
- MÃ¤Ã¤ritÃ¤ resurssirajoitukset Docker-kontille
- Toteuta varmuuskopiointistrategiat kÃ¤yttÃ¤jÃ¤tietoja varten
- Aseta kÃ¤Ã¤nteinen vÃ¤lityspalvelin SSL-pÃ¤Ã¤tteen toteuttamiseksi

### Integraatiomallit

**Paikallinen/pilvihybridi:**
```python
# Route based on complexity and privacy requirements
async def intelligent_routing(prompt: str, metadata: dict):
    if metadata.get("contains_pii"):
        return await foundry_local_completion(prompt)  # Privacy-sensitive
    elif len(prompt.split()) > 200:
        return await azure_openai_completion(prompt)   # Complex reasoning
    else:
        return await foundry_local_completion(prompt)  # Default local
```

**Monimodaalinen putkisto:**
```python
# Combine different AI capabilities
async def analyze_document(file_path: str):
    # 1. OCR with WebGPU (browser-based)
    text = await webgpu_ocr(file_path)
    
    # 2. Analysis with Foundry Local (private)
    summary = await foundry_local_analyze(text)
    
    # 3. Enhancement with cloud (if needed)
    if summary.confidence < 0.8:
        summary = await azure_openai_enhance(summary)
    
    return summary
```

## TuotantokÃ¤yttÃ¶Ã¶notto

### Tietoturva

- **API-avaimet**: KÃ¤ytÃ¤ ympÃ¤ristÃ¶muuttujia, Ã¤lÃ¤ koskaan kovakoodaa
- **Verkko**: KÃ¤ytÃ¤ HTTPS:Ã¤Ã¤ tuotannossa, harkitse VPN:Ã¤Ã¤ tiimin kÃ¤yttÃ¶Ã¶n
- **PÃ¤Ã¤synhallinta**: Toteuta autentikointi Open WebUI:lle
- **Tietosuoja**: Tarkista, mitkÃ¤ tiedot pysyvÃ¤t paikallisina ja mitkÃ¤ menevÃ¤t pilveen
- **PÃ¤ivitykset**: PidÃ¤ Foundry Local ja kontit ajan tasalla

### Seuranta ja yllÃ¤pito

- **Terveystarkistukset**: Toteuta pÃ¤Ã¤tepisteiden seuranta
- **Lokit**: Keskitetty lokien hallinta kaikista komponenteista
- **Metrikka**: Seuraa vasteaikoja, virheprosentteja, resurssien kÃ¤yttÃ¶Ã¤
- **Varmuuskopiointi**: SÃ¤Ã¤nnÃ¶llinen keskustelutietojen ja konfiguraatioiden varmuuskopiointi

## Viitteet ja resurssit

### Dokumentaatio
- [Chainlit-dokumentaatio](https://docs.chainlit.io/) - TÃ¤ydellinen kehysopas
- [Foundry Local -dokumentaatio](https://learn.microsoft.com/azure/ai-foundry/foundry-local/) - Microsoftin viralliset ohjeet
- [ONNX Runtime Web](https://onnxruntime.ai/docs/get-started/with-javascript/web.html) - WebGPU-integraatio
- [Open WebUI -dokumentaatio](https://docs.openwebui.com/) - Edistynyt konfigurointi

### Esimerkkitiedostot
- [`app.py`](../../../../../Module08/samples/04/app.py) - Tuotantovalmiit Chainlit-sovellukset
- [`chainlit_app.ipynb`](./chainlit_app.ipynb) - Opetuksellinen muistikirja
- [`webgpu-demo/`](../../../../../Module08/samples/04/webgpu-demo) - Selaimessa toimiva AI-pÃ¤Ã¤ttely
- [`open-webui-guide.md`](./open-webui-guide.md) - TÃ¤ydellinen Open WebUI -asennus

### LiittyvÃ¤t esimerkit
- [Session 4 -dokumentaatio](../../04.CuttingEdgeModels.md) - TÃ¤ydellinen session opas
- [Foundry Local -esimerkit](https://github.com/microsoft/foundry-local/tree/main/samples) - Viralliset esimerkit

---

**Vastuuvapauslauseke**:  
TÃ¤mÃ¤ asiakirja on kÃ¤Ã¤nnetty kÃ¤yttÃ¤mÃ¤llÃ¤ tekoÃ¤lypohjaista kÃ¤Ã¤nnÃ¶spalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, huomioithan, ettÃ¤ automaattiset kÃ¤Ã¤nnÃ¶kset voivat sisÃ¤ltÃ¤Ã¤ virheitÃ¤ tai epÃ¤tarkkuuksia. AlkuperÃ¤istÃ¤ asiakirjaa sen alkuperÃ¤isellÃ¤ kielellÃ¤ tulisi pitÃ¤Ã¤ ensisijaisena lÃ¤hteenÃ¤. Kriittisen tiedon osalta suositellaan ammattimaista ihmiskÃ¤Ã¤nnÃ¶stÃ¤. Emme ole vastuussa vÃ¤Ã¤rinkÃ¤sityksistÃ¤ tai virhetulkinnoista, jotka johtuvat tÃ¤mÃ¤n kÃ¤Ã¤nnÃ¶ksen kÃ¤ytÃ¶stÃ¤.