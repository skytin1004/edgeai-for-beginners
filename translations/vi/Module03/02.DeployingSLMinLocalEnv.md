<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "308873206bc5ec5d87e34ca2907d2c9c",
  "translation_date": "2025-09-18T13:09:47+00:00",
  "source_file": "Module03/02.DeployingSLMinLocalEnv.md",
  "language_code": "vi"
}
-->
# Ph·∫ßn 2: Tri·ªÉn khai M√¥i tr∆∞·ªùng C·ª•c b·ªô - Gi·∫£i ph√°p ∆Øu ti√™n B·∫£o m·∫≠t

Tri·ªÉn khai c√°c M√¥ h√¨nh Ng√¥n ng·ªØ Nh·ªè (SLMs) t·∫°i m√¥i tr∆∞·ªùng c·ª•c b·ªô ƒë√°nh d·∫•u m·ªôt s·ª± chuy·ªÉn ƒë·ªïi l·ªõn h∆∞·ªõng t·ªõi c√°c gi·∫£i ph√°p AI b·∫£o m·∫≠t, ti·∫øt ki·ªám chi ph√≠. H∆∞·ªõng d·∫´n to√†n di·ªán n√†y kh√°m ph√° hai khung n·ªÅn t·∫£ng m·∫°nh m·∫Ω‚ÄîOllama v√† Microsoft Foundry Local‚Äîgi√∫p c√°c nh√† ph√°t tri·ªÉn khai th√°c t·ªëi ƒëa ti·ªÅm nƒÉng c·ªßa SLMs trong khi v·∫´n duy tr√¨ quy·ªÅn ki·ªÉm so√°t ho√†n to√†n ƒë·ªëi v·ªõi m√¥i tr∆∞·ªùng tri·ªÉn khai c·ªßa h·ªç.

## Gi·ªõi thi·ªáu

Trong b√†i h·ªçc n√†y, ch√∫ng ta s·∫Ω kh√°m ph√° c√°c chi·∫øn l∆∞·ª£c tri·ªÉn khai n√¢ng cao cho M√¥ h√¨nh Ng√¥n ng·ªØ Nh·ªè trong m√¥i tr∆∞·ªùng c·ª•c b·ªô. Ch√∫ng ta s·∫Ω t√¨m hi·ªÉu c√°c kh√°i ni·ªám c∆° b·∫£n v·ªÅ tri·ªÉn khai AI c·ª•c b·ªô, xem x√©t hai n·ªÅn t·∫£ng h√†ng ƒë·∫ßu (Ollama v√† Microsoft Foundry Local), v√† cung c·∫•p h∆∞·ªõng d·∫´n th·ª±c ti·ªÖn ƒë·ªÉ tri·ªÉn khai c√°c gi·∫£i ph√°p s·∫µn s√†ng cho s·∫£n xu·∫•t.

## M·ª•c ti√™u h·ªçc t·∫≠p

Sau b√†i h·ªçc n√†y, b·∫°n s·∫Ω c√≥ th·ªÉ:

- Hi·ªÉu ki·∫øn tr√∫c v√† l·ª£i √≠ch c·ªßa c√°c khung tri·ªÉn khai SLM c·ª•c b·ªô.
- Tri·ªÉn khai c√°c gi·∫£i ph√°p s·∫µn s√†ng cho s·∫£n xu·∫•t b·∫±ng Ollama v√† Microsoft Foundry Local.
- So s√°nh v√† l·ª±a ch·ªçn n·ªÅn t·∫£ng ph√π h·ª£p d·ª±a tr√™n y√™u c·∫ßu v√† h·∫°n ch·∫ø c·ª• th·ªÉ.
- T·ªëi ∆∞u h√≥a tri·ªÉn khai c·ª•c b·ªô v·ªÅ hi·ªáu su·∫•t, b·∫£o m·∫≠t, v√† kh·∫£ nƒÉng m·ªü r·ªông.

## Hi·ªÉu Ki·∫øn tr√∫c Tri·ªÉn khai SLM C·ª•c b·ªô

Tri·ªÉn khai SLM c·ª•c b·ªô ƒë·∫°i di·ªán cho m·ªôt s·ª± chuy·ªÉn ƒë·ªïi c∆° b·∫£n t·ª´ c√°c d·ªãch v·ª• AI ph·ª• thu·ªôc v√†o ƒë√°m m√¢y sang c√°c gi·∫£i ph√°p b·∫£o m·∫≠t t·∫°i ch·ªó. C√°ch ti·∫øp c·∫≠n n√†y cho ph√©p c√°c t·ªï ch·ª©c duy tr√¨ quy·ªÅn ki·ªÉm so√°t ho√†n to√†n ƒë·ªëi v·ªõi c∆° s·ªü h·∫° t·∫ßng AI c·ªßa h·ªç trong khi ƒë·∫£m b·∫£o ch·ªß quy·ªÅn d·ªØ li·ªáu v√† s·ª± ƒë·ªôc l·∫≠p trong v·∫≠n h√†nh.

### Ph√¢n lo·∫°i Khung Tri·ªÉn khai

Hi·ªÉu c√°c c√°ch ti·∫øp c·∫≠n tri·ªÉn khai kh√°c nhau gi√∫p l·ª±a ch·ªçn chi·∫øn l∆∞·ª£c ph√π h·ª£p cho c√°c tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng c·ª• th·ªÉ:

- **T·∫≠p trung v√†o Ph√°t tri·ªÉn**: Thi·∫øt l·∫≠p ƒë∆°n gi·∫£n ƒë·ªÉ th·ª≠ nghi·ªám v√† t·∫°o m·∫´u.
- **C·∫•p Doanh nghi·ªáp**: C√°c gi·∫£i ph√°p s·∫µn s√†ng cho s·∫£n xu·∫•t v·ªõi kh·∫£ nƒÉng t√≠ch h·ª£p doanh nghi·ªáp.
- **ƒêa N·ªÅn t·∫£ng**: T∆∞∆°ng th√≠ch to√†n di·ªán tr√™n c√°c h·ªá ƒëi·ªÅu h√†nh v√† ph·∫ßn c·ª©ng kh√°c nhau.

### L·ª£i √≠ch Ch√≠nh c·ªßa Tri·ªÉn khai SLM C·ª•c b·ªô

Tri·ªÉn khai SLM c·ª•c b·ªô mang l·∫°i nhi·ªÅu l·ª£i √≠ch c∆° b·∫£n khi·∫øn n√≥ tr·ªü th√†nh l·ª±a ch·ªçn l√Ω t∆∞·ªüng cho c√°c ·ª©ng d·ª•ng doanh nghi·ªáp v√† nh·∫°y c·∫£m v·ªÅ b·∫£o m·∫≠t:

**B·∫£o m·∫≠t v√† Ri√™ng t∆∞**: X·ª≠ l√Ω c·ª•c b·ªô ƒë·∫£m b·∫£o d·ªØ li·ªáu nh·∫°y c·∫£m kh√¥ng bao gi·ªù r·ªùi kh·ªèi c∆° s·ªü h·∫° t·∫ßng c·ªßa t·ªï ch·ª©c, cho ph√©p tu√¢n th·ªß GDPR, HIPAA, v√† c√°c y√™u c·∫ßu quy ƒë·ªãnh kh√°c. C√°c tri·ªÉn khai c√°ch ly ho√†n to√†n c√≥ th·ªÉ th·ª±c hi·ªán ƒë∆∞·ª£c cho c√°c m√¥i tr∆∞·ªùng b·∫£o m·∫≠t, trong khi c√°c nh·∫≠t k√Ω ki·ªÉm tra ƒë·∫ßy ƒë·ªß duy tr√¨ s·ª± gi√°m s√°t b·∫£o m·∫≠t.

**Hi·ªáu qu·∫£ Chi ph√≠**: Lo·∫°i b·ªè c√°c m√¥ h√¨nh ƒë·ªãnh gi√° theo token gi√∫p gi·∫£m ƒë√°ng k·ªÉ chi ph√≠ v·∫≠n h√†nh. Y√™u c·∫ßu bƒÉng th√¥ng th·∫•p h∆°n v√† gi·∫£m s·ª± ph·ª• thu·ªôc v√†o ƒë√°m m√¢y mang l·∫°i c·∫•u tr√∫c chi ph√≠ d·ª± ƒëo√°n ƒë∆∞·ª£c cho ng√¢n s√°ch doanh nghi·ªáp.

**Hi·ªáu su·∫•t v√† ƒê·ªô tin c·∫≠y**: Th·ªùi gian suy lu·∫≠n nhanh h∆°n m√† kh√¥ng c√≥ ƒë·ªô tr·ªÖ m·∫°ng cho ph√©p c√°c ·ª©ng d·ª•ng th·ªùi gian th·ª±c. Ch·ª©c nƒÉng ngo·∫°i tuy·∫øn ƒë·∫£m b·∫£o ho·∫°t ƒë·ªông li√™n t·ª•c b·∫•t k·ªÉ k·∫øt n·ªëi internet, trong khi t·ªëi ∆∞u h√≥a t√†i nguy√™n c·ª•c b·ªô mang l·∫°i hi·ªáu su·∫•t nh·∫•t qu√°n.

## Ollama: N·ªÅn t·∫£ng Tri·ªÉn khai C·ª•c b·ªô To√†n di·ªán

### Ki·∫øn tr√∫c v√† Tri·∫øt l√Ω C·ªët l√µi

Ollama ƒë∆∞·ª£c thi·∫øt k·∫ø nh∆∞ m·ªôt n·ªÅn t·∫£ng th√¢n thi·ªán v·ªõi nh√† ph√°t tri·ªÉn, ph·ªï bi·∫øn, gi√∫p d√¢n ch·ªß h√≥a vi·ªác tri·ªÉn khai LLM c·ª•c b·ªô tr√™n c√°c c·∫•u h√¨nh ph·∫ßn c·ª©ng v√† h·ªá ƒëi·ªÅu h√†nh ƒëa d·∫°ng.

**N·ªÅn t·∫£ng K·ªπ thu·∫≠t**: ƒê∆∞·ª£c x√¢y d·ª±ng tr√™n khung llama.cpp m·∫°nh m·∫Ω, Ollama s·ª≠ d·ª•ng ƒë·ªãnh d·∫°ng m√¥ h√¨nh GGUF hi·ªáu qu·∫£ ƒë·ªÉ ƒë·∫°t hi·ªáu su·∫•t t·ªëi ∆∞u. T∆∞∆°ng th√≠ch ƒëa n·ªÅn t·∫£ng ƒë·∫£m b·∫£o h√†nh vi nh·∫•t qu√°n tr√™n c√°c m√¥i tr∆∞·ªùng Windows, macOS, v√† Linux, trong khi qu·∫£n l√Ω t√†i nguy√™n th√¥ng minh t·ªëi ∆∞u h√≥a vi·ªác s·ª≠ d·ª•ng CPU, GPU, v√† b·ªô nh·ªõ.

**Tri·∫øt l√Ω Thi·∫øt k·∫ø**: Ollama ∆∞u ti√™n s·ª± ƒë∆°n gi·∫£n m√† kh√¥ng l√†m gi·∫£m ch·ª©c nƒÉng, cung c·∫•p tri·ªÉn khai kh√¥ng c·∫ßn c·∫•u h√¨nh ƒë·ªÉ ƒë·∫°t nƒÉng su·∫•t ngay l·∫≠p t·ª©c. N·ªÅn t·∫£ng n√†y duy tr√¨ kh·∫£ nƒÉng t∆∞∆°ng th√≠ch r·ªông v·ªõi c√°c m√¥ h√¨nh trong khi cung c·∫•p API nh·∫•t qu√°n tr√™n c√°c ki·∫øn tr√∫c m√¥ h√¨nh kh√°c nhau.

### T√≠nh nƒÉng v√† Kh·∫£ nƒÉng N√¢ng cao

**Qu·∫£n l√Ω M√¥ h√¨nh Xu·∫•t s·∫Øc**: Ollama cung c·∫•p qu·∫£n l√Ω v√≤ng ƒë·ªùi m√¥ h√¨nh to√†n di·ªán v·ªõi kh·∫£ nƒÉng t·ª± ƒë·ªông t·∫£i xu·ªëng, l∆∞u tr·ªØ, v√† phi√™n b·∫£n h√≥a. N·ªÅn t·∫£ng h·ªó tr·ª£ h·ªá sinh th√°i m√¥ h√¨nh phong ph√∫ bao g·ªìm Llama 3.2, Google Gemma 2, Microsoft Phi-4, Qwen 2.5, DeepSeek, Mistral, v√† c√°c m√¥ h√¨nh nh√∫ng chuy√™n bi·ªát.

**T√πy ch·ªânh Qua Modelfiles**: Ng∆∞·ªùi d√πng n√¢ng cao c√≥ th·ªÉ t·∫°o c·∫•u h√¨nh m√¥ h√¨nh t√πy ch·ªânh v·ªõi c√°c tham s·ªë c·ª• th·ªÉ, l·ªùi nh·∫Øc h·ªá th·ªëng, v√† s·ª≠a ƒë·ªïi h√†nh vi. ƒêi·ªÅu n√†y cho ph√©p t·ªëi ∆∞u h√≥a theo lƒ©nh v·ª±c v√† ƒë√°p ·ª©ng c√°c y√™u c·∫ßu ·ª©ng d·ª•ng chuy√™n bi·ªát.

**T·ªëi ∆∞u h√≥a Hi·ªáu su·∫•t**: Ollama t·ª± ƒë·ªông ph√°t hi·ªán v√† s·ª≠ d·ª•ng tƒÉng t·ªëc ph·∫ßn c·ª©ng c√≥ s·∫µn bao g·ªìm NVIDIA CUDA, Apple Metal, v√† OpenCL. Qu·∫£n l√Ω b·ªô nh·ªõ th√¥ng minh ƒë·∫£m b·∫£o s·ª≠ d·ª•ng t√†i nguy√™n t·ªëi ∆∞u tr√™n c√°c c·∫•u h√¨nh ph·∫ßn c·ª©ng kh√°c nhau.

### Chi·∫øn l∆∞·ª£c Tri·ªÉn khai S·∫£n xu·∫•t

**C√†i ƒë·∫∑t v√† Thi·∫øt l·∫≠p**: Ollama cung c·∫•p c√†i ƒë·∫∑t ƒë∆°n gi·∫£n tr√™n c√°c n·ªÅn t·∫£ng th√¥ng qua tr√¨nh c√†i ƒë·∫∑t g·ªëc, tr√¨nh qu·∫£n l√Ω g√≥i (WinGet, Homebrew, APT), v√† c√°c container Docker cho tri·ªÉn khai d·∫°ng container.

```bash
# Cross-platform installation examples
# Windows (WinGet)
winget install Ollama.Ollama

# macOS (Homebrew)  
brew install ollama

# Linux (curl)
curl -fsSL https://ollama.com/install.sh | sh

# Docker deployment
docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
```

**L·ªánh v√† Ho·∫°t ƒë·ªông C∆° b·∫£n**:

```bash
# Model management
ollama pull qwen2.5:3b          # Download specific model
ollama pull phi4:mini           # Download Phi-4 mini variant
ollama list                     # List installed models
ollama rm <model>               # Remove model

# Model execution
ollama run qwen2.5:3b           # Interactive mode
ollama run phi4:mini "Explain quantum computing"  # Single query

# Custom model creation
ollama create enterprise-assistant -f ./Modelfile
```

**C·∫•u h√¨nh N√¢ng cao**: Modelfiles cho ph√©p t√πy ch·ªânh ph·ª©c t·∫°p cho c√°c y√™u c·∫ßu doanh nghi·ªáp:

```dockerfile
FROM qwen2.5:3b

PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER context_length 4096
PARAMETER num_gpu 1
PARAMETER num_thread 8

SYSTEM """
You are an enterprise assistant for Contoso Corporation.
Always maintain a professional tone and prioritize security best practices.
Never share confidential information without proper authentication.
"""

# Custom model knowledge (optional)
FILE ./contoso_guidelines.txt
FILE ./security_protocols.pdf
```

### V√≠ d·ª• T√≠ch h·ª£p cho Nh√† Ph√°t tri·ªÉn

**T√≠ch h·ª£p API Python**:

```python
import requests
import json

# API endpoint configuration
OLLAMA_ENDPOINT = "http://localhost:11434/api/generate"

# Model parameters
params = {
    "model": "phi4:mini",
    "prompt": "Write a function to calculate the Fibonacci sequence in Python",
    "system": "You are a helpful Python programming assistant. Provide clean, efficient code with comments.",
    "stream": False,
    "options": {
        "temperature": 0.2,
        "top_p": 0.95,
        "num_predict": 1024
    }
}

# Make API request
response = requests.post(OLLAMA_ENDPOINT, json=params)
result = response.json()

# Process and display response
print(result["response"])

# Streaming example (for real-time responses)
def stream_response():
    params["stream"] = True
    response = requests.post(OLLAMA_ENDPOINT, json=params, stream=True)
    
    for line in response.iter_lines():
        if line:
            chunk = json.loads(line)
            if "response" in chunk:
                print(chunk["response"], end="", flush=True)
            if chunk.get("done", False):
                print()
                break

# stream_response()  # Uncomment to run streaming example
```

**T√≠ch h·ª£p JavaScript/TypeScript (Node.js)**:

```javascript
const axios = require('axios');

// API configuration
const OLLAMA_API = 'http://localhost:11434/api';

// Function to generate text with Ollama
async function generateText(model, prompt, systemPrompt = '') {
  try {
    const response = await axios.post(`${OLLAMA_API}/generate`, {
      model: model,
      prompt: prompt,
      system: systemPrompt,
      stream: false,
      options: {
        temperature: 0.7,
        top_k: 40,
        top_p: 0.9,
        num_predict: 1024
      }
    });
    
    return response.data.response;
  } catch (error) {
    console.error('Error generating text:', error.message);
    throw error;
  }
}

// Example usage in an Express API
const express = require('express');
const app = express();
app.use(express.json());

app.post('/api/chat', async (req, res) => {
  const { message } = req.body;
  
  try {
    const response = await generateText(
      'phi4:mini',
      message,
      'You are a helpful AI assistant.'
    );
    
    res.json({ response });
  } catch (error) {
    res.status(500).json({ error: 'Failed to generate response' });
  }
});

app.listen(3000, () => {
  console.log('API server running on port 3000');
});
```

**S·ª≠ d·ª•ng API RESTful v·ªõi cURL**:

```bash
# Basic text generation
curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "phi4:mini",
    "prompt": "Write a recursive function to calculate factorial",
    "stream": false
  }'

# Chat completion (conversational)
curl -X POST http://localhost:11434/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen2.5:3b",
    "messages": [
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "What is edge computing?"}
    ],
    "stream": false
  }'

# Embedding generation (for vector databases)
curl -X POST http://localhost:11434/api/embeddings \
  -H "Content-Type: application/json" \
  -d '{
    "model": "nomic-embed-text",
    "prompt": "Edge AI represents a paradigm shift in artificial intelligence deployment"
  }'
```

### Tinh ch·ªânh & T·ªëi ∆∞u h√≥a Hi·ªáu su·∫•t

**C·∫•u h√¨nh B·ªô nh·ªõ & Lu·ªìng**:

```bash
# Adjust memory and thread allocation for large models
OLLAMA_HOST=0.0.0.0 OLLAMA_NUM_GPU=1 OLLAMA_NUM_THREAD=8 ollama serve

# GPU layer configuration for optimal performance
OLLAMA_GPU_LAYERS=35 ollama run qwen2.5:3b

# Run with specific CUDA device (multi-GPU systems)
CUDA_VISIBLE_DEVICES=0 ollama run phi4:mini
```

**L·ª±a ch·ªçn L∆∞·ª£ng h√≥a cho Ph·∫ßn c·ª©ng Kh√°c nhau**:

```bash
# Pull specific quantization variants for performance/quality tradeoffs
# F16 format (highest quality, highest memory usage)
ollama pull phi4:mini-f16

# Q8_0 format (high quality, moderate memory usage)
ollama pull phi4:mini-q8_0

# Q4_K_M format (good quality, lowest memory usage)
ollama pull phi4:mini-q4_k_m
```

```SYSTEM """
You are a specialized enterprise assistant focused on technical documentation and code analysis.
Provide concise, accurate responses with practical examples.
"""

TEMPLATE """{{ .System }}
User: {{ .Prompt }}
Assistant: """
```

## Microsoft Foundry Local: N·ªÅn t·∫£ng AI C·∫°nh C·∫•p Doanh Nghi·ªáp

### Ki·∫øn tr√∫c C·∫•p Doanh Nghi·ªáp

Microsoft Foundry Local ƒë·∫°i di·ªán cho m·ªôt gi·∫£i ph√°p doanh nghi·ªáp to√†n di·ªán ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·∫∑c bi·ªát cho tri·ªÉn khai AI c·∫°nh s·∫£n xu·∫•t v·ªõi t√≠ch h·ª£p s√¢u v√†o h·ªá sinh th√°i Microsoft.

**N·ªÅn t·∫£ng D·ª±a tr√™n ONNX**: ƒê∆∞·ª£c x√¢y d·ª±ng tr√™n ONNX Runtime ti√™u chu·∫©n ng√†nh, Foundry Local cung c·∫•p hi·ªáu su·∫•t t·ªëi ∆∞u tr√™n c√°c ki·∫øn tr√∫c ph·∫ßn c·ª©ng ƒëa d·∫°ng. N·ªÅn t·∫£ng t·∫≠n d·ª•ng t√≠ch h·ª£p Windows ML ƒë·ªÉ t·ªëi ∆∞u h√≥a Windows g·ªëc trong khi v·∫´n duy tr√¨ kh·∫£ nƒÉng t∆∞∆°ng th√≠ch ƒëa n·ªÅn t·∫£ng.

**TƒÉng t·ªëc Ph·∫ßn c·ª©ng Xu·∫•t s·∫Øc**: Foundry Local c√≥ kh·∫£ nƒÉng ph√°t hi·ªán v√† t·ªëi ∆∞u h√≥a ph·∫ßn c·ª©ng th√¥ng minh tr√™n CPU, GPU, v√† NPU. S·ª± h·ª£p t√°c s√¢u v·ªõi c√°c nh√† cung c·∫•p ph·∫ßn c·ª©ng (AMD, Intel, NVIDIA, Qualcomm) ƒë·∫£m b·∫£o hi·ªáu su·∫•t t·ªëi ∆∞u tr√™n c√°c c·∫•u h√¨nh ph·∫ßn c·ª©ng doanh nghi·ªáp.

### Tr·∫£i nghi·ªám Nh√† Ph√°t tri·ªÉn N√¢ng cao

**Truy c·∫≠p ƒêa Giao di·ªán**: Foundry Local cung c·∫•p c√°c giao di·ªán ph√°t tri·ªÉn to√†n di·ªán bao g·ªìm CLI m·∫°nh m·∫Ω ƒë·ªÉ qu·∫£n l√Ω v√† tri·ªÉn khai m√¥ h√¨nh, SDK ƒëa ng√¥n ng·ªØ (Python, NodeJS) ƒë·ªÉ t√≠ch h·ª£p g·ªëc, v√† API RESTful t∆∞∆°ng th√≠ch v·ªõi OpenAI ƒë·ªÉ di chuy·ªÉn li·ªÅn m·∫°ch.

**T√≠ch h·ª£p Visual Studio**: N·ªÅn t·∫£ng t√≠ch h·ª£p li·ªÅn m·∫°ch v·ªõi AI Toolkit cho VS Code, cung c·∫•p c√°c c√¥ng c·ª• chuy·ªÉn ƒë·ªïi, l∆∞·ª£ng h√≥a, v√† t·ªëi ∆∞u h√≥a m√¥ h√¨nh trong m√¥i tr∆∞·ªùng ph√°t tri·ªÉn. S·ª± t√≠ch h·ª£p n√†y tƒÉng t·ªëc quy tr√¨nh ph√°t tri·ªÉn v√† gi·∫£m ƒë·ªô ph·ª©c t·∫°p tri·ªÉn khai.

**Pipeline T·ªëi ∆∞u h√≥a M√¥ h√¨nh**: T√≠ch h·ª£p Microsoft Olive cho ph√©p c√°c quy tr√¨nh t·ªëi ∆∞u h√≥a m√¥ h√¨nh tinh vi bao g·ªìm l∆∞·ª£ng h√≥a ƒë·ªông, t·ªëi ∆∞u h√≥a ƒë·ªì th·ªã, v√† ƒëi·ªÅu ch·ªânh ph·∫ßn c·ª©ng c·ª• th·ªÉ. Kh·∫£ nƒÉng chuy·ªÉn ƒë·ªïi d·ª±a tr√™n ƒë√°m m√¢y th√¥ng qua Azure ML cung c·∫•p t·ªëi ∆∞u h√≥a quy m√¥ l·ªõn cho c√°c m√¥ h√¨nh l·ªõn.

### Chi·∫øn l∆∞·ª£c Tri·ªÉn khai S·∫£n xu·∫•t

**C√†i ƒë·∫∑t v√† C·∫•u h√¨nh**:

```bash
# Windows installation via WinGet
winget install Microsoft.FoundryLocal

# Verify installation
foundry-local --version

# Initialize local environment
foundry-local init
```

**Ho·∫°t ƒë·ªông Qu·∫£n l√Ω M√¥ h√¨nh**:

```bash
# Browse available models
foundry-local models list

# Filter by specific criteria
foundry-local models list --size small --type instruct

# Download and deploy models
foundry-local models pull microsoft/phi-4-mini
foundry-local models pull deepseek/r1-distill-qwen-1.5b

# Test model performance
foundry-local models test microsoft/phi-4-mini --benchmark
```

**C·∫•u h√¨nh Tri·ªÉn khai N√¢ng cao**:

```json
{
  "deployment": {
    "model": "microsoft/phi-4-mini",
    "hardware": {
      "preferred": "npu",
      "fallback": ["gpu", "cpu"]
    },
    "optimization": {
      "quantization": "dynamic",
      "batch_size": 4,
      "max_context": 4096
    },
    "api": {
      "port": 8080,
      "openai_compatible": true
    }
  }
}
```

### T√≠ch h·ª£p H·ªá sinh th√°i Doanh Nghi·ªáp

**B·∫£o m·∫≠t v√† Tu√¢n th·ªß**: Foundry Local cung c·∫•p c√°c t√≠nh nƒÉng b·∫£o m·∫≠t c·∫•p doanh nghi·ªáp bao g·ªìm ki·ªÉm so√°t truy c·∫≠p d·ª±a tr√™n vai tr√≤, nh·∫≠t k√Ω ki·ªÉm tra, b√°o c√°o tu√¢n th·ªß, v√† l∆∞u tr·ªØ m√¥ h√¨nh ƒë∆∞·ª£c m√£ h√≥a. T√≠ch h·ª£p v·ªõi c∆° s·ªü h·∫° t·∫ßng b·∫£o m·∫≠t c·ªßa Microsoft ƒë·∫£m b·∫£o tu√¢n th·ªß c√°c ch√≠nh s√°ch b·∫£o m·∫≠t doanh nghi·ªáp.

**D·ªãch v·ª• AI T√≠ch h·ª£p**: N·ªÅn t·∫£ng cung c·∫•p c√°c kh·∫£ nƒÉng AI s·∫µn s√†ng s·ª≠ d·ª•ng bao g·ªìm Phi Silica cho x·ª≠ l√Ω ng√¥n ng·ªØ c·ª•c b·ªô, AI Imaging cho tƒÉng c∆∞·ªùng v√† ph√¢n t√≠ch h√¨nh ·∫£nh, v√† c√°c API chuy√™n bi·ªát cho c√°c nhi·ªám v·ª• AI doanh nghi·ªáp ph·ªï bi·∫øn.

## Ph√¢n t√≠ch So s√°nh: Ollama vs Foundry Local

### So s√°nh Ki·∫øn tr√∫c K·ªπ thu·∫≠t

| **Kh√≠a c·∫°nh** | **Ollama** | **Foundry Local** |
|---------------|------------|-------------------|
| **ƒê·ªãnh d·∫°ng M√¥ h√¨nh** | GGUF (qua llama.cpp) | ONNX (qua ONNX Runtime) |
| **T·∫≠p trung N·ªÅn t·∫£ng** | ƒêa n·ªÅn t·∫£ng to√†n di·ªán | T·ªëi ∆∞u h√≥a Windows/Doanh nghi·ªáp |
| **T√≠ch h·ª£p Ph·∫ßn c·ª©ng** | H·ªó tr·ª£ GPU/CPU chung | T√≠ch h·ª£p s√¢u Windows ML, NPU |
| **T·ªëi ∆∞u h√≥a** | L∆∞·ª£ng h√≥a llama.cpp | Microsoft Olive + ONNX Runtime |
| **T√≠nh nƒÉng Doanh nghi·ªáp** | H∆∞·ªõng c·ªông ƒë·ªìng | C·∫•p doanh nghi·ªáp v·ªõi SLAs |

### ƒê·∫∑c ƒëi·ªÉm Hi·ªáu su·∫•t

**ƒêi·ªÉm m·∫°nh Hi·ªáu su·∫•t c·ªßa Ollama**:
- Hi·ªáu su·∫•t CPU v∆∞·ª£t tr·ªôi qua t·ªëi ∆∞u h√≥a llama.cpp.
- H√†nh vi nh·∫•t qu√°n tr√™n c√°c n·ªÅn t·∫£ng v√† ph·∫ßn c·ª©ng kh√°c nhau.
- S·ª≠ d·ª•ng b·ªô nh·ªõ hi·ªáu qu·∫£ v·ªõi t·∫£i m√¥ h√¨nh th√¥ng minh.
- Th·ªùi gian kh·ªüi ƒë·ªông nhanh cho c√°c k·ªãch b·∫£n ph√°t tri·ªÉn v√† th·ª≠ nghi·ªám.

**∆Øu ƒëi·ªÉm Hi·ªáu su·∫•t c·ªßa Foundry Local**:
- S·ª≠ d·ª•ng NPU v∆∞·ª£t tr·ªôi tr√™n ph·∫ßn c·ª©ng Windows hi·ªán ƒë·∫°i.
- TƒÉng t·ªëc GPU t·ªëi ∆∞u qua h·ª£p t√°c v·ªõi c√°c nh√† cung c·∫•p.
- Gi√°m s√°t v√† t·ªëi ∆∞u h√≥a hi·ªáu su·∫•t c·∫•p doanh nghi·ªáp.
- Kh·∫£ nƒÉng tri·ªÉn khai quy m√¥ l·ªõn cho m√¥i tr∆∞·ªùng s·∫£n xu·∫•t.

### Ph√¢n t√≠ch Tr·∫£i nghi·ªám Ph√°t tri·ªÉn

**Tr·∫£i nghi·ªám Ph√°t tri·ªÉn c·ªßa Ollama**:
- Y√™u c·∫ßu thi·∫øt l·∫≠p t·ªëi thi·ªÉu v·ªõi nƒÉng su·∫•t ngay l·∫≠p t·ª©c.
- Giao di·ªán d√≤ng l·ªánh tr·ª±c quan cho m·ªçi ho·∫°t ƒë·ªông.
- H·ªó tr·ª£ c·ªông ƒë·ªìng r·ªông r√£i v√† t√†i li·ªáu ƒë·∫ßy ƒë·ªß.
- T√πy ch·ªânh linh ho·∫°t qua Modelfiles.

**Tr·∫£i nghi·ªám Ph√°t tri·ªÉn c·ªßa Foundry Local**:
- T√≠ch h·ª£p IDE to√†n di·ªán v·ªõi h·ªá sinh th√°i Visual Studio.
- Quy tr√¨nh ph√°t tri·ªÉn doanh nghi·ªáp v·ªõi c√°c t√≠nh nƒÉng h·ª£p t√°c nh√≥m.
- K√™nh h·ªó tr·ª£ chuy√™n nghi·ªáp v·ªõi s·ª± h·ªó tr·ª£ t·ª´ Microsoft.
- C√¥ng c·ª• g·ª° l·ªói v√† t·ªëi ∆∞u h√≥a n√¢ng cao.

### T·ªëi ∆∞u h√≥a Tr∆∞·ªùng h·ª£p S·ª≠ d·ª•ng

**Ch·ªçn Ollama Khi**:
- Ph√°t tri·ªÉn ·ª©ng d·ª•ng ƒëa n·ªÅn t·∫£ng y√™u c·∫ßu h√†nh vi nh·∫•t qu√°n.
- ∆Øu ti√™n t√≠nh minh b·∫°ch m√£ ngu·ªìn m·ªü v√† ƒë√≥ng g√≥p c·ªông ƒë·ªìng.
- L√†m vi·ªác v·ªõi ngu·ªìn l·ª±c ho·∫∑c ng√¢n s√°ch h·∫°n ch·∫ø.
- X√¢y d·ª±ng c√°c ·ª©ng d·ª•ng th·ª≠ nghi·ªám ho·∫∑c t·∫≠p trung v√†o nghi√™n c·ª©u.
- Y√™u c·∫ßu kh·∫£ nƒÉng t∆∞∆°ng th√≠ch m√¥ h√¨nh r·ªông tr√™n c√°c ki·∫øn tr√∫c kh√°c nhau.

**Ch·ªçn Foundry Local Khi**:
- Tri·ªÉn khai ·ª©ng d·ª•ng doanh nghi·ªáp v·ªõi y√™u c·∫ßu hi·ªáu su·∫•t nghi√™m ng·∫∑t.
- T·∫≠n d·ª•ng t·ªëi ∆∞u h√≥a ph·∫ßn c·ª©ng c·ª• th·ªÉ c·ªßa Windows (NPU, Windows ML).
- Y√™u c·∫ßu h·ªó tr·ª£ doanh nghi·ªáp, SLAs, v√† c√°c t√≠nh nƒÉng tu√¢n th·ªß.
- X√¢y d·ª±ng ·ª©ng d·ª•ng s·∫£n xu·∫•t v·ªõi t√≠ch h·ª£p h·ªá sinh th√°i Microsoft.
- C·∫ßn c√°c c√¥ng c·ª• t·ªëi ∆∞u h√≥a n√¢ng cao v√† quy tr√¨nh ph√°t tri·ªÉn chuy√™n nghi·ªáp.

## Chi·∫øn l∆∞·ª£c Tri·ªÉn khai N√¢ng cao

### M√¥ h√¨nh Tri·ªÉn khai D·∫°ng Container

**Container h√≥a Ollama**:

```dockerfile
FROM ollama/ollama:latest

# Pre-load models for faster startup
RUN ollama pull qwen2.5:3b
RUN ollama pull phi4:mini

# Custom configuration
COPY modelfile ./
RUN ollama create enterprise-model -f modelfile

# Expose API port
EXPOSE 11434

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:11434/api/health || exit 1
```

**Tri·ªÉn khai Doanh Nghi·ªáp Foundry Local**:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: foundry-local-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: foundry-local
  template:
    metadata:
      labels:
        app: foundry-local
    spec:
      containers:
      - name: foundry-local
        image: microsoft/foundry-local:latest
        ports:
        - containerPort: 8080
        resources:
          requests:
            memory: "4Gi"
            cpu: "2000m"
          limits:
            memory: "8Gi"
            cpu: "4000m"
        env:
        - name: FOUNDRY_MODEL
          value: "microsoft/phi-4-mini"
        - name: FOUNDRY_HARDWARE
          value: "npu,gpu,cpu"
```

### K·ªπ thu·∫≠t T·ªëi ∆∞u h√≥a Hi·ªáu su·∫•t

**Chi·∫øn l∆∞·ª£c T·ªëi ∆∞u h√≥a Ollama**:

```bash
# GPU acceleration configuration
export OLLAMA_NUM_PARALLEL=4
export OLLAMA_MAX_LOADED_MODELS=2
export OLLAMA_FLASH_ATTENTION=1

# Memory optimization
export OLLAMA_MAX_VRAM=8G
export OLLAMA_KEEP_ALIVE=10m

# Start optimized server
ollama serve
```

**T·ªëi ∆∞u h√≥a Foundry Local**:

```json
{
  "performance": {
    "batch_processing": true,
    "parallel_requests": 8,
    "memory_optimization": {
      "enable_kv_cache": true,
      "max_cache_size": "4GB"
    },
    "hardware_scheduling": {
      "enable_dynamic_batching": true,
      "max_batch_size": 16
    }
  }
}
```

## C√¢n nh·∫Øc v·ªÅ B·∫£o m·∫≠t v√† Tu√¢n th·ªß

### Tri·ªÉn khai B·∫£o m·∫≠t Doanh Nghi·ªáp

**Th·ª±c h√†nh T·ªët nh·∫•t v·ªÅ B·∫£o m·∫≠t c·ªßa Ollama**:
- C√°ch ly m·∫°ng v·ªõi quy t·∫Øc t∆∞·ªùng l·ª≠a v√† truy c·∫≠p VPN.
- X√°c th·ª±c qua t√≠ch h·ª£p proxy ng∆∞·ª£c.
- X√°c minh t√≠nh to√†n v·∫πn m√¥ h√¨nh v√† ph√¢n ph·ªëi m√¥ h√¨nh an to√†n.
- Nh·∫≠t k√Ω ki·ªÉm tra cho truy c·∫≠p API v√† ho·∫°t ƒë·ªông m√¥ h√¨nh.

**B·∫£o m·∫≠t Doanh Nghi·ªáp c·ªßa Foundry Local**:
- Ki·ªÉm so√°t truy c·∫≠p d·ª±a tr√™n vai tr√≤ t√≠ch h·ª£p Active Directory.
- Nh·∫≠t k√Ω ki·ªÉm tra to√†n di·ªán v·ªõi b√°o c√°o tu√¢n th·ªß.
- L∆∞u tr·ªØ m√¥ h√¨nh ƒë∆∞·ª£c m√£ h√≥a v√† tri·ªÉn khai m√¥ h√¨nh an to√†n.
- T√≠ch h·ª£p v·ªõi c∆° s·ªü h·∫° t·∫ßng b·∫£o m·∫≠t c·ªßa Microsoft.

### Y√™u c·∫ßu Tu√¢n th·ªß v√† Quy ƒë·ªãnh

C·∫£ hai n·ªÅn t·∫£ng ƒë·ªÅu h·ªó tr·ª£ tu√¢n th·ªß quy ƒë·ªãnh th√¥ng qua:
- Ki·ªÉm so√°t c∆∞ tr√∫ d·ªØ li·ªáu ƒë·∫£m b·∫£o x·ª≠ l√Ω c·ª•c b·ªô.
- Nh·∫≠t k√Ω ki·ªÉm tra cho c√°c y√™u c·∫ßu b√°o c√°o quy ƒë·ªãnh.
- Ki·ªÉm so√°t truy c·∫≠p ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu nh·∫°y c·∫£m.
- M√£ h√≥a khi l∆∞u tr·ªØ v√† truy·ªÅn t·∫£i ƒë·ªÉ b·∫£o v·ªá d·ªØ li·ªáu.

## Th·ª±c h√†nh T·ªët nh·∫•t cho Tri·ªÉn khai S·∫£n xu·∫•t

### Gi√°m s√°t v√† Kh·∫£ nƒÉng Quan s√°t

**C√°c Ch·ªâ s·ªë Ch√≠nh c·∫ßn Gi√°m s√°t**:
- ƒê·ªô tr·ªÖ v√† th√¥ng l∆∞·ª£ng suy lu·∫≠n m√¥ h√¨nh.
- S·ª≠ d·ª•ng t√†i nguy√™n (CPU, GPU, b·ªô nh·ªõ).
- Th·ªùi gian ph·∫£n h·ªìi API v√† t·ª∑ l·ªá l·ªói.
- ƒê·ªô ch√≠nh x√°c m√¥ h√¨nh v√† s·ª± tr√¥i hi·ªáu su·∫•t.

**Tri·ªÉn khai Gi√°m s√°t**:

```yaml
# Prometheus monitoring configuration
- job_name: 'ollama'
  static_configs:
    - targets: ['localhost:11434']
  metrics_path: '/metrics'
  
- job_name: 'foundry-local'
  static_configs:
    - targets: ['localhost:8080']
  metrics_path: '/api/metrics'
```

### T√≠ch h·ª£p Tri·ªÉn khai Li√™n t·ª•c

**T√≠ch h·ª£p Pipeline CI/CD**:

```yaml
name: Deploy SLM Models
on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Deploy to Ollama
      run: |
        ollama pull qwen2.5:3b
        ollama create production-model -f Modelfile
        
    - name: Deploy to Foundry Local
      run: |
        foundry-local models pull microsoft/phi-4-mini
        foundry-local deploy --config production.json
```

## Xu h∆∞·ªõng v√† C√¢n nh·∫Øc T∆∞∆°ng lai

### C√¥ng ngh·ªá M·ªõi N·ªïi

C·∫£nh quan tri·ªÉn khai SLM c·ª•c b·ªô ti·∫øp t·ª•c ph√°t tri·ªÉn v·ªõi m·ªôt s·ªë xu h∆∞·ªõng ch√≠nh:

**Ki·∫øn tr√∫c M√¥ h√¨nh N√¢ng cao**: C√°c SLM th·∫ø h·ªá ti·∫øp theo v·ªõi t·ª∑ l·ªá hi·ªáu qu·∫£ v√† kh·∫£ nƒÉng ƒë∆∞·ª£c c·∫£i thi·ªán ƒëang xu·∫•t hi·ªán, bao g·ªìm c√°c m√¥ h√¨nh chuy√™n gia h·ªón h·ª£p cho kh·∫£ nƒÉng m·ªü r·ªông ƒë·ªông v√† c√°c ki·∫øn tr√∫c chuy√™n bi·ªát cho tri·ªÉn khai c·∫°nh.

**T√≠ch h·ª£p Ph·∫ßn c·ª©ng**: T√≠ch h·ª£p s√¢u h∆°n v·ªõi ph·∫ßn c·ª©ng AI chuy√™n bi·ªát bao g·ªìm NPU, silicon t√πy ch·ªânh, v√† b·ªô tƒÉng t·ªëc t√≠nh to√°n c·∫°nh s·∫Ω cung c·∫•p c√°c kh·∫£ nƒÉng hi·ªáu su·∫•t n√¢ng cao.

**Ti·∫øn h√≥a H·ªá sinh th√°i**: C√°c n·ªó l·ª±c ti√™u chu·∫©n h√≥a tr√™n c√°c n·ªÅn t·∫£ng tri·ªÉn khai v√† kh·∫£ nƒÉng t∆∞∆°ng t√°c ƒë∆∞·ª£c c·∫£i thi·ªán gi·ªØa c√°c khung s·∫Ω ƒë∆°n gi·∫£n h√≥a tri·ªÉn khai ƒëa n·ªÅn t·∫£ng.

### M√¥ h√¨nh √Åp d·ª•ng Ng√†nh

**√Åp d·ª•ng Doanh Nghi·ªáp**: Vi·ªác √°p d·ª•ng doanh nghi·ªáp ng√†y c√†ng tƒÉng ƒë∆∞·ª£c th√∫c ƒë·∫©y b·ªüi c√°c y√™u c·∫ßu b·∫£o m·∫≠t, t·ªëi ∆∞u h√≥a chi ph√≠, v√† nhu c·∫ßu tu√¢n th·ªß quy ƒë·ªãnh. C√°c lƒ©nh v·ª±c ch√≠nh ph·ªß v√† qu·ªëc ph√≤ng ƒë·∫∑c bi·ªát t·∫≠p trung v√†o c√°c tri·ªÉn khai c√°ch ly ho√†n to√†n.

**C√¢n nh·∫Øc To√†n c·∫ßu**: C√°c y√™u c·∫ßu ch·ªß quy·ªÅn d·ªØ li·ªáu qu·ªëc t·∫ø ƒëang th√∫c ƒë·∫©y vi·ªác √°p d·ª•ng tri·ªÉn khai c·ª•c b·ªô, ƒë·∫∑c bi·ªát ·ªü c√°c khu v·ª±c c√≥ quy ƒë·ªãnh b·∫£o v·ªá d·ªØ li·ªáu nghi√™m ng·∫∑t.

## Th√°ch th·ª©c v√† C√¢n nh·∫Øc

### Th√°ch th·ª©c K·ªπ thu·∫≠t

**Y√™u c·∫ßu C∆° s·ªü h·∫° t·∫ßng**: Tri·ªÉn khai c·ª•c b·ªô y√™u c·∫ßu l·∫≠p k·∫ø ho·∫°ch nƒÉng l·ª±c c·∫©n th·∫≠n v√† l·ª±a ch·ªçn ph·∫ßn c·ª©ng. C√°c t·ªï ch·ª©c ph·∫£i c√¢n b·∫±ng y√™u c·∫ßu hi·ªáu su·∫•t v·ªõi h·∫°n ch·∫ø chi ph√≠ trong khi ƒë·∫£m b·∫£o kh·∫£ nƒÉng m·ªü r·ªông cho kh·ªëi l∆∞·ª£ng c√¥ng vi·ªác ng√†y c√†ng tƒÉng.

**üîß B·∫£o tr√¨ v√† C·∫≠p nh·∫≠t**: C·∫≠p nh·∫≠t m√¥ h√¨nh th∆∞·ªùng xuy√™n, v√° b·∫£o m·∫≠t, v√† t·ªëi ∆∞u h√≥a hi·ªáu su·∫•t y√™u c·∫ßu ngu·ªìn l·ª±c v√† chuy√™n m√¥n chuy√™n d·ª•ng. C√°c pipeline tri·ªÉn khai t·ª± ƒë·ªông tr·ªü n√™n c·∫ßn thi·∫øt cho m√¥i tr∆∞·ªùng s·∫£n xu·∫•t.

### C√¢n nh·∫Øc B·∫£o m·∫≠t

**B·∫£o m·∫≠t M√¥ h√¨nh**: B·∫£o v·ªá c√°c m√¥ h√¨nh ƒë·ªôc quy·ªÅn kh·ªèi truy c·∫≠p ho·∫∑c tr√≠ch xu·∫•t tr√°i ph√©p y√™u c·∫ßu c√°c bi·ªán ph√°p b·∫£o m·∫≠t to√†n di·ªán bao g·ªìm m√£ h√≥a, ki·ªÉm so√°t truy c·∫≠p, v√† nh·∫≠t k√Ω ki·ªÉm tra.

**B·∫£o v·ªá D·ªØ li·ªáu**: ƒê·∫£m b·∫£o x·ª≠ l√Ω d·ªØ li·ªáu an to√†n trong to√†n b·ªô pipeline suy lu·∫≠n trong khi duy tr√¨ c√°c ti√™u chu·∫©n hi·ªáu su·∫•t v√† kh·∫£ nƒÉng s·ª≠ d·ª•ng.

## Danh s√°ch Ki·ªÉm tra Tri·ªÉn khai Th·ª±c ti·ªÖn

### ‚úÖ ƒê√°nh gi√° Tr∆∞·ªõc Tri·ªÉn khai

- [ ] Ph√¢n t√≠ch y√™u c·∫ßu ph·∫ßn c·ª©ng v√†

---

**Tuy√™n b·ªë mi·ªÖn tr·ª´ tr√°ch nhi·ªám**:  
T√†i li·ªáu n√†y ƒë√£ ƒë∆∞·ª£c d·ªãch b·∫±ng d·ªãch v·ª• d·ªãch thu·∫≠t AI [Co-op Translator](https://github.com/Azure/co-op-translator). M·∫∑c d√π ch√∫ng t√¥i c·ªë g·∫Øng ƒë·∫£m b·∫£o ƒë·ªô ch√≠nh x√°c, xin l∆∞u √Ω r·∫±ng c√°c b·∫£n d·ªãch t·ª± ƒë·ªông c√≥ th·ªÉ ch·ª©a l·ªói ho·∫∑c kh√¥ng ch√≠nh x√°c. T√†i li·ªáu g·ªëc b·∫±ng ng√¥n ng·ªØ b·∫£n ƒë·ªãa n√™n ƒë∆∞·ª£c coi l√† ngu·ªìn th√¥ng tin ch√≠nh th·ª©c. ƒê·ªëi v·ªõi c√°c th√¥ng tin quan tr·ªçng, khuy·∫øn ngh·ªã s·ª≠ d·ª•ng d·ªãch v·ª• d·ªãch thu·∫≠t chuy√™n nghi·ªáp b·ªüi con ng∆∞·ªùi. Ch√∫ng t√¥i kh√¥ng ch·ªãu tr√°ch nhi·ªám cho b·∫•t k·ª≥ s·ª± hi·ªÉu l·∫ßm ho·∫∑c di·ªÖn gi·∫£i sai n√†o ph√°t sinh t·ª´ vi·ªác s·ª≠ d·ª•ng b·∫£n d·ªãch n√†y.