<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2f1754a482b6a84e07287a5b775e65b6",
  "translation_date": "2025-10-01T00:56:17+00:00",
  "source_file": "Module08/samples/04/README.md",
  "language_code": "vi"
}
-->
# Máº«u 04: á»¨ng dá»¥ng Chat Sáº£n xuáº¥t vá»›i Chainlit

Má»™t máº«u toÃ n diá»‡n trÃ¬nh bÃ y nhiá»u cÃ¡ch tiáº¿p cáº­n Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c á»©ng dá»¥ng chat sáºµn sÃ ng cho sáº£n xuáº¥t sá»­ dá»¥ng Microsoft Foundry Local, vá»›i giao diá»‡n web hiá»‡n Ä‘áº¡i, pháº£n há»“i theo luá»“ng vÃ  cÃ¡c cÃ´ng nghá»‡ trÃ¬nh duyá»‡t tiÃªn tiáº¿n.

## Nhá»¯ng gÃ¬ Ä‘Æ°á»£c bao gá»“m

- **ðŸš€ á»¨ng dá»¥ng Chat Chainlit** (`app.py`): á»¨ng dá»¥ng chat sáºµn sÃ ng sáº£n xuáº¥t vá»›i pháº£n há»“i theo luá»“ng
- **ðŸŒ Demo WebGPU** (`webgpu-demo/`): Suy luáº­n AI trÃªn trÃ¬nh duyá»‡t vá»›i tÄƒng tá»‘c pháº§n cá»©ng
- **ðŸŽ¨ TÃ­ch há»£p Open WebUI** (`open-webui-guide.md`): Giao diá»‡n chuyÃªn nghiá»‡p giá»‘ng ChatGPT
- **ðŸ“š Notebook giÃ¡o dá»¥c** (`chainlit_app.ipynb`): TÃ i liá»‡u há»c táº­p tÆ°Æ¡ng tÃ¡c

## Báº¯t Ä‘áº§u nhanh

### 1. á»¨ng dá»¥ng Chat Chainlit

```cmd
# Navigate to Module08 directory
cd Module08

# Start your model
foundry model run phi-4-mini

# Run Chainlit app (using port 8080 to avoid conflicts)
chainlit run samples\04\app.py -w --port 8080
```

Má»Ÿ táº¡i: `http://localhost:8080`

### 2. Demo WebGPU trÃªn trÃ¬nh duyá»‡t

```cmd
# Navigate to WebGPU demo
cd Module08\samples\04\webgpu-demo

# Serve the demo
python -m http.server 5173
```

Má»Ÿ táº¡i: `http://localhost:5173`

### 3. CÃ i Ä‘áº·t Open WebUI

```cmd
# Run Open WebUI with Docker
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

Má»Ÿ táº¡i: `http://localhost:3000`

## Máº«u kiáº¿n trÃºc

### Ma tráº­n quyáº¿t Ä‘á»‹nh Local vs Cloud

| TÃ¬nh huá»‘ng | Khuyáº¿n nghá»‹ | LÃ½ do |
|------------|-------------|-------|
| **Dá»¯ liá»‡u nháº¡y cáº£m vá» quyá»n riÃªng tÆ°** | ðŸ  Local (Foundry) | Dá»¯ liá»‡u khÃ´ng rá»i khá»i thiáº¿t bá»‹ |
| **LÃ½ luáº­n phá»©c táº¡p** | â˜ï¸ Cloud (Azure OpenAI) | Truy cáº­p vÃ o cÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n |
| **Chat thá»i gian thá»±c** | ðŸ  Local (Foundry) | Äá»™ trá»… tháº¥p, pháº£n há»“i nhanh hÆ¡n |
| **PhÃ¢n tÃ­ch tÃ i liá»‡u** | ðŸ”„ Káº¿t há»£p | Local Ä‘á»ƒ trÃ­ch xuáº¥t, cloud Ä‘á»ƒ phÃ¢n tÃ­ch |
| **Táº¡o mÃ£** | ðŸ  Local (Foundry) | Quyá»n riÃªng tÆ° + mÃ´ hÃ¬nh chuyÃªn biá»‡t |
| **Nhiá»‡m vá»¥ nghiÃªn cá»©u** | â˜ï¸ Cloud (Azure OpenAI) | Cáº§n cÆ¡ sá»Ÿ kiáº¿n thá»©c rá»™ng |

### So sÃ¡nh cÃ´ng nghá»‡

| CÃ´ng nghá»‡ | TrÆ°á»ng há»£p sá»­ dá»¥ng | Æ¯u Ä‘iá»ƒm | NhÆ°á»£c Ä‘iá»ƒm |
|-----------|--------------------|---------|------------|
| **Chainlit** | NhÃ  phÃ¡t triá»ƒn Python, táº¡o máº«u nhanh | Dá»… thiáº¿t láº­p, há»— trá»£ theo luá»“ng | Chá»‰ há»— trá»£ Python |
| **WebGPU** | Quyá»n riÃªng tÆ° tá»‘i Ä‘a, ká»‹ch báº£n offline | TÃ­ch há»£p trÃ¬nh duyá»‡t, khÃ´ng cáº§n mÃ¡y chá»§ | KÃ­ch thÆ°á»›c mÃ´ hÃ¬nh háº¡n cháº¿ |
| **Open WebUI** | Triá»ƒn khai sáº£n xuáº¥t, nhÃ³m lÃ m viá»‡c | Giao diá»‡n chuyÃªn nghiá»‡p, quáº£n lÃ½ ngÆ°á»i dÃ¹ng | YÃªu cáº§u Docker |

## YÃªu cáº§u

- **Foundry Local**: ÄÃ£ cÃ i Ä‘áº·t vÃ  cháº¡y ([Táº£i xuá»‘ng](https://aka.ms/foundry-local-installer))
- **Python**: PhiÃªn báº£n 3.10+ vá»›i mÃ´i trÆ°á»ng áº£o
- **MÃ´ hÃ¬nh**: Ãt nháº¥t má»™t mÃ´ hÃ¬nh Ä‘Ã£ táº£i (`foundry model run phi-4-mini`)
- **TrÃ¬nh duyá»‡t**: Chrome/Edge há»— trá»£ WebGPU cho cÃ¡c demo
- **Docker**: DÃ nh cho Open WebUI (tÃ¹y chá»n)

## CÃ i Ä‘áº·t & Thiáº¿t láº­p

### 1. Thiáº¿t láº­p mÃ´i trÆ°á»ng Python

```cmd
# Navigate to Module08 directory
cd Module08

# Create and activate virtual environment
py -m venv .venv
.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Thiáº¿t láº­p Foundry Local

```cmd
# Verify Foundry Local installation
foundry --version

# Start the service
foundry service start

# Load a model
foundry model run phi-4-mini

# Verify model is running
foundry service ps
```

## á»¨ng dá»¥ng máº«u

### á»¨ng dá»¥ng Chat Chainlit

**TÃ­nh nÄƒng:**
- ðŸš€ **Pháº£n há»“i theo luá»“ng thá»i gian thá»±c**: CÃ¡c token xuáº¥t hiá»‡n khi Ä‘Æ°á»£c táº¡o
- ðŸ›¡ï¸ **Xá»­ lÃ½ lá»—i máº¡nh máº½**: Giáº£m thiá»ƒu vÃ  phá»¥c há»“i má»™t cÃ¡ch linh hoáº¡t
- ðŸŽ¨ **Giao diá»‡n hiá»‡n Ä‘áº¡i**: Giao diá»‡n chat chuyÃªn nghiá»‡p cÃ³ sáºµn
- ðŸ”§ **Cáº¥u hÃ¬nh linh hoáº¡t**: Biáº¿n mÃ´i trÆ°á»ng vÃ  tá»± Ä‘á»™ng phÃ¡t hiá»‡n
- ðŸ“± **Thiáº¿t káº¿ Ä‘Ã¡p á»©ng**: Hoáº¡t Ä‘á»™ng trÃªn cáº£ mÃ¡y tÃ­nh vÃ  thiáº¿t bá»‹ di Ä‘á»™ng

**Báº¯t Ä‘áº§u nhanh:**
```cmd
# Run with default settings (recommended)
chainlit run samples\04\app.py -w --port 8080

# Use specific model
set MODEL=qwen2.5-7b
chainlit run samples\04\app.py -w --port 8080

# Manual endpoint configuration
set BASE_URL=http://localhost:51211
set API_KEY=your-api-key
chainlit run samples\04\app.py -w --port 8080
```

### Demo WebGPU trÃªn trÃ¬nh duyá»‡t

**TÃ­nh nÄƒng:**
- ðŸŒ **AI tÃ­ch há»£p trÃ¬nh duyá»‡t**: KhÃ´ng cáº§n mÃ¡y chá»§, cháº¡y hoÃ n toÃ n trÃªn trÃ¬nh duyá»‡t
- âš¡ **TÄƒng tá»‘c WebGPU**: TÄƒng tá»‘c pháº§n cá»©ng khi kháº£ dá»¥ng
- ðŸ”’ **Quyá»n riÃªng tÆ° tá»‘i Ä‘a**: Dá»¯ liá»‡u khÃ´ng bao giá» rá»i khá»i thiáº¿t bá»‹ cá»§a báº¡n
- ðŸŽ¯ **KhÃ´ng cáº§n cÃ i Ä‘áº·t**: Hoáº¡t Ä‘á»™ng trÃªn báº¥t ká»³ trÃ¬nh duyá»‡t tÆ°Æ¡ng thÃ­ch nÃ o
- ðŸ”„ **Giáº£m thiá»ƒu linh hoáº¡t**: Tá»± Ä‘á»™ng chuyá»ƒn sang CPU náº¿u WebGPU khÃ´ng kháº£ dá»¥ng

**Cháº¡y:**
```cmd
cd samples\04\webgpu-demo
python -m http.server 5173
# Open http://localhost:5173
```

### TÃ­ch há»£p Open WebUI

**TÃ­nh nÄƒng:**
- ðŸŽ¨ **Giao diá»‡n giá»‘ng ChatGPT**: ChuyÃªn nghiá»‡p, giao diá»‡n quen thuá»™c
- ðŸ‘¥ **Há»— trá»£ nhiá»u ngÆ°á»i dÃ¹ng**: TÃ i khoáº£n ngÆ°á»i dÃ¹ng vÃ  lá»‹ch sá»­ há»™i thoáº¡i
- ðŸ“ **Xá»­ lÃ½ tá»‡p**: Táº£i lÃªn vÃ  phÃ¢n tÃ­ch tÃ i liá»‡u
- ðŸ”„ **Chuyá»ƒn Ä‘á»•i mÃ´ hÃ¬nh**: Dá»… dÃ ng chuyá»ƒn Ä‘á»•i giá»¯a cÃ¡c mÃ´ hÃ¬nh khÃ¡c nhau
- ðŸ³ **Triá»ƒn khai Docker**: Thiáº¿t láº­p container sáºµn sÃ ng sáº£n xuáº¥t

**Thiáº¿t láº­p nhanh:**
```cmd
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

## Tham chiáº¿u cáº¥u hÃ¬nh

### Biáº¿n mÃ´i trÆ°á»ng

| Biáº¿n | MÃ´ táº£ | Máº·c Ä‘á»‹nh | VÃ­ dá»¥ |
|------|-------|----------|-------|
| `MODEL` | BÃ­ danh mÃ´ hÃ¬nh sá»­ dá»¥ng | `phi-4-mini` | `qwen2.5-7b` |
| `BASE_URL` | Äiá»ƒm cuá»‘i Foundry Local | Tá»± Ä‘á»™ng phÃ¡t hiá»‡n | `http://localhost:51211` |
| `API_KEY` | KhÃ³a API (tÃ¹y chá»n cho local) | `""` | `your-api-key` |

## Xá»­ lÃ½ sá»± cá»‘

### CÃ¡c váº¥n Ä‘á» thÆ°á»ng gáº·p

**á»¨ng dá»¥ng Chainlit:**

1. **Dá»‹ch vá»¥ khÃ´ng kháº£ dá»¥ng:**
   ```cmd
   # Check Foundry Local status
   foundry service status
   foundry service ps
   
   # Validate API endpoint (note: port 51211)
   curl http://localhost:51211/v1/models
   ```

2. **Xung Ä‘á»™t cá»•ng:**
   ```cmd
   # Check what's using port 8080
   netstat -ano | findstr :8080
   
   # Use different port if needed
   chainlit run samples\04\app.py -w --port 3000
   ```

3. **Váº¥n Ä‘á» mÃ´i trÆ°á»ng Python:**
   ```cmd
   # Verify correct interpreter in VS Code
   # Ctrl+Shift+P â†’ Python: Select Interpreter
   # Choose: Module08/.venv/Scripts/python.exe
   
   # Reinstall dependencies
   pip install -r requirements.txt
   ```

**Demo WebGPU:**

1. **WebGPU khÃ´ng Ä‘Æ°á»£c há»— trá»£:**
   - Cáº­p nháº­t Chrome/Edge lÃªn phiÃªn báº£n 113+
   - Báº­t WebGPU: `chrome://flags/#enable-unsafe-webgpu`
   - Kiá»ƒm tra tráº¡ng thÃ¡i GPU: `chrome://gpu`
   - Demo sáº½ tá»± Ä‘á»™ng chuyá»ƒn sang CPU

2. **Lá»—i táº£i mÃ´ hÃ¬nh:**
   - Äáº£m báº£o káº¿t ná»‘i internet Ä‘á»ƒ táº£i mÃ´ hÃ¬nh
   - Kiá»ƒm tra console trÃ¬nh duyá»‡t Ä‘á»ƒ tÃ¬m lá»—i CORS
   - XÃ¡c minh báº¡n Ä‘ang phá»¥c vá»¥ qua HTTP (khÃ´ng pháº£i file://)

**Open WebUI:**

1. **Káº¿t ná»‘i bá»‹ tá»« chá»‘i:**
   ```cmd
   # Check Docker is running
   docker --version
   
   # Check container status
   docker ps | findstr open-webui
   
   # View container logs
   docker logs open-webui
   ```

2. **MÃ´ hÃ¬nh khÃ´ng xuáº¥t hiá»‡n:**
   ```cmd
   # Verify Foundry Local endpoint
   curl http://localhost:51211/v1/models
   
   # Restart Open WebUI
   docker restart open-webui
   ```

### Danh sÃ¡ch kiá»ƒm tra xÃ¡c thá»±c

```cmd
# âœ… 1. Foundry Local Setup
foundry --version                    # Should show version
foundry service status               # Should show "running"
foundry model list                   # Should show loaded models
curl http://localhost:51211/v1/models  # Should return JSON

# âœ… 2. Python Environment  
python --version                     # Should be 3.10+
pip list | findstr chainlit         # Should show chainlit package
pip list | findstr openai           # Should show openai package

# âœ… 3. Application Testing
chainlit run samples\04\app.py -w --port 8080  # Should open browser
# Test WebGPU demo at localhost:5173
# Test Open WebUI at localhost:3000
```

## Sá»­ dá»¥ng nÃ¢ng cao

### Tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t

**Chainlit:**
- Sá»­ dá»¥ng pháº£n há»“i theo luá»“ng Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t cáº£m nháº­n
- Triá»ƒn khai káº¿t ná»‘i pooling Ä‘á»ƒ xá»­ lÃ½ Ä‘á»“ng thá»i cao
- Bá»™ nhá»› Ä‘á»‡m pháº£n há»“i mÃ´ hÃ¬nh cho cÃ¡c truy váº¥n láº·p láº¡i
- GiÃ¡m sÃ¡t sá»­ dá»¥ng bá»™ nhá»› vá»›i lá»‹ch sá»­ há»™i thoáº¡i lá»›n

**WebGPU:**
- Sá»­ dá»¥ng WebGPU Ä‘á»ƒ Ä‘áº¡t quyá»n riÃªng tÆ° vÃ  tá»‘c Ä‘á»™ tá»‘i Ä‘a
- Triá»ƒn khai lÆ°á»£ng hÃ³a mÃ´ hÃ¬nh Ä‘á»ƒ giáº£m kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh
- Sá»­ dá»¥ng Web Workers Ä‘á»ƒ xá»­ lÃ½ ná»n
- Bá»™ nhá»› Ä‘á»‡m mÃ´ hÃ¬nh Ä‘Ã£ biÃªn dá»‹ch trong lÆ°u trá»¯ trÃ¬nh duyá»‡t

**Open WebUI:**
- Sá»­ dá»¥ng cÃ¡c volume persistent Ä‘á»ƒ lÆ°u lá»‹ch sá»­ há»™i thoáº¡i
- Cáº¥u hÃ¬nh giá»›i háº¡n tÃ i nguyÃªn cho container Docker
- Triá»ƒn khai chiáº¿n lÆ°á»£c sao lÆ°u cho dá»¯ liá»‡u ngÆ°á»i dÃ¹ng
- Thiáº¿t láº­p proxy ngÆ°á»£c Ä‘á»ƒ káº¿t thÃºc SSL

### Máº«u tÃ­ch há»£p

**Káº¿t há»£p Local/Cloud:**
```python
# Route based on complexity and privacy requirements
async def intelligent_routing(prompt: str, metadata: dict):
    if metadata.get("contains_pii"):
        return await foundry_local_completion(prompt)  # Privacy-sensitive
    elif len(prompt.split()) > 200:
        return await azure_openai_completion(prompt)   # Complex reasoning
    else:
        return await foundry_local_completion(prompt)  # Default local
```

**Pipeline Ä‘a phÆ°Æ¡ng thá»©c:**
```python
# Combine different AI capabilities
async def analyze_document(file_path: str):
    # 1. OCR with WebGPU (browser-based)
    text = await webgpu_ocr(file_path)
    
    # 2. Analysis with Foundry Local (private)
    summary = await foundry_local_analyze(text)
    
    # 3. Enhancement with cloud (if needed)
    if summary.confidence < 0.8:
        summary = await azure_openai_enhance(summary)
    
    return summary
```

## Triá»ƒn khai sáº£n xuáº¥t

### CÃ¢n nháº¯c vá» báº£o máº­t

- **KhÃ³a API**: Sá»­ dá»¥ng biáº¿n mÃ´i trÆ°á»ng, khÃ´ng bao giá» mÃ£ hÃ³a cá»©ng
- **Máº¡ng**: Sá»­ dá»¥ng HTTPS trong sáº£n xuáº¥t, cÃ¢n nháº¯c VPN cho truy cáº­p nhÃ³m
- **Kiá»ƒm soÃ¡t truy cáº­p**: Triá»ƒn khai xÃ¡c thá»±c cho Open WebUI
- **Quyá»n riÃªng tÆ° dá»¯ liá»‡u**: Kiá»ƒm tra dá»¯ liá»‡u nÃ o á»Ÿ láº¡i local vÃ  dá»¯ liá»‡u nÃ o lÃªn cloud
- **Cáº­p nháº­t**: Giá»¯ Foundry Local vÃ  cÃ¡c container Ä‘Æ°á»£c cáº­p nháº­t

### GiÃ¡m sÃ¡t vÃ  báº£o trÃ¬

- **Kiá»ƒm tra sá»©c khá»e**: Triá»ƒn khai giÃ¡m sÃ¡t Ä‘iá»ƒm cuá»‘i
- **Ghi nháº­t kÃ½**: Táº­p trung nháº­t kÃ½ tá»« táº¥t cáº£ cÃ¡c thÃ nh pháº§n
- **Sá»‘ liá»‡u**: Theo dÃµi thá»i gian pháº£n há»“i, tá»· lá»‡ lá»—i, sá»­ dá»¥ng tÃ i nguyÃªn
- **Sao lÆ°u**: Sao lÆ°u thÆ°á»ng xuyÃªn dá»¯ liá»‡u há»™i thoáº¡i vÃ  cáº¥u hÃ¬nh

## TÃ i liá»‡u tham kháº£o vÃ  tÃ i nguyÃªn

### TÃ i liá»‡u

- [TÃ i liá»‡u Chainlit](https://docs.chainlit.io/) - HÆ°á»›ng dáº«n Ä‘áº§y Ä‘á»§ vá» framework
- [TÃ i liá»‡u Foundry Local](https://learn.microsoft.com/azure/ai-foundry/foundry-local/) - TÃ i liá»‡u chÃ­nh thá»©c cá»§a Microsoft
- [ONNX Runtime Web](https://onnxruntime.ai/docs/get-started/with-javascript/web.html) - TÃ­ch há»£p WebGPU
- [TÃ i liá»‡u Open WebUI](https://docs.openwebui.com/) - Cáº¥u hÃ¬nh nÃ¢ng cao

### Tá»‡p máº«u

- [`app.py`](../../../../../Module08/samples/04/app.py) - á»¨ng dá»¥ng Chainlit sáº£n xuáº¥t
- [`chainlit_app.ipynb`](./chainlit_app.ipynb) - Notebook giÃ¡o dá»¥c
- [`webgpu-demo/`](../../../../../Module08/samples/04/webgpu-demo) - Suy luáº­n AI trÃªn trÃ¬nh duyá»‡t
- [`open-webui-guide.md`](./open-webui-guide.md) - HÆ°á»›ng dáº«n thiáº¿t láº­p Open WebUI hoÃ n chá»‰nh

### Máº«u liÃªn quan

- [TÃ i liá»‡u PhiÃªn 4](../../04.CuttingEdgeModels.md) - HÆ°á»›ng dáº«n phiÃªn Ä‘áº§y Ä‘á»§
- [Máº«u Foundry Local](https://github.com/microsoft/foundry-local/tree/main/samples) - Máº«u chÃ­nh thá»©c

---

**TuyÃªn bá»‘ miá»…n trá»« trÃ¡ch nhiá»‡m**:  
TÃ i liá»‡u nÃ y Ä‘Ã£ Ä‘Æ°á»£c dá»‹ch báº±ng dá»‹ch vá»¥ dá»‹ch thuáº­t AI [Co-op Translator](https://github.com/Azure/co-op-translator). Máº·c dÃ¹ chÃºng tÃ´i cá»‘ gáº¯ng Ä‘áº£m báº£o Ä‘á»™ chÃ­nh xÃ¡c, xin lÆ°u Ã½ ráº±ng cÃ¡c báº£n dá»‹ch tá»± Ä‘á»™ng cÃ³ thá»ƒ chá»©a lá»—i hoáº·c khÃ´ng chÃ­nh xÃ¡c. TÃ i liá»‡u gá»‘c báº±ng ngÃ´n ngá»¯ báº£n Ä‘á»‹a nÃªn Ä‘Æ°á»£c coi lÃ  nguá»“n thÃ´ng tin chÃ­nh thá»©c. Äá»‘i vá»›i cÃ¡c thÃ´ng tin quan trá»ng, khuyáº¿n nghá»‹ sá»­ dá»¥ng dá»‹ch vá»¥ dá»‹ch thuáº­t chuyÃªn nghiá»‡p bá»Ÿi con ngÆ°á»i. ChÃºng tÃ´i khÃ´ng chá»‹u trÃ¡ch nhiá»‡m cho báº¥t ká»³ sá»± hiá»ƒu láº§m hoáº·c diá»…n giáº£i sai nÃ o phÃ¡t sinh tá»« viá»‡c sá»­ dá»¥ng báº£n dá»‹ch nÃ y.