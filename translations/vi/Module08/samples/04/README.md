<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "562ac0eae12d808c9f45fbb77eb5c84f",
  "translation_date": "2025-09-25T00:08:44+00:00",
  "source_file": "Module08/samples/04/README.md",
  "language_code": "vi"
}
-->
# M·∫´u 04: ·ª®ng d·ª•ng Chat S·∫£n xu·∫•t v·ªõi Chainlit

M·ªôt m·∫´u to√†n di·ªán minh h·ªça nhi·ªÅu c√°ch ti·∫øp c·∫≠n ƒë·ªÉ x√¢y d·ª±ng ·ª©ng d·ª•ng chat s·∫µn s√†ng cho s·∫£n xu·∫•t s·ª≠ d·ª•ng Microsoft Foundry Local, v·ªõi giao di·ªán web hi·ªán ƒë·∫°i, ph·∫£n h·ªìi theo lu·ªìng, v√† c√°c c√¥ng ngh·ªá tr√¨nh duy·ªát ti√™n ti·∫øn.

## N·ªôi dung bao g·ªìm

- **üöÄ ·ª®ng d·ª•ng Chat Chainlit** (`app.py`): ·ª®ng d·ª•ng chat s·∫µn s√†ng s·∫£n xu·∫•t v·ªõi ph·∫£n h·ªìi theo lu·ªìng
- **üåê Demo WebGPU** (`webgpu-demo/`): Suy lu·∫≠n AI tr√™n tr√¨nh duy·ªát v·ªõi tƒÉng t·ªëc ph·∫ßn c·ª©ng
- **üé® T√≠ch h·ª£p Open WebUI** (`open-webui-guide.md`): Giao di·ªán chuy√™n nghi·ªáp gi·ªëng ChatGPT
- **üìö Notebook gi√°o d·ª•c** (`chainlit_app.ipynb`): T√†i li·ªáu h·ªçc t·∫≠p t∆∞∆°ng t√°c

## B·∫Øt ƒë·∫ßu nhanh

### 1. ·ª®ng d·ª•ng Chat Chainlit

```cmd
# Navigate to Module08 directory
cd Module08

# Start your model
foundry model run phi-4-mini

# Run Chainlit app (using port 8080 to avoid conflicts)
chainlit run samples\04\app.py -w --port 8080
```

M·ªü t·∫°i: `http://localhost:8080`

### 2. Demo WebGPU tr√™n tr√¨nh duy·ªát

```cmd
# Navigate to WebGPU demo
cd Module08\samples\04\webgpu-demo

# Serve the demo
python -m http.server 5173
```

M·ªü t·∫°i: `http://localhost:5173`

### 3. C√†i ƒë·∫∑t Open WebUI

```cmd
# Run Open WebUI with Docker
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

M·ªü t·∫°i: `http://localhost:3000`

## M·∫´u Ki·∫øn tr√∫c

### Ma tr·∫≠n quy·∫øt ƒë·ªãnh Local vs Cloud

| T√¨nh hu·ªëng | Khuy·∫øn ngh·ªã | L√Ω do |
|------------|-------------|-------|
| **D·ªØ li·ªáu nh·∫°y c·∫£m v·ªÅ quy·ªÅn ri√™ng t∆∞** | üè† Local (Foundry) | D·ªØ li·ªáu kh√¥ng r·ªùi kh·ªèi thi·∫øt b·ªã |
| **L√Ω lu·∫≠n ph·ª©c t·∫°p** | ‚òÅÔ∏è Cloud (Azure OpenAI) | Truy c·∫≠p v√†o c√°c m√¥ h√¨nh l·ªõn h∆°n |
| **Chat th·ªùi gian th·ª±c** | üè† Local (Foundry) | ƒê·ªô tr·ªÖ th·∫•p, ph·∫£n h·ªìi nhanh h∆°n |
| **Ph√¢n t√≠ch t√†i li·ªáu** | üîÑ Hybrid | Local ƒë·ªÉ tr√≠ch xu·∫•t, cloud ƒë·ªÉ ph√¢n t√≠ch |
| **T·∫°o m√£** | üè† Local (Foundry) | Quy·ªÅn ri√™ng t∆∞ + m√¥ h√¨nh chuy√™n bi·ªát |
| **Nhi·ªám v·ª• nghi√™n c·ª©u** | ‚òÅÔ∏è Cloud (Azure OpenAI) | C·∫ßn c∆° s·ªü ki·∫øn th·ª©c r·ªông |

### So s√°nh c√¥ng ngh·ªá

| C√¥ng ngh·ªá | Tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng | ∆Øu ƒëi·ªÉm | Nh∆∞·ª£c ƒëi·ªÉm |
|-----------|--------------------|---------|------------|
| **Chainlit** | Nh√† ph√°t tri·ªÉn Python, t·∫°o m·∫´u nhanh | C√†i ƒë·∫∑t d·ªÖ d√†ng, h·ªó tr·ª£ lu·ªìng | Ch·ªâ h·ªó tr·ª£ Python |
| **WebGPU** | Quy·ªÅn ri√™ng t∆∞ t·ªëi ƒëa, k·ªãch b·∫£n offline | T√≠ch h·ª£p tr√¨nh duy·ªát, kh√¥ng c·∫ßn m√°y ch·ªß | K√≠ch th∆∞·ªõc m√¥ h√¨nh h·∫°n ch·∫ø |
| **Open WebUI** | Tri·ªÉn khai s·∫£n xu·∫•t, nh√≥m l√†m vi·ªác | Giao di·ªán chuy√™n nghi·ªáp, qu·∫£n l√Ω ng∆∞·ªùi d√πng | Y√™u c·∫ßu Docker |

## Y√™u c·∫ßu

- **Foundry Local**: ƒê√£ c√†i ƒë·∫∑t v√† ch·∫°y ([T·∫£i xu·ªëng](https://aka.ms/foundry-local-installer))
- **Python**: Phi√™n b·∫£n 3.10+ v·ªõi m√¥i tr∆∞·ªùng ·∫£o
- **M√¥ h√¨nh**: √çt nh·∫•t m·ªôt m√¥ h√¨nh ƒë√£ t·∫£i (`foundry model run phi-4-mini`)
- **Tr√¨nh duy·ªát**: Chrome/Edge h·ªó tr·ª£ WebGPU cho c√°c demo
- **Docker**: D√†nh cho Open WebUI (t√πy ch·ªçn)

## C√†i ƒë·∫∑t & Thi·∫øt l·∫≠p

### 1. Thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng Python

```cmd
# Navigate to Module08 directory
cd Module08

# Create and activate virtual environment
py -m venv .venv
.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Thi·∫øt l·∫≠p Foundry Local

```cmd
# Verify Foundry Local installation
foundry --version

# Start the service
foundry service start

# Load a model
foundry model run phi-4-mini

# Verify model is running
foundry service ps
```

## ·ª®ng d·ª•ng m·∫´u

### ·ª®ng d·ª•ng Chat Chainlit

**T√≠nh nƒÉng:**
- üöÄ **Ph·∫£n h·ªìi theo lu·ªìng th·ªùi gian th·ª±c**: C√°c token xu·∫•t hi·ªán khi ƒë∆∞·ª£c t·∫°o
- üõ°Ô∏è **X·ª≠ l√Ω l·ªói m·∫°nh m·∫Ω**: Gi·∫£m thi·ªÉu v√† ph·ª•c h·ªìi m·ªôt c√°ch linh ho·∫°t
- üé® **Giao di·ªán hi·ªán ƒë·∫°i**: Giao di·ªán chat chuy√™n nghi·ªáp c√≥ s·∫µn
- üîß **C·∫•u h√¨nh linh ho·∫°t**: Bi·∫øn m√¥i tr∆∞·ªùng v√† t·ª± ƒë·ªông ph√°t hi·ªán
- üì± **Thi·∫øt k·∫ø ƒë√°p ·ª©ng**: Ho·∫°t ƒë·ªông tr√™n c·∫£ m√°y t√≠nh v√† thi·∫øt b·ªã di ƒë·ªông

**B·∫Øt ƒë·∫ßu nhanh:**
```cmd
# Run with default settings (recommended)
chainlit run samples\04\app.py -w --port 8080

# Use specific model
set MODEL=qwen2.5-7b-instruct
chainlit run samples\04\app.py -w --port 8080

# Manual endpoint configuration
set BASE_URL=http://localhost:51211
set API_KEY=your-api-key
chainlit run samples\04\app.py -w --port 8080
```

### Demo WebGPU tr√™n tr√¨nh duy·ªát

**T√≠nh nƒÉng:**
- üåê **AI t√≠ch h·ª£p tr√¨nh duy·ªát**: Kh√¥ng c·∫ßn m√°y ch·ªß, ch·∫°y ho√†n to√†n tr√™n tr√¨nh duy·ªát
- ‚ö° **TƒÉng t·ªëc WebGPU**: TƒÉng t·ªëc ph·∫ßn c·ª©ng khi kh·∫£ d·ª•ng
- üîí **Quy·ªÅn ri√™ng t∆∞ t·ªëi ƒëa**: D·ªØ li·ªáu kh√¥ng bao gi·ªù r·ªùi kh·ªèi thi·∫øt b·ªã c·ªßa b·∫°n
- üéØ **Kh√¥ng c·∫ßn c√†i ƒë·∫∑t**: Ho·∫°t ƒë·ªông tr√™n b·∫•t k·ª≥ tr√¨nh duy·ªát t∆∞∆°ng th√≠ch n√†o
- üîÑ **D·ª± ph√≤ng linh ho·∫°t**: T·ª± ƒë·ªông chuy·ªÉn sang CPU n·∫øu WebGPU kh√¥ng kh·∫£ d·ª•ng

**Ch·∫°y:**
```cmd
cd samples\04\webgpu-demo
python -m http.server 5173
# Open http://localhost:5173
```

### T√≠ch h·ª£p Open WebUI

**T√≠nh nƒÉng:**
- üé® **Giao di·ªán gi·ªëng ChatGPT**: Chuy√™n nghi·ªáp, giao di·ªán quen thu·ªôc
- üë• **H·ªó tr·ª£ nhi·ªÅu ng∆∞·ªùi d√πng**: T√†i kho·∫£n ng∆∞·ªùi d√πng v√† l·ªãch s·ª≠ h·ªôi tho·∫°i
- üìÅ **X·ª≠ l√Ω t·ªáp**: T·∫£i l√™n v√† ph√¢n t√≠ch t√†i li·ªáu
- üîÑ **Chuy·ªÉn ƒë·ªïi m√¥ h√¨nh**: D·ªÖ d√†ng chuy·ªÉn ƒë·ªïi gi·ªØa c√°c m√¥ h√¨nh kh√°c nhau
- üê≥ **Tri·ªÉn khai Docker**: Thi·∫øt l·∫≠p container s·∫µn s√†ng s·∫£n xu·∫•t

**C√†i ƒë·∫∑t nhanh:**
```cmd
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

## Tham chi·∫øu c·∫•u h√¨nh

### Bi·∫øn m√¥i tr∆∞·ªùng

| Bi·∫øn | M√¥ t·∫£ | M·∫∑c ƒë·ªãnh | V√≠ d·ª• |
|------|-------|----------|-------|
| `MODEL` | B√≠ danh m√¥ h√¨nh s·ª≠ d·ª•ng | `phi-4-mini` | `qwen2.5-7b-instruct` |
| `BASE_URL` | Endpoint Foundry Local | T·ª± ƒë·ªông ph√°t hi·ªán | `http://localhost:51211` |
| `API_KEY` | API key (t√πy ch·ªçn cho local) | `""` | `your-api-key` |

## X·ª≠ l√Ω s·ª± c·ªë

### C√°c v·∫•n ƒë·ªÅ th∆∞·ªùng g·∫∑p

**·ª®ng d·ª•ng Chainlit:**

1. **D·ªãch v·ª• kh√¥ng kh·∫£ d·ª•ng:**
   ```cmd
   # Check Foundry Local status
   foundry service status
   foundry service ps
   
   # Validate API endpoint (note: port 51211)
   curl http://localhost:51211/v1/models
   ```

2. **Xung ƒë·ªôt c·ªïng:**
   ```cmd
   # Check what's using port 8080
   netstat -ano | findstr :8080
   
   # Use different port if needed
   chainlit run samples\04\app.py -w --port 3000
   ```

3. **V·∫•n ƒë·ªÅ m√¥i tr∆∞·ªùng Python:**
   ```cmd
   # Verify correct interpreter in VS Code
   # Ctrl+Shift+P ‚Üí Python: Select Interpreter
   # Choose: Module08/.venv/Scripts/python.exe
   
   # Reinstall dependencies
   pip install -r requirements.txt
   ```

**Demo WebGPU:**

1. **WebGPU kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£:**
   - C·∫≠p nh·∫≠t Chrome/Edge l√™n phi√™n b·∫£n 113+
   - B·∫≠t WebGPU: `chrome://flags/#enable-unsafe-webgpu`
   - Ki·ªÉm tra tr·∫°ng th√°i GPU: `chrome://gpu`
   - Demo s·∫Ω t·ª± ƒë·ªông chuy·ªÉn sang CPU

2. **L·ªói t·∫£i m√¥ h√¨nh:**
   - ƒê·∫£m b·∫£o k·∫øt n·ªëi internet ƒë·ªÉ t·∫£i m√¥ h√¨nh
   - Ki·ªÉm tra console tr√¨nh duy·ªát ƒë·ªÉ t√¨m l·ªói CORS
   - X√°c minh b·∫°n ƒëang ph·ª•c v·ª• qua HTTP (kh√¥ng ph·∫£i file://)

**Open WebUI:**

1. **K·∫øt n·ªëi b·ªã t·ª´ ch·ªëi:**
   ```cmd
   # Check Docker is running
   docker --version
   
   # Check container status
   docker ps | findstr open-webui
   
   # View container logs
   docker logs open-webui
   ```

2. **M√¥ h√¨nh kh√¥ng xu·∫•t hi·ªán:**
   ```cmd
   # Verify Foundry Local endpoint
   curl http://localhost:51211/v1/models
   
   # Restart Open WebUI
   docker restart open-webui
   ```

### Danh s√°ch ki·ªÉm tra x√°c th·ª±c

```cmd
# ‚úÖ 1. Foundry Local Setup
foundry --version                    # Should show version
foundry service status               # Should show "running"
foundry model list                   # Should show loaded models
curl http://localhost:51211/v1/models  # Should return JSON

# ‚úÖ 2. Python Environment  
python --version                     # Should be 3.10+
pip list | findstr chainlit         # Should show chainlit package
pip list | findstr openai           # Should show openai package

# ‚úÖ 3. Application Testing
chainlit run samples\04\app.py -w --port 8080  # Should open browser
# Test WebGPU demo at localhost:5173
# Test Open WebUI at localhost:3000
```

## S·ª≠ d·ª•ng n√¢ng cao

### T·ªëi ∆∞u h√≥a hi·ªáu su·∫•t

**Chainlit:**
- S·ª≠ d·ª•ng ph·∫£n h·ªìi theo lu·ªìng ƒë·ªÉ c·∫£i thi·ªán hi·ªáu su·∫•t c·∫£m nh·∫≠n
- Tri·ªÉn khai pooling k·∫øt n·ªëi ƒë·ªÉ x·ª≠ l√Ω ƒë·ªìng th·ªùi cao
- B·ªô nh·ªõ ƒë·ªám ph·∫£n h·ªìi m√¥ h√¨nh cho c√°c truy v·∫•n l·∫∑p l·∫°i
- Gi√°m s√°t s·ª≠ d·ª•ng b·ªô nh·ªõ v·ªõi l·ªãch s·ª≠ h·ªôi tho·∫°i l·ªõn

**WebGPU:**
- S·ª≠ d·ª•ng WebGPU ƒë·ªÉ ƒë·∫°t quy·ªÅn ri√™ng t∆∞ v√† t·ªëc ƒë·ªô t·ªëi ƒëa
- Tri·ªÉn khai l∆∞·ª£ng h√≥a m√¥ h√¨nh ƒë·ªÉ gi·∫£m k√≠ch th∆∞·ªõc m√¥ h√¨nh
- S·ª≠ d·ª•ng Web Workers ƒë·ªÉ x·ª≠ l√Ω n·ªÅn
- B·ªô nh·ªõ ƒë·ªám m√¥ h√¨nh ƒë√£ bi√™n d·ªãch trong l∆∞u tr·ªØ tr√¨nh duy·ªát

**Open WebUI:**
- S·ª≠ d·ª•ng volume l∆∞u tr·ªØ ƒë·ªÉ gi·ªØ l·ªãch s·ª≠ h·ªôi tho·∫°i
- C·∫•u h√¨nh gi·ªõi h·∫°n t√†i nguy√™n cho container Docker
- Tri·ªÉn khai chi·∫øn l∆∞·ª£c sao l∆∞u cho d·ªØ li·ªáu ng∆∞·ªùi d√πng
- Thi·∫øt l·∫≠p proxy ng∆∞·ª£c ƒë·ªÉ k·∫øt th√∫c SSL

### M·∫´u t√≠ch h·ª£p

**Hybrid Local/Cloud:**
```python
# Route based on complexity and privacy requirements
async def intelligent_routing(prompt: str, metadata: dict):
    if metadata.get("contains_pii"):
        return await foundry_local_completion(prompt)  # Privacy-sensitive
    elif len(prompt.split()) > 200:
        return await azure_openai_completion(prompt)   # Complex reasoning
    else:
        return await foundry_local_completion(prompt)  # Default local
```

**Pipeline ƒêa ph∆∞∆°ng th·ª©c:**
```python
# Combine different AI capabilities
async def analyze_document(file_path: str):
    # 1. OCR with WebGPU (browser-based)
    text = await webgpu_ocr(file_path)
    
    # 2. Analysis with Foundry Local (private)
    summary = await foundry_local_analyze(text)
    
    # 3. Enhancement with cloud (if needed)
    if summary.confidence < 0.8:
        summary = await azure_openai_enhance(summary)
    
    return summary
```

## Tri·ªÉn khai s·∫£n xu·∫•t

### C√¢n nh·∫Øc v·ªÅ b·∫£o m·∫≠t

- **API Keys**: S·ª≠ d·ª•ng bi·∫øn m√¥i tr∆∞·ªùng, kh√¥ng bao gi·ªù m√£ h√≥a c·ª©ng
- **M·∫°ng**: S·ª≠ d·ª•ng HTTPS trong s·∫£n xu·∫•t, c√¢n nh·∫Øc VPN cho truy c·∫≠p nh√≥m
- **Ki·ªÉm so√°t truy c·∫≠p**: Tri·ªÉn khai x√°c th·ª±c cho Open WebUI
- **Quy·ªÅn ri√™ng t∆∞ d·ªØ li·ªáu**: Ki·ªÉm tra d·ªØ li·ªáu n√†o ·ªü l·∫°i local v√† d·ªØ li·ªáu n√†o l√™n cloud
- **C·∫≠p nh·∫≠t**: Gi·ªØ Foundry Local v√† container lu√¥n ƒë∆∞·ª£c c·∫≠p nh·∫≠t

### Gi√°m s√°t v√† b·∫£o tr√¨

- **Ki·ªÉm tra s·ª©c kh·ªèe**: Tri·ªÉn khai gi√°m s√°t endpoint
- **Ghi nh·∫≠t k√Ω**: T·∫≠p trung h√≥a nh·∫≠t k√Ω t·ª´ t·∫•t c·∫£ c√°c th√†nh ph·∫ßn
- **S·ªë li·ªáu**: Theo d√µi th·ªùi gian ph·∫£n h·ªìi, t·ª∑ l·ªá l·ªói, s·ª≠ d·ª•ng t√†i nguy√™n
- **Sao l∆∞u**: Sao l∆∞u th∆∞·ªùng xuy√™n d·ªØ li·ªáu h·ªôi tho·∫°i v√† c·∫•u h√¨nh

## T√†i li·ªáu tham kh·∫£o v√† ngu·ªìn l·ª±c

### T√†i li·ªáu
- [T√†i li·ªáu Chainlit](https://docs.chainlit.io/) - H∆∞·ªõng d·∫´n ƒë·∫ßy ƒë·ªß v·ªÅ framework
- [T√†i li·ªáu Foundry Local](https://learn.microsoft.com/azure/ai-foundry/foundry-local/) - T√†i li·ªáu ch√≠nh th·ª©c c·ªßa Microsoft
- [ONNX Runtime Web](https://onnxruntime.ai/docs/get-started/with-javascript/web.html) - T√≠ch h·ª£p WebGPU
- [T√†i li·ªáu Open WebUI](https://docs.openwebui.com/) - C·∫•u h√¨nh n√¢ng cao

### T·ªáp m·∫´u
- [`app.py`](../../../../../Module08/samples/04/app.py) - ·ª®ng d·ª•ng Chainlit s·∫£n xu·∫•t
- [`chainlit_app.ipynb`](./chainlit_app.ipynb) - Notebook gi√°o d·ª•c
- [`webgpu-demo/`](../../../../../Module08/samples/04/webgpu-demo) - Suy lu·∫≠n AI tr√™n tr√¨nh duy·ªát
- [`open-webui-guide.md`](./open-webui-guide.md) - H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t Open WebUI ho√†n ch·ªânh

### M·∫´u li√™n quan
- [T√†i li·ªáu Phi√™n 4](../../04.CuttingEdgeModels.md) - H∆∞·ªõng d·∫´n phi√™n ƒë·∫ßy ƒë·ªß
- [M·∫´u Foundry Local](https://github.com/microsoft/foundry-local/tree/main/samples) - M·∫´u ch√≠nh th·ª©c

---

