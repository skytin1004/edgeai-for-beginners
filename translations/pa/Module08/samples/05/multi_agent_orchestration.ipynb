{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b861ae53",
   "metadata": {},
   "source": [
    "# ри╕рйИриВрикри▓ 05: риори▓риЯрйА-риПриЬрй░риЯ риЖри░риХри╕риЯрйНри░рйЗри╕ри╝рии ри╕ри┐ри╕риЯрио\n",
    "\n",
    "риЗри╣ риирйЛриЯримрйБрй▒риХ Microsoft Foundry Local рижрйА ри╡ри░ридрйЛриВ риХри░риХрйЗ AI-риЪри▓ри┐рид риПриЬрй░риЯ ри╕ри┐ри╕риЯрио римригри╛риЙриг ри▓риИ риЗрй▒риХ риЙрй▒риЪ-рикрй▒ризри░рйА риори▓риЯрйА-риПриЬрй░риЯ риЖри░риХрйАриЯрйИриХриЪри░ рижри┐риЦри╛риЙриВрижрйА ри╣рйИред\n",
    "\n",
    "## риЭри▓риХ\n",
    "\n",
    "риЗри╕ ри╕рйИриВрикри▓ ри╡ри┐рй▒риЪ **риори▓риЯрйА-риПриЬрй░риЯ риХрйЛриЖри░рибрйАриирйЗриЯри░** риирйВрй░ ри▓ри╛риЧрйВ риХрйАридри╛ риЧри┐риЖ ри╣рйИ риЬрйЛ ри╡ри┐ри╕ри╝рйЗри╕ри╝ риПриЬрй░риЯри╛риВ риирйВрй░ риЖри░риХри╕риЯрйНри░рйЗриЯ риХри░рижри╛ ри╣рйИ:\n",
    "\n",
    "- ЁЯФН **ри░ри┐риЯри░рйАри╡ри▓ риПриЬрй░риЯ**: риЧри┐риЖрии ри╕ри░рйЛридри╛риВ ридрйЛриВ ри╕римрй░ризрид риЬри╛ригриХри╛ри░рйА риХрй▒риврижри╛ ри╣рйИ\n",
    "- ЁЯза **ри░рйАриЬри╝риири┐рй░риЧ риПриЬрй░риЯ**: риХрижрио-рижри░-риХрижрио ри╡ри┐ри╕ри╝ри▓рйЗри╕ри╝риг риЕридрйЗ ридри░риХри╕ри╝рйАри▓ ри╕рйЛриЪ-ри╡ри┐риЪри╛ри░ риХри░рижри╛ ри╣рйИ\n",
    "- тЪб **риРриЧриЬри╝ри┐риХри┐риКри╕ри╝рии риПриЬрй░риЯ**: ри╕рй░ри░риЪри┐рид рилри╛ри░риорйИриЯри╛риВ ри╡ри┐рй▒риЪ риХри╛ри░ри╡ри╛риИрипрйЛриЧ рипрйЛриЬриири╛ри╡ри╛риВ римригри╛риЙриВрижри╛ ри╣рйИ\n",
    "- ЁЯОп **риХрйЛриЖри░рибрйАриирйЗриЯри░**: рикрйВри░рйЗ риПриЬрй░риЯ ри╡ри░риХрилри▓рйЛ риирйВрй░ риЖри░риХри╕риЯрйНри░рйЗриЯ риХри░рижри╛ ри╣рйИ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e840290d",
   "metadata": {},
   "source": [
    "## риЖри░риХрйАриЯрйИриХриЪри░ рикрйИриЯри░рии\n",
    "\n",
    "```\n",
    "User Goal тЖТ Coordinator\n",
    "     тЖУ\n",
    "1. Retrieval Agent тЖТ Context\n",
    "     тЖУ\n",
    "2. Reasoning Agent тЖТ Decision\n",
    "     тЖУ\n",
    "3. Execution Agent тЖТ Actions\n",
    "     тЖУ\n",
    "Structured Result\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240650a",
   "metadata": {},
   "source": [
    "## рикрйВри░ри╡ ри╕ри╝ри░ридри╛риВ риЕридрйЗ ри╕рйИриЯриЕрй▒рик\n",
    "\n",
    "риприХрйАриирйА римригри╛риУ риХри┐ ридрйБри╣ри╛рибрйЗ риХрйЛри▓ Foundry Local риЗрй▒риХ ри╕риори░рй▒рие риори╛рибри▓ риири╛ри▓ риЪри▓ ри░ри┐ри╣ри╛ ри╣рйИ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc33b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install openai foundry-local-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c6fe9e",
   "metadata": {},
   "source": [
    "## ри▓ри╛риЗримрйНри░рйЗри░рйАриЖриВ риЕридрйЗ ри╕рй░ри░риЪриири╛ риЖрипри╛рид риХри░рйЛ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5160a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, Any, List\n",
    "from openai import OpenAI\n",
    "\n",
    "try:\n",
    "    from foundry_local import FoundryLocalManager\n",
    "    FOUNDRY_SDK_AVAILABLE = True\n",
    "    print(\"тЬЕ Foundry Local SDK is available\")\n",
    "except ImportError:\n",
    "    FOUNDRY_SDK_AVAILABLE = False\n",
    "    print(\"тЪая╕П Foundry Local SDK not available, will use manual configuration\")\n",
    "\n",
    "# Configuration\n",
    "MODEL_ALIAS = \"phi-4-mini\"  # Change to your preferred model\n",
    "BASE_URL = \"http://localhost:8000\"\n",
    "API_KEY = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba6a90f",
   "metadata": {},
   "source": [
    "## рилри╛риКриВрибри░рйА риХри▓ри╛риЗрй░риЯ ри╕рйИриЯриЕрй▒рик\n",
    "\n",
    "ри╕рин риПриЬрй░риЯри╛риВ ри▓риИ риЗрй▒риХ ри╕ри╛риВриЭри╛ риХри▓ри╛риЗрй░риЯ римригри╛риУ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc80453",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoundryClient:\n",
    "    \"\"\"Shared client for all specialist agents.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_alias: str = MODEL_ALIAS):\n",
    "        self.client = None\n",
    "        self.model_name = None\n",
    "        self.model_alias = model_alias\n",
    "        self._initialize_client()\n",
    "    \n",
    "    def _initialize_client(self):\n",
    "        \"\"\"Initialize OpenAI client with Foundry Local or fallback configuration.\"\"\"\n",
    "        if FOUNDRY_SDK_AVAILABLE:\n",
    "            try:\n",
    "                print(f\"ЁЯФД Initializing Foundry Local with model: {self.model_alias}...\")\n",
    "                manager = FoundryLocalManager(self.model_alias)\n",
    "                model_info = manager.get_model_info(self.model_alias)\n",
    "                \n",
    "                self.client = OpenAI(\n",
    "                    base_url=manager.endpoint,\n",
    "                    api_key=manager.api_key\n",
    "                )\n",
    "                self.model_name = model_info.id\n",
    "                print(f\"тЬЕ Foundry Local SDK initialized with model: {self.model_name}\")\n",
    "                return\n",
    "            except Exception as e:\n",
    "                print(f\"тЪая╕П Could not use Foundry SDK ({e}), falling back to manual configuration\")\n",
    "        \n",
    "        # Fallback to manual configuration\n",
    "        self.client = OpenAI(\n",
    "            base_url=f\"{BASE_URL}/v1\",\n",
    "            api_key=API_KEY\n",
    "        )\n",
    "        self.model_name = self.model_alias\n",
    "        print(f\"ЁЯФз Manual configuration initialized with model: {self.model_name}\")\n",
    "    \n",
    "    def chat(self, messages: List[Dict[str, str]], max_tokens: int = 300, temperature: float = 0.4) -> str:\n",
    "        \"\"\"Send chat completion request to the model.\"\"\"\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model_name,\n",
    "                messages=messages,\n",
    "                max_tokens=max_tokens,\n",
    "                temperature=temperature\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {str(e)}\"\n",
    "    \n",
    "    def check_health(self) -> bool:\n",
    "        \"\"\"Check if the client is working properly.\"\"\"\n",
    "        try:\n",
    "            test_response = self.chat(\n",
    "                [{\"role\": \"user\", \"content\": \"Say 'OK'\"}],\n",
    "                max_tokens=5\n",
    "            )\n",
    "            return \"OK\" in test_response and \"Error\" not in test_response\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "# Initialize the shared client\n",
    "print(\"Initializing Foundry Client...\")\n",
    "foundry_client = FoundryClient()\n",
    "\n",
    "# Health check\n",
    "if foundry_client.check_health():\n",
    "    print(\"тЬЕ Client health check passed!\")\n",
    "else:\n",
    "    print(\"тЭМ Client health check failed. Please ensure Foundry Local is running with a model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9e6e2b",
   "metadata": {},
   "source": [
    "## ри╡ри┐ри╕ри╝рйЗри╕ри╝ риПриЬрй░риЯ риХри▓ри╛ри╕ри╛риВ\n",
    "\n",
    "ри╣ри░ риПриЬрй░риЯ риирйВрй░ риЦри╛ри╕ риЬри╝ри╣ри┐риирйА риХрй░риори╛риВ ри▓риИ ри╡ризрйАриЖ римригри╛риЗриЖ риЧри┐риЖ ри╣рйИ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2ce141",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalAgent:\n",
    "    \"\"\"Agent specialized in retrieving relevant information from knowledge sources.\"\"\"\n",
    "    \n",
    "    SYSTEM = \"\"\"You are a specialized retrieval agent. Your job is to extract and retrieve \n",
    "    the most relevant information from knowledge sources based on a given query. Focus on key facts, \n",
    "    data points, and contextual information that would be useful for decision-making.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: FoundryClient):\n",
    "        self.client = client\n",
    "    \n",
    "    def run(self, query: str) -> str:\n",
    "        \"\"\"Retrieve relevant information based on the query.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.SYSTEM},\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"\"\"Query: {query}\n",
    "\n",
    "Retrieve the most relevant key facts, data points, and contextual information that would \n",
    "help answer this query or support decision-making around it. Provide specific, actionable \n",
    "information rather than general statements.\"\"\"\n",
    "            }\n",
    "        ]\n",
    "        return self.client.chat(messages)\n",
    "\n",
    "\n",
    "class ReasoningAgent:\n",
    "    \"\"\"Agent specialized in step-by-step analysis and reasoning.\"\"\"\n",
    "    \n",
    "    SYSTEM = \"\"\"You are a specialized reasoning agent. Your job is to analyze inputs \n",
    "    step-by-step and produce structured, logical conclusions. Break down complex problems \n",
    "    into manageable parts and provide clear reasoning for your conclusions.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: FoundryClient):\n",
    "        self.client = client\n",
    "    \n",
    "    def run(self, context: str, question: str) -> str:\n",
    "        \"\"\"Analyze context and question to produce structured conclusions.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.SYSTEM},\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"\"\"Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Analyze this step-by-step and provide a structured, logical conclusion with clear reasoning. \n",
    "Break down the problem, consider different angles, and provide a well-reasoned decision or recommendation.\"\"\"\n",
    "            }\n",
    "        ]\n",
    "        return self.client.chat(messages, max_tokens=400)\n",
    "\n",
    "\n",
    "class ExecutionAgent:\n",
    "    \"\"\"Agent specialized in creating actionable execution plans.\"\"\"\n",
    "    \n",
    "    SYSTEM = \"\"\"You are a specialized execution agent. Your job is to transform decisions \n",
    "    and conclusions into concrete, actionable steps. Always format your response as valid JSON \n",
    "    with an array of action items. Each action should be specific, measurable, and achievable.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: FoundryClient):\n",
    "        self.client = client\n",
    "    \n",
    "    def run(self, decision: str) -> str:\n",
    "        \"\"\"Transform decision into actionable steps in JSON format.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.SYSTEM},\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"\"\"Decision/Conclusion:\n",
    "{decision}\n",
    "\n",
    "Create 3-5 specific, actionable steps to implement this decision. Format as JSON with this structure:\n",
    "{{\n",
    "  \"actions\": [\n",
    "    {{\n",
    "      \"step\": 1,\n",
    "      \"description\": \"Specific action description\",\n",
    "      \"priority\": \"high/medium/low\",\n",
    "      \"timeline\": \"timeframe for completion\",\n",
    "      \"resources\": [\"required resources or people\"]\n",
    "    }}\n",
    "  ]\n",
    "}}\"\"\"\n",
    "            }\n",
    "        ]\n",
    "        return self.client.chat(messages, max_tokens=400, temperature=0.3)\n",
    "\n",
    "print(\"тЬЕ Agent classes defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb6288d",
   "metadata": {},
   "source": [
    "## риори▓риЯрйА-риПриЬрй░риЯ риХрйЛриЖри░рибрйАриирйЗриЯри░\n",
    "\n",
    "риХрйЛриЖри░рибрйАриирйЗриЯри░ ри╕ри╛ри░рйЗ риПриЬрй░риЯри╛риВ риирйВрй░ риЬриЯри┐ри▓ риХрй░риори╛риВ риирйВрй░ ри╕рй░ринри╛ри▓риг ри▓риИ ри╕рй░риЧриари┐рид риХри░рижри╛ ри╣рйИ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e27d7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coordinator:\n",
    "    \"\"\"Multi-agent coordinator that orchestrates specialist agents to handle complex tasks.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: FoundryClient):\n",
    "        \"\"\"Initialize the coordinator with specialist agents.\"\"\"\n",
    "        self.client = client\n",
    "        self.retrieval = RetrievalAgent(client)\n",
    "        self.reasoning = ReasoningAgent(client)\n",
    "        self.execution = ExecutionAgent(client)\n",
    "    \n",
    "    def handle(self, user_goal: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Orchestrate multiple agents to handle a complex user goal.\n",
    "        \n",
    "        Args:\n",
    "            user_goal: The user's high-level goal or request\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing the goal, context, decision, and actions\n",
    "        \"\"\"\n",
    "        print(f\"ЁЯОп **Coordinator:** Processing goal: {user_goal}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Step 1: Retrieve relevant context\n",
    "        print(\"ЁЯУЪ **Step 1:** Retrieving context...\")\n",
    "        context = self.retrieval.run(user_goal)\n",
    "        print(f\"   тЬЕ Context retrieved ({len(context)} chars)\")\n",
    "        print(f\"   ЁЯУД Preview: {context[:150]}...\\n\")\n",
    "        \n",
    "        # Step 2: Analyze and reason about the context\n",
    "        print(\"ЁЯза **Step 2:** Analyzing and reasoning...\")\n",
    "        decision = self.reasoning.run(context, user_goal)\n",
    "        print(f\"   тЬЕ Analysis completed ({len(decision)} chars)\")\n",
    "        print(f\"   ЁЯТб Preview: {decision[:150]}...\\n\")\n",
    "        \n",
    "        # Step 3: Create actionable execution plan\n",
    "        print(\"тЪб **Step 3:** Creating execution plan...\")\n",
    "        actions = self.execution.run(decision)\n",
    "        print(f\"   тЬЕ Execution plan created ({len(actions)} chars)\")\n",
    "        \n",
    "        # Try to parse actions as JSON for preview\n",
    "        try:\n",
    "            actions_json = json.loads(actions)\n",
    "            action_count = len(actions_json.get('actions', []))\n",
    "            print(f\"   ЁЯУЛ Actions planned: {action_count}\\n\")\n",
    "        except:\n",
    "            print(f\"   ЁЯУЛ Actions: {actions[:100]}...\\n\")\n",
    "        \n",
    "        end_time = time.time()\n",
    "        processing_time = end_time - start_time\n",
    "        \n",
    "        result = {\n",
    "            \"goal\": user_goal,\n",
    "            \"context\": context,\n",
    "            \"decision\": decision,\n",
    "            \"actions\": actions,\n",
    "            \"agent_flow\": [\"retrieval\", \"reasoning\", \"execution\"],\n",
    "            \"processing_time\": processing_time,\n",
    "            \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        \n",
    "        print(f\"тЬЕ **Coordination Complete** (тП▒я╕П {processing_time:.2f}s)\")\n",
    "        return result\n",
    "    \n",
    "    def handle_with_feedback(self, user_goal: str, feedback_rounds: int = 1) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Handle a goal with multiple feedback rounds for refinement.\n",
    "        \n",
    "        Args:\n",
    "            user_goal: The user's high-level goal or request\n",
    "            feedback_rounds: Number of feedback rounds to perform\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing the refined result\n",
    "        \"\"\"\n",
    "        result = self.handle(user_goal)\n",
    "        \n",
    "        for round_num in range(feedback_rounds):\n",
    "            print(f\"\\nЁЯФД **Feedback Round {round_num + 1}:**\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            # Use reasoning agent to refine the execution plan\n",
    "            refinement_prompt = f\"\"\"\n",
    "            Original Goal: {user_goal}\n",
    "            Current Decision: {result['decision']}\n",
    "            Current Actions: {result['actions']}\n",
    "            \n",
    "            Review the above and suggest improvements or refinements to make the execution plan more effective.\n",
    "            Consider potential challenges, resource optimization, and success metrics.\n",
    "            \"\"\"\n",
    "            \n",
    "            refined_decision = self.reasoning.run(result['context'], refinement_prompt)\n",
    "            refined_actions = self.execution.run(refined_decision)\n",
    "            \n",
    "            result['decision'] = refined_decision\n",
    "            result['actions'] = refined_actions\n",
    "            result['refinement_rounds'] = round_num + 1\n",
    "            \n",
    "            print(f\"   тЬЕ Round {round_num + 1} refinement completed\")\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Initialize coordinator\n",
    "coordinator = Coordinator(foundry_client)\n",
    "print(\"тЬЕ Multi-agent coordinator initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97499608",
   "metadata": {},
   "source": [
    "## риЙрижри╛ри╣ри░рии 1: ри╡рикри╛ри░ рипрйЛриЬриири╛ римригри╛риЙригри╛\n",
    "\n",
    "риЖриУ ри╕ри╣ри┐-ри╕рй░рипрйЛриЬриХ риирйВрй░ ри╡рикри╛ри░ рипрйЛриЬриири╛ римригри╛риЙриг рижрйЗ ри▓риХри╕ри╝ риири╛ри▓ рикри░риЦрйАриП:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87106196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business planning example\n",
    "business_goal = \"Create a plan to onboard 5 new customers this month\"\n",
    "\n",
    "print(f\"ЁЯЪА **Business Planning Example**\")\n",
    "print(f\"ЁЯУЛ Goal: {business_goal}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "business_result = coordinator.handle(business_goal)\n",
    "\n",
    "print(\"\\nЁЯУК **Final Result Summary:**\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ЁЯОп **Goal:** {business_result['goal']}\")\n",
    "print(f\"тП▒я╕П **Processing Time:** {business_result['processing_time']:.2f} seconds\")\n",
    "print(f\"ЁЯХТ **Timestamp:** {business_result['timestamp']}\")\n",
    "\n",
    "print(f\"\\nЁЯУЪ **Context (Retrieval Agent):**\")\n",
    "print(business_result['context'])\n",
    "\n",
    "print(f\"\\nЁЯза **Decision (Reasoning Agent):**\")\n",
    "print(business_result['decision'])\n",
    "\n",
    "print(f\"\\nтЪб **Actions (Execution Agent):**\")\n",
    "print(business_result['actions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1159c3",
   "metadata": {},
   "source": [
    "## риЙрижри╛ри╣ри░рии 2: ри░ригриирйАридрйА ри╡ри┐риХри╛ри╕\n",
    "\n",
    "риЗрй▒риХ ри╣рйЛри░ риЬриЯри┐ри▓ ри░ригриирйАридрйА ри╡ри┐риХри╛ри╕ рижрйЗ ри▓риХри╕ри╝ риири╛ри▓ риЯрйИри╕риЯ риХри░рйЛ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7532b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy development example\n",
    "strategy_goal = \"Develop a strategy to improve team productivity by 20% while maintaining work-life balance\"\n",
    "\n",
    "print(f\"ЁЯОп **Strategy Development Example**\")\n",
    "print(f\"ЁЯУЛ Goal: {strategy_goal}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "strategy_result = coordinator.handle(strategy_goal)\n",
    "\n",
    "print(\"\\nЁЯУК **Structured Action Plan:**\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Try to parse and display actions in a structured format\n",
    "try:\n",
    "    actions_data = json.loads(strategy_result['actions'])\n",
    "    if 'actions' in actions_data:\n",
    "        for i, action in enumerate(actions_data['actions'], 1):\n",
    "            print(f\"\\nЁЯУМ **Action {i}:**\")\n",
    "            print(f\"   ЁЯУЭ Description: {action.get('description', 'N/A')}\")\n",
    "            print(f\"   ЁЯФе Priority: {action.get('priority', 'N/A')}\")\n",
    "            print(f\"   тП░ Timeline: {action.get('timeline', 'N/A')}\")\n",
    "            print(f\"   ЁЯЫая╕П Resources: {', '.join(action.get('resources', ['N/A']))}\")\n",
    "    else:\n",
    "        print(strategy_result['actions'])\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Raw actions output:\")\n",
    "    print(strategy_result['actions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d46b319",
   "metadata": {},
   "source": [
    "## риЙрижри╛ри╣ри░рии 3: рилрйАрибримрйИриХ ри▓рйВрик ри╕рйБризри╛ри░\n",
    "\n",
    "рикрйБриири░ри╛ри╡ри░ридрйА ри╕рйБризри╛ри░ ри▓риИ рилрйАрибримрйИриХ риориХрйИриири┐риЬри╝рио рижри┐риЦри╛риУ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5fb98ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   тЬЕ Round 2 refinement completed\n",
      "\n",
      "ЁЯПЖ **Final Refined Result:**\n",
      "==================================================\n",
      "ЁЯОп **Goal:** Design a customer feedback collection system for a software product\n",
      "ЁЯФД **Refinement Rounds:** 2\n",
      "тП▒я╕П **Total Processing Time:** 559.18 seconds\n",
      "\n",
      "ЁЯза **Final Decision:**\n",
      "The execution plan for designing a customer feedback collection system for a software product is comprehensive, but there are areas where it could be refined for better effectiveness. Here are some suggestions:\n",
      "\n",
      "1. **Review of Existing Feedback Mechanisms**: This step is crucial as it sets the direction for the feedback collection system. However, it could be more effective if it also includes a review of existing feedback mechanisms and their shortcomings. This will help in understanding what can be improved.\n",
      "\n",
      "2. **Survey or Focus Group for Feedback Channels**: While the plan includes a variety of feedback channels, it could be beneficial to conduct a survey or a small focus group with a sample of the target audience to understand their preferred feedback channels. This will ensure that the chosen channels are indeed the most effective for the target audience.\n",
      "\n",
      "3. **User Testing of Feedback Form**: The plan is clear, but it could be improved by including a step for user testing of the feedback form. This will help in identifying any issues with the form's design or content before it is launched.\n",
      "\n",
      "4. **Regular Audits for Data Collection and Storage**: The plan includes compliance with data protection regulations, which is crucial. However, it could be more effective if it also includes a step for regular audits of the data collection and storage system to ensure ongoing compliance.\n",
      "\n",
      "5. **Training on Data Visualization Tools**: The plan is comprehensive, but it could be improved by including a step for training the team on how to use the data visualization tools. This will ensure that the team can effectively interpret and present the data.\n",
      "\n",
      "6. **Tracking System for Implementation of Changes**: The plan includes a feedback loop, which is excellent. However, it could be more effective if it also includes a step for tracking the implementation of changes based on feedback. This will help in understanding the impact of the feedback on the product.\n",
      "\n",
      "Potential challenges could be ensuring the feedback form is user-friendly and concise, maintaining data protection compliance, and effectively tracking the implementation of changes based\n",
      "\n",
      "тЪб **Final Action Plan:**\n",
      "```json\n",
      "{\n",
      "  \"actions\": [\n",
      "    {\n",
      "      \"step\": 1,\n",
      "      \"description\": \"Conduct a comprehensive review of existing feedback mechanisms, including their effectiveness and shortcomings.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"1 week\",\n",
      "      \"resources\": [\"Product management team\", \"Customer service team\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 2,\n",
      "      \"description\": \"Organize a survey or focus group with a sample of the target audience to determine preferred feedback channels.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"2 weeks\",\n",
      "      \"resources\": [\"Survey platform\", \"Focus group participants\", \"Marketing team\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 3,\n",
      "      \"description\": \"Implement user testing for the feedback form with a diverse group of users to identify design and content issues.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"3 weeks\",\n",
      "      \"resources\": [\"UX/UI designers\", \"Test participants\", \"Feedback collection tools\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 4,\n",
      "      \"description\": \"Schedule and conduct regular audits of the data collection and storage system to ensure compliance with data protection regulations.\",\n",
      "      \"priority\": \"medium\",\n",
      "      \"timeline\": \"Quarterly\",\n",
      "      \"resources\": [\"Data protection officer\", \"IT security team\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 5,\n",
      "      \"description\": \"Develop and deliver training sessions for the team on how to use data visualization tools effectively.\",\n",
      "      \"priority\": \"medium\",\n",
      "      \"timeline\": \"1 month\",\n",
      "      \"resources\": [\"Data visualization software\", \"Training materials\", \"Internal trainers or external experts\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 6,\n",
      "      \"description\": \"Create a tracking system to monitor the implementation of changes based on customer feedback and measure the impact.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"2 months\",\n",
      "      \"resources\": [\"Project management software\", \"Product development team\n"
     ]
    }
   ],
   "source": [
    "# Feedback loop example\n",
    "feedback_goal = \"Design a customer feedback collection system for a software product\"\n",
    "\n",
    "print(f\"ЁЯФД **Feedback Loop Refinement Example**\")\n",
    "print(f\"ЁЯУЛ Goal: {feedback_goal}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Process with 2 feedback rounds\n",
    "feedback_result = coordinator.handle_with_feedback(feedback_goal, feedback_rounds=2)\n",
    "\n",
    "print(\"\\nЁЯПЖ **Final Refined Result:**\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ЁЯОп **Goal:** {feedback_result['goal']}\")\n",
    "print(f\"ЁЯФД **Refinement Rounds:** {feedback_result.get('refinement_rounds', 0)}\")\n",
    "print(f\"тП▒я╕П **Total Processing Time:** {feedback_result['processing_time']:.2f} seconds\")\n",
    "\n",
    "print(f\"\\nЁЯза **Final Decision:**\")\n",
    "print(feedback_result['decision'])\n",
    "\n",
    "print(f\"\\nтЪб **Final Action Plan:**\")\n",
    "print(feedback_result['actions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed152f7",
   "metadata": {},
   "source": [
    "## риЗрй░риЯри░риРриХриЯри┐ри╡ риПриЬрй░риЯ риЯрйИри╕риЯри┐рй░риЧ\n",
    "\n",
    "ри╡рй▒риЦ-ри╡рй▒риЦ риПриЬрй░риЯри╛риВ риирйВрй░ риЕри▓рй▒риЧ-риЕри▓рй▒риЧ риЯрйИри╕риЯ риХри░рйЛ ридри╛риВ риЬрйЛ риЙриирйНри╣ри╛риВ рижрйА ри╡ри┐ри╕ри╝рйЗри╕ри╝ рипрйЛриЧридри╛ри╡ри╛риВ риирйВрй░ ри╕риориЭри┐риЖ риЬри╛ ри╕риХрйЗ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "948c737c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ЁЯзк **Individual Agent Testing**\n",
      "тЭУ Query: How can we reduce customer support response time?\n",
      "============================================================\n",
      "\n",
      "ЁЯФН **Retrieval Agent:**\n",
      "1. Implementing AI-powered chatbots: AI-powered chatbots can handle common customer queries, reducing the workload on human agents and speeding up response times. According to a study by Accenture, AI chatbots can handle 80% of customer interactions, freeing up human agents to handle more complex issues.\n",
      "\n",
      "2. Streamlining the support process: Simplifying the support process and removing unnecessary steps can help reduce response times. This could involve consolidating support channels, creating self-help resources, or automating certain processes.\n",
      "\n",
      "3. Increasing support staff: Hiring additional support staff or training existing staff to handle more complex issues can help reduce response times. A study by Forrester found that increasing the number of support agents by just 10% can reduce average response time by 20%.\n",
      "\n",
      "4. Prioritizing urgent issues: Prioritizing urgent issues and ensuring they are addressed first can help reduce response times. This could involve implementing a ticketing system that prioritizes issues based on their urgency.\n",
      "\n",
      "5. Providing training and resources: Providing support staff with the necessary training and resources can help them handle issues more efficiently, reducing response times. This could involve providing training on specific products or services, or creating a knowledge base that support staff can reference.\n",
      "\n",
      "6. Analyzing and optimizing response times: Regularly analyzing response times and identifying areas for improvement can help reduce response times. This could involve tracking response times for different types of issues, or analyzing the support process to identify bottlenecks.\n",
      "\n",
      "7. Outs\n",
      "\n",
      "ЁЯза **Reasoning Agent:**\n",
      "Step 1: Implementing AI-powered chatbots\n",
      "- Reasoning: AI chatbots can handle common customer queries, freeing up human agents to handle more complex issues. This can significantly reduce response times for routine inquiries.\n",
      "- Conclusion: Implement AI-powered chatbots to handle common customer queries.\n",
      "\n",
      "Step 2: Streamlining the support process\n",
      "- Reasoning: Simplifying the support process and removing unnecessary steps can help reduce response times. This could involve consolidating support channels, creating self-help resources, or automating certain processes.\n",
      "- Conclusion: Streamline the support process by consolidating support channels, creating self-help resources, and automating processes where possible.\n",
      "\n",
      "Step 3: Increasing support staff\n",
      "- Reasoning: Hiring additional support staff or training existing staff to handle more complex issues can help reduce response times. A study by Forrester found that increasing the number of support agents by just 10% can reduce average response time by 20%.\n",
      "- Conclusion: Consider hiring additional support staff or training existing staff to handle more complex issues to reduce response times.\n",
      "\n",
      "Step 4: Prioritizing urgent issues\n",
      "- Reasoning: Prioritizing urgent issues and ensuring they are addressed first can help reduce response times. This could involve implementing a ticketing system that prioritizes issues based on their urgency.\n",
      "- Conclusion: Implement a ticketing system that prioritizes issues based on their urgency to reduce response times.\n",
      "\n",
      "Step 5: Providing training and resources\n",
      "- Reasoning: Providing support staff with the necessary training and resources can help them handle issues more efficiently, reducing response times. This could involve providing training on specific products or services, or creating a knowledge base that support staff can reference.\n",
      "- Conclusion: Provide necessary training and resources to support staff to handle issues more efficiently and reduce response times.\n",
      "\n",
      "Step 6: Analyzing and optimizing response times\n",
      "- Reasoning: Regularly analyzing response times and identifying areas for improvement can help reduce response times. This could involve tracking response times for different types\n",
      "\n",
      "тЪб **Execution Agent:**\n",
      "```json\n",
      "{\n",
      "  \"actions\": [\n",
      "    {\n",
      "      \"step\": 1,\n",
      "      \"description\": \"Select and integrate an AI-powered chatbot platform that fits the company's needs and customer service goals.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"1 month\",\n",
      "      \"resources\": [\"IT team\", \"Customer service manager\", \"AI chatbot platform vendor\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 2,\n",
      "      \"description\": \"Review and streamline the current support process, eliminating redundant steps and consolidating support channels.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"2 weeks\",\n",
      "      \"resources\": [\"Customer service manager\", \"Support team\", \"Process improvement tools\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 3,\n",
      "      \"description\": \"Develop a training program for support staff to enhance their skills in handling complex issues and using the new AI chatbot system.\",\n",
      "      \"priority\": \"medium\",\n",
      "      \"timeline\": \"1 month\",\n",
      "      \"resources\": [\"Training department\", \"Support staff\", \"AI chatbot system documentation\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 4,\n",
      "      \"description\": \"Implement a ticketing system that prioritizes issues based on urgency, ensuring that urgent issues are addressed first.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"3 weeks\",\n",
      "      \"resources\": [\"IT team\", \"Customer service manager\", \"Ticketing system software\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 5,\n",
      "      \"description\": \"Create a comprehensive knowledge base and provide resources to support staff to enable them to resolve issues more efficiently.\",\n",
      "      \"priority\": \"medium\",\n",
      "      \"timeline\": \"2 weeks\",\n",
      "      \"resources\": [\"Content creators\", \"Support staff\", \"Knowledge base platform\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 6,\n",
      "      \"description\": \"Set up a system for regularly analyzing response times and identifying areas for improvement.\",\n",
      "      \"priority\": \"medium\",\n",
      "      \"timeline\": \"Ongoing\",\n",
      "      \"\n"
     ]
    }
   ],
   "source": [
    "def test_individual_agents(query: str):\n",
    "    \"\"\"Test each agent individually with the same query.\"\"\"\n",
    "    print(f\"ЁЯзк **Individual Agent Testing**\")\n",
    "    print(f\"тЭУ Query: {query}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Test Retrieval Agent\n",
    "    print(\"\\nЁЯФН **Retrieval Agent:**\")\n",
    "    retrieval_result = coordinator.retrieval.run(query)\n",
    "    print(retrieval_result)\n",
    "    \n",
    "    # Test Reasoning Agent (using retrieval result as context)\n",
    "    print(\"\\nЁЯза **Reasoning Agent:**\")\n",
    "    reasoning_result = coordinator.reasoning.run(retrieval_result, query)\n",
    "    print(reasoning_result)\n",
    "    \n",
    "    # Test Execution Agent (using reasoning result)\n",
    "    print(\"\\nтЪб **Execution Agent:**\")\n",
    "    execution_result = coordinator.execution.run(reasoning_result)\n",
    "    print(execution_result)\n",
    "\n",
    "# Test with a simple query\n",
    "test_query = \"How can we reduce customer support response time?\"\n",
    "test_individual_agents(test_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccb3f9c",
   "metadata": {},
   "source": [
    "## риХри╕риЯрио риЧрйЛри▓ риЯрйИри╕риЯри┐рй░риЧ\n",
    "\n",
    "риЗри╕ ри╕рйИри▓ риирйВрй░ риЖрикригрйЗ риЧрйЛри▓ри╛риВ рижрйА риЬри╛риВриЪ риХри░рии ри▓риИ ри╡ри░ридрйЛ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea65a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ЁЯОи **Custom Goal Testing**\n",
      "ЁЯУЛ Your Goal: Create a training program for new AI engineers joining our company\n",
      "============================================================\n",
      "ЁЯОп **Coordinator:** Processing goal: Create a training program for new AI engineers joining our company\n",
      "============================================================\n",
      "ЁЯУЪ **Step 1:** Retrieving context...\n",
      "   тЬЕ Context retrieved (1408 chars)\n",
      "   ЁЯУД Preview: 1. **Program Structure**: A modular program with a mix of theoretical and practical sessions. Modules could include:\n",
      "   - Introduction to AI and Machi...\n",
      "\n",
      "ЁЯза **Step 2:** Analyzing and reasoning...\n"
     ]
    }
   ],
   "source": [
    "# Custom goal testing - modify the goal below\n",
    "custom_goal = \"Create a training program for new AI engineers joining our company\"\n",
    "\n",
    "print(f\"ЁЯОи **Custom Goal Testing**\")\n",
    "print(f\"ЁЯУЛ Your Goal: {custom_goal}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Choose processing method\n",
    "use_feedback = True  # Set to True for feedback rounds, False for basic processing\n",
    "feedback_rounds = 1  # Number of feedback rounds if use_feedback is True\n",
    "\n",
    "if use_feedback:\n",
    "    custom_result = coordinator.handle_with_feedback(custom_goal, feedback_rounds=feedback_rounds)\n",
    "    print(f\"\\nтЬи **Result with {feedback_rounds} feedback round(s):**\")\n",
    "else:\n",
    "    custom_result = coordinator.handle(custom_goal)\n",
    "    print(f\"\\nтЬи **Basic Result:**\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"ЁЯУЪ **Context:** {custom_result['context'][:200]}...\")\n",
    "print(f\"\\nЁЯза **Decision:** {custom_result['decision'][:200]}...\")\n",
    "print(f\"\\nтЪб **Actions:** {custom_result['actions'][:200]}...\")\n",
    "\n",
    "# Show processing stats\n",
    "print(f\"\\nЁЯУК **Statistics:**\")\n",
    "print(f\"   тП▒я╕П Processing Time: {custom_result['processing_time']:.2f}s\")\n",
    "print(f\"   ЁЯФД Refinement Rounds: {custom_result.get('refinement_rounds', 0)}\")\n",
    "print(f\"   ЁЯУП Total Content Length: {len(custom_result['context']) + len(custom_result['decision']) + len(custom_result['actions'])} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a6d1c2",
   "metadata": {},
   "source": [
    "## рикрйНри░рижри░ри╕ри╝рии ри╡ри┐ри╕ри╝ри▓рйЗри╕ри╝риг\n",
    "\n",
    "риори▓риЯрйА-риПриЬрй░риЯ ри╕ри┐ри╕риЯрио рижрйЗ рикрйНри░рижри░ри╕ри╝рии рижри╛ ри╡ри┐ри╕ри╝ри▓рйЗри╕ри╝риг риХри░рйЛ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef5496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_benchmark(goals: List[str], iterations: int = 2) -> Dict[str, Any]:\n",
    "    \"\"\"Benchmark the coordinator performance with multiple goals.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(f\"ЁЯУК **Performance Benchmark**\")\n",
    "    print(f\"ЁЯОп Goals: {len(goals)}\")\n",
    "    print(f\"ЁЯФД Iterations per goal: {iterations}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i, goal in enumerate(goals, 1):\n",
    "        print(f\"\\nЁЯОп **Goal {i}:** {goal[:50]}...\")\n",
    "        goal_times = []\n",
    "        \n",
    "        for j in range(iterations):\n",
    "            print(f\"   ЁЯФД Iteration {j+1}/{iterations}...\", end=\" \")\n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                result = coordinator.handle(goal)\n",
    "                end_time = time.time()\n",
    "                processing_time = end_time - start_time\n",
    "                goal_times.append(processing_time)\n",
    "                print(f\"тЬЕ {processing_time:.2f}s\")\n",
    "            except Exception as e:\n",
    "                print(f\"тЭМ Error: {e}\")\n",
    "        \n",
    "        if goal_times:\n",
    "            avg_time = sum(goal_times) / len(goal_times)\n",
    "            results.append({\n",
    "                \"goal\": goal,\n",
    "                \"avg_time\": avg_time,\n",
    "                \"min_time\": min(goal_times),\n",
    "                \"max_time\": max(goal_times),\n",
    "                \"times\": goal_times\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Benchmark with different types of goals\n",
    "benchmark_goals = [\n",
    "    \"Create a social media marketing strategy\",\n",
    "    \"Improve employee onboarding process\",\n",
    "    \"Design a mobile app user interface\",\n",
    "    \"Plan a product launch campaign\"\n",
    "]\n",
    "\n",
    "benchmark_results = performance_benchmark(benchmark_goals, iterations=2)\n",
    "\n",
    "# Display benchmark summary\n",
    "print(\"\\nЁЯПЖ **Benchmark Summary:**\")\n",
    "print(\"=\" * 50)\n",
    "for result in benchmark_results:\n",
    "    print(f\"ЁЯУЭ {result['goal'][:40]}...\")\n",
    "    print(f\"   тП▒я╕П Average: {result['avg_time']:.2f}s\")\n",
    "    print(f\"   тЪб Fastest: {result['min_time']:.2f}s\")\n",
    "    print(f\"   ЁЯРМ Slowest: {result['max_time']:.2f}s\")\n",
    "    print()\n",
    "\n",
    "if benchmark_results:\n",
    "    overall_avg = sum(r['avg_time'] for r in benchmark_results) / len(benchmark_results)\n",
    "    print(f\"ЁЯУК **Overall Average Processing Time:** {overall_avg:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49cca35",
   "metadata": {},
   "source": [
    "## рикрйНри░рйЛрибриХри╕ри╝рии рибри┐рикри▓рйМриЗриорйИриВриЯ риорижрижриЧри╛ри░\n",
    "\n",
    "рикрйНри░рйЛрибриХри╕ри╝рии ри╡ри┐рй▒риЪ ри╡ри░ридрйЛриВ ри▓риИ риХрйЛриЖри░рибрйАриирйЗриЯри░ риирйВрй░ риХри┐ри╡рйЗриВ ри▓рикрйЗриЯригри╛ ри╣рйИ риЗри╕рижри╛ риЙрижри╛ри╣ри░рии:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299fed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionCoordinator:\n",
    "    \"\"\"Production-ready wrapper for the multi-agent coordinator.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_alias: str = \"phi-4-mini\"):\n",
    "        self.client = FoundryClient(model_alias)\n",
    "        self.coordinator = Coordinator(self.client)\n",
    "        self.request_count = 0\n",
    "        self.total_processing_time = 0\n",
    "    \n",
    "    def process_goal(self, goal: str, include_feedback: bool = False, feedback_rounds: int = 1) -> Dict[str, Any]:\n",
    "        \"\"\"Process a goal with production monitoring.\"\"\"\n",
    "        self.request_count += 1\n",
    "        \n",
    "        try:\n",
    "            if include_feedback:\n",
    "                result = self.coordinator.handle_with_feedback(goal, feedback_rounds=feedback_rounds)\n",
    "            else:\n",
    "                result = self.coordinator.handle(goal)\n",
    "            \n",
    "            self.total_processing_time += result['processing_time']\n",
    "            \n",
    "            # Add production metadata\n",
    "            result['request_id'] = self.request_count\n",
    "            result['status'] = 'success'\n",
    "            result['model'] = self.client.model_name\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'request_id': self.request_count,\n",
    "                'status': 'error',\n",
    "                'error': str(e),\n",
    "                'goal': goal,\n",
    "                'timestamp': time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get production statistics.\"\"\"\n",
    "        avg_processing_time = self.total_processing_time / max(1, self.request_count)\n",
    "        \n",
    "        return {\n",
    "            'total_requests': self.request_count,\n",
    "            'total_processing_time': self.total_processing_time,\n",
    "            'average_processing_time': avg_processing_time,\n",
    "            'model': self.client.model_name,\n",
    "            'client_healthy': self.client.check_health()\n",
    "        }\n",
    "\n",
    "# Example production usage\n",
    "prod_coordinator = ProductionCoordinator()\n",
    "\n",
    "# Process a goal\n",
    "prod_goal = \"Create a quarterly business review presentation\"\n",
    "prod_result = prod_coordinator.process_goal(prod_goal)\n",
    "\n",
    "print(f\"ЁЯПн **Production Processing Result:**\")\n",
    "print(f\"ЁЯУК Status: {prod_result['status']}\")\n",
    "print(f\"ЁЯФв Request ID: {prod_result['request_id']}\")\n",
    "print(f\"тП▒я╕П Processing Time: {prod_result.get('processing_time', 'N/A')}s\")\n",
    "print(f\"ЁЯдЦ Model: {prod_result.get('model', 'N/A')}\")\n",
    "\n",
    "# Show production stats\n",
    "stats = prod_coordinator.get_stats()\n",
    "print(f\"\\nЁЯУК **Production Statistics:**\")\n",
    "print(f\"   ЁЯУИ Total Requests: {stats['total_requests']}\")\n",
    "print(f\"   тП▒я╕П Average Processing Time: {stats['average_processing_time']:.2f}s\")\n",
    "print(f\"   ЁЯТЪ Client Health: {'тЬЕ Healthy' if stats['client_healthy'] else 'тЭМ Unhealthy'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d3849",
   "metadata": {},
   "source": [
    "## ри╕ри╛ри░ риЕридрйЗ ри╕рин ридрйЛриВ ри╡ризрйАриЖ ридри░рйАриХрйЗ\n",
    "\n",
    "риЗри╕ риирйЛриЯримрйБрй▒риХ риирйЗ риЗрй▒риХ риЙрй▒риЪ-рикрй▒ризри░рйА римри╣рйБ-риПриЬрй░риЯ риЖри░риХрйЗри╕риЯри░ ри╕ри┐ри╕риЯрио рижри╛ рикрйНри░рижри░ри╕ри╝рии риХрйАридри╛:\n",
    "\n",
    "### тЬЕ рикрйНри░рижри░ри╕ри╝ри┐рид риорйБрй▒риЦ ри╡ри┐ри╕ри╝рйЗри╕ри╝ридри╛ри╡ри╛риВ\n",
    "\n",
    "1. **ЁЯПЧя╕П риПриЬрй░риЯ ри╡ри┐ри╕ри╝рйЗри╕ри╝ридри╛**: ри╣ри░ риПриЬрй░риЯ риирйВрй░ риЦри╛ри╕ риЬри╝ри╣ри┐риирйА риХрй░риори╛риВ ри▓риИ риЕриирйБриХрйВри▓ риХрйАридри╛ риЧри┐риЖ\n",
    "2. **ЁЯОп ри╡ри░риХрилри▓рйЛ риЖри░риХрйЗри╕риЯрйНри░рйЗри╕ри╝рии**: римри╣рйБ-риХрижрио рикрйНри░риХри┐ри░ри┐риЖ рижри╛ ри╕ри╣ри┐-ри╕рй░риЪри╛ри▓рии\n",
    "3. **ЁЯУЛ риври╛риВриЪри╛римрй▒риз риЖриЙриЯрикрйБрй▒риЯ**: JSON-рилри╛ри░риорйИриЯ ри╡ри┐рй▒риЪ риХри╛ри░ри╡ри╛риИ рипрйЛриЬриири╛ри╡ри╛риВ\n",
    "4. **ЁЯФД рилрйАрибримрйИриХ ри▓рйВрикри╕**: римри╣рйБ-рижрйМри░ ри╕рйБризри╛ри░ ри╕риори░рй▒риери╛\n",
    "5. **тЪб рикрйНри░рижри░ри╕ри╝рии риири┐риЧри░ри╛риирйА**: рикрйНри░риХри┐ри░ри┐риЖ ри╕риори╛риВ риЕридрйЗ ри╕ри┐ри╣рид рижрйА риЬри╛риВриЪ\n",
    "6. **ЁЯПн риЙридрикри╛рижрии ри▓риИ ридри┐риЖри░**: риири┐риЧри░ри╛риирйА риири╛ри▓ риРриВриЯри░рикрйНри░ри╛риИриЬри╝-риЧрйНри░рйЗриб ри░рйИрикри░\n",
    "\n",
    "### ЁЯза риПриЬрй░риЯ ринрйВриори┐риХри╛ри╡ри╛риВ рижри╛ ри╕ри╛ри░\n",
    "\n",
    "| риПриЬрй░риЯ | риЙрижрйЗри╕ри╝ | риЗриирикрйБриЯ | риЖриЙриЯрикрйБрй▒риЯ |\n",
    "|-------|---------|-------|--------|\n",
    "| **ЁЯФН ри░рйАриЯри░рйАри╡ри▓** | ри╕римрй░ризрид риЬри╛ригриХри╛ри░рйА риХрй▒ривригри╛ | рипрйВриЬри╝ри░ рикрйНри░ри╕ри╝рии | ри╕рй░рижри░ринрид ридрй▒рие риЕридрйЗ рибри╛риЯри╛ |\n",
    "| **ЁЯза ри░рйАриЬри╝риири┐рй░риЧ** | ридри░риХри╕рй░риЧрид ри╡ри┐ри╕ри╝ри▓рйЗри╕ри╝риг | ри╕рй░рижри░рин + рикрйНри░ри╕ри╝рии | риври╛риВриЪри╛римрй▒риз рилрйИри╕ри▓ри╛ |\n",
    "| **тЪб риРриЧриЬри╝ри┐риХри┐риКри╕ри╝рии** | риХри╛ри░ри╡ри╛риИ рипрйЛриЬриири╛ри╡ри╛риВ римригри╛риЙригри╛ | рилрйИри╕ри▓ри╛ | JSON риХри╛ри░ри╡ри╛риИ риХрижрио |\n",
    "| **ЁЯОп риХрйЛриЖри░рибрйАриирйЗриЯри░** | ри╡ри░риХрилри▓рйЛ рижри╛ ри╕ри╣ри┐-ри╕рй░риЪри╛ри▓рии | рипрйВриЬри╝ри░ рижри╛ ри▓риХри╕ри╝ | рикрйВри░ри╛ рииридрйАриЬри╛ |\n",
    "\n",
    "### ЁЯЪА ри╡ри░ридрйЛриВ рижрйЗ риХрйЗри╕\n",
    "\n",
    "- **римри┐риЬри╝риири╕ рипрйЛриЬриири╛ римригри╛риЙригри╛**: ри░ригриирйАридри┐риХ рипрйЛриЬриири╛ риЕридрйЗ риХри╛ри░ри╡ри╛риИ\n",
    "- **рикрйНри░рйЛриЬрйИриХриЯ рикрйНри░римрй░ризрии**: риХрй░риори╛риВ рижрйА ри╡ри┐ринри╛риЬриири╛ риЕридрйЗ ри╕риори╛риВ-ри╕ри╛ри░ригрйА римригри╛риЙригри╛  \n",
    "- **риЧри╡рйИри╕ри╝ригри╛**: риЬри╛ригриХри╛ри░рйА риЗриХрй▒риарйА риХри░риири╛ риЕридрйЗ ри╡ри┐ри╕ри╝ри▓рйЗри╕ри╝риг\n",
    "- **рилрйИри╕ри▓ри╛ ри╕ри╣ри╛риЗридри╛**: риЬриЯри┐ри▓ рилрйИри╕ри▓рйЗ ри▓рйИриг рижрйА рикрйНри░риХри┐ри░ри┐риЖ\n",
    "- **ри╡ри░риХрилри▓рйЛ риЖриЯрйЛриорйЗри╕ри╝рии**: римри╣рйБ-риХрижрио риХри╛ри░рйЛримри╛ри░рйА рикрйНри░риХри┐ри░ри┐риЖри╡ри╛риВ\n",
    "\n",
    "### ЁЯТб ри╕рин ридрйЛриВ ри╡ризрйАриЖ ридри░рйАриХрйЗ\n",
    "\n",
    "1. **ЁЯОп ри╕ри┐рй░риЧри▓ риЬри╝ри┐рй░риорйЗри╡ри╛ри░рйА**: ри╣ри░ риПриЬрй░риЯ рижри╛ риЗрй▒риХ ри╕рикри╕ри╝риЯ риЙрижрйЗри╕ри╝ ри╣рйЛри╡рйЗ\n",
    "2. **ЁЯФЧ ри╕рикри╕ри╝риЯ риЗрй░риЯри░рилрйЗри╕**: риори┐риЖри░рйАриХрйНри░ри┐рид риЗриирикрйБриЯ/риЖриЙриЯрикрйБрй▒риЯ рилри╛ри░риорйИриЯ\n",
    "3. **ЁЯЫбя╕П риЧри▓ридрйА ри╕рй░ринри╛ри▓ригри╛**: риЕри╕рилри▓ридри╛ри╡ри╛риВ 'ридрйЗ ри╕рйБриЪри╛ри░рйВ риШриЯри╛риЕ\n",
    "4. **ЁЯУК риири┐риЧри░ри╛риирйА**: ри╡ри┐ри╕ридрйНри░ри┐рид ри▓ри╛риЧри┐рй░риЧ риЕридрйЗ рикрйНри░рижри░ри╕ри╝рии риЯрйНри░рйИриХри┐рй░риЧ\n",
    "5. **ЁЯФД рилрйАрибримрйИриХ ри▓рйВрикри╕**: рижрйБри╣ри░ри╛риИрипрйЛриЧ ри╕рйБризри╛ри░ риориХрйИриири┐риЬри╝рио\n",
    "6. **тЪЦя╕П ри▓рйЛриб римрйИри▓рйИриВри╕ри┐рй░риЧ**: ри╕рйБридрй░ридри░ риХри╛риори╛риВ ри▓риИ ри╕риори╛риВридри░ рикрйНри░риХри┐ри░ри┐риЖ 'ридрйЗ ри╡ри┐риЪри╛ри░ риХри░рйЛ\n",
    "\n",
    "### ЁЯФо риЕриЧри▓рйЗ риХрижрио\n",
    "\n",
    "- **ЁЯФз рилрй░риХри╕ри╝рии риХри╛ри▓ри┐рй░риЧ**: римри╛ри╣ри░рйА APIs риЕридрйЗ риЯрйВри▓риЬри╝ риири╛ри▓ риЗрй░риЯрйАриЧрйНри░рйЗри╕ри╝рии\n",
    "- **ЁЯза риорйИриорйЛри░рйА ри╕ри┐ри╕риЯрио**: риПриЬрй░риЯри╛риВ ри▓риИ ри╕риери╛риИ риорйИриорйЛри░рйА ри╕ри╝ри╛риори▓ риХри░рйЛ\n",
    "- **ЁЯОн ри╡ри┐ри╕ри╝рйЗри╕ри╝ риори╛рибри▓**: ри╡рй▒риЦ-ри╡рй▒риЦ риПриЬрй░риЯри╛риВ ри▓риИ ри╡рй▒риЦ-ри╡рй▒риЦ риори╛рибри▓ ри╡ри░ридрйЛ\n",
    "- **ЁЯСе ри╣ри┐риКриории-риЗрии-риж-ри▓рйВрик**: риориирйБрй▒риЦрйА ри╕риорйАриЦри┐риЖ риЕридрйЗ риориириЬри╝рйВри░рйА риХрижрио ри╕ри╝ри╛риори▓ риХри░рйЛ\n",
    "- **ЁЯУК риЙрй▒риЪридрио ри╡ри┐ри╕ри╝ри▓рйЗри╕ри╝риг**: ри╡ри┐ри╕ридрйНри░ри┐рид риири┐риЧри░ри╛риирйА риЕридрйЗ риорйИриЯрйНри░ри┐риХри╕\n",
    "\n",
    "риЗри╣ римри╣рйБ-риПриЬрй░риЯ ри╕ри┐ри╕риЯрио риЗри╣ рижри┐риЦри╛риЙриВрижри╛ ри╣рйИ риХри┐ риХри┐ри╡рйЗриВ ри╡ри┐ри╕ри╝рйЗри╕ри╝ридри╛ри╡ри╛риВ ри╡ри╛ри▓рйЗ риПриЬрй░риЯри╛риВ рижрйА ридри╛риХрид риирйВрй░ риЬрйЛрйЬ риХрйЗ риЙрй▒риЪ-рикрй▒ризри░рйА AI ри╡ри░риХрилри▓рйЛ римригри╛риИ риЬри╛ ри╕риХрижрйА ри╣рйИ, риЬрижрйЛриВ риХри┐ риори╛риИриХри░рйЛри╕ри╛рилриЯ рилри╛риКриВрибри░рйА ри▓рйЛриХри▓ риири╛ри▓ ри╕риери╛риириХ риЗрй░рилри░рйИриВри╕ рижрйЗ риЧрйЛрикриирйАрипридри╛ риЕридрйЗ рикрйНри░рижри░ри╕ри╝рии рилри╛риЗрижрйЗ римри░риХри░ри╛ри░ ри░рй▒риЦрйЗ риЬри╛риВрижрйЗ ри╣рииред\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "coopTranslator": {
   "original_hash": "e769e8958054219004d420c9a7b3584b",
   "translation_date": "2025-09-24T21:45:27+00:00",
   "source_file": "Module08/samples/05/multi_agent_orchestration.ipynb",
   "language_code": "pa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}