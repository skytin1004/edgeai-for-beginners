<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "33ecd8ecf0e9347a2b4839a9916e49fb",
  "translation_date": "2025-10-01T00:02:24+00:00",
  "source_file": "Module08/06.ModelsAsTools.md",
  "language_code": "pa"
}
-->
## ‡®ù‡®≤‡®ï

Foundry Local ‡®®‡®æ‡®≤ AI ‡®Æ‡®æ‡®°‡®≤‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®Æ‡©ã‡®°‡®ø‡®ä‡®≤‡®∞, ‡®ï‡®∏‡®ü‡®Æ‡®æ‡®à‡®ú‡®º ‡®ï‡®∞‡®® ‡®Ø‡©ã‡®ó ‡®ü‡©Ç‡®≤ ‡®µ‡®ú‡©ã‡®Ç ‡®µ‡®∞‡®§‡©ã ‡®ú‡©ã ‡®∏‡®ø‡©±‡®ß‡©á ‡®°‡®ø‡®µ‡®æ‡®à‡®∏ '‡®§‡©á ‡®ö‡®≤‡®¶‡©á ‡®π‡®®‡•§ ‡®á‡®∏ ‡®∏‡©à‡®∏‡®º‡®® ‡®µ‡®ø‡©±‡®ö ‡®ó‡©ã‡®™‡®®‡©Ä‡®Ø‡®§‡®æ-‡®∏‡©∞‡®∞‡®ï‡®∏‡®º‡®ï, ‡®ò‡©±‡®ü-‡®µ‡®ø‡®≤‡©∞‡®¨‡©Ä ‡®á‡©∞‡®´‡®∞‡©à‡®Ç‡®∏ ‡®≤‡®à ‡®µ‡®ø‡®π‡®æ‡®∞‡®ï ‡®µ‡®∞‡®ï‡®´‡®≤‡©ã‡®ú‡®º ‡®§‡©á ‡®ú‡®º‡©ã‡®∞ ‡®¶‡®ø‡©±‡®§‡®æ ‡®ó‡®ø‡®Ü ‡®π‡©à ‡®Ö‡®§‡©á SDKs, APIs, ‡®ú‡®æ‡®Ç CLI ‡®∞‡®æ‡®π‡©Ä‡®Ç ‡®á‡®®‡©ç‡®π‡®æ‡®Ç ‡®ü‡©Ç‡®≤‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®ï‡®ø‡®µ‡©á‡®Ç ‡®á‡©∞‡®ü‡®ø‡®ó‡©ç‡®∞‡©á‡®ü ‡®ï‡®∞‡®®‡®æ ‡®π‡©à‡•§ ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®á‡®π ‡®µ‡©Ä ‡®∏‡®ø‡©±‡®ñ‡©ã‡®ó‡©á ‡®ï‡®ø ‡®ú‡®¶‡©ã‡®Ç ‡®≤‡©ã‡©ú ‡®π‡©ã‡®µ‡©á ‡®§‡®æ‡®Ç Azure AI Foundry ‡®µ‡©±‡®≤ ‡®ï‡®ø‡®µ‡©á‡®Ç ‡®∏‡®ï‡©á‡®≤ ‡®ï‡®∞‡®®‡®æ ‡®π‡©à‡•§

> **üîÑ ‡®Ü‡®ß‡©Å‡®®‡®ø‡®ï SDK ‡®≤‡®à ‡®Ö‡®™‡®°‡©á‡®ü ‡®ï‡©Ä‡®§‡®æ**: ‡®á‡®π ‡®Æ‡©ã‡®°‡®ø‡®ä‡®≤ ‡®®‡®µ‡©Ä‡®Ç Microsoft Foundry-Local ‡®∞‡®ø‡®™‡©ã‡®ú‡®º‡®ü‡®∞‡©Ä ‡®™‡©à‡®ü‡®∞‡®®‡®æ‡®Ç ‡®®‡®æ‡®≤ ‡®Ö‡®®‡©Å‡®ï‡©Ç‡®≤ ‡®ï‡©Ä‡®§‡®æ ‡®ó‡®ø‡®Ü ‡®π‡©à ‡®Ö‡®§‡©á `samples/06/` ‡®µ‡®ø‡©±‡®ö ‡®∏‡®Æ‡®æ‡®∞‡®ü ‡®∞‡®æ‡®ä‡®ü‡®ø‡©∞‡®ó ‡®á‡©∞‡®™‡®≤‡©Ä‡®Æ‡©à‡®Ç‡®ü‡©á‡®∏‡®º‡®® ‡®®‡®æ‡®≤ ‡®Æ‡©á‡®≤ ‡®ñ‡®æ‡®Ç‡®¶‡®æ ‡®π‡©à‡•§ ‡®â‡®¶‡®æ‡®π‡®∞‡®®‡®æ‡®Ç ‡®π‡©Å‡®£ ‡®Ü‡®ß‡©Å‡®®‡®ø‡®ï `foundry-local-sdk` ‡®Ö‡®§‡©á ‡®â‡©±‡®ö‡®§‡®Æ ‡®Æ‡®æ‡®°‡®≤ ‡®ö‡©ã‡®£ ‡®∞‡®£‡®®‡©Ä‡®§‡©Ä‡®Ü‡®Ç ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®¶‡©á ‡®π‡®®‡•§

**üèóÔ∏è ‡®Ü‡®∞‡®ï‡©Ä‡®ü‡©à‡®ï‡®ö‡®∞ ‡®π‡®æ‡®à‡®≤‡®æ‡®à‡®ü‡®∏:**
- **‡®∏‡®Æ‡®æ‡®∞‡®ü ‡®Æ‡®æ‡®°‡®≤ ‡®∞‡®æ‡®ä‡®ü‡®ø‡©∞‡®ó**: ‡®ú‡®®‡®∞‡®≤, ‡®§‡®∞‡®ï, ‡®ï‡©ã‡®°, ‡®Ö‡®§‡©á ‡®∞‡®ö‡®®‡®æ‡®§‡®Æ‡®ï ‡®Æ‡®æ‡®°‡®≤‡®æ‡®Ç ‡®µ‡®ø‡©±‡®ö ‡®ï‡©Ä‡®µ‡®∞‡®°-‡®Ö‡®ß‡®æ‡®∞‡®ø‡®§ ‡®ö‡©ã‡®£
- **‡®Ü‡®ß‡©Å‡®®‡®ø‡®ï SDK ‡®á‡©∞‡®ü‡®ø‡®ó‡©ç‡®∞‡©á‡®∏‡®º‡®®**: `FoundryLocalManager` ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®®‡®æ‡®≤ ‡®∏‡®µ‡©à‡®ö‡®æ‡®≤‡®ï ‡®∏‡©á‡®µ‡®æ ‡®ñ‡©ã‡®ú
- **‡®µ‡®æ‡®§‡®æ‡®µ‡®∞‡®£ ‡®∏‡©∞‡®∞‡®ö‡®®‡®æ**: ‡®µ‡®æ‡®§‡®æ‡®µ‡®∞‡®£ ‡®µ‡©à‡®∞‡©Ä‡®è‡®¨‡®≤‡®æ‡®Ç ‡®∞‡®æ‡®π‡©Ä‡®Ç ‡®≤‡®ö‡®ï‡©Ä‡®≤ ‡®Æ‡®æ‡®°‡®≤ ‡®Ö‡®∏‡®æ‡®à‡®®‡®Æ‡©à‡®Ç‡®ü
- **‡®π‡©à‡®≤‡®• ‡®Æ‡®æ‡®®‡©Ä‡®ü‡®∞‡®ø‡©∞‡®ó**: ‡®∏‡©á‡®µ‡®æ ‡®µ‡©à‡®ß‡®§‡®æ ‡®Ö‡®§‡©á ‡®Æ‡®æ‡®°‡®≤ ‡®â‡®™‡®≤‡®¨‡®ß‡®§‡®æ ‡®¶‡©Ä ‡®ú‡®æ‡®Ç‡®ö
- **‡®™‡©ç‡®∞‡©ã‡®°‡®ï‡®∏‡®º‡®® ‡®≤‡®à ‡®§‡®ø‡®Ü‡®∞**: ‡®µ‡®ø‡®∏‡®§‡©ç‡®∞‡®ø‡®§ ‡®ó‡®≤‡®§‡©Ä ‡®∏‡©∞‡®≠‡®æ‡®≤ ‡®Ö‡®§‡©á ‡®´‡®æ‡®≤‡®¨‡©à‡®ï ‡®Æ‡®ï‡©à‡®®‡®ø‡®ú‡®º‡®Æ

**üìÅ ‡®∏‡®•‡®æ‡®®‡®ï ‡®á‡©∞‡®™‡®≤‡©Ä‡®Æ‡©à‡®Ç‡®ü‡©á‡®∏‡®º‡®®:**
- `samples/06/router.py` - ‡®∏‡®Æ‡®æ‡®∞‡®ü ‡®Æ‡®æ‡®°‡®≤ ‡®∞‡®æ‡®ä‡®ü‡®∞ ‡®ï‡©Ä‡®µ‡®∞‡®°-‡®Ö‡®ß‡®æ‡®∞‡®ø‡®§ ‡®ö‡©ã‡®£ ‡®®‡®æ‡®≤
- `samples/06/model_router.ipynb` - ‡®á‡©∞‡®ü‡®∞‡®ê‡®ï‡®ü‡®ø‡®µ ‡®â‡®¶‡®æ‡®π‡®∞‡®® ‡®Ö‡®§‡©á ‡®¨‡©à‡®Ç‡®ö‡®Æ‡®æ‡®∞‡®ï
- `samples/06/README.md` - ‡®∏‡©∞‡®∞‡®ö‡®®‡®æ ‡®Ö‡®§‡©á ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®®‡®ø‡®∞‡®¶‡©á‡®∏‡®º

‡®π‡®µ‡®æ‡®≤‡©á:
- Foundry Local ‡®°‡©å‡®ï‡®∏: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
- ‡®á‡©∞‡®´‡®∞‡©à‡®Ç‡®∏ SDKs ‡®®‡®æ‡®≤ ‡®á‡©∞‡®ü‡®ø‡®ó‡©ç‡®∞‡©á‡®ü ‡®ï‡®∞‡©ã: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
- Hugging Face ‡®Æ‡®æ‡®°‡®≤‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®ï‡©∞‡®™‡®æ‡®á‡®≤ ‡®ï‡®∞‡©ã: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models

## ‡®ù‡®≤‡®ï

Foundry Local ‡®®‡®æ‡®≤ AI ‡®Æ‡®æ‡®°‡®≤‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®Æ‡©ã‡®°‡®ø‡®ä‡®≤‡®∞, ‡®ï‡®∏‡®ü‡®Æ‡®æ‡®à‡®ú‡®º ‡®ï‡®∞‡®® ‡®Ø‡©ã‡®ó ‡®ü‡©Ç‡®≤ ‡®µ‡®ú‡©ã‡®Ç ‡®µ‡®∞‡®§‡©ã ‡®ú‡©ã ‡®∏‡®ø‡©±‡®ß‡©á ‡®°‡®ø‡®µ‡®æ‡®à‡®∏ '‡®§‡©á ‡®ö‡®≤‡®¶‡©á ‡®π‡®®‡•§ ‡®á‡®∏ ‡®∏‡©à‡®∏‡®º‡®® ‡®µ‡®ø‡©±‡®ö ‡®ó‡©ã‡®™‡®®‡©Ä‡®Ø‡®§‡®æ-‡®∏‡©∞‡®∞‡®ï‡®∏‡®º‡®ï, ‡®ò‡©±‡®ü-‡®µ‡®ø‡®≤‡©∞‡®¨‡©Ä ‡®á‡©∞‡®´‡®∞‡©à‡®Ç‡®∏ ‡®≤‡®à ‡®µ‡®ø‡®π‡®æ‡®∞‡®ï ‡®µ‡®∞‡®ï‡®´‡®≤‡©ã‡®ú‡®º ‡®§‡©á ‡®ú‡®º‡©ã‡®∞ ‡®¶‡®ø‡©±‡®§‡®æ ‡®ó‡®ø‡®Ü ‡®π‡©à ‡®Ö‡®§‡©á SDKs, APIs, ‡®ú‡®æ‡®Ç CLI ‡®∞‡®æ‡®π‡©Ä‡®Ç ‡®á‡®®‡©ç‡®π‡®æ‡®Ç ‡®ü‡©Ç‡®≤‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®ï‡®ø‡®µ‡©á‡®Ç ‡®á‡©∞‡®ü‡®ø‡®ó‡©ç‡®∞‡©á‡®ü ‡®ï‡®∞‡®®‡®æ ‡®π‡©à‡•§ ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®á‡®π ‡®µ‡©Ä ‡®∏‡®ø‡©±‡®ñ‡©ã‡®ó‡©á ‡®ï‡®ø ‡®ú‡®¶‡©ã‡®Ç ‡®≤‡©ã‡©ú ‡®π‡©ã‡®µ‡©á ‡®§‡®æ‡®Ç Azure AI Foundry ‡®µ‡©±‡®≤ ‡®ï‡®ø‡®µ‡©á‡®Ç ‡®∏‡®ï‡©á‡®≤ ‡®ï‡®∞‡®®‡®æ ‡®π‡©à‡•§

‡®π‡®µ‡®æ‡®≤‡©á:
- Foundry Local ‡®°‡©å‡®ï‡®∏: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
- ‡®á‡©∞‡®´‡®∞‡©à‡®Ç‡®∏ SDKs ‡®®‡®æ‡®≤ ‡®á‡©∞‡®ü‡®ø‡®ó‡©ç‡®∞‡©á‡®ü ‡®ï‡®∞‡©ã: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
- Hugging Face ‡®Æ‡®æ‡®°‡®≤‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®ï‡©∞‡®™‡®æ‡®á‡®≤ ‡®ï‡®∞‡©ã: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models

## ‡®∏‡®ø‡©±‡®ñ‡®£ ‡®¶‡©á ‡®â‡®¶‡©á‡®∏‡®º
- ‡®°‡®ø‡®µ‡®æ‡®à‡®∏ '‡®§‡©á ‡®Æ‡®æ‡®°‡®≤-‡®µ‡®ú‡©ã‡®Ç-‡®ü‡©Ç‡®≤ ‡®™‡©à‡®ü‡®∞‡®® ‡®°‡®ø‡®ú‡®º‡®æ‡®à‡®® ‡®ï‡®∞‡©ã
- OpenAI-‡®Ö‡®®‡©Å‡®ï‡©Ç‡®≤ REST API ‡®ú‡®æ‡®Ç SDKs ‡®∞‡®æ‡®π‡©Ä‡®Ç ‡®á‡©∞‡®ü‡®ø‡®ó‡©ç‡®∞‡©á‡®ü ‡®ï‡®∞‡©ã
- ‡®Æ‡®æ‡®°‡®≤‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®°‡©ã‡®Æ‡©á‡®®-‡®µ‡®ø‡®∏‡®º‡©á‡®∏‡®º ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®¶‡©á ‡®ï‡©á ‡®ï‡®∏‡®ü‡®Æ‡®æ‡®à‡®ú‡®º ‡®ï‡®∞‡©ã
- Azure AI Foundry ‡®≤‡®à ‡®π‡®æ‡®à‡®¨‡©ç‡®∞‡®ø‡®° ‡®∏‡®ï‡©á‡®≤‡®ø‡©∞‡®ó ‡®¶‡©Ä ‡®Ø‡©ã‡®ú‡®®‡®æ ‡®¨‡®£‡®æ‡®ì

## ‡®≠‡®æ‡®ó 1: ‡®∏‡®Æ‡®æ‡®∞‡®ü ‡®Æ‡®æ‡®°‡®≤ ‡®∞‡®æ‡®ä‡®ü‡®∞ (‡®Ü‡®ß‡©Å‡®®‡®ø‡®ï ‡®á‡©∞‡®™‡®≤‡©Ä‡®Æ‡©à‡®Ç‡®ü‡©á‡®∏‡®º‡®®)

‡®â‡®¶‡©á‡®∏‡®º: ‡®ï‡®µ‡©à‡®∞‡©Ä ‡®∏‡®Æ‡©±‡®ó‡®∞‡©Ä ‡®¶‡©á ‡®Ö‡®ß‡®æ‡®∞ '‡®§‡©á ‡®∏‡®µ‡©à‡®ö‡®æ‡®≤‡®ï ‡®∞‡®æ‡®ä‡®ü‡®ø‡©∞‡®ó ‡®®‡®æ‡®≤ ‡®∏‡®Æ‡®æ‡®∞‡®ü ‡®Æ‡®æ‡®°‡®≤ ‡®ö‡©ã‡®£ ‡®®‡©Ç‡©∞ ‡®≤‡®æ‡®ó‡©Ç ‡®ï‡®∞‡©ã‡•§

> **üìã ‡®®‡©ã‡®ü**: ‡®á‡®π ‡®á‡©∞‡®™‡®≤‡©Ä‡®Æ‡©à‡®Ç‡®ü‡©á‡®∏‡®º‡®® `samples/06/router.py` ‡®µ‡®ø‡©±‡®ö ‡®µ‡®∞‡®§‡©á ‡®ó‡®è ‡®™‡©à‡®ü‡®∞‡®®‡®æ‡®Ç ‡®®‡®æ‡®≤ ‡®Æ‡©á‡®≤ ‡®ñ‡®æ‡®Ç‡®¶‡©Ä ‡®π‡©à ‡®ú‡®ø‡®∏ ‡®µ‡®ø‡©±‡®ö ‡®â‡©±‡®ö‡®§‡®Æ ‡®ï‡©Ä‡®µ‡®∞‡®°-‡®Ö‡®ß‡®æ‡®∞‡®ø‡®§ ‡®Æ‡®æ‡®°‡®≤ ‡®ö‡©ã‡®£ ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®π‡©à‡•§

‡®™‡®π‡®ø‡®≤‡®æ ‡®ï‡®¶‡®Æ) FoundryLocalManager ‡®®‡®æ‡®≤ ‡®Ü‡®ß‡©Å‡®®‡®ø‡®ï ‡®Æ‡®æ‡®°‡®≤ ‡®∞‡®æ‡®ä‡®ü‡®∞ ‡®®‡©Ç‡©∞ ‡®™‡®∞‡®ø‡®≠‡®æ‡®∏‡®º‡®ø‡®§ ‡®ï‡®∞‡©ã  
```python
# router/intelligent_router.py
from foundry_local import FoundryLocalManager
from openai import OpenAI
from typing import Dict, Any, Optional
import os
import json

class ModelRouter:
    """Intelligent model router that selects appropriate models for different task types."""
    
    def __init__(self):
        self.client = None
        self.base_url = None
        self.tools = self._load_tool_registry()
        self._initialize_client()
    
    def _load_tool_registry(self) -> Dict[str, Dict[str, Any]]:
        """Load tool registry from environment or use defaults."""
        default_tools = {
            "general": {
                "model": os.environ.get("GENERAL_MODEL", "phi-4-mini"),
                "notes": "Fast general-purpose chat and Q&A",
                "temperature": 0.7
            },
            "reasoning": {
                "model": os.environ.get("REASONING_MODEL", "deepseek-r1-7b"),
                "notes": "Step-by-step analysis and logical reasoning",
                "temperature": 0.3
            },
            "code": {
                "model": os.environ.get("CODE_MODEL", "qwen2.5-7b"),
                "notes": "Code generation, debugging, and technical tasks",
                "temperature": 0.2
            },
            "creative": {
                "model": os.environ.get("CREATIVE_MODEL", "phi-4-mini"),
                "notes": "Creative writing and storytelling",
                "temperature": 0.9
            }
        }
        
        # Check for environment override
        tools_env = os.environ.get("TOOL_REGISTRY")
        if tools_env:
            try:
                return json.loads(tools_env)
            except json.JSONDecodeError:
                print("Warning: Invalid TOOL_REGISTRY JSON, using defaults")
        
        return default_tools
```
  
‡®¶‡©Ç‡®ú‡®æ ‡®ï‡®¶‡®Æ) ‡®Ü‡®ß‡©Å‡®®‡®ø‡®ï SDK ‡®Ö‡®§‡©á ‡®∏‡©á‡®µ‡®æ ‡®ñ‡©ã‡®ú ‡®®‡®æ‡®≤ ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü ‡®®‡©Ç‡©∞ ‡®∏‡®º‡©Å‡®∞‡©Ç ‡®ï‡®∞‡©ã  
```python
    def _initialize_client(self):
        """Initialize OpenAI client with Foundry Local or fallback configuration."""
        try:
            from foundry_local import FoundryLocalManager
            # Try to use any available model for client initialization
            first_model = next(iter(self.tools.values()))["model"]
            manager = FoundryLocalManager(first_model)
            
            self.client = OpenAI(
                base_url=manager.endpoint,
                api_key=manager.api_key
            )
            self.base_url = manager.endpoint
            print(f"‚úÖ Foundry Local SDK initialized")
        except Exception as e:
            print(f"Warning: Could not use Foundry SDK ({e}), falling back to manual configuration")
            # Fallback to manual configuration
            self.base_url = os.environ.get("BASE_URL", "http://localhost:8000")
            api_key = os.environ.get("API_KEY", "")
            
            self.client = OpenAI(
                base_url=f"{self.base_url}/v1",
                api_key=api_key
            )
            print(f"Initialized manual configuration at {self.base_url}")
    
    def select_tool(self, user_query: str) -> str:
        """Select the most appropriate tool based on the user query."""
        query_lower = user_query.lower()
        
        # Code-related keywords
        code_keywords = ["code", "python", "function", "class", "method", "bug", "debug", 
                        "programming", "script", "algorithm", "implementation", "refactor"]
        if any(keyword in query_lower for keyword in code_keywords):
            return "code"
        
        # Reasoning keywords
        reasoning_keywords = ["why", "how", "explain", "step-by-step", "reason", "analyze", 
                             "think", "logic", "because", "cause", "compare", "evaluate"]
        if any(keyword in query_lower for keyword in reasoning_keywords):
            return "reasoning"
        
        # Creative keywords
        creative_keywords = ["story", "poem", "creative", "imagine", "write", "tale", 
                           "narrative", "fiction", "character", "plot"]
        if any(keyword in query_lower for keyword in creative_keywords):
            return "creative"
        
        # Default to general
        return "general"
    
    def chat(self, model: str, content: str, max_tokens: int = 300, temperature: Optional[float] = None) -> str:
        """Send chat completion request to the specified model."""
        try:
            params = {
                "model": model,
                "messages": [{"role": "user", "content": content}],
                "max_tokens": max_tokens
            }
            
            if temperature is not None:
                params["temperature"] = temperature
            
            response = self.client.chat.completions.create(**params)
            return response.choices[0].message.content
        except Exception as e:
            return f"Error generating response with model {model}: {str(e)}"
```
  
‡®§‡©Ä‡®ú‡®æ ‡®ï‡®¶‡®Æ) ‡®∏‡®Æ‡®æ‡®∞‡®ü ‡®∞‡®æ‡®ä‡®ü‡®ø‡©∞‡®ó ‡®Ö‡®§‡©á ‡®ê‡®ó‡®ú‡®º‡®ø‡®ï‡®ø‡®ä‡®∏‡®º‡®® ‡®®‡©Ç‡©∞ ‡®≤‡®æ‡®ó‡©Ç ‡®ï‡®∞‡©ã (‡®µ‡©á‡®ñ‡©ã `samples/06/router.py`)  
```python
    def route_and_run(self, prompt: str) -> Dict[str, Any]:
        """Route the prompt to the appropriate model and generate response."""
        tool_key = self.select_tool(prompt)
        tool_config = self.tools[tool_key]
        model = tool_config["model"]
        temperature = tool_config.get("temperature", 0.7)
        
        print(f"üéØ Selected tool: {tool_key} (model: {model})")
        
        answer = self.chat(
            model=model, 
            content=prompt, 
            max_tokens=400, 
            temperature=temperature
        )
        
        return {
            "tool": tool_key,
            "model": model,
            "tool_description": tool_config["notes"],
            "temperature": temperature,
            "answer": answer
        }
    
    def check_service_health(self) -> Dict[str, Any]:
        """Check Foundry Local service health and available models."""
        try:
            models_response = self.client.models.list()
            available_models = [model.id for model in models_response.data]
            
            return {
                "status": "healthy",
                "base_url": self.base_url,
                "available_models": available_models,
                "tools_configured": list(self.tools.keys())
            }
        except Exception as e:
            return {
                "status": "error",
                "base_url": self.base_url,
                "error": str(e)
            }

if __name__ == "__main__":
    # Ensure: foundry model run phi-4-mini
    router = ModelRouter()
    
    # Check health
    health = router.check_service_health()
    print(f"Service Health: {json.dumps(health, indent=2)}")
    
    # Test different query types
    queries = [
        "Write a Python function to calculate fibonacci numbers",  # -> code
        "Explain step-by-step why the sky is blue",  # -> reasoning
        "Tell me a creative story about AI",  # -> creative
        "What's the weather like today?"  # -> general
    ]
    
    for query in queries:
        result = router.route_and_run(query)
        print(f"\nQuery: {query}")
        print(f"Selected: {result['tool']} -> {result['model']}")
        print(f"Answer: {result['answer'][:100]}...")
```
  

## ‡®≠‡®æ‡®ó 2: ‡®Ü‡®ß‡©Å‡®®‡®ø‡®ï SDK ‡®á‡©∞‡®ü‡®ø‡®ó‡©ç‡®∞‡©á‡®∏‡®º‡®® (‡®ï‡®¶‡®Æ-‡®¶‡®∞-‡®ï‡®¶‡®Æ)

‡®â‡®¶‡©á‡®∏‡®º: OpenAI Python SDK ‡®®‡®æ‡®≤ Foundry Local SDK ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á ‡®∏‡®π‡©Ä ‡®á‡©∞‡®ü‡®ø‡®ó‡©ç‡®∞‡©á‡®∏‡®º‡®® ‡®ï‡®∞‡©ã‡•§

‡®™‡®π‡®ø‡®≤‡®æ ‡®ï‡®¶‡®Æ) Dependencies ‡®á‡©∞‡®∏‡®ü‡®æ‡®≤ ‡®ï‡®∞‡©ã  
```cmd
cd Module08
.\.venv\Scripts\activate
pip install foundry-local-sdk openai
```
  
‡®¶‡©Ç‡®ú‡®æ ‡®ï‡®¶‡®Æ) ‡®µ‡®æ‡®§‡®æ‡®µ‡®∞‡®£ ‡®∏‡©∞‡®∞‡®ö‡®®‡®æ (‡®µ‡®ø‡®ï‡®≤‡®™‡®ø‡®ï - ‡®µ‡©á‡®ñ‡©ã `samples/06/README.md`)  
```cmd
REM Override default models per tool
set GENERAL_MODEL=phi-4-mini
set REASONING_MODEL=deepseek-r1-7b
set CODE_MODEL=qwen2.5-7b
REM Or provide a full JSON registry
set TOOL_REGISTRY={"general":{"model":"phi-4-mini"},"reasoning":{"model":"deepseek-r1-7b"}}
```
  
‡®§‡©Ä‡®ú‡®æ ‡®ï‡®¶‡®Æ) ‡®Ü‡®ß‡©Å‡®®‡®ø‡®ï SDK ‡®á‡©∞‡®ü‡®ø‡®ó‡©ç‡®∞‡©á‡®∏‡®º‡®®  
```python
# modern_sdk_demo.py
from foundry_local import FoundryLocalManager
from openai import OpenAI
import sys

def main():
    """Demonstrate modern SDK integration."""
    try:
        # Initialize with FoundryLocalManager
        alias = "phi-4-mini"
        manager = FoundryLocalManager(alias)
        
        # Create OpenAI client using Foundry Local endpoint
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key
        )
        
        # Get model info
        model_info = manager.get_model_info(alias)
        print(f"Using model: {model_info.id}")
        
        # Make request with streaming
        stream = client.chat.completions.create(
            model=model_info.id,
            messages=[{"role": "user", "content": "Explain edge AI benefits in one paragraph."}],
            stream=True,
            max_tokens=200
        )
        
        print("Response: ", end="")
        for chunk in stream:
            if chunk.choices[0].delta.content:
                print(chunk.choices[0].delta.content, end="", flush=True)
        print()
        
    except Exception as e:
        print(f"Error: {e}")
        print("Ensure Foundry Local is running with: foundry model run phi-4-mini")
        sys.exit(1)

if __name__ == "__main__":
    main()
```
  

## ‡®≠‡®æ‡®ó 3: ‡®°‡©ã‡®Æ‡©á‡®® ‡®ï‡®∏‡®ü‡®Æ‡®æ‡®à‡®ú‡®º‡©á‡®∏‡®º‡®® (‡®ï‡®¶‡®Æ-‡®¶‡®∞-‡®ï‡®¶‡®Æ)

‡®â‡®¶‡©á‡®∏‡®º: ‡®™‡©ç‡®∞‡©ã‡®Æ‡®™‡®ü ‡®ü‡©à‡®Ç‡®™‡®≤‡©á‡®ü ‡®Ö‡®§‡©á JSON ‡®∏‡®ï‡©Ä‡®Æ‡®æ ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á ‡®°‡©ã‡®Æ‡©á‡®® ‡®≤‡®à ‡®Ü‡®â‡®ü‡®™‡©Å‡©±‡®ü ‡®®‡©Ç‡©∞ ‡®ï‡®∏‡®ü‡®Æ‡®æ‡®à‡®ú‡®º ‡®ï‡®∞‡©ã‡•§

‡®™‡®π‡®ø‡®≤‡®æ ‡®ï‡®¶‡®Æ) ‡®°‡©ã‡®Æ‡©á‡®® ‡®™‡©ç‡®∞‡©ã‡®Æ‡®™‡®ü ‡®ü‡©à‡®Ç‡®™‡®≤‡©á‡®ü ‡®¨‡®£‡®æ‡®ì  
```python
# domain/templates.py
BUSINESS_ANALYST_SYSTEM = """
You are a senior business analyst. Provide:
1) Key insights
2) Risks
3) Next steps
Respond in valid JSON with fields: insights, risks, next_steps.
"""
```
  
‡®¶‡©Ç‡®ú‡®æ ‡®ï‡®¶‡®Æ) JSON ‡®Ü‡®â‡®ü‡®™‡©Å‡©±‡®ü ‡®®‡©Ç‡©∞ ‡®≤‡®æ‡®ó‡©Ç ‡®ï‡®∞‡©ã  
```python
# domain/analyst.py
import requests, os, json

BASE_URL = os.getenv("OPENAI_BASE_URL", "http://localhost:8000/v1")
API_KEY = os.getenv("OPENAI_API_KEY", "local-key")
HEADERS = {"Content-Type":"application/json","Authorization":f"Bearer {API_KEY}"}

from domain.templates import BUSINESS_ANALYST_SYSTEM

def analyze(text: str) -> dict:
    messages = [
        {"role":"system","content": BUSINESS_ANALYST_SYSTEM},
        {"role":"user","content": f"Analyze this business text:\n{text}"}
    ]
    r = requests.post(f"{BASE_URL}/chat/completions", json={
    "model":"phi-4-mini",
        "messages": messages,
        "response_format": {"type":"json_object"},
        "temperature": 0.3
    }, headers=HEADERS, timeout=60)
    r.raise_for_status()
    # Parse JSON content
    content = r.json()["choices"][0]["message"]["content"]
    return json.loads(content)

if __name__ == "__main__":
    print(analyze("Sales dipped 12% in Q3 due to supply constraints and marketing cuts."))
```
  

## ‡®≠‡®æ‡®ó 4: ‡®Ü‡®´‡®≤‡®æ‡®à‡®® ‡®Ö‡®§‡©á ‡®∏‡©Å‡®∞‡©±‡®ñ‡®ø‡®Ü ‡®∞‡®µ‡©±‡®à‡®Ü (‡®ï‡®¶‡®Æ-‡®¶‡®∞-‡®ï‡®¶‡®Æ)

‡®â‡®¶‡©á‡®∏‡®º: ‡®Æ‡®æ‡®°‡®≤‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®∏‡®•‡®æ‡®®‡®ï ‡®§‡©å‡®∞ '‡®§‡©á ‡®ü‡©Ç‡®≤ ‡®µ‡®ú‡©ã‡®Ç ‡®ö‡®≤‡®æ‡®â‡®£ ‡®∏‡®Æ‡©á‡®Ç ‡®ó‡©ã‡®™‡®®‡©Ä‡®Ø‡®§‡®æ ‡®Ö‡®§‡©á ‡®≤‡®ö‡®ï‡®§‡®æ ‡®®‡©Ç‡©∞ ‡®Ø‡®ï‡©Ä‡®®‡©Ä ‡®¨‡®£‡®æ‡®ì‡•§

‡®™‡®π‡®ø‡®≤‡®æ ‡®ï‡®¶‡®Æ) ‡®∏‡®•‡®æ‡®®‡®ï ‡®ê‡®Ç‡®°‡®™‡©å‡®á‡©∞‡®ü ‡®®‡©Ç‡©∞ ‡®™‡©ç‡®∞‡©Ä-‡®µ‡®æ‡®∞‡®Æ ‡®Ö‡®§‡©á ‡®µ‡©à‡®ß ‡®ï‡®∞‡©ã  
```cmd
foundry model run phi-4-mini
curl http://localhost:8000/v1/models
```
  
‡®¶‡©Ç‡®ú‡®æ ‡®ï‡®¶‡®Æ) ‡®á‡®®‡®™‡©Å‡®ü ‡®®‡©Ç‡©∞ ‡®∏‡©à‡®®‡©Ä‡®ü‡®æ‡®à‡®ú‡®º ‡®ï‡®∞‡©ã  
```python
# security/sanitize.py
import re
EMAIL_RE = re.compile(r"[\w\.-]+@[\w\.-]+")
PHONE_RE = re.compile(r"\+?\d[\d\s\-]{7,}\d")

def sanitize(text: str) -> str:
    text = EMAIL_RE.sub("[REDACTED_EMAIL]", text)
    text = PHONE_RE.sub("[REDACTED_PHONE]", text)
    return text
```
  
‡®§‡©Ä‡®ú‡®æ ‡®ï‡®¶‡®Æ) ‡®∏‡®ø‡®∞‡®´-‡®∏‡®•‡®æ‡®®‡®ï ‡®´‡®≤‡©à‡®ó ‡®Ö‡®§‡©á ‡®≤‡©å‡®ó‡®ø‡©∞‡®ó  
```python
# security/local_only.py
import os, json, time
LOG = os.getenv("MODELS_AS_TOOLS_LOG", "./tools_logs.jsonl")

def record(event: dict):
    with open(LOG, "a", encoding="utf-8") as f:
        f.write(json.dumps(event) + "\n")

# Usage before each call
def before_call(tool_name, payload):
    record({"ts": time.time(), "tool": tool_name, "event": "before_call"})

# After each call
def after_call(tool_name, result):
    record({"ts": time.time(), "tool": tool_name, "event": "after_call"})
```
  

## ‡®≠‡®æ‡®ó 5: ‡®™‡©ç‡®∞‡©ã‡®°‡®ï‡®∏‡®º‡®® ‡®°‡®ø‡®™‡®≤‡©å‡®á‡®Æ‡©à‡®Ç‡®ü ‡®Ö‡®§‡©á ‡®∏‡®ï‡©á‡®≤‡®ø‡©∞‡®ó

‡®â‡®¶‡©á‡®∏‡®º: ‡®Æ‡®æ‡®®‡©Ä‡®ü‡®∞‡®ø‡©∞‡®ó ‡®Ö‡®§‡©á Azure AI Foundry ‡®á‡©∞‡®ü‡®ø‡®ó‡©ç‡®∞‡©á‡®∏‡®º‡®® ‡®®‡®æ‡®≤ ‡®∏‡®Æ‡®æ‡®∞‡®ü ‡®∞‡®æ‡®ä‡®ü‡®∞ ‡®®‡©Ç‡©∞ ‡®°‡®ø‡®™‡®≤‡©å‡®á ‡®ï‡®∞‡©ã‡•§

> **üìã ‡®®‡©ã‡®ü**: `samples/06/model_router.ipynb` ‡®µ‡®ø‡©±‡®ö ‡®∏‡®•‡®æ‡®®‡®ï ‡®á‡©∞‡®™‡®≤‡©Ä‡®Æ‡©à‡®Ç‡®ü‡©á‡®∏‡®º‡®® ‡®™‡©ç‡®∞‡©ã‡®°‡®ï‡®∏‡®º‡®® ‡®°‡®ø‡®™‡®≤‡©å‡®á‡®Æ‡©à‡®Ç‡®ü ‡®™‡©à‡®ü‡®∞‡®®‡®æ‡®Ç ‡®¶‡©á ‡®µ‡®ø‡®∏‡®§‡©ç‡®∞‡®ø‡®§ ‡®â‡®¶‡®æ‡®π‡®∞‡®® ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à‡•§

‡®™‡®π‡®ø‡®≤‡®æ ‡®ï‡®¶‡®Æ) ‡®Æ‡®æ‡®®‡©Ä‡®ü‡®∞‡®ø‡©∞‡®ó ‡®®‡®æ‡®≤ ‡®™‡©ç‡®∞‡©ã‡®°‡®ï‡®∏‡®º‡®® ‡®∞‡®æ‡®ä‡®ü‡®∞ (‡®µ‡©á‡®ñ‡©ã `samples/06/router.py`)  
```python
# production/router.py
from router.intelligent_router import ModelRouter
import json
import time
import sys

class ProductionModelRouter(ModelRouter):
    """Production-ready model router with monitoring and logging."""
    
    def __init__(self):
        super().__init__()
        self.request_count = 0
        self.error_count = 0
        self.start_time = time.time()
    
    def route_and_run_with_monitoring(self, prompt: str) -> Dict[str, Any]:
        """Route with comprehensive monitoring and error handling."""
        start_time = time.time()
        self.request_count += 1
        
        try:
            result = self.route_and_run(prompt)
            processing_time = time.time() - start_time
            
            # Log successful request
            self._log_request({
                "status": "success",
                "tool": result["tool"],
                "model": result["model"],
                "processing_time": processing_time,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            })
            
            result["processing_time"] = processing_time
            return result
            
        except Exception as e:
            self.error_count += 1
            error_result = {
                "status": "error",
                "error": str(e),
                "processing_time": time.time() - start_time,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            }
            
            self._log_request(error_result)
            return error_result
    
    def _log_request(self, data: Dict[str, Any]):
        """Log request data for monitoring."""
        print(f"üìä {json.dumps(data)}")
    
    def get_stats(self) -> Dict[str, Any]:
        """Get router statistics."""
        uptime = time.time() - self.start_time
        return {
            "uptime_seconds": uptime,
            "total_requests": self.request_count,
            "error_count": self.error_count,
            "success_rate": (self.request_count - self.error_count) / max(1, self.request_count),
            "requests_per_minute": self.request_count / max(1, uptime / 60)
        }

def main():
    """Production router demo."""
    router = ProductionModelRouter()
    
    # Health check
    health = router.check_service_health()
    if health["status"] == "error":
        print(f"‚ùå Service health check failed: {health['error']}")
        sys.exit(1)
    
    print(f"‚úÖ Service healthy with {len(health['available_models'])} models")
    
    # Process user query
    user_prompt = " ".join(sys.argv[1:]) or "Write three benefits of on-device AI in JSON format."
    print(f"\nüéØ Processing: {user_prompt}")
    
    result = router.route_and_run_with_monitoring(user_prompt)
    
    if result.get("status") == "error":
        print(f"‚ùå Error: {result['error']}")
    else:
        print(f"\nüìã Result:")
        print(f"Tool: {result['tool']} -> Model: {result['model']}")
        print(f"Processing Time: {result['processing_time']:.2f}s")
        print(f"Answer: {result['answer']}")
    
    # Show stats
    stats = router.get_stats()
    print(f"\nüìä Statistics: {json.dumps(stats, indent=2)}")

if __name__ == "__main__":
    main()
```
  

## ‡®π‡©à‡®Ç‡®°‡®∏-‡®Ü‡®® ‡®ö‡©à‡©±‡®ï‡®≤‡®ø‡®∏‡®ü
- [ ] ‡®ï‡©Ä‡®µ‡®∞‡®°-‡®Ö‡®ß‡®æ‡®∞‡®ø‡®§ ‡®ö‡©ã‡®£ ‡®®‡®æ‡®≤ ‡®∏‡®Æ‡®æ‡®∞‡®ü ‡®Æ‡®æ‡®°‡®≤ ‡®∞‡®æ‡®ä‡®ü‡®∞ ‡®®‡©Ç‡©∞ ‡®≤‡®æ‡®ó‡©Ç ‡®ï‡®∞‡©ã (`samples/06/router.py`)
- [ ] ‡®ï‡®à ‡®µ‡®ø‡®∏‡®º‡©á‡®∏‡®º ‡®Æ‡®æ‡®°‡®≤‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®∏‡©∞‡®∞‡®ö‡®ø‡®§ ‡®ï‡®∞‡©ã (‡®ú‡®®‡®∞‡®≤, ‡®§‡®∞‡®ï, ‡®ï‡©ã‡®°, ‡®∞‡®ö‡®®‡®æ‡®§‡®Æ‡®ï)
- [ ] ‡®á‡©∞‡®ü‡®∞‡®ê‡®ï‡®ü‡®ø‡®µ Jupyter ‡®®‡©ã‡®ü‡®¨‡©Å‡©±‡®ï ‡®¶‡©Ä ‡®ú‡®æ‡®Ç‡®ö ‡®ï‡®∞‡©ã (`samples/06/model_router.ipynb`)
- [ ] ‡®µ‡®æ‡®§‡®æ‡®µ‡®∞‡®£-‡®Ö‡®ß‡®æ‡®∞‡®ø‡®§ ‡®Æ‡®æ‡®°‡®≤ ‡®∏‡©∞‡®∞‡®ö‡®®‡®æ ‡®∏‡©à‡®ü ‡®ï‡®∞‡©ã
- [ ] ‡®∏‡©á‡®µ‡®æ ‡®π‡©à‡®≤‡®• ‡®Æ‡®æ‡®®‡©Ä‡®ü‡®∞‡®ø‡©∞‡®ó ‡®Ö‡®§‡©á ‡®ó‡®≤‡®§‡©Ä ‡®∏‡©∞‡®≠‡®æ‡®≤ ‡®®‡©Ç‡©∞ ‡®≤‡®æ‡®ó‡©Ç ‡®ï‡®∞‡©ã
- [ ] ‡®µ‡®ø‡®∏‡®§‡©ç‡®∞‡®ø‡®§ ‡®≤‡©å‡®ó‡®ø‡©∞‡®ó ‡®®‡®æ‡®≤ ‡®™‡©ç‡®∞‡©ã‡®°‡®ï‡®∏‡®º‡®® ‡®∞‡®æ‡®ä‡®ü‡®∞ ‡®®‡©Ç‡©∞ ‡®°‡®ø‡®™‡®≤‡©å‡®á ‡®ï‡®∞‡©ã  

## ‡®∏‡®•‡®æ‡®®‡®ï ‡®∏‡©à‡®Ç‡®™‡®≤ ‡®á‡©∞‡®ü‡®ø‡®ó‡©ç‡®∞‡©á‡®∏‡®º‡®®

‡®™‡©Ç‡®∞‡©Ä ‡®á‡©∞‡®™‡®≤‡©Ä‡®Æ‡©à‡®Ç‡®ü‡©á‡®∏‡®º‡®® ‡®ö‡®≤‡®æ‡®ì:  
```cmd
cd Module08
.\.venv\Scripts\activate

REM Start required models
foundry model run phi-4-mini
foundry model run qwen2.5-7b
foundry model run deepseek-r1-7b

REM Test the intelligent router
python samples\06\router.py "Write a Python function to sort a list"
python samples\06\router.py "Explain step-by-step how bubble sort works"
python samples\06\router.py "Tell me a creative story about robots"

REM Explore the interactive notebook
jupyter notebook samples/06/model_router.ipynb
```
  

## ‡®π‡®µ‡®æ‡®≤‡©á ‡®Ö‡®§‡©á ‡®Ö‡®ó‡®≤‡©á ‡®ï‡®¶‡®Æ
- **‡®∏‡®•‡®æ‡®®‡®ï ‡®á‡©∞‡®™‡®≤‡©Ä‡®Æ‡©à‡®Ç‡®ü‡©á‡®∏‡®º‡®®**: `samples/06/` - ‡®ï‡®à ‡®Æ‡®æ‡®°‡®≤ ‡®∏‡®π‡®æ‡®á‡®§‡®æ ‡®®‡®æ‡®≤ ‡®™‡©Ç‡®∞‡®æ ‡®∏‡®Æ‡®æ‡®∞‡®ü ‡®∞‡®æ‡®ä‡®ü‡®∞  
- **Microsoft ‡®∏‡©à‡®Ç‡®™‡®≤**: [Hello Foundry Local](https://github.com/microsoft/Foundry-Local/tree/main/samples/python/hello-foundry-local)  
- **‡®á‡©∞‡®ü‡®ø‡®ó‡©ç‡®∞‡©á‡®∏‡®º‡®® ‡®°‡©å‡®ï‡®∏**: [‡®á‡©∞‡®´‡®∞‡©à‡®Ç‡®∏ SDKs ‡®®‡®æ‡®≤ ‡®á‡©∞‡®ü‡®ø‡®ó‡©ç‡®∞‡©á‡®ü ‡®ï‡®∞‡©ã](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks)  
- **‡®â‡©±‡®ö‡®§‡®Æ ‡®™‡©à‡®ü‡®∞‡®®**: Module 5 ‡®µ‡®ø‡©±‡®ö ‡®´‡©∞‡®ï‡®∏‡®º‡®® ‡®ï‡®æ‡®≤‡®ø‡©∞‡®ó ‡®Ö‡®§‡©á ‡®Æ‡®≤‡®ü‡©Ä-‡®è‡®ú‡©∞‡®ü ‡®Ü‡®∞‡®ï‡©à‡®∏‡®ü‡©ç‡®∞‡©á‡®∏‡®º‡®® ‡®¶‡©Ä ‡®ñ‡©ã‡®ú ‡®ï‡®∞‡©ã  

## ‡®∏‡®Æ‡®æ‡®™‡®§‡©Ä

Foundry Local ‡®Æ‡®ú‡®º‡®¨‡©Ç‡®§ ‡®°‡®ø‡®µ‡®æ‡®à‡®∏-‡®Ö‡®ß‡®æ‡®∞‡®ø‡®§ AI ‡®®‡©Ç‡©∞ ‡®Ø‡©ã‡®ó ‡®¨‡®£‡®æ‡®â‡®Ç‡®¶‡®æ ‡®π‡©à ‡®ú‡®ø‡©±‡®•‡©á ‡®Æ‡®æ‡®°‡®≤ ‡®∏‡®Æ‡®æ‡®∞‡®ü, ‡®µ‡®ø‡®∏‡®º‡©á‡®∏‡®º ‡®ü‡©Ç‡®≤ ‡®¨‡®£ ‡®ú‡®æ‡®Ç‡®¶‡©á ‡®π‡®®‡•§ ‡®∏‡®µ‡©à‡®ö‡®æ‡®≤‡®ï ‡®Æ‡®æ‡®°‡®≤ ‡®ö‡©ã‡®£, ‡®µ‡®ø‡®∏‡®§‡©ç‡®∞‡®ø‡®§ ‡®Æ‡®æ‡®®‡©Ä‡®ü‡®∞‡®ø‡©∞‡®ó, ‡®Ö‡®§‡©á ‡®™‡©ç‡®∞‡©ã‡®°‡®ï‡®∏‡®º‡®®-‡®§‡®ø‡®Ü‡®∞ ‡®™‡©à‡®ü‡®∞‡®®‡®æ‡®Ç ‡®®‡®æ‡®≤, ‡®ü‡©Ä‡®Æ‡®æ‡®Ç ‡®ó‡©ã‡®™‡®®‡©Ä‡®Ø‡®§‡®æ ‡®Ö‡®§‡©á ‡®™‡©ç‡®∞‡®¶‡®∞‡®∏‡®º‡®® ‡®®‡©Ç‡©∞ ‡®¨‡®∞‡®ï‡®∞‡®æ‡®∞ ‡®∞‡©±‡®ñ‡®¶‡©á ‡®π‡©ã‡®è ‡®µ‡©±‡®ñ-‡®µ‡©±‡®ñ ‡®ü‡®æ‡®∏‡®ï ‡®™‡©ç‡®∞‡®ï‡®æ‡®∞‡®æ‡®Ç ‡®≤‡®à ‡®Ö‡®®‡©Å‡®ï‡©Ç‡®≤ ‡®∏‡©Ç‡®ñ‡®Æ AI ‡®ê‡®™‡®≤‡©Ä‡®ï‡©á‡®∏‡®º‡®® ‡®∏‡®º‡®ø‡®™ ‡®ï‡®∞ ‡®∏‡®ï‡®¶‡©Ä‡®Ü‡®Ç ‡®π‡®®‡•§ ‡®á‡©±‡®•‡©á ‡®¶‡®∞‡®∏‡®æ‡®á‡®Ü ‡®ó‡®ø‡®Ü ‡®∏‡®Æ‡®æ‡®∞‡®ü ‡®∞‡®æ‡®ä‡®ü‡®∞ ‡®™‡©à‡®ü‡®∞‡®® ‡®ú‡®ü‡®ø‡®≤ AI ‡®∏‡®ø‡®∏‡®ü‡®Æ ‡®¨‡®£‡®æ‡®â‡®£ ‡®≤‡®à ‡®á‡©±‡®ï ‡®Æ‡®ú‡®º‡®¨‡©Ç‡®§ ‡®®‡©Ä‡®Ç‡®π ‡®™‡©ç‡®∞‡®¶‡®æ‡®® ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à ‡®ú‡©ã ‡®∏‡®•‡®æ‡®®‡®ï ‡®µ‡®ø‡®ï‡®æ‡®∏ ‡®§‡©ã‡®Ç ‡®™‡©ç‡®∞‡©ã‡®°‡®ï‡®∏‡®º‡®® ‡®°‡®ø‡®™‡®≤‡©å‡®á‡®Æ‡©à‡®Ç‡®ü ‡®§‡©±‡®ï ‡®∏‡®ï‡©á‡®≤ ‡®ï‡®∞ ‡®∏‡®ï‡®¶‡®æ ‡®π‡©à‡•§

---

**‡®Ö‡®∏‡®µ‡©Ä‡®ï‡®∞‡®§‡®æ**:  
‡®á‡®π ‡®¶‡®∏‡®§‡®æ‡®µ‡©á‡®ú‡®º AI ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®∏‡©á‡®µ‡®æ [Co-op Translator](https://github.com/Azure/co-op-translator) ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®ï‡©Ä‡®§‡®æ ‡®ó‡®ø‡®Ü ‡®π‡©à‡•§ ‡®π‡®æ‡®≤‡®æ‡®Ç‡®ï‡®ø ‡®Ö‡®∏‡©Ä‡®Ç ‡®∏‡®π‡©Ä‡®Ö‡®§ ‡®≤‡®à ‡®Ø‡®§‡®®‡®∏‡®º‡©Ä‡®≤ ‡®π‡®æ‡®Ç, ‡®ï‡®ø‡®∞‡®™‡®æ ‡®ï‡®∞‡®ï‡©á ‡®ß‡®ø‡®Ü‡®® ‡®¶‡®ø‡®ì ‡®ï‡®ø ‡®∏‡®µ‡©à‡®ö‡®æ‡®≤‡®ø‡®§ ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶‡®æ‡®Ç ‡®µ‡®ø‡©±‡®ö ‡®ó‡®≤‡®§‡©Ä‡®Ü‡®Ç ‡®ú‡®æ‡®Ç ‡®Ö‡®∏‡©Å‡®ö‡©±‡®ú‡©á‡®™‡®£ ‡®π‡©ã ‡®∏‡®ï‡®¶‡©á ‡®π‡®®‡•§ ‡®á‡®∏ ‡®¶‡©Ä ‡®Æ‡©Ç‡®≤ ‡®≠‡®æ‡®∏‡®º‡®æ ‡®µ‡®ø‡©±‡®ö ‡®Æ‡©å‡®ú‡©Ç‡®¶ ‡®Ö‡®∏‡®≤ ‡®¶‡®∏‡®§‡®æ‡®µ‡©á‡®ú‡®º ‡®®‡©Ç‡©∞ ‡®Ö‡®ß‡®ø‡®ï‡®æ‡®∞‡®§ ‡®∏‡®∞‡©ã‡®§ ‡®Æ‡©∞‡®®‡®ø‡®Ü ‡®ú‡®æ‡®£‡®æ ‡®ö‡®æ‡®π‡©Ä‡®¶‡®æ ‡®π‡©à‡•§ ‡®Æ‡®π‡©±‡®§‡®µ‡®™‡©Ç‡®∞‡®® ‡®ú‡®æ‡®£‡®ï‡®æ‡®∞‡©Ä ‡®≤‡®à, ‡®™‡©á‡®∏‡®º‡©á‡®µ‡®∞ ‡®Æ‡®®‡©Å‡©±‡®ñ‡©Ä ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®¶‡©Ä ‡®∏‡®ø‡®´‡®æ‡®∞‡®∏‡®º ‡®ï‡©Ä‡®§‡©Ä ‡®ú‡®æ‡®Ç‡®¶‡©Ä ‡®π‡©à‡•§ ‡®á‡®∏ ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®§‡©ã‡®Ç ‡®™‡©à‡®¶‡®æ ‡®π‡©ã‡®£ ‡®µ‡®æ‡®≤‡©á ‡®ï‡®ø‡®∏‡©á ‡®µ‡©Ä ‡®ó‡®≤‡®§‡®´‡®π‡®ø‡®Æ‡©Ä ‡®ú‡®æ‡®Ç ‡®ó‡®≤‡®§ ‡®µ‡®ø‡®Ü‡®ñ‡®ø‡®Ü ‡®≤‡®à ‡®Ö‡®∏‡©Ä‡®Ç ‡®ú‡®º‡®ø‡©∞‡®Æ‡©á‡®µ‡®æ‡®∞ ‡®®‡®π‡©Ä‡®Ç ‡®π‡®æ‡®Ç‡•§