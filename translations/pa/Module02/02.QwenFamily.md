<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1c8c05964be6fb235b026feed0bf066e",
  "translation_date": "2025-10-01T20:50:24+00:00",
  "source_file": "Module02/02.QwenFamily.md",
  "language_code": "pa"
}
-->
# ри╕рйИриХри╕ри╝рии 2: риХри╡рйИрии рикри░ри┐ри╡ри╛ри░ рижрйЗ риорйВри▓ ри╕ри┐ризри╛риВрид

риХри╡рйИрии риори╛рибри▓ рикри░ри┐ри╡ри╛ри░ риЕри▓рйАримри╛римри╛ риХри▓ри╛риЙриб рижрйЗ ри╡рй▒рибрйЗ ринри╛ри╕ри╝ри╛ риори╛рибри▓ риЕридрйЗ риори▓риЯрйАриорйЛрибри▓ AI ри▓риИ ри╡ри┐ри╕ридрйНри░ри┐рид рижрйНри░ри┐ри╕ри╝риЯрйАриХрйЛриг риирйВрй░ рижри░ри╕ри╛риЙриВрижри╛ ри╣рйИред риЗри╣ ри╕ри╛римрид риХри░рижри╛ ри╣рйИ риХри┐ риЦрйБрй▒ри▓рйНри╣рйЗ-ри╕ри░рйЛрид риори╛рибри▓ ри╕ри╝ри╛риирижри╛ри░ рикрйНри░рижри░ри╕ри╝рии ри╣ри╛ри╕ри▓ риХри░ ри╕риХрижрйЗ ри╣рии риЕридрйЗ ри╡рй▒риЦ-ри╡рй▒риЦ ридри░рйАриХри┐риЖриВ риири╛ри▓ ридрйИриири╛рид риХрйАридрйЗ риЬри╛ ри╕риХрижрйЗ ри╣рииред риЗри╣ ри╕риориЭригри╛ риори╣рй▒ридри╡рикрйВри░рии ри╣рйИ риХри┐ риХри╡рйИрии рикри░ри┐ри╡ри╛ри░ ри╕ри╝риХридрйАри╕ри╝ри╛ри▓рйА AI ри╕риори░рй▒риери╛ри╡ри╛риВ риирйВрй░ ри▓риЪриХрйАри▓рйЗ ридри░рйАриХрйЗ риири╛ри▓ риХри┐ри╡рйЗриВ рипрйЛриЧ римригри╛риЙриВрижри╛ ри╣рйИ, риЬрижрйЛриВ риХри┐ ри╡рй▒риЦ-ри╡рй▒риЦ риХрй░риори╛риВ ри╡ри┐рй▒риЪ риорйБриХри╛римри▓ри╛ридрйА рикрйНри░рижри░ри╕ри╝рии риирйВрй░ риХри╛риЗрио ри░рй▒риЦрижри╛ ри╣рйИред

## рибри┐ри╡рйИри▓рикри░ри╛риВ ри▓риИ ри╕ри░рйЛрид

### ри╣рй▒риЧри┐рй░риЧ рилрйЗри╕ риори╛рибри▓ ри░ри┐рикрйЛриЬри╝риЯри░рйА
риЪрйБригрйЗ ри╣рйЛриП риХри╡рйИрии рикри░ри┐ри╡ри╛ри░ рижрйЗ риори╛рибри▓ [ри╣рй▒риЧри┐рй░риЧ рилрйЗри╕](https://huggingface.co/models?search=qwen) ри░ри╛ри╣рйАриВ риЙрикри▓римриз ри╣рии, риЬрйЛ риХри┐ риЗриирйНри╣ри╛риВ риори╛рибри▓ри╛риВ рижрйЗ риХрйБриЭ ри░рйВрикри╛риВ ридрй▒риХ рикри╣рйБрй░риЪ рикрйНри░рижри╛рии риХри░рижрйЗ ри╣рииред ридрйБри╕рйАриВ риЙрикри▓римриз ри░рйВрикри╛риВ рижрйА риЦрйЛриЬ риХри░ ри╕риХрижрйЗ ри╣рйЛ, риЖрикригрйЗ ри╡ри┐ри╢рйЗри╕ри╝ риЙрикрипрйЛриЧри╛риВ ри▓риИ риЙриирйНри╣ри╛риВ риирйВрй░ ри╕рйБризри╛ри░ ри╕риХрижрйЗ ри╣рйЛ, риЕридрйЗ ри╡рй▒риЦ-ри╡рй▒риЦ рилри░рйЗриори╡ри░риХри╛риВ ри░ри╛ри╣рйАриВ ридрйИриири╛рид риХри░ ри╕риХрижрйЗ ри╣рйЛред

### ри╕риери╛риириХ ри╡ри┐риХри╛ри╕ риЯрйВри▓
ри╕риери╛риириХ ри╡ри┐риХри╛ри╕ риЕридрйЗ риЯрйИри╕риЯри┐рй░риЧ ри▓риИ, ридрйБри╕рйАриВ [риори╛риИриХри░рйЛри╕ри╛рилриЯ рилри╛риКриВрибри░рйА ри▓рйЛриХри▓](https://github.com/microsoft/foundry-local) рижрйА ри╡ри░ридрйЛриВ риХри░ ри╕риХрижрйЗ ри╣рйЛ, риЬрйЛ риХри┐ ридрйБри╣ри╛рибрйЗ ри╡ри┐риХри╛ри╕ риори╕ри╝рйАрии 'ридрйЗ риЙрикри▓римриз риХри╡рйИрии риори╛рибри▓ри╛риВ риирйВрй░ ри╡ризрйАриЖ рикрйНри░рижри░ри╕ри╝рии риири╛ри▓ риЪри▓ри╛риЙриг ри▓риИ ри╣рйИред

### рижри╕ридри╛ри╡рйЗриЬри╝ ри╕ри░рйЛрид
- [риХри╡рйИрии риори╛рибри▓ рижри╕ридри╛ри╡рйЗриЬри╝](https://huggingface.co/docs/transformers/model_doc/qwen)
- [риРриЬ ридрйИриири╛ридрйА ри▓риИ риХри╡рйИрии риори╛рибри▓ри╛риВ риирйВрй░ ри╡ризрйАриЖ римригри╛риЙригри╛](https://github.com/microsoft/olive)

## рикри░ри┐риЪрип

риЗри╕ риЯри┐риКриЯрйЛри░ри┐риЕри▓ ри╡ри┐рй▒риЪ, риЕри╕рйАриВ риЕри▓рйАримри╛римри╛ рижрйЗ риХри╡рйИрии риори╛рибри▓ рикри░ри┐ри╡ри╛ри░ риЕридрйЗ риЗри╕рижрйЗ риорйВри▓ ризри╛ри░риири╛ри╡ри╛риВ рижрйА риЦрйЛриЬ риХри░ри╛риВриЧрйЗред риЕри╕рйАриВ риХри╡рйИрии рикри░ри┐ри╡ри╛ри░ рижрйЗ ри╡ри┐риХри╛ри╕, риири╡рйАрииридрио ри╕ри┐риЦри▓ри╛риИ ри╡ри┐ризрйАриЖриВ риЬрйЛ риХри╡рйИрии риори╛рибри▓ри╛риВ риирйВрй░ рикрйНри░ринри╛ри╡ри╕ри╝ри╛ри▓рйА римригри╛риЙриВрижрйАриЖриВ ри╣рии, рикри░ри┐ри╡ри╛ри░ ри╡ри┐рй▒риЪ риорйБрй▒риЦ ри░рйВрикри╛риВ, риЕридрйЗ ри╡рй▒риЦ-ри╡рй▒риЦ ри╕риери┐ридрйАриЖриВ ри╡ри┐рй▒риЪ ри╡ри┐ри╣ри╛ри░риХ риЕри░риЬри╝рйАриЖриВ риирйВрй░ риХри╡ри░ риХри░ри╛риВриЧрйЗред

## ри╕ри┐рй▒риЦриг рижрйЗ риЙрижрйЗри╕ри╝

риЗри╕ риЯри┐риКриЯрйЛри░ри┐риЕри▓ рижрйЗ риЕрй░рид ридрй▒риХ, ридрйБри╕рйАриВ ри╕риори░рй▒рие ри╣рйЛри╡рйЛриЧрйЗ:

- риЕри▓рйАримри╛римри╛ рижрйЗ риХри╡рйИрии риори╛рибри▓ рикри░ри┐ри╡ри╛ри░ рижрйЗ рибри┐риЬри╝ри╛риИрии рилри╝ри▓ри╕рилри╝рйЗ риЕридрйЗ ри╡ри┐риХри╛ри╕ риирйВрй░ ри╕риориЭригри╛
- риорйБрй▒риЦ риири╡рйАрииридри╛ри╡ри╛риВ рижрйА рикриЫри╛риг риХри░риири╛ риЬрйЛ риХри╡рйИрии риори╛рибри▓ри╛риВ риирйВрй░ ри╡рй▒риЦ-ри╡рй▒риЦ рикрйИри░ри╛риорйАриЯри░ риЖриХри╛ри░ри╛риВ ри╡ри┐рй▒риЪ риЙрй▒риЪ рикрйНри░рижри░ри╕ри╝рии ри╣ри╛ри╕ри▓ риХри░рии рипрйЛриЧ римригри╛риЙриВрижрйАриЖриВ ри╣рии
- ри╡рй▒риЦ-ри╡рй▒риЦ риХри╡рйИрии риори╛рибри▓ ри░рйВрикри╛риВ рижрйЗ рилри╛риЗрижрйЗ риЕридрйЗ ри╕рйАриори╛ри╡ри╛риВ риирйВрй░ рикриЫри╛ригриири╛
- риЕри╕ри▓-рижрйБриирйАриЖ рижрйАриЖриВ ри╕риери┐ридрйАриЖриВ ри▓риИ риЙриЪри┐рид ри░рйВрикри╛риВ рижрйА риЪрйЛриг риХри░рии ри▓риИ риХри╡рйИрии риори╛рибри▓ри╛риВ рижрйЗ риЧри┐риЖрии риирйВрй░ ри▓ри╛риЧрйВ риХри░риири╛

## риЖризрйБриири┐риХ AI риори╛рибри▓ ри▓рйИриВрибри╕риХрйЗрик риирйВрй░ ри╕риориЭригри╛

AI ри▓рйИриВрибри╕риХрйЗрик ри╡ри┐рй▒риЪ риори╣рй▒ридри╡рикрйВри░рии ридримрижрйАри▓рйАриЖриВ риЖриИриЖриВ ри╣рии, риЬри┐рй▒риерйЗ ри╡рй▒риЦ-ри╡рй▒риЦ ри╕рй░риЧриарии ринри╛ри╕ри╝ри╛ риори╛рибри▓ ри╡ри┐риХри╛ри╕ ри▓риИ ри╡рй▒риЦ-ри╡рй▒риЦ рижрйНри░ри┐ри╕ри╝риЯрйАриХрйЛригри╛риВ рижрйА рикри╛ри▓ригри╛ риХри░рижрйЗ ри╣рииред риЬрижрйЛриВ риХри┐ риХрйБриЭ риЧрйБрикрид римрй░риж-ри╕ри░рйЛрид риори╛рибри▓ри╛риВ 'ридрйЗ ризри┐риЖрии риХрйЗриВрижрйНри░ри┐рид риХри░рижрйЗ ри╣рии, ри╣рйЛри░ риЦрйБрй▒ри▓рйНри╣рйЗ-ри╕ри░рйЛрид рикри╣рйБрй░риЪрипрйЛриЧридри╛ риЕридрйЗ рикри╛ри░рижри░ри╕ри╝ридри╛ 'ридрйЗ риЬри╝рйЛри░ рижри┐рй░рижрйЗ ри╣рииред ри░ри╡ри╛риЗридрйА рижрйНри░ри┐ри╕ри╝риЯрйАриХрйЛриг ри╡ри┐рй▒риЪ риЬри╛риВ ридри╛риВ ри╡рй▒рибрйЗ риЧрйБрикрид риори╛рибри▓ ри╕ри╝ри╛риори▓ ри╣рйБрй░рижрйЗ ри╣рии риЬрйЛ ри╕ри┐ри░рилри╝ APIs ри░ри╛ри╣рйАриВ рикри╣рйБрй░риЪрипрйЛриЧ ри╣рйБрй░рижрйЗ ри╣рии риЬри╛риВ риЦрйБрй▒ри▓рйНри╣рйЗ-ри╕ри░рйЛрид риори╛рибри▓ риЬрйЛ ри╕риори░рй▒риери╛ри╡ри╛риВ ри╡ри┐рй▒риЪ рикри┐рй▒риЫрйЗ ри░ри╣ри┐ ри╕риХрижрйЗ ри╣рииред

риЗри╣ рикрйИри░ри╛рибри╛риИрио ри╕рй░риЧриариири╛риВ ри▓риИ риЪрйБригрйМридрйАриЖриВ рикрйИрижри╛ риХри░рижри╛ ри╣рйИ риЬрйЛ риЖрикригрйЗ рибри╛риЯри╛, ри▓ри╛риЧридри╛риВ, риЕридрйЗ ридрйИриири╛ридрйА ри▓риЪриХридри╛ 'ридрйЗ риири┐рипрй░ридри░риг риХри╛риЗрио ри░рй▒риЦрижрйЗ ри╣рйЛриП ри╕ри╝риХридрйАри╕ри╝ри╛ри▓рйА AI ри╕риори░рй▒риери╛ри╡ри╛риВ рижрйА ринри╛ри▓ риХри░рижрйЗ ри╣рииред ри░ри╡ри╛риЗридрйА рижрйНри░ри┐ри╕ри╝риЯрйАриХрйЛриг риЕриХри╕ри░ риХрй▒риЯрйЗ-ризри╛ри░рйЗ рикрйНри░рижри░ри╕ри╝рии риЕридрйЗ ри╡ри┐ри╣ри╛ри░риХ ридрйИриири╛ридрйА ри╡ри┐риЪри╛ри░ри╛риВ рижрйЗ ри╡ри┐риЪриХри╛ри░ риЪрйЛриг риХри░рии рижрйА ри▓рйЛрйЬ рикрйИрижри╛ риХри░рижри╛ ри╣рйИред

## рикри╣рйБрй░риЪрипрйЛриЧ AI ри╕ри╝рйНри░рйЗри╕ри╝риаридри╛ рижрйА риЪрйБригрйМридрйА

ри╡рй▒риЦ-ри╡рй▒риЦ ри╕риери┐ридрйАриЖриВ ри╡ри┐рй▒риЪ риЙрй▒риЪ-риЧрйБригри╡рй▒ридри╛ ри╡ри╛ри▓рйЗ, рикри╣рйБрй░риЪрипрйЛриЧ AI рижрйА ри▓рйЛрйЬ римри╣рйБрид риори╣рй▒ридри╡рикрйВри░рии ри╣рйЛ риЧриИ ри╣рйИред риЙри╣ риЕри░риЬри╝рйАриЖриВ ри╡ри┐риЪри╛ри░рйЛ риЬрйЛ ри╡рй▒риЦ-ри╡рй▒риЦ ри╕рй░риЧриариириХ риЬри╝ри░рйВри░ридри╛риВ ри▓риИ ри▓риЪриХрйАри▓рйЗ ридрйИриири╛ридрйА ри╡ри┐риХри▓рикри╛риВ рижрйА ри▓рйЛрйЬ ри░рй▒риЦрижрйАриЖриВ ри╣рии, риЬри┐рй▒риерйЗ API ри▓ри╛риЧридри╛риВ риори╣рй▒ридри╡рикрйВри░рии ри╣рйЛ ри╕риХрижрйАриЖриВ ри╣рии, риЧри▓рйЛримри▓ риЕри░риЬри╝рйАриЖриВ ри▓риИ римри╣рйБ-ринри╛ри╕ри╝ри╛риИ ри╕риори░рй▒риери╛ри╡ри╛риВ, риЬри╛риВ риХрйЛрибри┐рй░риЧ риЕридрйЗ риЧригри┐рид ри╡ри░риЧрйЗ риЦрйЗридри░ри╛риВ ри╡ри┐рй▒риЪ ри╡ри┐ри╕ри╝рйЗри╕ри╝ рибрйЛриорйЗрии риири┐рикрйБригридри╛ред

### риорйБрй▒риЦ ридрйИриири╛ридрйА риЬри╝ри░рйВри░ридри╛риВ

риЖризрйБриири┐риХ AI ридрйИриири╛ридрйАриЖриВ риХрйБриЭ риорйБрй▒риври▓рйЗ риЬри╝ри░рйВри░ридри╛риВ рижри╛ ри╕ри╛ри╣риоригри╛ риХри░рижрйАриЖриВ ри╣рии риЬрйЛ ри╡ри┐ри╣ри╛ри░риХ ри▓ри╛риЧрйВридри╛ риирйВрй░ ри╕рйАриори┐рид риХри░рижрйАриЖриВ ри╣рии:

- **рикри╣рйБрй░риЪрипрйЛриЧридри╛**: рикри╛ри░рижри░ри╕ри╝ридри╛ риЕридрйЗ риХри╕риЯриори╛риИриЬри╝рйЗри╕ри╝рии ри▓риИ риЦрйБрй▒ри▓рйНри╣рйЗ-ри╕ри░рйЛрид рижрйА риЙрикри▓римризридри╛
- **ри▓ри╛риЧрид рижрйА рикрйНри░ринри╛ри╡ри╕ри╝рйАри▓ридри╛**: ри╡рй▒риЦ-ри╡рй▒риЦ римриЬриЯри╛риВ ри▓риИ ри╡ри╛риЬрим риЧригриири╛ридриориХ риЬри╝ри░рйВри░ридри╛риВ
- **ри▓риЪриХридри╛**: ри╡рй▒риЦ-ри╡рй▒риЦ ридрйИриири╛ридрйА ри╕риери┐ридрйАриЖриВ ри▓риИ риХриИ риори╛рибри▓ риЖриХри╛ри░
- **риЧри▓рйЛримри▓ рикри╣рйБрй░риЪ**: риориЬри╝римрйВрид римри╣рйБ-ринри╛ри╕ри╝ри╛риИ риЕридрйЗ ри╕рй▒ринри┐риЖриЪри╛ри░риХ ри╕риори░рй▒риери╛ри╡ри╛риВ
- **риири┐рикрйБригридри╛**: ри╡ри┐ри╢рйЗри╕ри╝ риЙрикрипрйЛриЧри╛риВ ри▓риИ рибрйЛриорйЗрии-ри╡ри┐ри╕ри╝рйЗри╕ри╝ ри░рйВрик

## риХри╡рйИрии риори╛рибри▓ рилри╝ри▓ри╕рилри╝ри╛

риХри╡рйИрии риори╛рибри▓ рикри░ри┐ри╡ри╛ри░ AI риори╛рибри▓ ри╡ри┐риХри╛ри╕ ри▓риИ риЗрй▒риХ ри╡ри┐ри╕ридрйНри░ри┐рид рижрйНри░ри┐ри╕ри╝риЯрйАриХрйЛриг риирйВрй░ рижри░ри╕ри╛риЙриВрижри╛ ри╣рйИ, риЬрйЛ риЦрйБрй▒ри▓рйНри╣рйЗ-ри╕ри░рйЛрид рикри╣рйБрй░риЪрипрйЛриЧридри╛, римри╣рйБ-ринри╛ри╕ри╝ри╛риИ ри╕риори░рй▒риери╛ри╡ри╛риВ, риЕридрйЗ ри╡ри┐ри╣ри╛ри░риХ ридрйИриири╛ридрйА риирйВрй░ рикрйНри░ри╛риериори┐риХридри╛ рижри┐рй░рижри╛ ри╣рйИ, риЬрижрйЛриВ риХри┐ риорйБриХри╛римри▓ри╛ридрйА рикрйНри░рижри░ри╕ри╝рии ри╡ри┐ри╕ри╝рйЗри╕ри╝ридри╛ри╡ри╛риВ риирйВрй░ риХри╛риЗрио ри░рй▒риЦрижри╛ ри╣рйИред риХри╡рйИрии риори╛рибри▓ риЗри╣ ри╡рй▒риЦ-ри╡рй▒риЦ риори╛рибри▓ риЖриХри╛ри░ри╛риВ, риЙрй▒риЪ-риЧрйБригри╡рй▒ридри╛ ри╕ри┐риЦри▓ри╛риИ ри╡ри┐ризрйАриЖриВ, риЕридрйЗ ри╡рй▒риЦ-ри╡рй▒риЦ рибрйЛриорйЗриири╛риВ ри▓риИ ри╡ри┐ри╕ри╝рйЗри╕ри╝ ри░рйВрикри╛риВ ри░ри╛ри╣рйАриВ ри╣ри╛ри╕ри▓ риХри░рижрйЗ ри╣рииред

риХри╡рйИрии рикри░ри┐ри╡ри╛ри░ ри╡ри┐рй▒риЪ ри╡рй▒риЦ-ри╡рй▒риЦ рижрйНри░ри┐ри╕ри╝риЯрйАриХрйЛриг ри╕ри╝ри╛риори▓ ри╣рии риЬрйЛ рикрйНри░рижри░ри╕ри╝рии-рикрйНри░ринри╛ри╡ри╕ри╝рйАри▓ридри╛ ри╕рикрйИриХриЯрйНри░рио ри╡ри┐рй▒риЪ ри╡ри┐риХри▓рик рикрйНри░рижри╛рии риХри░рижрйЗ ри╣рии, риорйЛримри╛риИри▓ рибри┐ри╡ри╛риИри╕ри╛риВ ридрйЛриВ ри▓рйИ риХрйЗ риРриириЯри░рикрйНри░ри╛риИриЬри╝ ри╕ри░ри╡ри░ри╛риВ ридрй▒риХ ридрйИриири╛ридрйА риирйВрй░ рипрйЛриЧ римригри╛риЙриВрижрйЗ ри╣рии, риЬрижрйЛриВ риХри┐ риЕри░риерикрйВри░рии AI ри╕риори░рй▒риери╛ри╡ри╛риВ рикрйНри░рижри╛рии риХри░рижрйЗ ри╣рииред риЙрй▒риЪ-риЧрйБригри╡рй▒ридри╛ ри╡ри╛ри▓рйЗ AI ридрй▒риХ рикри╣рйБрй░риЪ риирйВрй░ ри▓рйЛриХридрй░ридри░рид риХри░рии рижри╛ риЙрижрйЗри╕ри╝ ри╣рйИ, риЬрижрйЛриВ риХри┐ ридрйИриири╛ридрйА риЪрйЛригри╛риВ ри╡ри┐рй▒риЪ ри▓риЪриХридри╛ рикрйНри░рижри╛рии риХри░рижрйЗ ри╣рииред

### риорйБрй▒риЦ риХри╡рйИрии рибри┐риЬри╝ри╛риИрии ри╕ри┐ризри╛риВрид

риХри╡рйИрии риори╛рибри▓ риХрйБриЭ риорйБрй▒риври▓рйЗ ри╕ри┐ризри╛риВридри╛риВ 'ридрйЗ римригрйЗ ри╣рии риЬрйЛ риЙриирйНри╣ри╛риВ риирйВрй░ ри╣рйЛри░ ринри╛ри╕ри╝ри╛ риори╛рибри▓ рикри░ри┐ри╡ри╛ри░ри╛риВ ридрйЛриВ ри╡рй▒риЦ риХри░рижрйЗ ри╣рии:

- **риЦрйБрй▒ри▓рйНри╣рйЗ-ри╕ри░рйЛрид рикри╣ри┐ри▓ри╛риВ**: риЦрйЛриЬ риЕридрйЗ ри╡рикри╛ри░риХ риЙрикрипрйЛриЧ ри▓риИ рикрйВри░рйА рикри╛ри░рижри░ри╕ри╝ридри╛ риЕридрйЗ рикри╣рйБрй░риЪрипрйЛриЧридри╛
- **ри╡ри┐ри╕ридрйНри░ри┐рид ри╕ри┐риЦри▓ри╛риИ**: риХриИ ринри╛ри╕ри╝ри╛ри╡ри╛риВ риЕридрйЗ рибрйЛриорйЗриири╛риВ риирйВрй░ риХри╡ри░ риХри░рии ри╡ри╛ри▓рйЗ ри╡рй▒рибрйЗ, ри╡ри┐ри╡ри┐риз рибри╛риЯри╛ри╕рйИриЯри╛риВ 'ридрйЗ ри╕ри┐риЦри▓ри╛риИ
- **ри╕риХрйЗри▓рипрйЛриЧ риЖри░риХрйАриЯрйИриХриЪри░**: ри╡рй▒риЦ-ри╡рй▒риЦ риЧригриири╛ридриориХ риЬри╝ри░рйВри░ридри╛риВ риирйВрй░ риори┐ри▓ри╛риЙриг ри▓риИ риХриИ риори╛рибри▓ риЖриХри╛ри░
- **ри╡ри┐ри╕ри╝рйЗри╕ри╝рид риири┐рикрйБригридри╛**: ри╡ри┐ри╢рйЗри╕ри╝ риХрй░риори╛риВ ри▓риИ риЕриирйБриХрйВри▓ри┐рид рибрйЛриорйЗрии-ри╡ри┐ри╕ри╝рйЗри╕ри╝ ри░рйВрик

## риХри╡рйИрии рикри░ри┐ри╡ри╛ри░ риирйВрй░ рипрйЛриЧ римригри╛риЙриг ри╡ри╛ри▓рйАриЖриВ риорйБрй▒риЦ ридриХриири╛ри▓рйЛриЬрйАриЖриВ

### ри╡рй▒рибрйЗ рикрйИриори╛риирйЗ рижрйА ри╕ри┐риЦри▓ри╛риИ

риХри╡рйИрии рикри░ри┐ри╡ри╛ри░ рижрйА риЗрй▒риХ рикри░ри┐риЪри╛риЗриХ ри╡ри┐ри╕ри╝рйЗри╕ри╝ридри╛ риори╛рибри▓ ри╡ри┐риХри╛ри╕ ри╡ри┐рй▒риЪ ри╕ри┐риЦри▓ри╛риИ рибри╛риЯри╛ риЕридрйЗ риЧригриири╛ридриориХ ри╕ри░рйЛридри╛риВ рижри╛ ри╡рй▒рибри╛ рикрйИриори╛риири╛ ри╣рйИред риХри╡рйИрии риори╛рибри▓ ри╕ри╛ри╡ризри╛риирйА риири╛ри▓ риЪрйБригрйЗ риЧриП, римри╣рйБ-ринри╛ри╕ри╝ри╛риИ рибри╛риЯри╛ри╕рйИриЯри╛риВ рижри╛ ри▓ри╛рин ри▓рйИриВрижрйЗ ри╣рии риЬрйЛ риЯрйНри░ри┐ри▓рйАриЕрии риЯрйЛриХриири╕ риирйВрй░ риХри╡ри░ риХри░рижрйЗ ри╣рии, риЬрйЛ ри╡ри┐ри╕ридрйНри░ри┐рид ри╡ри┐ри╕ри╝ри╡ риЧри┐риЖрии риЕридрйЗ ридри░риХ ри╕риори░рй▒риери╛ри╡ри╛риВ рикрйНри░рижри╛рии риХри░рии ри▓риИ рибри┐риЬри╝ри╛риИрии риХрйАридрйЗ риЧриП ри╣рииред

риЗри╣ рижрйНри░ри┐ри╕ри╝риЯрйАриХрйЛриг риЙрй▒риЪ-риЧрйБригри╡рй▒ридри╛ ри╡ри╛ри▓рйЗ ри╡рйИрй▒рим ри╕риорй▒риЧри░рйА, риЕриХри╛рижриори┐риХ ри╕ри╛ри╣ри┐рид, риХрйЛриб ри░ри┐рикрйЛриЬри╝риЯри░рйА, риЕридрйЗ римри╣рйБ-ринри╛ри╕ри╝ри╛риИ ри╕ри░рйЛридри╛риВ риирйВрй░ риори┐ри▓ри╛ риХрйЗ риХрй░рио риХри░рижри╛ ри╣рйИред ри╕ри┐риЦри▓ри╛риИ ри╡ри┐ризрйА ри╡рй▒риЦ-ри╡рй▒риЦ рибрйЛриорйЗриири╛риВ риЕридрйЗ ринри╛ри╕ри╝ри╛ри╡ри╛риВ ри╡ри┐рй▒риЪ риЧри┐риЖрии рижрйА риЪрйМрйЬри╛риИ риЕридрйЗ ри╕риориЭ рижрйА риЧри╣ри┐ри░ри╛риИ рижрйЛри╡ри╛риВ 'ридрйЗ риЬри╝рйЛри░ рижри┐рй░рижрйА ри╣рйИред

### ридри░риХ риЕридрйЗ ри╕рйЛриЪриг рижрйА риЙрдиреНрдирид ри╕риори░рй▒риери╛

ридри╛риЬри╝ри╛ риХри╡рйИрии риори╛рибри▓ри╛риВ ри╡ри┐рй▒риЪ ри╕рйБризри╛ри░рид ридри░риХ ри╕риори░рй▒риери╛ри╡ри╛риВ ри╕ри╝ри╛риори▓ ри╣рии риЬрйЛ риЬриЯри┐ри▓ римри╣рйБ-риХрижрио ри╕риорй▒ри╕ри┐риЖ ри╣рй▒ри▓ риХри░рии рипрйЛриЧ римригри╛риЙриВрижрйАриЖриВ ри╣рии:

**ри╕рйЛриЪриг рижри╛ риорйЛриб (Qwen3)**: риори╛рибри▓ ри╡ри┐ри╕ридрйНри░ри┐рид риХрижрио-рижри░-риХрижрио ридри░риХ ри╡ри┐рй▒риЪ ри╕ри╝ри╛риори▓ ри╣рйЛ ри╕риХрижрйЗ ри╣рии, риЕрй░ридрио риЬри╡ри╛рим рижрйЗриг ридрйЛриВ рикри╣ри┐ри▓ри╛риВ, риориирйБрй▒риЦрйА ри╕риорй▒ри╕ри┐риЖ-ри╣рй▒ри▓ риХри░рии рижрйЗ рижрйНри░ри┐ри╕ри╝риЯрйАриХрйЛригри╛риВ рижрйЗ ри╕риори╛рииред

**рижрйБриЕри▓-риорйЛриб риУрикри░рйЗри╕ри╝рии**: ри╕ризри╛ри░рии рикрйБрй▒риЫриЧри┐рй▒риЫ ри▓риИ ридрйЗриЬри╝ риЬри╡ри╛рим риорйЛриб риЕридрйЗ риЬриЯри┐ри▓ ри╕риорй▒ри╕ри┐риЖри╡ри╛риВ ри▓риИ риЧри╣ри┐ри░рйЗ ри╕рйЛриЪриг рижрйЗ риорйЛриб рижрйЗ ри╡ри┐риЪриХри╛ри░ ри╕ри╡ри┐рй▒риЪ риХри░рии рижрйА ри╕риори░рй▒риери╛ред

**риЪрйЗрии-риЖрил-риерйМриЯ риЗрй░риЯрйАриЧрйНри░рйЗри╕ри╝рии**: ридри░риХ риХрижриори╛риВ рижрйА риХрйБрижри░ридрйА ри╕ри╝ри╛риори▓ ри╣рйЛриг риЬрйЛ риЬриЯри┐ри▓ риХрй░риори╛риВ ри╡ри┐рй▒риЪ рикри╛ри░рижри░ри╕ри╝ридри╛ риЕридрйЗ ри╕ри╣рйАридри╛ риирйВрй░ ри╕рйБризри╛ри░рижрйЗ ри╣рииред

### риЖри░риХрйАриЯрйИриХриЪри░ри▓ риири╡рйАрииридри╛ри╡ри╛риВ

риХри╡рйИрии рикри░ри┐ри╡ри╛ри░ ри╡ри┐рй▒риЪ риХрйБриЭ риЖри░риХрйАриЯрйИриХриЪри░ри▓ риЕриирйБриХрйВри▓ридри╛ри╡ри╛риВ ри╕ри╝ри╛риори▓ ри╣рии риЬрйЛ рикрйНри░рижри░ри╕ри╝рии риЕридрйЗ рикрйНри░ринри╛ри╡ри╕ри╝рйАри▓ридри╛ рижрйЛри╡ри╛риВ ри▓риИ рибри┐риЬри╝ри╛риИрии риХрйАридрйАриЖриВ риЧриИриЖриВ ри╣рии:

**ри╕риХрйЗри▓рипрйЛриЧ рибри┐риЬри╝ри╛риИрии**: риори╛рибри▓ риЖриХри╛ри░ри╛риВ ри╡ри┐рй▒риЪ ри╕риери┐ри░ риЖри░риХрйАриЯрйИриХриЪри░ риЬрйЛ риЖри╕ри╛рии ри╕риХрйЗри▓ри┐рй░риЧ риЕридрйЗ ридрйБри▓риири╛ рипрйЛриЧ римригри╛риЙриВрижри╛ ри╣рйИред

**риори▓риЯрйАриорйЛрибри▓ риЗрй░риЯрйАриЧрйНри░рйЗри╕ри╝рии**: риЯрйИриХри╕риЯ, ри╡ри┐риЬри╝рии, риЕридрйЗ риЖрибрйАриУ рикрйНри░рйЛри╕рйИри╕ри┐рй░риЧ ри╕риори░рй▒риери╛ри╡ри╛риВ рижрйА риЗрй▒риХриЬрйБриЯ риЖри░риХрйАриЯрйИриХриЪри░ ри╡ри┐рй▒риЪ ри╕ри╣рйА ри╕ри╝ри╛риори▓ ри╣рйЛригред

**ридрйИриири╛ридрйА риЕриирйБриХрйВри▓ридри╛**: ри╡рй▒риЦ-ри╡рй▒риЦ ри╣ри╛ри░рибри╡рйЗриЕри░ ри╕рй░ри░риЪриири╛ри╡ри╛риВ ри▓риИ риХриИ риХрйБриЖриВриЯрйАриЬри╝рйЗри╕ри╝рии ри╡ри┐риХри▓рик риЕридрйЗ ридрйИриири╛ридрйА рилри╛ри░риорйИриЯред

## риори╛рибри▓ риЖриХри╛ри░ риЕридрйЗ ридрйИриири╛ридрйА ри╡ри┐риХри▓рик

риЖризрйБриири┐риХ ридрйИриири╛ридрйА ри╡ри╛ридри╛ри╡ри░риг риХри╡рйИрии риори╛рибри▓ри╛риВ рижрйА ри▓риЪриХридри╛ ридрйЛриВ ри▓ри╛рин риЙриари╛риЙриВрижрйЗ ри╣рии риЬрйЛ ри╡рй▒риЦ-ри╡рй▒риЦ риЧригриири╛ридриориХ риЬри╝ри░рйВри░ридри╛риВ ри╡ри┐рй▒риЪ рилрйИри▓рйЗ ри╣рйЛриП ри╣рии:

### риЫрйЛриЯрйЗ риори╛рибри▓ (0.5B-3B)

риХри╡рйИрии риЫрйЛриЯрйЗ риори╛рибри▓ рикрйНри░рижри╛рии риХри░рижри╛ ри╣рйИ риЬрйЛ риРриЬ ридрйИриири╛ридрйА, риорйЛримри╛риИри▓ риРрикри▓рйАриХрйЗри╕ри╝риири╛риВ, риЕридрйЗ ри╕ри░рйЛрид-ри╕рйАриори┐рид ри╡ри╛ридри╛ри╡ри░ригри╛риВ ри▓риИ рипрйЛриЧ ри╣рии, риЬрижрйЛриВ риХри┐ ри╕ри╝ри╛риирижри╛ри░ ри╕риори░рй▒риери╛ри╡ри╛риВ риХри╛риЗрио ри░рй▒риЦрижрйЗ ри╣рииред

### риорй▒ризрио риори╛рибри▓ (7B-32B)

риорй▒ризрио-ри╕ри╝рйНри░рйЗригрйА рижрйЗ риори╛рибри▓ рикрйЗри╕ри╝рйЗри╡ри░ риЕри░риЬри╝рйАриЖриВ ри▓риИ ри╡ризрйАриЖ ри╕риори░рй▒риери╛ри╡ри╛риВ рикрйНри░рижри╛рии риХри░рижрйЗ ри╣рии, риЬрйЛ рикрйНри░рижри░ри╕ри╝рии риЕридрйЗ риЧригриири╛ридриориХ риЬри╝ри░рйВри░ридри╛риВ рижрйЗ ри╡ри┐риЪриХри╛ри░ ри╕ри╝ри╛риирижри╛ри░ ри╕рй░ридрйБри▓рии рикрйНри░рижри╛рии риХри░рижрйЗ ри╣рииред

### ри╡рй▒рибрйЗ риори╛рибри▓ (72B+)

рикрйВри░рйЗ рикрйИриори╛риирйЗ рижрйЗ риори╛рибри▓ риорй░риЧри╛риВ ри╡ри╛ри▓рйАриЖриВ риЕри░риЬри╝рйАриЖриВ, риЦрйЛриЬ, риЕридрйЗ риРриириЯри░рикрйНри░ри╛риИриЬри╝ ридрйИриири╛ридрйАриЖриВ ри▓риИ ри░ри╛риЬ-риЕрилри╝ри╕ри░ рикрйНри░рижри░ри╕ри╝рии рикрйНри░рижри╛рии риХри░рижрйЗ ри╣рии риЬрйЛ ри╡рй▒риз ридрйЛриВ ри╡рй▒риз ри╕риори░рй▒риери╛ рижрйА ри▓рйЛрйЬ ри░рй▒риЦрижрйЗ ри╣рииред

## риХри╡рйИрии риори╛рибри▓ рикри░ри┐ри╡ри╛ри░ рижрйЗ рилри╛риЗрижрйЗ

### риЦрйБрй▒ри▓рйНри╣рйЗ-ри╕ри░рйЛрид рикри╣рйБрй░риЪрипрйЛриЧридри╛

риХри╡рйИрии риори╛рибри▓ рикрйВри░рйА рикри╛ри░рижри░ри╕ри╝ридри╛ риЕридрйЗ риХри╕риЯриори╛риИриЬри╝рйЗри╕ри╝рии ри╕риори░рй▒риери╛ри╡ри╛риВ рикрйНри░рижри╛рии риХри░рижрйЗ ри╣рии, ри╕рй░риЧриариири╛риВ риирйВрй░ риЖрикригрйЗ ри╡ри┐ри╢рйЗри╕ри╝ риЬри╝ри░рйВри░ридри╛риВ ри▓риИ риори╛рибри▓ри╛риВ риирйВрй░ ри╕риориЭриг, римрижри▓риг, риЕридрйЗ риЕриирйБриХрйВри▓ри┐рид риХри░рии рипрйЛриЧ римригри╛риЙриВрижрйЗ ри╣рии, риЬрижрйЛриВ риХри┐ ри╡ри┐риХри░рйЗридри╛ ри▓ри╛риХ-риЗрии ридрйЛриВ римриЪрижрйЗ ри╣рииред

### ридрйИриири╛ридрйА ри▓риЪриХридри╛

риори╛рибри▓ риЖриХри╛ри░ри╛риВ рижрйА ри╕ри╝рйНри░рйЗригрйА ри╡рй▒риЦ-ри╡рй▒риЦ ри╣ри╛ри░рибри╡рйЗриЕри░ ри╕рй░ри░риЪриири╛ри╡ри╛риВ ри╡ри┐рй▒риЪ ридрйИриири╛ридрйА рипрйЛриЧ римригри╛риЙриВрижрйА ри╣рйИ, риорйЛримри╛риИри▓ рибри┐ри╡ри╛риИри╕ри╛риВ ридрйЛриВ ри▓рйИ риХрйЗ риЙрй▒риЪ-риЕрй░рид ри╕ри░ри╡ри░ри╛риВ ридрй▒риХ, ри╕рй░риЧриариири╛риВ риирйВрй░ риЖрикригрйЗ AI риври╛риВриЪрйЗ рижрйА риЪрйЛриг ри╡ри┐рй▒риЪ ри▓риЪриХридри╛ рикрйНри░рижри╛рии риХри░рижрйА ри╣рйИред

### римри╣рйБ-ринри╛ри╕ри╝ри╛риИ ри╕ри╝рйНри░рйЗри╕ри╝риаридри╛

риХри╡рйИрии риори╛рибри▓ римри╣рйБ-ринри╛ри╕ри╝ри╛риИ ри╕риориЭ риЕридрйЗ риЬриири░рйЗри╕ри╝рии ри╡ри┐рй▒риЪ ри╕ри╝ри╛риирижри╛ри░ ри╣рии, риХриИ ринри╛ри╕ри╝ри╛ри╡ри╛риВ рижри╛ ри╕риори░риерии риХри░рижрйЗ ри╣рии, риЦри╛ри╕ ридрйМри░ 'ридрйЗ риЕрй░риЧри░рйЗриЬри╝рйА риЕридрйЗ риЪрйАриирйА ри╡ри┐рй▒риЪ риориЬри╝римрйВридрйА, риЬрйЛ риЙриирйНри╣ри╛риВ риирйВрй░ риЧри▓рйЛримри▓ риЕри░риЬри╝рйАриЖриВ ри▓риИ рипрйЛриЧ римригри╛риЙриВрижри╛ ри╣рйИред

### риорйБриХри╛римри▓ри╛ридрйА рикрйНри░рижри░ри╕ри╝рии

риХри╡рйИрии риори╛рибри▓ римрйИриВриЪриори╛ри░риХри╛риВ 'ридрйЗ риорйБриХри╛римри▓ри╛ридрйА рииридрйАриЬрйЗ ри╣ри╛ри╕ри▓ риХри░рижрйЗ ри╣рии, риЬрижрйЛриВ риХри┐ риЦрйБрй▒ри▓рйНри╣рйЗ-ри╕ри░рйЛрид рикри╣рйБрй░риЪрипрйЛриЧридри╛ рикрйНри░рижри╛рии риХри░рижрйЗ ри╣рии, риЗри╣ ри╕ри╛римрид риХри░рижрйЗ ри╣рии риХри┐ риЦрйБрй▒ри▓рйНри╣рйЗ риори╛рибри▓ риЧрйБрикрид ри╡ри┐риХри▓рикри╛риВ риири╛ри▓ риорйЗри▓ риЦри╛ ри╕риХрижрйЗ ри╣рииред

### ри╡ри┐ри╕ри╝рйЗри╕ри╝рид ри╕риори░рй▒риери╛ри╡ри╛риВ

рибрйЛриорйЗрии-ри╡ри┐ри╕ри╝рйЗри╕ри╝ ри░рйВрик риЬри┐ри╡рйЗриВ риХри┐ Qwen-Coder риЕридрйЗ Qwen-Math
- Qwen3-235B-A22B риирйЗ риХрйЛрибри┐рй░риЧ, риЧригри┐рид, риЕридрйЗ риЖрио ри╕риори░рй▒риери╛ри╡ри╛риВ рижрйЗ римрйИриВриЪриори╛ри░риХ риорйБри▓ри╛риВриХригри╛риВ ри╡ри┐рй▒риЪ DeepSeek-R1, o1, o3-mini, Grok-3, риЕридрйЗ Gemini-2.5-Pro ри╡ри░риЧрйЗ риЙрй▒риЪ-рикрй▒ризри░рйА риори╛рибри▓ри╛риВ риири╛ри▓ ридрйБри▓риири╛ридриориХ рииридрйАриЬрйЗ рикрйНри░ри╛рикрид риХрйАридрйЗ ри╣рииред  
- Qwen3-30B-A3B риирйЗ QwQ-32B риирйВрй░ 10 риЧрйБригри╛ риЬри╝ри┐риЖрижри╛ риРриХриЯрйАри╡рйЗриЯ риХрйАридрйЗ рикрйИри░ри╛риорйАриЯри░ри╛риВ риири╛ри▓ рикри┐рй▒риЫрйЗ риЫрй▒риб рижри┐рй▒ридри╛ред  
- Qwen3-4B рижрйА риХри╛ри░риЧрйБриЬри╝ри╛ри░рйА Qwen2.5-72B-Instruct рижрйЗ ри╕риори╛рии ри╣рйИред  

**риХрйБри╕ри╝ри▓ридри╛ рикрйНри░ри╛рикридрйАриЖриВ:**  
- Qwen3-MoE римрйЗри╕ риори╛рибри▓ Qwen2.5 рибрйИриВри╕ римрйЗри╕ риори╛рибри▓ри╛риВ рижрйЗ ри╕риори╛рии рикрйНри░рижри░ри╕ри╝рии риХри░рижрйЗ ри╣рии, риЬрижрйЛриВ риХри┐ ри╕ри┐ри░рил 10% риРриХриЯрйАри╡ рикрйИри░ри╛риорйАриЯри░ри╛риВ рижрйА ри╡ри░ридрйЛриВ риХри░рижрйЗ ри╣рииред  
- рибрйИриВри╕ риори╛рибри▓ри╛риВ рижрйЗ риорйБриХри╛римри▓рйЗ ри╕ри┐риЦри▓ри╛риИ риЕридрйЗ риЗрй░рилри░рйИриВри╕ ри╡ри┐рй▒риЪ риори╣рй▒ридри╡рикрйВри░рии ри▓ри╛риЧрид рижрйА римриЪридред  

**римри╣рйБринри╛ри╕ри╝ри╛риИ ри╕риори░рй▒риери╛ри╡ри╛риВ:**  
- Qwen3 риори╛рибри▓ 119 ринри╛ри╕ри╝ри╛ри╡ри╛риВ риЕридрйЗ римрйЛри▓рйАриЖриВ рижри╛ ри╕риори░риерии риХри░рижрйЗ ри╣рииред  
- ри╡рй▒риЦ-ри╡рй▒риЦ ринри╛ри╕ри╝ри╛риИ риЕридрйЗ ри╕рй▒ринри┐риЖриЪри╛ри░риХ ри╕рй░рижри░ринри╛риВ ри╡ри┐рй▒риЪ риориЬри╝римрйВрид рикрйНри░рижри░ри╕ри╝рииред  

**ри╕ри┐риЦри▓ри╛риИ рикрй▒ризри░:**  
- Qwen3 риирйЗ ри▓риЧринриЧ 36 риЯрйНри░ри┐ри▓рйАриЕрии риЯрйЛриХрии ри╡ри░рид риХрйЗ Qwen2.5 рижрйЗ 18 риЯрйНри░ри┐ри▓рйАриЕрии риЯрйЛриХрии рижрйЗ риорйБриХри╛римри▓рйЗ рижрйЛ риЧрйБригри╛ рикрй▒ризри░ рикрйНри░ри╛рикрид риХрйАридри╛ ри╣рйИ, риЬрйЛ 119 ринри╛ри╕ри╝ри╛ри╡ри╛риВ риЕридрйЗ римрйЛри▓рйАриЖриВ риирйВрй░ риХри╡ри░ риХри░рижрйЗ ри╣рииред  

### риори╛рибри▓ ридрйБри▓риири╛ риорйИриЯрйНри░ри┐риХри╕  

| риори╛рибри▓ ри╕рйАри░рйАриЬри╝ | рикрйИри░ри╛риорйАриЯри░ ри░рйЗриВриЬ | ри╕рй░рижри░рин ри▓рй░римри╛риИ | риорйБрй▒риЦ ридри╛риХридри╛риВ | ри╕рин ридрйЛриВ ри╡ризрйАриЖ ри╡ри░ридрйЛриВ риХрйЗри╕ |  
|--------------|------------------|----------------|---------------|----------------|  
| **Qwen2.5** | 0.5B-72B | 32K-128K | ри╕рй░ридрйБри▓ри┐рид рикрйНри░рижри░ри╕ри╝рии, римри╣рйБринри╛ри╕ри╝ри╛риИ | риЖрио риРрикри▓рйАриХрйЗри╕ри╝рии, риЙридрикри╛рижрии ридрйИриири╛ридрйА |  
| **Qwen2.5-Coder** | 1.5B-32B | 128K | риХрйЛриб риЬриири░рйЗри╕ри╝рии, рикрйНри░рйЛриЧри░ри╛риори┐рй░риЧ | ри╕рйМрилриЯри╡рйЗриЕри░ ри╡ри┐риХри╛ри╕, риХрйЛрибри┐рй░риЧ ри╕ри╣ри╛риЗридри╛ |  
| **Qwen2.5-Math** | 1.5B-72B | 4K-128K | риЧригри┐ридриХ ридри░риХ | ри╕ри╝ри┐риХри╕ри╝ри╛ рикри▓рйЗриЯрилри╛ри░рио, STEM риРрикри▓рйАриХрйЗри╕ри╝рии |  
| **Qwen2.5-VL** | ри╡рй▒риЦ-ри╡рй▒риЦ | ри╡рйИри░рйАриПримри▓ | ри╡ри┐риЬри╝рии-ринри╛ри╕ри╝ри╛ ри╕риориЭ | риори▓риЯрйАриорйЛрибри▓ риРрикри▓рйАриХрйЗри╕ри╝рии, риЪри┐рй▒ридри░ ри╡ри┐ри╕ри╝ри▓рйЗри╕ри╝риг |  
| **Qwen3** | 0.6B-235B | ри╡рйИри░рйАриПримри▓ | риЙрй▒риЪ ридри░риХ, ри╕рйЛриЪриг рижри╛ риврй░риЧ | риЬриЯри┐ри▓ ридри░риХ, риЦрйЛриЬ риРрикри▓рйАриХрйЗри╕ри╝рии |  
| **Qwen3 MoE** | 30B-235B риХрйБрй▒ри▓ | ри╡рйИри░рйАриПримри▓ | риХрйБри╕ри╝ри▓ ри╡рй▒рибрйЗ рикрй▒ризри░ рижри╛ рикрйНри░рижри░ри╕ри╝рии | риЙрижрипрйЛриЧ риРрикри▓рйАриХрйЗри╕ри╝рии, риЙрй▒риЪ-рикрйНри░рижри░ри╕ри╝рии рижрйА ри▓рйЛрйЬ |  

## риори╛рибри▓ риЪрйЛриг риЧри╛риИриб  

### риЖрио риРрикри▓рйАриХрйЗри╕ри╝рии ри▓риИ  
- **Qwen2.5-0.5B/1.5B**: риорйЛримри╛риИри▓ риРрикри╕, риРриЬ рибри┐ри╡ри╛риИри╕, ри░рйАриЕри▓-риЯри╛риИрио риРрикри▓рйАриХрйЗри╕ри╝рии  
- **Qwen2.5-3B/7B**: риЖрио риЪрйИриЯримрйЛриЯ, ри╕риорй▒риЧри░рйА риЬриири░рйЗри╕ри╝рии, Q&A ри╕ри┐ри╕риЯрио  

### риЧригри┐ридриХ риЕридрйЗ ридри░риХ рижрйЗ риХрй░риори╛риВ ри▓риИ  
- **Qwen2.5-Math**: риЧригри┐ридриХ ри╕риорй▒ри╕ри┐риЖ ри╣рй▒ри▓ риЕридрйЗ STEM ри╕ри╝ри┐риХри╕ри╝ри╛  
- **Qwen3 Thinking Mode риири╛ри▓**: риЬриЯри┐ри▓ ридри░риХ риЬри┐ри╕ ри╡ри┐рй▒риЪ риХрижрио-рижри░-риХрижрио ри╡ри┐ри╕ри╝ри▓рйЗри╕ри╝риг рижрйА ри▓рйЛрйЬ ри╣рйИ  

### рикрйНри░рйЛриЧри░ри╛риори┐рй░риЧ риЕридрйЗ ри╡ри┐риХри╛ри╕ ри▓риИ  
- **Qwen2.5-Coder**: риХрйЛриб риЬриири░рйЗри╕ри╝рии, рибрйАримрй▒риЧри┐рй░риЧ, рикрйНри░рйЛриЧри░ри╛риори┐рй░риЧ ри╕ри╣ри╛риЗридри╛  
- **Qwen3**: ридри░риХ ри╕риори░рй▒риери╛ри╡ри╛риВ риири╛ри▓ риЙрй▒риЪ-рикрй▒ризри░рйА рикрйНри░рйЛриЧри░ри╛риори┐рй░риЧ риХрй░рио  

### риори▓риЯрйАриорйЛрибри▓ риРрикри▓рйАриХрйЗри╕ри╝рии ри▓риИ  
- **Qwen2.5-VL**: риЪри┐рй▒ридри░ ри╕риориЭ, ри╡ри┐риЬри╝рйБриЕри▓ рикрйНри░ри╕ри╝рии риЙрй▒ридри░  
- **Qwen-Audio**: риЖрибрйАриУ рикрйНри░рйЛри╕рйИри╕ри┐рй░риЧ риЕридрйЗ римрйЛри▓ ри╕риориЭ  

### риЙрижрипрйЛриЧ ридрйИриири╛ридрйА ри▓риИ  
- **Qwen2.5-32B/72B**: риЙрй▒риЪ-рикрйНри░рижри░ри╕ри╝рии ринри╛ри╕ри╝ри╛ ри╕риориЭ  
- **Qwen3-235B-A22B**: риорй░риЧри╛риВ ри╡ри╛ри▓рйЗ риРрикри▓рйАриХрйЗри╕ри╝рии ри▓риИ ри╡рй▒риз ридрйЛриВ ри╡рй▒риз ри╕риори░рй▒риери╛  

## ридрйИриири╛ридрйА рикри▓рйЗриЯрилри╛ри░рио риЕридрйЗ рикри╣рйБрй░риЪрипрйЛриЧридри╛  

### риХри▓ри╛риЙриб рикри▓рйЗриЯрилри╛ри░рио  
- **Hugging Face Hub**: ри╕риорйБрй▒риЪрйЗ риори╛рибри▓ ри░ри┐рикрйЛриЬри╝риЯри░рйА риири╛ри▓ риХриори┐риКриири┐риЯрйА ри╕ри╣ри╛риЗридри╛  
- **ModelScope**: Alibaba рижри╛ риори╛рибри▓ рикри▓рйЗриЯрилри╛ри░рио риЬри┐ри╣рйЬри╛ риЕриирйБриХрйВри▓ридри╛ риЯрйВри▓ри╛риВ риири╛ри▓ ри╣рйИ  
- **ри╡рй▒риЦ-ри╡рй▒риЦ риХри▓ри╛риЙриб рикрйНри░рижри╛ридри╛**: ри╕риЯрйИриВрибри░риб ML рикри▓рйЗриЯрилри╛ри░риори╛риВ рижрйБриЖри░ри╛ ри╕ри╣ри╛риЗридри╛  

### ри╕риери╛риириХ ри╡ри┐риХри╛ри╕ рилри░рйЗриори╡ри░риХ  
- **Transformers**: риЖри╕ри╛рии ридрйИриири╛ридрйА ри▓риИ ри╕риЯрйИриВрибри░риб Hugging Face риЗрй░риЯрйАриЧрйНри░рйЗри╕ри╝рии  
- **vLLM**: риЙридрикри╛рижрии ри╡ри╛ридри╛ри╡ри░ригри╛риВ ри▓риИ риЙрй▒риЪ-рикрйНри░рижри░ри╕ри╝рии ри╕ри░ри╡ри┐рй░риЧ  
- **Ollama**: ри╕риери╛риириХ ридрйИриири╛ридрйА риЕридрйЗ рикрйНри░римрй░ризрии ри▓риИ ри╕ризри╛ри░рии  
- **ONNX Runtime**: ри╡рй▒риЦ-ри╡рй▒риЦ ри╣ри╛ри░рибри╡рйЗриЕри░ ри▓риИ рикри▓рйЗриЯрилри╛ри░рио риЕриирйБриХрйВри▓ридри╛  
- **llama.cpp**: ри╡рй▒риЦ-ри╡рй▒риЦ рикри▓рйЗриЯрилри╛ри░риори╛риВ ри▓риИ риХрйБри╕ри╝ри▓ C++ риЗрй░рикри▓рйАриорйИриВриЯрйЗри╕ри╝рии  

### ри╕ри┐риЦри▓ри╛риИ ри╕ри░рйЛрид  
- **Qwen рижри╕ридри╛ри╡рйЗриЬри╝**: риЕризри┐риХри╛ри░рид рижри╕ридри╛ри╡рйЗриЬри╝ риЕридрйЗ риори╛рибри▓ риХри╛ри░риб  
- **Hugging Face Model Hub**: риЗрй░риЯри░рйИриХриЯри┐ри╡ рибрйИриорйЛ риЕридрйЗ риХриори┐риКриири┐риЯрйА риЙрижри╛ри╣ри░рии  
- **риЦрйЛриЬ рикрйЗрикри░**: Arxiv 'ридрйЗ ридриХриирйАриХрйА рикрйЗрикри░ри╛риВ ри▓риИ риЧри╣ри┐ри░ри╛риИ риири╛ри▓ ри╕риориЭ  
- **риХриори┐риКриири┐риЯрйА рилрйЛри░рио**: ри╕ри░риЧри░рио риХриори┐риКриири┐риЯрйА ри╕ри╣ри╛риЗридри╛ риЕридрйЗ риЪри░риЪри╛  

### Qwen риори╛рибри▓ри╛риВ риири╛ри▓ ри╕ри╝рйБри░рйВриЖрид  

#### ри╡ри┐риХри╛ри╕ рикри▓рйЗриЯрилри╛ри░рио  
1. **Hugging Face Transformers**: ри╕риЯрйИриВрибри░риб Python риЗрй░риЯрйАриЧрйНри░рйЗри╕ри╝рии риири╛ри▓ ри╕ри╝рйБри░рйВ риХри░рйЛ  
2. **ModelScope**: Alibaba рижрйЗ риЕриирйБриХрйВри▓ ридрйИриири╛ридрйА риЯрйВри▓ри╛риВ рижрйА риЦрйЛриЬ риХри░рйЛ  
3. **ри╕риери╛риириХ ридрйИриири╛ридрйА**: Ollama риЬри╛риВ ри╕ри┐рй▒ризрйЗ Transformers ри╡ри░рид риХрйЗ ри╕риери╛риириХ риЯрйИри╕риЯри┐рй░риЧ риХри░рйЛ  

#### ри╕ри┐риЦри▓ри╛риИ рикри╛рие  
1. **риорйБрй▒риЦ ризри╛ри░риири╛ри╡ри╛риВ риирйВрй░ ри╕риориЭрйЛ**: Qwen рикри░ри┐ри╡ри╛ри░ рижрйА риЖри░риХрйАриЯрйИриХриЪри░ риЕридрйЗ ри╕риори░рй▒риери╛ри╡ри╛риВ рижри╛ риЕризри┐риРрии риХри░рйЛ  
2. **ри╡рйИри░рйАриРриВриЯри╕ риири╛ри▓ рикрйНри░рипрйЛриЧ риХри░рйЛ**: ри╡рй▒риЦ-ри╡рй▒риЦ риори╛рибри▓ риЖриХри╛ри░ри╛риВ рижрйА риХрйЛри╕ри╝ри┐ри╕ри╝ риХри░рйЛ ридри╛риВ риЬрйЛ рикрйНри░рижри░ри╕ри╝рии рижрйЗ ри╡рикри╛ри░-римрй░рижрйАриЖриВ риирйВрй░ ри╕риориЭри┐риЖ риЬри╛ ри╕риХрйЗ  
3. **риЕриори▓ ри╡ри┐рй▒риЪ ри▓ри╛риЙриг рижрйА риЕринри┐риЖри╕ риХри░рйЛ**: ри╡ри┐риХри╛ри╕ рижрйЗ ри╡ри╛ридри╛ри╡ри░ригри╛риВ ри╡ри┐рй▒риЪ риори╛рибри▓ ридрйИриири╛рид риХри░рйЛ  
4. **ридрйИриири╛ридрйА риирйВрй░ риЕриирйБриХрйВри▓ римригри╛риУ**: риЙридрикри╛рижрии рижрйЗ ри╡ри░ридрйЛриВ риХрйЗри╕ри╛риВ ри▓риИ рилри╛риИрии-риЯри┐риКрии риХри░рйЛ  

#### ри╕рин ридрйЛриВ ри╡ризрйАриЖ риЕринри┐риЖри╕  
- **риЫрйЛриЯрйЗ риири╛ри▓ ри╕ри╝рйБри░рйВ риХри░рйЛ**: ри╕ри╝рйБри░рйВриЖридрйА ри╡ри┐риХри╛ри╕ ри▓риИ риЫрйЛриЯрйЗ риори╛рибри▓ (1.5B-7B) риири╛ри▓ ри╕ри╝рйБри░рйВ риХри░рйЛ  
- **риЪрйИриЯ риЯрйИриВрикри▓рйЗриЯ ри╡ри░ридрйЛ**: ри╡ризрйАриЖ рииридрйАриЬри┐риЖриВ ри▓риИ ри╕ри╣рйА рилри╛ри░риорйИриЯри┐рй░риЧ ри▓ри╛риЧрйВ риХри░рйЛ  
- **ри╕ри░рйЛридри╛риВ рижрйА риири┐риЧри░ри╛риирйА риХри░рйЛ**: риорйИриори░рйА рижрйА ри╡ри░ридрйЛриВ риЕридрйЗ риЗрй░рилри░рйИриВри╕ рижрйА риЧридрйА риирйВрй░ риЯрйНри░рйИриХ риХри░рйЛ  
- **ри╡ри┐ри╕ри╝рйЗри╕ри╝ридри╛ риирйВрй░ ризри┐риЖрии ри╡ри┐рй▒риЪ ри░рй▒риЦрйЛ**: риЬрижрйЛриВ ри▓рйЛрйЬ ри╣рйЛри╡рйЗ ридри╛риВ риЦрйЗридри░-ри╡ри┐ри╕ри╝рйЗри╕ри╝ ри╡рйИри░рйАриРриВриЯри╕ рижрйА риЪрйЛриг риХри░рйЛ  

## риЙрй▒риЪ-рикрй▒ризри░рйА ри╡ри░ридрйЛриВ рижрйЗ рикрйИриЯри░рии  

### рилри╛риИрии-риЯри┐риКриири┐рй░риЧ риЙрижри╛ри╣ри░рии  

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig, get_peft_model
from trl import SFTTrainer
from datasets import load_dataset

# Load base model for fine-tuning
model_name = "Qwen/Qwen2.5-7B-Instruct"
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.bfloat16,
    device_map="auto"
)

tokenizer = AutoTokenizer.from_pretrained(model_name)
tokenizer.pad_token = tokenizer.eos_token

# Configure LoRA for efficient fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.1,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj"]
)

# Apply LoRA to model
model = get_peft_model(model, peft_config)

# Training configuration
training_args = TrainingArguments(
    output_dir="./qwen-finetuned",
    learning_rate=5e-5,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,
    num_train_epochs=3,
    warmup_steps=100,
    logging_steps=10,
    save_steps=500,
    evaluation_strategy="steps",
    eval_steps=500,
    bf16=True,
    remove_unused_columns=False
)

# Load and prepare dataset
def format_instruction(example):
    return f"<|im_start|>user\n{example['instruction']}<|im_end|>\n<|im_start|>assistant\n{example['output']}<|im_end|>"

dataset = load_dataset("your-custom-dataset")
dataset = dataset.map(
    lambda x: {"text": format_instruction(x)},
    remove_columns=dataset["train"].column_names
)

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_args,
    train_dataset=dataset["train"],
    eval_dataset=dataset["validation"],
    tokenizer=tokenizer,
    max_seq_length=2048,
    packing=True
)

# Start fine-tuning
trainer.train()
```
  
### ри╡ри┐ри╕ри╝рйЗри╕ри╝ рикрйНри░рй░рикриЯ риЗрй░риЬрйАриирйАриЕри░ри┐рй░риЧ  

**риЬриЯри┐ри▓ ридри░риХ рижрйЗ риХрй░риори╛риВ ри▓риИ:**  
```python
def create_reasoning_prompt(problem, context=""):
    """Create structured prompt for complex reasoning"""
    prompt = f"""<|im_start|>system
You are Qwen, a helpful AI assistant. When solving complex problems, break down your reasoning into clear steps.

Instructions:
1. Analyze the problem carefully
2. Identify key components and relationships
3. Work through the solution step by step
4. Verify your answer
5. Provide a clear final answer

{context}
<|im_end|>
<|im_start|>user
{problem}

Please solve this step by step, showing your reasoning process.
<|im_end|>
<|im_start|>assistant"""
    
    return prompt

# Example usage
complex_problem = """
A company's revenue grows by 15% each year. If they had $2 million in revenue in 2020, 
and they want to reach $5 million by 2025, will they achieve this goal? 
If not, what growth rate would they need?
"""

reasoning_prompt = create_reasoning_prompt(complex_problem)
```
  
**ри╕рй░рижри░рин риири╛ри▓ риХрйЛриб риЬриири░рйЗри╕ри╝рии ри▓риИ:**  
```python
def create_coding_prompt(task, language="Python", context="", constraints=""):
    """Create structured prompt for code generation"""
    prompt = f"""<|im_start|>system
You are Qwen-Coder, an expert programming assistant. Generate clean, efficient, and well-documented code.

Requirements:
- Use {language} programming language
- Include comprehensive docstrings
- Add type hints where appropriate
- Follow best practices and conventions
- Include example usage

{context}
<|im_end|>
<|im_start|>user
Task: {task}

{f"Constraints: {constraints}" if constraints else ""}

Please provide a complete, production-ready solution.
<|im_end|>
<|im_start|>assistant"""
    
    return prompt

# Example usage
coding_task = """
Create a class that manages a simple in-memory cache with TTL (time-to-live) support.
The cache should support get, set, delete operations and automatically expire entries.
"""

constraints = """
- Thread-safe operations
- Configurable default TTL
- Memory-efficient cleanup of expired entries
- Support for custom serialization
"""

coding_prompt = create_coding_prompt(coding_task, "Python", constraints=constraints)
```
  
### римри╣рйБринри╛ри╕ри╝ри╛риИ риРрикри▓рйАриХрйЗри╕ри╝рии  

```python
def create_multilingual_prompt(query, target_languages=["en", "zh", "es"]):
    """Create prompt for multilingual responses"""
    language_names = {
        "en": "English",
        "zh": "Chinese (ф╕нцЦЗ)",
        "es": "Spanish (Espa├▒ol)",
        "fr": "French (Fran├зais)",
        "de": "German (Deutsch)",
        "ja": "Japanese (цЧецЬмшкЮ)"
    }
    
    lang_list = [language_names.get(lang, lang) for lang in target_languages]
    lang_str = ", ".join(lang_list)
    
    prompt = f"""<|im_start|>system
You are Qwen, a multilingual AI assistant. Provide responses in multiple languages as requested.
Ensure cultural appropriateness and natural expression in each language.
<|im_end|>
<|im_start|>user
Please answer the following question in {lang_str}:

{query}

Provide clear, culturally appropriate responses in each requested language.
<|im_end|>
<|im_start|>assistant"""
    
    return prompt

# Example usage
multilingual_query = "What are the benefits of renewable energy for the environment?"
multilingual_prompt = create_multilingual_prompt(
    multilingual_query, 
    target_languages=["en", "zh", "es"]
)
```
  
### ЁЯФз риЙридрикри╛рижрии ридрйИриири╛ридрйА рикрйИриЯри░рии  

```python
import asyncio
from typing import List, Dict, Optional
from dataclasses import dataclass
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

@dataclass
class GenerationConfig:
    max_tokens: int = 512
    temperature: float = 0.7
    top_p: float = 0.9
    repetition_penalty: float = 1.05
    do_sample: bool = True

class QwenService:
    """Production-ready Qwen model service"""
    
    def __init__(self, model_name: str, device: str = "auto"):
        self.model_name = model_name
        self.device = device
        self.model = None
        self.tokenizer = None
        self._load_model()
    
    def _load_model(self):
        """Load model and tokenizer"""
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModelForCausalLM.from_pretrained(
            self.model_name,
            torch_dtype=torch.bfloat16,
            device_map=self.device,
            trust_remote_code=True
        )
        
        # Optimize for inference
        self.model.eval()
        if hasattr(self.model, 'generation_config'):
            self.model.generation_config.pad_token_id = self.tokenizer.eos_token_id
    
    def format_chat(self, messages: List[Dict[str, str]]) -> str:
        """Format messages using chat template"""
        return self.tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )
    
    async def generate_async(
        self, 
        messages: List[Dict[str, str]], 
        config: GenerationConfig = GenerationConfig()
    ) -> str:
        """Async generation for high-throughput applications"""
        formatted_prompt = self.format_chat(messages)
        
        # Tokenize input
        inputs = self.tokenizer(
            formatted_prompt,
            return_tensors="pt",
            truncation=True,
            max_length=4096
        ).to(self.model.device)
        
        # Generate response
        with torch.no_grad():
            outputs = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.model.generate(
                    **inputs,
                    max_new_tokens=config.max_tokens,
                    temperature=config.temperature,
                    top_p=config.top_p,
                    repetition_penalty=config.repetition_penalty,
                    do_sample=config.do_sample,
                    pad_token_id=self.tokenizer.eos_token_id
                )
            )
        
        # Extract generated text
        generated_text = self.tokenizer.decode(
            outputs[0][inputs.input_ids.shape[1]:],
            skip_special_tokens=True
        )
        
        return generated_text.strip()
    
    def generate_batch(
        self, 
        batch_messages: List[List[Dict[str, str]]], 
        config: GenerationConfig = GenerationConfig()
    ) -> List[str]:
        """Batch generation for efficiency"""
        formatted_prompts = [self.format_chat(messages) for messages in batch_messages]
        
        # Tokenize batch
        inputs = self.tokenizer(
            formatted_prompts,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=4096
        ).to(self.model.device)
        
        # Generate responses
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=config.max_tokens,
                temperature=config.temperature,
                top_p=config.top_p,
                repetition_penalty=config.repetition_penalty,
                do_sample=config.do_sample,
                pad_token_id=self.tokenizer.eos_token_id
            )
        
        # Extract all generated texts
        responses = []
        for i, output in enumerate(outputs):
            generated_text = self.tokenizer.decode(
                output[inputs.input_ids[i].shape[0]:],
                skip_special_tokens=True
            )
            responses.append(generated_text.strip())
        
        return responses

# Example usage
async def main():
    # Initialize service
    qwen_service = QwenService("Qwen/Qwen2.5-7B-Instruct")
    
    # Single generation
    messages = [
        {"role": "user", "content": "Explain machine learning in simple terms"}
    ]
    response = await qwen_service.generate_async(messages)
    print("Single Response:", response)
    
    # Batch generation
    batch_messages = [
        [{"role": "user", "content": "What is artificial intelligence?"}],
        [{"role": "user", "content": "How does deep learning work?"}],
        [{"role": "user", "content": "What are neural networks?"}]
    ]
    
    batch_responses = qwen_service.generate_batch(batch_messages)
    for i, response in enumerate(batch_responses):
        print(f"Batch Response {i+1}:", response)

# Run the example
# asyncio.run(main())
```
  
## рикрйНри░рижри░ри╕ри╝рии риЕриирйБриХрйВри▓ридри╛ ри░ригриирйАридрйАриЖриВ  

### риорйИриори░рйА риЕриирйБриХрйВри▓ридри╛  

```python
# Memory-efficient loading strategies
from transformers import AutoModelForCausalLM, BitsAndBytesConfig

# 8-bit quantization for memory efficiency
quantization_config = BitsAndBytesConfig(
    load_in_8bit=True,
    llm_int8_threshold=6.0,
    llm_int8_has_fp16_weight=False
)

model = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen2.5-7B-Instruct",
    quantization_config=quantization_config,
    device_map="auto",
    torch_dtype=torch.float16
)

# 4-bit quantization for maximum efficiency
quantization_config_4bit = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.bfloat16,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4"
)

efficient_model = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen2.5-7B-Instruct",
    quantization_config=quantization_config_4bit,
    device_map="auto"
)
```
  
### риЗрй░рилри░рйИриВри╕ риЕриирйБриХрйВри▓ридри╛  

```python
import torch
from torch.nn.attention import SDPABackend, sdpa_kernel

# Optimized inference configuration
def optimized_inference_setup():
    """Configure optimizations for inference"""
    
    # Enable optimized attention mechanisms
    torch.backends.cuda.enable_flash_sdp(True)
    torch.backends.cuda.enable_math_sdp(True)
    torch.backends.cuda.enable_mem_efficient_sdp(True)
    
    # Set optimal threading
    torch.set_num_threads(4)  # Adjust based on your CPU
    
    # Enable JIT compilation for repeated patterns
    torch.jit.set_fusion_strategy([('STATIC', 3), ('DYNAMIC', 20)])

def fast_generate(model, tokenizer, prompt, max_tokens=256):
    """Optimized generation function"""
    with torch.no_grad():
        # Use optimized attention backend
        with sdpa_kernel(SDPABackend.FLASH_ATTENTION):
            inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
            
            # Generate with optimizations
            outputs = model.generate(
                **inputs,
                max_new_tokens=max_tokens,
                do_sample=True,
                temperature=0.7,
                use_cache=True,  # Enable KV caching
                pad_token_id=tokenizer.eos_token_id,
                early_stopping=True
            )
            
            response = tokenizer.decode(
                outputs[0][inputs.input_ids.shape[1]:],
                skip_special_tokens=True
            )
            
    return response.strip()
```
  
## ри╕рин ридрйЛриВ ри╡ризрйАриЖ риЕринри┐риЖри╕ риЕридрйЗ рижри┐ри╕ри╝ри╛-риири┐ри░рижрйЗри╕ри╝  

### ри╕рйБри░рй▒риЦри┐риЖ риЕридрйЗ риЧрйЛрикриирйАрипридри╛  

```python
import hashlib
import time
from typing import Optional

class SecureQwenService:
    """Security-focused Qwen service implementation"""
    
    def __init__(self, model_name: str):
        self.model_name = model_name
        self.model = None
        self.tokenizer = None
        self.request_logs = {}
        self._load_model()
    
    def _sanitize_input(self, text: str) -> str:
        """Sanitize user input to prevent injection attacks"""
        # Remove or escape potentially harmful patterns
        dangerous_patterns = [
            "<script>", "</script>", 
            "javascript:", "data:",
            "<iframe>", "</iframe>"
        ]
        
        sanitized = text
        for pattern in dangerous_patterns:
            sanitized = sanitized.replace(pattern, "")
        
        return sanitized
    
    def _rate_limit_check(self, user_id: str, max_requests: int = 100, window: int = 3600) -> bool:
        """Simple rate limiting implementation"""
        current_time = time.time()
        
        if user_id not in self.request_logs:
            self.request_logs[user_id] = []
        
        # Clean old requests
        self.request_logs[user_id] = [
            req_time for req_time in self.request_logs[user_id]
            if current_time - req_time < window
        ]
        
        # Check rate limit
        if len(self.request_logs[user_id]) >= max_requests:
            return False
        
        # Log current request
        self.request_logs[user_id].append(current_time)
        return True
    
    def _hash_sensitive_data(self, data: str) -> str:
        """Hash sensitive data for logging"""
        return hashlib.sha256(data.encode()).hexdigest()[:16]
    
    def secure_generate(
        self, 
        messages: List[Dict[str, str]], 
        user_id: str,
        max_tokens: int = 512
    ) -> Optional[str]:
        """Generate with security measures"""
        
        # Rate limiting
        if not self._rate_limit_check(user_id):
            return "Rate limit exceeded. Please try again later."
        
        # Input sanitization
        sanitized_messages = []
        for message in messages:
            sanitized_content = self._sanitize_input(message.get("content", ""))
            sanitized_messages.append({
                "role": message.get("role", "user"),
                "content": sanitized_content
            })
        
        # Content length validation
        total_content_length = sum(len(msg["content"]) for msg in sanitized_messages)
        if total_content_length > 8192:  # Reasonable limit
            return "Input too long. Please reduce the content length."
        
        # Log request (with hashed sensitive data)
        content_hash = self._hash_sensitive_data(str(sanitized_messages))
        print(f"Processing request from user {user_id[:8]}... Content hash: {content_hash}")
        
        # Generate response
        try:
            formatted_prompt = self.tokenizer.apply_chat_template(
                sanitized_messages,
                tokenize=False,
                add_generation_prompt=True
            )
            
            inputs = self.tokenizer(formatted_prompt, return_tensors="pt").to(self.model.device)
            
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=min(max_tokens, 1024),  # Enforce reasonable limits
                    temperature=0.7,
                    top_p=0.9,
                    repetition_penalty=1.05,
                    do_sample=True,
                    pad_token_id=self.tokenizer.eos_token_id
                )
            
            response = self.tokenizer.decode(
                outputs[0][inputs.input_ids.shape[1]:],
                skip_special_tokens=True
            )
            
            return response.strip()
            
        except Exception as e:
            print(f"Generation error for user {user_id[:8]}...: {str(e)}")
            return "An error occurred while processing your request."
```
  
### риири┐риЧри░ри╛риирйА риЕридрйЗ риорйБри▓ри╛риВриХриг  

```python
import time
import psutil
import torch
from dataclasses import dataclass
from typing import List, Dict, Any

@dataclass
class PerformanceMetrics:
    """Performance metrics for monitoring"""
    response_time: float
    memory_usage: float
    gpu_usage: float
    token_count: int
    tokens_per_second: float

class QwenMonitor:
    """Monitor Qwen model performance and health"""
    
    def __init__(self):
        self.metrics_history = []
    
    def measure_performance(self, model, tokenizer, prompt: str) -> PerformanceMetrics:
        """Measure comprehensive performance metrics"""
        start_time = time.time()
        start_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        
        # GPU metrics (if available)
        gpu_usage = 0
        if torch.cuda.is_available():
            torch.cuda.reset_peak_memory_stats()
            gpu_usage = torch.cuda.memory_allocated() / 1024 / 1024  # MB
        
        # Generate response
        inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
        
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=256,
                temperature=0.7,
                do_sample=True,
                pad_token_id=tokenizer.eos_token_id
            )
        
        # Calculate metrics
        end_time = time.time()
        end_memory = psutil.Process().memory_info().rss / 1024 / 1024
        
        response_time = end_time - start_time
        memory_usage = end_memory - start_memory
        
        if torch.cuda.is_available():
            gpu_usage = torch.cuda.max_memory_allocated() / 1024 / 1024
        
        token_count = outputs.shape[1] - inputs.input_ids.shape[1]
        tokens_per_second = token_count / response_time if response_time > 0 else 0
        
        metrics = PerformanceMetrics(
            response_time=response_time,
            memory_usage=memory_usage,
            gpu_usage=gpu_usage,
            token_count=token_count,
            tokens_per_second=tokens_per_second
        )
        
        self.metrics_history.append(metrics)
        return metrics
    
    def get_average_metrics(self, last_n: int = 10) -> Dict[str, float]:
        """Get average metrics from recent measurements"""
        if not self.metrics_history:
            return {}
        
        recent_metrics = self.metrics_history[-last_n:]
        
        return {
            "avg_response_time": sum(m.response_time for m in recent_metrics) / len(recent_metrics),
            "avg_memory_usage": sum(m.memory_usage for m in recent_metrics) / len(recent_metrics),
            "avg_gpu_usage": sum(m.gpu_usage for m in recent_metrics) / len(recent_metrics),
            "avg_tokens_per_second": sum(m.tokens_per_second for m in recent_metrics) / len(recent_metrics)
        }
    
    def health_check(self, model, tokenizer) -> Dict[str, Any]:
        """Perform comprehensive health check"""
        health_status = {
            "status": "healthy",
            "checks": {},
            "recommendations": []
        }
        
        try:
            # Test basic functionality
            test_prompt = "Hello, how are you?"
            metrics = self.measure_performance(model, tokenizer, test_prompt)
            
            # Check response time
            if metrics.response_time > 10.0:  # seconds
                health_status["checks"]["response_time"] = "slow"
                health_status["recommendations"].append("Consider model optimization or hardware upgrade")
            else:
                health_status["checks"]["response_time"] = "good"
            
            # Check memory usage
            if metrics.memory_usage > 1000:  # MB
                health_status["checks"]["memory_usage"] = "high"
                health_status["recommendations"].append("Monitor memory usage and consider cleanup")
            else:
                health_status["checks"]["memory_usage"] = "good"
            
            # Check token generation rate
            if metrics.tokens_per_second < 5:
                health_status["checks"]["generation_speed"] = "slow"
                health_status["recommendations"].append("Optimize inference configuration")
            else:
                health_status["checks"]["generation_speed"] = "good"
            
            # Overall status
            if any(check in ["slow", "high"] for check in health_status["checks"].values()):
                health_status["status"] = "degraded"
            
        except Exception as e:
            health_status["status"] = "unhealthy"
            health_status["error"] = str(e)
            health_status["recommendations"].append("Check model loading and configuration")
        
        return health_status

# Example usage
monitor = QwenMonitor()

# Regular performance monitoring
def monitor_model_performance(model, tokenizer, test_prompts: List[str]):
    """Monitor model performance with various prompts"""
    for prompt in test_prompts:
        metrics = monitor.measure_performance(model, tokenizer, prompt)
        print(f"Prompt: {prompt[:50]}...")
        print(f"Response time: {metrics.response_time:.2f}s")
        print(f"Tokens/sec: {metrics.tokens_per_second:.1f}")
        print(f"Memory usage: {metrics.memory_usage:.1f}MB")
        print("-" * 50)
    
    # Show average metrics
    avg_metrics = monitor.get_average_metrics()
    print("Average Performance Metrics:")
    for metric, value in avg_metrics.items():
        print(f"{metric}: {value:.2f}")
```
  
## риири┐ри╕ри╝риХри░ри╕ри╝  

Qwen риори╛рибри▓ рикри░ри┐ри╡ри╛ри░ риЗрй▒риХ ри╡ри┐ри╕ридрйНри░ри┐рид рижрйНри░ри┐ри╕ри╝риЯрйАриХрйЛриг риирйВрй░ рижри░ри╕ри╛риЙриВрижри╛ ри╣рйИ риЬрйЛ AI ридриХриири╛ри▓рйЛриЬрйА риирйВрй░ ри▓рйЛриХридрй░ридри░ри┐риХ римригри╛риЙриг рижрйЗ риири╛ри▓-риири╛ри▓ ри╡рй▒риЦ-ри╡рй▒риЦ риРрикри▓рйАриХрйЗри╕ри╝рии ри╡ри┐рй▒риЪ риорйБриХри╛римри▓ри╛ридриориХ рикрйНри░рижри░ри╕ри╝рии риирйВрй░ риХри╛риЗрио ри░рй▒риЦрижри╛ ри╣рйИред риЗри╕ рижрйА риЦрйБрй▒ри▓рйНри╣рйЗ-ри╕ри░рйЛрид рикри╣рйБрй░риЪрипрйЛриЧридри╛, римри╣рйБринри╛ри╕ри╝ри╛риИ ри╕риори░рй▒риери╛ри╡ри╛риВ, риЕридрйЗ ри▓риЪриХрижри╛ри░ ридрйИриири╛ридрйА ри╡ри┐риХри▓рикри╛риВ рижрйБриЖри░ри╛, Qwen ри╕рй░риЧриариири╛риВ риЕридрйЗ ри╡ри┐риХри╛ри╕риХри╛ри░ри╛риВ риирйВрй░ ри╕ри╝риХридрйАри╕ри╝ри╛ри▓рйА AI ри╕риори░рй▒риери╛ри╡ри╛риВ рижрйА ри╡ри░ридрйЛриВ риХри░рии рипрйЛриЧ римригри╛риЙриВрижри╛ ри╣рйИ, риЪри╛ри╣рйЗ риЙри╣риири╛риВ рижрйЗ ри╕ри░рйЛрид риЬри╛риВ ри╡ри┐ри╢рйЗри╕ри╝ риЬри╝ри░рйВри░ридри╛риВ риЬрйЛ ри╡рйА ри╣рйЛригред  

### риорйБрй▒риЦ ри╕ри┐рй▒риЯрйЗ  

**риЦрйБрй▒ри▓рйНри╣рйЗ-ри╕ри░рйЛрид рижрйА ри╕ри╝ри╛риирижри╛ри░ридри╛**: Qwen рижри┐риЦри╛риЙриВрижри╛ ри╣рйИ риХри┐ риЦрйБрй▒ри▓рйНри╣рйЗ-ри╕ри░рйЛрид риори╛рибри▓ риЧрйБрикрид ри╡ри┐риХри▓рикри╛риВ рижрйЗ риири╛ри▓ риорйБриХри╛римри▓ри╛ридриориХ рикрйНри░рижри░ри╕ри╝рии рикрйНри░ри╛рикрид риХри░ ри╕риХрижрйЗ ри╣рии, риЬрижрйЛриВ риХри┐ рикри╛ри░рижри░ри╕ри╝ридри╛, риЕриирйБриХрйВри▓ридри╛, риЕридрйЗ риири┐рипрй░ридри░риг рикрйНри░рижри╛рии риХри░рижрйЗ ри╣рииред  

**ри╕риХрйЗри▓рипрйЛриЧ риЖри░риХрйАриЯрйИриХриЪри░**: 0.5B ридрйЛриВ 235B рикрйИри░ри╛риорйАриЯри░ри╛риВ рижрйА ри░рйЗриВриЬ риорйЛримри╛риИри▓ рибри┐ри╡ри╛риИри╕ ридрйЛриВ риЙрижрипрйЛриЧ риХри▓ри╕риЯри░ри╛риВ ридрй▒риХ риЧригриири╛ридриориХ ри╡ри╛ридри╛ри╡ри░ригри╛риВ рижрйЗ рикрйВри░рйЗ ри╕рикрйИриХриЯрйНри░рио ри╡ри┐рй▒риЪ ридрйИриири╛ридрйА рипрйЛриЧ римригри╛риЙриВрижрйА ри╣рйИред  

**ри╡ри┐ри╕ри╝рйЗри╕ри╝ ри╕риори░рй▒риери╛ри╡ри╛риВ**: Qwen-Coder, Qwen-Math, риЕридрйЗ Qwen-VL ри╡ри░риЧрйЗ риЦрйЗридри░-ри╡ри┐ри╕ри╝рйЗри╕ри╝ ри╡рйИри░рйАриРриВриЯри╕ риЖрио ринри╛ри╕ри╝ри╛ ри╕риориЭ риирйВрй░ риХри╛риЗрио ри░рй▒риЦрижрйЗ ри╣рйЛриП ри╡ри┐ри╕ри╝рйЗри╕ри╝ ридриЬри░римри╛ рикрйНри░рижри╛рии риХри░рижрйЗ ри╣рииред  

**ри╡ри┐ри╕ри╝ри╡ рикри╣рйБрй░риЪрипрйЛриЧридри╛**: 119+ ринри╛ри╕ри╝ри╛ри╡ри╛риВ ри╡ри┐рй▒риЪ риориЬри╝римрйВрид римри╣рйБринри╛ри╕ри╝ри╛риИ ри╕риори░рй▒риери╛ Qwen риирйВрй░ риЕрй░ридри░ри░ри╛ри╕ри╝риЯри░рйА риРрикри▓рйАриХрйЗри╕ри╝рии риЕридрйЗ ри╡рй▒риЦ-ри╡рй▒риЦ риЙрикринрйЛриЧридри╛ риЕризри╛ри░ри╛риВ ри▓риИ рипрйЛриЧ римригри╛риЙриВрижрйА ри╣рйИред  

**ри▓риЧри╛ридри╛ри░ риири╡рйАрииридри╛**: Qwen 1.0 ридрйЛриВ Qwen3 ридрй▒риХ рижри╛ ри╡ри┐риХри╛ри╕ ри╕риори░рй▒риери╛ри╡ри╛риВ, риХрйБри╕ри╝ри▓ридри╛, риЕридрйЗ ридрйИриири╛ридрйА ри╡ри┐риХри▓рикри╛риВ ри╡ри┐рй▒риЪ ри▓риЧри╛ридри╛ри░ ри╕рйБризри╛ри░ рижри┐риЦри╛риЙриВрижри╛ ри╣рйИред  

### ринри╡ри┐рй▒риЦ рижрйА рижрйНри░ри┐ри╕ри╝риЯрйА  

риЬри┐ри╡рйЗриВ риХри┐ Qwen рикри░ри┐ри╡ри╛ри░ ри╡ри┐риХри╕ри┐рид ри╣рйБрй░рижри╛ ри╣рйИ, риЕри╕рйАриВ риЙриорйАриж риХри░ ри╕риХрижрйЗ ри╣ри╛риВ:  

- **ри╡ризрйАриХ риХрйБри╕ри╝ри▓ридри╛**: ри╡ризрйЗри░рйЗ ри╡ризрйАриЖ рикрйНри░рижри░ри╕ри╝рии-рикрйИри░ри╛риорйАриЯри░ риЕриирйБрикри╛ридри╛риВ ри▓риИ ри▓риЧри╛ридри╛ри░ риЕриирйБриХрйВри▓ридри╛  
- **ри╡ри┐ри╕ридрйНри░ри┐рид риори▓риЯрйАриорйЛрибри▓ ри╕риори░рй▒риери╛ри╡ри╛риВ**: ри╣рйЛри░ ри╕рйБризри╛ри░ри┐рид ри╡ри┐риЬри╝рии, риЖрибрйАриУ, риЕридрйЗ риЯрйИриХри╕риЯ рикрйНри░рйЛри╕рйИри╕ри┐рй░риЧ рижри╛ риЗриХрй▒риа  
- **ридри░риХ ри╡ри┐рй▒риЪ ри╕рйБризри╛ри░**: риЙрй▒риЪ-ридри░риХ риориХрйИриири┐риЬри╝рио риЕридрйЗ римри╣рйБ-риХрижрио ри╕риорй▒ри╕ри┐риЖ ри╣рй▒ри▓ ри╕риори░рй▒риери╛ри╡ри╛риВ  
- **ри╡ризрйЗри░рйЗ ридрйИриири╛ридрйА риЯрйВри▓**: ри╡рй▒риЦ-ри╡рй▒риЦ ридрйИриири╛ридрйА рижрйНри░ри┐ри╕ри╝ри╛риВ ри▓риИ ри╕рйБризри╛ри░ри┐рид рилри░рйЗриори╡ри░риХ риЕридрйЗ риЕриирйБриХрйВри▓ридри╛ риЯрйВри▓  
- **риХриори┐риКриири┐риЯрйА ри╡ри╛ризри╛**: риЯрйВри▓ри╛риВ, риРрикри▓рйАриХрйЗри╕ри╝рии, риЕридрйЗ риХриори┐риКриири┐риЯрйА рипрйЛриЧрижри╛риири╛риВ рижри╛ ри╡ризрйЗри░ри╛ рикри░ри┐ри╕ри░  

### риЕриЧри▓рйЗ риХрижрио  

риЪри╛ри╣рйЗ ридрйБри╕рйАриВ риЪрйИриЯримрйЛриЯ римригри╛риЙриг, ри╕ри╝ри┐риХри╕ри╝ри╛ риЯрйВри▓ ри╡ри┐риХри╕ри┐рид риХри░рии, риХрйЛрибри┐рй░риЧ ри╕ри╣ри╛риЗриХ римригри╛риЙриг, риЬри╛риВ римри╣рйБринри╛ри╕ри╝ри╛риИ риРрикри▓рйАриХрйЗри╕ри╝рии 'ридрйЗ риХрй░рио риХри░ ри░ри╣рйЗ ри╣рйЛри╡рйЛ, Qwen рикри░ри┐ри╡ри╛ри░ ри╕риХрйЗри▓рипрйЛриЧ ри╣рй▒ри▓ рикрйНри░рижри╛рии риХри░рижри╛ ри╣рйИ риЬри┐ри╕ ри╡ри┐рй▒риЪ риориЬри╝римрйВрид риХриори┐риКриири┐риЯрйА ри╕ри╣ри╛риЗридри╛ риЕридрйЗ ри╡ри┐ри╕ридрйНри░ри┐рид рижри╕ридри╛ри╡рйЗриЬри╝ ри╣рйИред  

ридри╛риЬри╝ри╛ риЕрй▒рикрибрйЗриЯри╛риВ, риори╛рибри▓ ри░ри┐ри▓рйАриЬри╝, риЕридрйЗ ри╡ри┐ри╕ридрйНри░ри┐рид ридриХриирйАриХрйА рижри╕ридри╛ри╡рйЗриЬри╝ ри▓риИ, риЕризри┐риХри╛ри░рид Qwen ри░ри┐рикрйЛриЬри╝риЯри░рйАриЬри╝ 'ридрйЗ Hugging Face 'ридрйЗ риЬри╛риУ риЕридрйЗ ри╕ри░риЧри░рио риХриори┐риКриири┐риЯрйА риЪри░риЪри╛ риЕридрйЗ риЙрижри╛ри╣ри░риири╛риВ рижрйА риЦрйЛриЬ риХри░рйЛред  

AI ри╡ри┐риХри╛ри╕ рижри╛ ринри╡ри┐рй▒риЦ рикри╣рйБрй░риЪрипрйЛриЧ, рикри╛ри░рижри░ри╕ри╝рйА, риЕридрйЗ ри╕ри╝риХридрйАри╕ри╝ри╛ри▓рйА риЯрйВри▓ри╛риВ ри╡ри┐рй▒риЪ ри╣рйИ риЬрйЛ ри╕ри╛ри░рйЗ риЦрйЗридри░ри╛риВ риЕридрйЗ рикрй▒ризри░ри╛риВ ри╡ри┐рй▒риЪ риири╡рйАрииридри╛ риирйВрй░ рипрйЛриЧ римригри╛риЙриВрижрйЗ ри╣рииред Qwen рикри░ри┐ри╡ри╛ри░ риЗри╕ рижрйНри░ри┐ри╕ри╝риЯрйАриХрйЛриг риирйВрй░ рижри░ри╕ри╛риЙриВрижри╛ ри╣рйИ, ри╕рй░риЧриариири╛риВ риЕридрйЗ ри╡ри┐риХри╛ри╕риХри╛ри░ри╛риВ риирйВрй░ риЕриЧри▓рйА рикрйАрйЬрйНри╣рйА рижрйЗ AI-риЪри╛ри▓рид риРрикри▓рйАриХрйЗри╕ри╝рии римригри╛риЙриг ри▓риИ риорйВри▓ римрйБриири┐риЖриж рикрйНри░рижри╛рии риХри░рижри╛ ри╣рйИред  

## ри╡ри╛ризрйВ ри╕ри░рйЛрид  

- **риЕризри┐риХри╛ри░рид рижри╕ридри╛ри╡рйЗриЬри╝**: [Qwen рижри╕ридри╛ри╡рйЗриЬри╝](https://qwen.readthedocs.io/)  
- **риори╛рибри▓ ри╣рй▒рим**: [Hugging Face Qwen Collections](https://huggingface.co/collections/Qwen/)  
- **ридриХриирйАриХрйА рикрйЗрикри░**: [Qwen риЦрйЛриЬ рикрйНри░риХри╛ри╕ри╝рии](https://arxiv.org/search/?query=Qwen&searchtype=all)  
- **риХриори┐риКриири┐риЯрйА**: [GitHub риЪри░риЪри╛ риЕридрйЗ риорйБрй▒рижрйЗ](https://github.com/QwenLM/)  
- **ModelScope рикри▓рйЗриЯрилри╛ри░рио**: [Alibaba ModelScope](https://modelscope.cn/models?page=1&tasks=natural-language-processing&type=1)  

## ри╕ри┐риЦри▓ри╛риИ рижрйЗ рииридрйАриЬрйЗ  

риЗри╕ риорйМрибри┐риКри▓ риирйВрй░ рикрйВри░ри╛ риХри░рии ридрйЛриВ римри╛риЕриж, ридрйБри╕рйАриВ рипрйЛриЧ ри╣рйЛри╡рйЛриЧрйЗ:  

1. Qwen риори╛рибри▓ рикри░ри┐ри╡ри╛ри░ рижрйА риЖри░риХрйАриЯрйИриХриЪри░риХ рилри╛риЗрижрйЗ риЕридрйЗ риЗри╕ рижрйЗ риЦрйБрй▒ри▓рйНри╣рйЗ-ри╕ри░рйЛрид рижрйНри░ри┐ри╕ри╝риЯрйАриХрйЛриг риирйВрй░ ри╕риориЭри╛риЙригри╛ред  
2. ри╡ри┐ри╕ри╝рйЗри╕ри╝ риРрикри▓рйАриХрйЗри╕ри╝рии рижрйАриЖриВ риЬри╝ри░рйВри░ридри╛риВ риЕридрйЗ ри╕ри░рйЛридри╛риВ

---

**риЕри╕ри╡рйАриХри░ридри╛**:  
риЗри╣ рижри╕ридри╛ри╡рйЗриЬри╝ AI риЕриирйБри╡ри╛риж ри╕рйЗри╡ри╛ [Co-op Translator](https://github.com/Azure/co-op-translator) рижрйА ри╡ри░ридрйЛриВ риХри░риХрйЗ риЕриирйБри╡ри╛риж риХрйАридри╛ риЧри┐риЖ ри╣рйИред ри╣ри╛ри▓ри╛риВриХри┐ риЕри╕рйАриВ ри╕ри╣рйА ри╣рйЛриг рижрйА риХрйЛри╕ри╝ри┐ри╕ри╝ риХри░рижрйЗ ри╣ри╛риВ, риХри┐ри░рикри╛ риХри░риХрйЗ ризри┐риЖрии рижри┐риУ риХри┐ ри╕ри╡рйИриЪри╛ри▓ри┐рид риЕриирйБри╡ри╛рижри╛риВ ри╡ри┐рй▒риЪ риЧри▓ридрйАриЖриВ риЬри╛риВ риЕри╕рйБриЪрйАридридри╛ри╡ри╛риВ ри╣рйЛ ри╕риХрижрйАриЖриВ ри╣рииред риЗри╕ рижрйА риорйВри▓ ринри╛ри╕ри╝ри╛ ри╡ри┐рй▒риЪ риорйМриЬрйВриж риЕри╕ри▓ рижри╕ридри╛ри╡рйЗриЬри╝ риирйВрй░ риЕризри┐риХри╛ри░рид ри╕ри░рйЛрид риорй░риири┐риЖ риЬри╛ригри╛ риЪри╛ри╣рйАрижри╛ ри╣рйИред риори╣рй▒ридри╡рикрйВри░рии риЬри╛ригриХри╛ри░рйА ри▓риИ, рикрйЗри╕ри╝рйЗри╡ри░ риориирйБрй▒риЦрйА риЕриирйБри╡ри╛риж рижрйА ри╕ри┐рилри╛ри░ри╕ри╝ риХрйАридрйА риЬри╛риВрижрйА ри╣рйИред риЗри╕ риЕриирйБри╡ри╛риж рижрйА ри╡ри░ридрйЛриВ ридрйЛриВ рикрйИрижри╛ ри╣рйЛриг ри╡ри╛ри▓рйЗ риХри┐ри╕рйЗ ри╡рйА риЧри▓ридрилри╣ри┐риорйА риЬри╛риВ риЧри▓рид ри╡ри┐риЖриЦри┐риЖ ри▓риИ риЕри╕рйАриВ риЬри╝ри┐рй░риорйЗри╡ри╛ри░ риири╣рйАриВ ри╣ри╛риВред