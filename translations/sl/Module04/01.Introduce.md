<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "49e18143f97a802a8647f4be28355348",
  "translation_date": "2025-09-19T00:57:50+00:00",
  "source_file": "Module04/01.Introduce.md",
  "language_code": "sl"
}
-->
# Poglavje 1: Osnove pretvorbe modelov in kvantizacije

Pretvorba formatov modelov in kvantizacija predstavljata kljuÄne napredke v EdgeAI, saj omogoÄata napredne zmogljivosti strojnega uÄenja na napravah z omejenimi viri. Razumevanje, kako uÄinkovito pretvoriti, optimizirati in implementirati modele, je bistvenega pomena za gradnjo praktiÄnih reÅ¡itev umetne inteligence na robu.

## Uvod

V tem priroÄniku bomo raziskali tehnike pretvorbe formatov modelov in kvantizacije ter njihove napredne strategije implementacije. Pokrili bomo temeljne koncepte stiskanja modelov, meje in klasifikacije formatov, tehnike optimizacije ter praktiÄne strategije implementacije za okolja robnega raÄunalniÅ¡tva.

## Cilji uÄenja

Na koncu tega priroÄnika boste sposobni:

- ğŸ”¢ Razumeti meje kvantizacije in klasifikacije razliÄnih ravni natanÄnosti.
- ğŸ› ï¸ Prepoznati kljuÄne tehnike pretvorbe formatov za implementacijo modelov na robnih napravah.
- ğŸš€ NauÄiti se naprednih strategij kvantizacije in stiskanja za optimizirano sklepanje.

## Razumevanje meja in klasifikacij kvantizacije modelov

Kvantizacija modelov je tehnika, zasnovana za zmanjÅ¡anje natanÄnosti parametrov nevronskih mreÅ¾ z bistveno manj bitov kot njihovi modeli s polno natanÄnostjo. Medtem ko modeli s polno natanÄnostjo uporabljajo 32-bitne predstavitve s plavajoÄo vejico, so kvantizirani modeli posebej zasnovani za uÄinkovitost in implementacijo na robu.

Okvir klasifikacije natanÄnosti nam pomaga razumeti razliÄne kategorije ravni kvantizacije in njihove ustrezne primere uporabe. Ta klasifikacija je kljuÄna za izbiro prave ravni natanÄnosti za specifiÄne scenarije robnega raÄunalniÅ¡tva.

### Okvir klasifikacije natanÄnosti

Razumevanje meja natanÄnosti pomaga pri izbiri ustreznih ravni kvantizacije za razliÄne scenarije robnega raÄunalniÅ¡tva:

- **ğŸ”¬ Zelo nizka natanÄnost**: Kvantizacija od 1-bit do 2-bit (ekstremno stiskanje za specializirano strojno opremo)
- **ğŸ“± Nizka natanÄnost**: Kvantizacija od 3-bit do 4-bit (uravnoteÅ¾ena zmogljivost in uÄinkovitost)
- **âš–ï¸ Srednja natanÄnost**: Kvantizacija od 5-bit do 8-bit (pribliÅ¾evanje zmogljivostim modelov s polno natanÄnostjo ob ohranjanju uÄinkovitosti)

NatanÄne meje ostajajo fluidne v raziskovalni skupnosti, vendar veÄina praktikov obravnava 8-bitne in niÅ¾je kot "kvantizirane," pri Äemer nekateri viri doloÄajo specializirane pragove za razliÄne cilje strojne opreme.

### KljuÄne prednosti kvantizacije modelov

Kvantizacija modelov ponuja veÄ temeljnih prednosti, zaradi katerih je idealna za aplikacije robnega raÄunalniÅ¡tva:

**Operativna uÄinkovitost**: Kvantizirani modeli omogoÄajo hitrejÅ¡e Äase sklepanja zaradi zmanjÅ¡ane raÄunske kompleksnosti, kar jih naredi idealne za aplikacije v realnem Äasu. Zahtevajo manj raÄunalniÅ¡kih virov, kar omogoÄa implementacijo na napravah z omejenimi viri, hkrati pa porabijo manj energije in ohranjajo zmanjÅ¡an ogljiÄni odtis.

**Prilagodljivost implementacije**: Ti modeli omogoÄajo zmogljivosti umetne inteligence na napravi brez potrebe po internetni povezavi, izboljÅ¡ujejo zasebnost in varnost z lokalno obdelavo, jih je mogoÄe prilagoditi za aplikacije specifiÄne za doloÄeno podroÄje in so primerni za razliÄna okolja robnega raÄunalniÅ¡tva.

**UÄinkovitost stroÅ¡kov**: Kvantizirani modeli ponujajo stroÅ¡kovno uÄinkovito usposabljanje in implementacijo v primerjavi z modeli s polno natanÄnostjo, z zmanjÅ¡animi operativnimi stroÅ¡ki in niÅ¾jimi zahtevami po pasovni Å¡irini za aplikacije na robu.

## Napredne strategije pridobivanja formatov modelov

### GGUF (General GGML Universal Format)

GGUF sluÅ¾i kot primarni format za implementacijo kvantiziranih modelov na CPU in robnih napravah. Format ponuja obseÅ¾ne vire za pretvorbo in implementacijo modelov:

**Funkcije odkrivanja formata**: Format ponuja napredno podporo za razliÄne ravni kvantizacije, zdruÅ¾ljivost licenc in optimizacijo zmogljivosti. Uporabniki lahko dostopajo do zdruÅ¾ljivosti med platformami, realnoÄasovnih meril zmogljivosti in podpore za WebGPU za implementacijo v brskalniku.

**Zbirke ravni kvantizacije**: Priljubljeni formati kvantizacije vkljuÄujejo Q4_K_M za uravnoteÅ¾eno stiskanje, serijo Q5_K_S za aplikacije, osredotoÄene na kakovost, Q8_0 za skoraj originalno natanÄnost in eksperimentalne formate, kot je Q2_K za implementacijo z zelo nizko natanÄnostjo. Format vkljuÄuje tudi razliÄice, ki jih vodi skupnost, s specializiranimi konfiguracijami za specifiÄna podroÄja ter sploÅ¡no uporabo in razliÄice, prilagojene navodilom, optimizirane za razliÄne primere uporabe.

### ONNX (Open Neural Network Exchange)

Format ONNX zagotavlja zdruÅ¾ljivost med okviri za kvantizirane modele z izboljÅ¡animi integracijskimi zmogljivostmi:

**Integracija v podjetjih**: Format vkljuÄuje modele s podporo na ravni podjetja in zmogljivostmi optimizacije, ki vkljuÄujejo dinamiÄno kvantizacijo za prilagodljivo natanÄnost in statiÄno kvantizacijo za implementacijo v produkciji. Prav tako podpira modele iz razliÄnih okvirov s standardiziranimi pristopi kvantizacije.

**Prednosti za podjetja**: Vgrajena orodja za optimizacijo, implementacijo med platformami in pospeÅ¡evanje strojne opreme so integrirana v razliÄne pogone za sklepanje. Neposredna podpora okvirov s standardiziranimi API-ji, integrirane funkcije optimizacije in celoviti delovni tokovi implementacije izboljÅ¡ujejo izkuÅ¡njo v podjetjih.

## Napredne tehnike kvantizacije in optimizacije

### Llama.cpp okvir za optimizacijo

Llama.cpp ponuja najsodobnejÅ¡e tehnike kvantizacije za maksimalno uÄinkovitost pri implementaciji na robu:

**Metode kvantizacije**: Okvir podpira razliÄne ravni kvantizacije, vkljuÄno z Q4_0 (4-bitna kvantizacija z odliÄno redukcijo velikosti - idealna za mobilno implementacijo), Q5_1 (5-bitna kvantizacija, ki uravnoteÅ¾i kakovost in stiskanje - primerna za sklepanje na robu) in Q8_0 (8-bitna kvantizacija za skoraj originalno kakovost - priporoÄljiva za uporabo v produkciji). Napredni formati, kot je Q2_K, predstavljajo najsodobnejÅ¡e stiskanje za ekstremne scenarije.

**Prednosti implementacije**: Sklepanje, optimizirano za CPU, s pospeÅ¡evanjem SIMD omogoÄa uÄinkovito nalaganje in izvajanje modelov. ZdruÅ¾ljivost med platformami na arhitekturah x86, ARM in Apple Silicon omogoÄa strojno neodvisne zmogljivosti implementacije.

**Primerjava pomnilniÅ¡kega odtisa**: RazliÄne ravni kvantizacije ponujajo razliÄne kompromise med velikostjo modela in kakovostjo. Q4_0 zagotavlja pribliÅ¾no 75 % redukcijo velikosti, Q5_1 ponuja 70 % redukcijo z boljÅ¡o ohranitvijo kakovosti, Q8_0 pa dosega 50 % redukcijo ob ohranjanju skoraj originalne zmogljivosti.

### Microsoft Olive optimizacijski paket

Microsoft Olive ponuja celovite delovne tokove optimizacije modelov, zasnovane za produkcijska okolja:

**Tehnike optimizacije**: Paket vkljuÄuje dinamiÄno kvantizacijo za samodejno izbiro natanÄnosti, optimizacijo grafov in zdruÅ¾evanje operaterjev za izboljÅ¡ano uÄinkovitost, optimizacije, specifiÄne za strojno opremo, za implementacijo na CPU, GPU in NPU ter veÄstopenjske optimizacijske procese. Specializirani delovni tokovi kvantizacije podpirajo razliÄne ravni natanÄnosti od 8-bitne do eksperimentalne 1-bitne konfiguracije.

**Avtomatizacija delovnih tokov**: Avtomatizirano primerjanje med razliÄicami optimizacije zagotavlja ohranjanje kakovostnih metrik med optimizacijo. Integracija s priljubljenimi okviri strojnega uÄenja, kot sta PyTorch in ONNX, omogoÄa optimizacijo za implementacijo v oblaku in na robu.

### Apple MLX okvir

Apple MLX zagotavlja nativno optimizacijo, posebej zasnovano za naprave Apple Silicon:

**Optimizacija za Apple Silicon**: Okvir uporablja arhitekturo zdruÅ¾enega pomnilnika z integracijo Metal Performance Shaders, samodejno sklepanje z meÅ¡ano natanÄnostjo in optimizirano uporabo pasovne Å¡irine pomnilnika. Modeli kaÅ¾ejo izjemno zmogljivost na Äipih serije M z optimalnim ravnovesjem za razliÄne implementacije na napravah Apple.

**Razvojne funkcije**: Podpora za API-je Python in Swift z operacijami polj, zdruÅ¾ljivimi z NumPy, zmogljivostmi samodejne diferenciacije in brezhibno integracijo z razvojnimi orodji Apple zagotavljajo celovito razvojno okolje.

## Strategije implementacije v produkciji in sklepanje

### Ollama: Poenostavljena lokalna implementacija

Ollama poenostavi implementacijo modelov z funkcijami, pripravljenimi za podjetja, za lokalna in robna okolja:

**Zmogljivosti implementacije**: Namestitev in izvajanje modelov z enim ukazom z avtomatskim pridobivanjem in predpomnjenjem modelov. Podpora za razliÄne kvantizirane formate z REST API-jem za integracijo aplikacij ter zmogljivosti za upravljanje in preklapljanje med veÄ modeli. Napredne ravni kvantizacije zahtevajo specifiÄne konfiguracije za optimalno implementacijo.

**Napredne funkcije**: Podpora za prilagajanje modelov, generiranje datotek Dockerfile za implementacijo v kontejnerjih, pospeÅ¡evanje GPU z avtomatskim zaznavanjem ter moÅ¾nosti kvantizacije in optimizacije modelov zagotavljajo celovito prilagodljivost implementacije.

### VLLM: Sklepanje z visoko zmogljivostjo

VLLM zagotavlja optimizacijo sklepanja na ravni produkcije za scenarije z visoko prepustnostjo:

**Optimizacije zmogljivosti**: PagedAttention za uÄinkovito raÄunsko obdelavo pozornosti, dinamiÄno zdruÅ¾evanje za optimizacijo prepustnosti, paralelizem tenzorjev za skaliranje na veÄ GPU-jih in spekulativno dekodiranje za zmanjÅ¡anje zakasnitve. Napredni kvantizirani formati zahtevajo specializirane jedrne funkcije za sklepanje za optimalno zmogljivost.

**Integracija v podjetjih**: API konÄne toÄke, zdruÅ¾ljive z OpenAI, podpora za implementacijo v Kubernetesu, integracija za spremljanje in opazovanje ter zmogljivosti samodejnega skaliranja zagotavljajo reÅ¡itve za implementacijo na ravni podjetja.

### Microsoftove reÅ¡itve za rob

Microsoft zagotavlja celovite zmogljivosti implementacije na robu za okolja podjetij:

**Funkcije robnega raÄunalniÅ¡tva**: Zasnova arhitekture "offline-first" z optimizacijo za omejene vire, upravljanje lokalnega registra modelov in zmogljivosti sinhronizacije med robom in oblakom zagotavljajo zanesljivo implementacijo na robu.

**Varnost in skladnost**: Lokalna obdelava podatkov za ohranjanje zasebnosti, varnostni nadzori na ravni podjetja, beleÅ¾enje revizij in poroÄanje o skladnosti ter upravljanje dostopa na podlagi vlog zagotavljajo celovito varnost za implementacije na robu.

## NajboljÅ¡e prakse za implementacijo kvantizacije modelov

### Smernice za izbiro ravni kvantizacije

Pri izbiri ravni kvantizacije za implementacijo na robu upoÅ¡tevajte naslednje dejavnike:

**Premisleki o Å¡tevilu natanÄnosti**: Izberite zelo nizko natanÄnost, kot je Q2_K, za ekstremne mobilne aplikacije, nizko natanÄnost, kot je Q4_K_M, za uravnoteÅ¾ene scenarije zmogljivosti, in srednjo natanÄnost, kot je Q8_0, ko se pribliÅ¾ujete zmogljivostim modelov s polno natanÄnostjo ob ohranjanju uÄinkovitosti. Eksperimentalni formati ponujajo specializirano stiskanje za specifiÄne raziskovalne aplikacije.

**Usklajenost s primerom uporabe**: Ujemajte zmogljivosti kvantizacije s specifiÄnimi zahtevami aplikacije, pri Äemer upoÅ¡tevajte dejavnike, kot so ohranjanje natanÄnosti, hitrost sklepanja, omejitve pomnilnika in zahteve za delovanje brez povezave.

### Izbira strategije optimizacije

**Pristop kvantizacije**: Izberite ustrezne ravni kvantizacije glede na zahteve glede kakovosti in omejitve strojne opreme. UpoÅ¡tevajte Q4_0 za maksimalno stiskanje, Q5_1 za uravnoteÅ¾ene kompromise med kakovostjo in stiskanjem ter Q8_0 za ohranjanje skoraj originalne kakovosti. Eksperimentalni formati predstavljajo mejo ekstremnega stiskanja za specializirane aplikacije.

**Izbira okvira**: Izberite optimizacijske okvire glede na ciljno strojno opremo in zahteve implementacije. Uporabite Llama.cpp za implementacijo, optimizirano za CPU, Microsoft Olive za celovite delovne tokove optimizacije in Apple MLX za naprave Apple Silicon.

## PraktiÄne pretvorbe formatov in primeri uporabe

### Scenariji implementacije v resniÄnem svetu

**Mobilne aplikacije**: Formati Q4_K odliÄno delujejo v aplikacijah za pametne telefone z minimalnim pomnilniÅ¡kim odtisom, medtem ko Q8_0 zagotavlja uravnoteÅ¾eno zmogljivost za aplikacije na tabliÄnih raÄunalnikih. Formati Q5_K ponujajo vrhunsko kakovost za mobilne produktivne aplikacije.

**Namizno in robno raÄunalniÅ¡tvo**: Q5_K zagotavlja optimalno zmogljivost za namizne aplikacije, Q8_0 ponuja visokokakovostno sklepanje za delovna okolja, Q4_K pa omogoÄa uÄinkovito obdelavo na robnih napravah.

**Raziskave in eksperimentalno**: Napredni formati kvantizacije omogoÄajo raziskovanje sklepanja z zelo nizko natanÄnostjo za akademske raziskave in aplikacije dokazovanja koncepta, ki zahtevajo ekstremne omejitve virov.

### Primerjalna merila zmogljivosti

**Hitrost sklepanja**: Q4_K dosega najhitrejÅ¡e Äase sklepanja na mobilnih CPU-jih, Q5_K zagotavlja uravnoteÅ¾eno razmerje med hitrostjo in kakovostjo za sploÅ¡ne aplikacije, Q8_0 ponuja vrhunsko kakovost za kompleksne naloge, eksperimentalni formati pa zagotavljajo teoretiÄno maksimalno prepustnost s specializirano strojno opremo.

**Zahteve po pomnilniku**: Ravni kvantizacije segajo od Q2_K (manj kot 500 MB za majhne modele) do Q8_0 (pribliÅ¾no 50 % originalne velikosti), pri Äemer eksperimentalne konfiguracije doseÅ¾ejo maksimalna razmerja stiskanja.

## Izzivi in premisleki

### Kompromisi zmogljivosti

Implementacija kvantizacije zahteva skrbno razmislek o kompromisih med velikostjo modela, hitrostjo sklepanja in kakovostjo izhoda. Medtem ko Q4_K ponuja izjemno hitrost in uÄinkovitost, Q8_0 zagotavlja vrhunsko kakovost na raÄun poveÄanih zahtev po virih. Q5_K predstavlja srednjo pot, primerno za veÄino sploÅ¡nih aplikacij.

### ZdruÅ¾ljivost strojne opreme

RazliÄne robne naprave imajo razliÄne zmogljivosti in omejitve. Q4_K deluje uÄinkovito na osnovnih procesorjih, Q5_K zahteva zmerne raÄunske vire, Q8_0 pa koristi zmogljivejÅ¡i strojni opremi. Eksperimentalni formati zahtevajo specializirano strojno ali programsko opremo za optimalno delovanje.

### Varnost in zasebnost

Medtem ko kvantizirani modeli omogoÄajo lokalno obdelavo za izboljÅ¡ano zasebnost, je treba uvesti ustrezne varnostne ukrepe za zaÅ¡Äito modelov in podatkov v robnih okoljih. To je Å¡e posebej pomembno pri implementaciji

---

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve za prevajanje z umetno inteligenco [Co-op Translator](https://github.com/Azure/co-op-translator). ÄŒeprav si prizadevamo za natanÄnost, vas prosimo, da upoÅ¡tevate, da lahko avtomatizirani prevodi vsebujejo napake ali netoÄnosti. Izvirni dokument v njegovem maternem jeziku je treba obravnavati kot avtoritativni vir. Za kljuÄne informacije priporoÄamo profesionalni ÄloveÅ¡ki prevod. Ne prevzemamo odgovornosti za morebitne nesporazume ali napaÄne razlage, ki bi nastale zaradi uporabe tega prevoda.