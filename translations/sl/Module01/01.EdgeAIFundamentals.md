<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "76b134be93f45283a2df8f8a93717d06",
  "translation_date": "2025-10-17T10:16:08+00:00",
  "source_file": "Module01/01.EdgeAIFundamentals.md",
  "language_code": "sl"
}
-->
# Poglavje 1: Osnove EdgeAI

EdgeAI predstavlja spremembo paradigme pri uvajanju umetne inteligence, saj prinaÅ¡a zmogljivosti AI neposredno na robne naprave, namesto da bi se zanaÅ¡ali izkljuÄno na obdelavo v oblaku. Pomembno je razumeti, kako EdgeAI omogoÄa lokalno obdelavo AI na napravah z omejenimi viri, hkrati pa ohranja sprejemljivo zmogljivost in se spopada z izzivi, kot so zasebnost, zakasnitve in delovanje brez povezave.

## Uvod

V tej lekciji bomo raziskali EdgeAI in njegove temeljne koncepte. Pokrili bomo tradicionalno paradigmo raÄunalniÅ¡tva AI, izzive robnega raÄunalniÅ¡tva, kljuÄne tehnologije, ki omogoÄajo EdgeAI, ter praktiÄne aplikacije v razliÄnih industrijah.

## Cilji uÄenja

Do konca te lekcije boste lahko:

- Razumeli razliko med tradicionalnim pristopom AI, ki temelji na oblaku, in pristopom EdgeAI.
- Prepoznali kljuÄne tehnologije, ki omogoÄajo obdelavo AI na robnih napravah.
- Prepoznali prednosti in omejitve implementacij EdgeAI.
- Uporabili znanje o EdgeAI v resniÄnih scenarijih in primerih uporabe.

## Razumevanje tradicionalne paradigme raÄunalniÅ¡tva AI

Tradicionalno se aplikacije generativne AI zanaÅ¡ajo na infrastrukturo za visoko zmogljivo raÄunalniÅ¡tvo, da uÄinkovito izvajajo velike jezikovne modele (LLM). Organizacije obiÄajno uvajajo te modele na GPU grozdih v oblaÄnih okoljih, dostopajo pa do njihovih zmogljivosti prek API vmesnikov.

Ta centraliziran model dobro deluje za Å¡tevilne aplikacije, vendar ima prirojene omejitve pri scenarijih robnega raÄunalniÅ¡tva. Tradicionalni pristop vkljuÄuje poÅ¡iljanje uporabniÅ¡kih poizvedb na oddaljene streÅ¾nike, njihovo obdelavo z zmogljivo strojno opremo in vraÄanje rezultatov prek interneta. ÄŒeprav ta metoda omogoÄa dostop do najsodobnejÅ¡ih modelov, ustvarja odvisnosti od internetne povezljivosti, uvaja zakasnitve in odpira vpraÅ¡anja zasebnosti, ko je treba obÄutljive podatke prenesti na zunanje streÅ¾nike.

Nekateri kljuÄni koncepti, ki jih moramo razumeti pri delu s tradicionalnimi paradigmi raÄunalniÅ¡tva AI, vkljuÄujejo:

- **â˜ï¸ Obdelava v oblaku**: AI modeli se izvajajo na zmogljivi streÅ¾niÅ¡ki infrastrukturi z visokimi raÄunalniÅ¡kimi viri.
- **ğŸ”Œ Dostop prek API**: Aplikacije dostopajo do zmogljivosti AI prek oddaljenih API klicev, namesto lokalne obdelave.
- **ğŸ›ï¸ Centralizirano upravljanje modelov**: Modeli se vzdrÅ¾ujejo in posodabljajo centralno, kar zagotavlja doslednost, vendar zahteva omreÅ¾no povezljivost.
- **ğŸ“ˆ Skalabilnost virov**: Infrastruktura v oblaku se lahko dinamiÄno prilagaja za obvladovanje razliÄnih raÄunalniÅ¡kih zahtev.

## Izzivi robnega raÄunalniÅ¡tva

Robne naprave, kot so prenosniki, mobilni telefoni in naprave interneta stvari (IoT), kot sta Raspberry Pi in NVIDIA Orin Nano, predstavljajo edinstvene omejitve pri raÄunalniÅ¡kih zmogljivostih. Te naprave imajo obiÄajno omejeno procesorsko moÄ, pomnilnik in energetske vire v primerjavi z infrastrukturo podatkovnih centrov.

Zagon tradicionalnih LLM na takÅ¡nih napravah je bil zgodovinsko teÅ¾aven zaradi teh strojnih omejitev. Vendar pa je potreba po obdelavi AI na robu postala vse bolj pomembna v razliÄnih scenarijih. Pomislite na situacije, kjer je internetna povezljivost nezanesljiva ali nedostopna, kot so oddaljena industrijska obmoÄja, vozila med prevozom ali obmoÄja s slabo omreÅ¾no pokritostjo. Poleg tega aplikacije, ki zahtevajo visoke varnostne standarde, kot so medicinske naprave, finanÄni sistemi ali vladne aplikacije, morda potrebujejo lokalno obdelavo obÄutljivih podatkov za ohranjanje zasebnosti in skladnosti.

### KljuÄne omejitve robnega raÄunalniÅ¡tva

Okolja robnega raÄunalniÅ¡tva se sooÄajo z veÄ temeljnimi omejitvami, ki jih tradicionalne reÅ¡itve AI, ki temeljijo na oblaku, ne sreÄujejo:

- **Omejena procesorska moÄ**: Robne naprave imajo obiÄajno manj procesorskih jeder in niÅ¾je frekvence kot streÅ¾niÅ¡ka strojna oprema.
- **Omejitve pomnilnika**: RazpoloÅ¾ljiva RAM in kapaciteta shranjevanja sta na robnih napravah bistveno zmanjÅ¡ani.
- **Omejitve energije**: Naprave na baterijski pogon morajo uravnoteÅ¾iti zmogljivost z energetsko porabo za daljÅ¡e delovanje.
- **Toplotno upravljanje**: Kompaktne oblike omejujejo zmogljivosti hlajenja, kar vpliva na trajno zmogljivost pod obremenitvijo.

## Kaj je EdgeAI?

### Koncept: Definicija EdgeAI

EdgeAI se nanaÅ¡a na uvajanje in izvajanje algoritmov umetne inteligence neposredno na robnih napravahâ€”fiziÄni strojni opremi, ki obstaja na "robovih" omreÅ¾ja, blizu mesta, kjer se podatki ustvarjajo in zbirajo. Te naprave vkljuÄujejo pametne telefone, IoT senzorje, pametne kamere, avtonomna vozila, nosljive naprave in industrijsko opremo. Za razliko od tradicionalnih sistemov AI, ki se zanaÅ¡ajo na oblaÄne streÅ¾nike za obdelavo, EdgeAI prinaÅ¡a inteligenco neposredno na vir podatkov.

V svojem bistvu EdgeAI decentralizira obdelavo AI, jo premika stran od centraliziranih podatkovnih centrov in jo razporeja po obseÅ¾nem omreÅ¾ju naprav, ki sestavljajo naÅ¡ digitalni ekosistem. To predstavlja temeljno arhitekturno spremembo v naÄinu oblikovanja in uvajanja sistemov AI.

KljuÄni konceptualni stebri EdgeAI vkljuÄujejo:

- **Obdelava v bliÅ¾ini**: RaÄunanje poteka fiziÄno blizu mesta, kjer podatki nastajajo.
- **Decentralizirana inteligenca**: ZmoÅ¾nosti odloÄanja so razporejene med veÄ napravami.
- **Suverenost podatkov**: Informacije ostajajo pod lokalnim nadzorom in pogosto nikoli ne zapustijo naprave.
- **Avtonomno delovanje**: Naprave lahko delujejo inteligentno brez stalne povezljivosti.
- **Vgrajena AI**: Inteligenca postane intrinziÄna zmogljivost vsakodnevnih naprav.

### Vizualizacija arhitekture EdgeAI

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         TRADITIONAL AI ARCHITECTURE                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   Data Transfer  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   API Response   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Edge Devices â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚ Cloud Servers â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ End Users â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     Data                         Model Inference                     Results
   Collection                     High Latency
                                  High Bandwidth
                                  Privacy Concerns
                               
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            EDGE AI ARCHITECTURE                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   Direct Response  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Edge Devices with Embedded AI         â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚ End Users â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â”‚ Sensors â”‚â”€>â”‚ SLM Inference â”‚â”€>â”‚ Local Action â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     Data         Low Latency       Immediate
   Collection     Processing        Response
                  No Data Transfer
                  Enhanced Privacy
```

EdgeAI predstavlja spremembo paradigme pri uvajanju umetne inteligence, saj prinaÅ¡a zmogljivosti AI neposredno na robne naprave, namesto da bi se zanaÅ¡ali izkljuÄno na obdelavo v oblaku. Ta pristop omogoÄa izvajanje AI modelov lokalno na napravah z omejenimi raÄunalniÅ¡kimi viri, kar zagotavlja zmogljivosti sklepanja v realnem Äasu brez potrebe po stalni internetni povezljivosti.

EdgeAI vkljuÄuje razliÄne tehnologije in tehnike, zasnovane za izboljÅ¡anje uÄinkovitosti AI modelov in njihovo primernost za uvajanje na napravah z omejenimi viri. Cilj je ohraniti sprejemljivo zmogljivost, hkrati pa bistveno zmanjÅ¡ati raÄunalniÅ¡ke in pomnilniÅ¡ke zahteve AI modelov.

Poglejmo temeljne pristope, ki omogoÄajo implementacije EdgeAI na razliÄnih vrstah naprav in primerih uporabe.

### Temeljna naÄela EdgeAI

EdgeAI temelji na veÄ osnovnih naÄelih, ki ga razlikujejo od tradicionalnega AI, ki temelji na oblaku:

- **Lokalna obdelava**: Sklepanje AI poteka neposredno na robni napravi brez potrebe po zunanji povezljivosti.
- **Optimizacija virov**: Modeli so posebej optimizirani za strojne omejitve ciljnih naprav.
- **Zmogljivost v realnem Äasu**: Obdelava poteka z minimalno zakasnitvijo za Äasovno obÄutljive aplikacije.
- **Zasebnost po zasnovi**: ObÄutljivi podatki ostajajo na napravi, kar poveÄuje varnost in skladnost.

## KljuÄne tehnologije, ki omogoÄajo EdgeAI

### Kvantizacija modelov

Ena najpomembnejÅ¡ih tehnik v EdgeAI je kvantizacija modelov. Ta proces vkljuÄuje zmanjÅ¡anje natanÄnosti parametrov modela, obiÄajno iz 32-bitnih plavajoÄih Å¡tevil na 8-bitna cela Å¡tevila ali celo niÅ¾je natanÄnostne formate. ÄŒeprav se to zmanjÅ¡anje natanÄnosti morda zdi zaskrbljujoÄe, raziskave kaÅ¾ejo, da lahko Å¡tevilni AI modeli ohranijo svojo zmogljivost tudi ob znatno zmanjÅ¡ani natanÄnosti.

Kvantizacija deluje tako, da preslika obseg vrednosti plavajoÄih Å¡tevil na manjÅ¡i nabor diskretnih vrednosti. Na primer, namesto da bi za predstavitev vsakega parametra uporabili 32 bitov, kvantizacija morda uporabi le 8 bitov, kar vodi do 4-kratnega zmanjÅ¡anja zahtev po pomnilniku in pogosto do hitrejÅ¡ih Äasov sklepanja.

```python
# Example: PyTorch model quantization 
import torch

# Load a pre-trained model
model = torch.load('large_model.pth')

# Quantize the model to INT8
quantized_model = torch.quantization.quantize_dynamic(
    model,  # model to quantize
    {torch.nn.Linear, torch.nn.Conv2d},  # layers to quantize
    dtype=torch.qint8  # quantization data type
)

# Save the quantized model
torch.save(quantized_model, 'quantized_model.pth')

# Memory usage comparison
original_size = model.size()
quantized_size = quantized_model.size()
print(f"Memory reduction: {original_size / quantized_size:.2f}x")
```

RazliÄne tehnike kvantizacije vkljuÄujejo:

- **Post-trening kvantizacija (PTQ)**: Uporablja se po treningu modela brez potrebe po ponovnem treningu.
- **Kvantizacija zavedna treninga (QAT)**: VkljuÄuje uÄinke kvantizacije med treningom za boljÅ¡o natanÄnost.
- **DinamiÄna kvantizacija**: Kvantizira uteÅ¾i na int8, vendar dinamiÄno izraÄunava aktivacije.
- **StatiÄna kvantizacija**: Vnaprej izraÄuna vse parametre kvantizacije za uteÅ¾i in aktivacije.

Za uvajanje EdgeAI je izbira ustrezne strategije kvantizacije odvisna od specifiÄne arhitekture modela, zahtev glede zmogljivosti in strojnih zmogljivosti ciljnih naprav.

### Kompresija in optimizacija modelov

Poleg kvantizacije razliÄne tehnike kompresije pomagajo zmanjÅ¡ati velikost modela in raÄunalniÅ¡ke zahteve. Te vkljuÄujejo:

**Obrezovanje**: Ta tehnika odstrani nepotrebne povezave ali nevrone iz nevronskih mreÅ¾. Z identifikacijo in odpravo parametrov, ki malo prispevajo k zmogljivosti modela, lahko obrezovanje znatno zmanjÅ¡a velikost modela, hkrati pa ohranja natanÄnost.

```python
# Example: Neural network pruning in TensorFlow
import tensorflow as tf
import tensorflow_model_optimization as tfmot

# Define the model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Apply pruning during training
pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(
    initial_sparsity=0.0,
    final_sparsity=0.5,  # 50% of connections will be pruned
    begin_step=0,
    end_step=10000
)

pruned_model = tfmot.sparsity.keras.prune_low_magnitude(
    model, pruning_schedule=pruning_schedule
)

# Compile the pruned model
pruned_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model while pruning
pruned_model.fit(x_train, y_train, epochs=10)

# Convert to a smaller model for deployment
final_model = tfmot.sparsity.keras.strip_pruning(pruned_model)
```

**Destilacija znanja**: Ta pristop vkljuÄuje trening manjÅ¡ega "Å¡tudentskega" modela, da posnema vedenje veÄjega "uÄiteljskega" modela. Å tudentski model se nauÄi pribliÅ¾ati uÄiteljeve izhode, pogosto doseÅ¾e podobno zmogljivost z bistveno manj parametri.

**Optimizacija arhitekture modela**: Raziskovalci so razvili specializirane arhitekture, zasnovane posebej za robno uvajanje, kot so MobileNets, EfficientNets in druge lahke arhitekture, ki uravnoteÅ¾ijo zmogljivost z raÄunalniÅ¡ko uÄinkovitostjo.

### Majhni jezikovni modeli (SLM)

NaraÅ¡ÄajoÄi trend v EdgeAI je razvoj majhnih jezikovnih modelov (SLM). Ti modeli so zasnovani od zaÄetka, da so kompaktni in uÄinkoviti, hkrati pa Å¡e vedno zagotavljajo smiselne zmogljivosti naravnega jezika. SLM doseÅ¾ejo to z natanÄno izbiro arhitekture, uÄinkovitimi tehnikami treninga in osredotoÄenim treningom na specifiÄne domene ali naloge.

Za razliko od tradicionalnih pristopov, ki vkljuÄujejo kompresijo velikih modelov, so SLM pogosto trenirani z manjÅ¡imi nabori podatkov in optimiziranimi arhitekturami, posebej zasnovanimi za robno uvajanje. Ta pristop lahko vodi do modelov, ki niso le manjÅ¡i, ampak tudi bolj uÄinkoviti za specifiÄne primere uporabe.

## Strojna pospeÅ¡itev za EdgeAI

Sodobne robne naprave vse pogosteje vkljuÄujejo specializirano strojno opremo, zasnovano za pospeÅ¡evanje AI delovnih obremenitev:

### Nevronske procesne enote (NPU)

NPU so specializirani procesorji, zasnovani posebej za nevronske mreÅ¾ne izraÄune. Ti Äipi lahko izvajajo naloge sklepanja AI veliko bolj uÄinkovito kot tradicionalni CPU, pogosto z niÅ¾jo porabo energije. Å tevilni sodobni pametni telefoni, prenosniki in IoT naprave zdaj vkljuÄujejo NPU za omogoÄanje obdelave AI na napravi.

```csharp
// Example: Using Windows ML to target NPU acceleration in C#
using Microsoft.ML.OnnxRuntime;

// Create session options with NPU provider
var sessionOptions = new SessionOptions();
sessionOptions.AppendExecutionProvider_DmlExecutionProvider();  // DirectML for NPU

// Load the ONNX model
using var session = new InferenceSession("model.onnx", sessionOptions);

// Create input tensor
var inputTensor = new DenseTensor<float>(new[] { 1, 3, 224, 224 });  // Example input shape
var inputs = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor("input", inputTensor) };

// Run inference with NPU acceleration
using var results = session.Run(inputs);
var output = results.First().AsTensor<float>();

// Process output
Console.WriteLine($"Inference result: {output[0]}");
```

Naprave z NPU vkljuÄujejo:

- **Apple**: ÄŒipi serije A in M z Neural Engine
- **Qualcomm**: Procesorji Snapdragon s Hexagon DSP/NPU
- **Samsung**: Procesorji Exynos z NPU
- **Intel**: Movidius VPU in pospeÅ¡evalniki Habana Labs
- **Microsoft**: Windows Copilot+ raÄunalniki z NPU

### ğŸ® PospeÅ¡evanje z GPU

ÄŒeprav robne naprave morda nimajo zmogljivih GPU, ki jih najdemo v podatkovnih centrih, mnoge Å¡e vedno vkljuÄujejo integrirane ali diskretne GPU, ki lahko pospeÅ¡ijo AI delovne obremenitve. Sodobni mobilni GPU in integrirani grafiÄni procesorji lahko zagotovijo pomembne izboljÅ¡ave zmogljivosti za naloge sklepanja AI.

```python
# Example: Using TensorRT for GPU acceleration on edge devices
import tensorrt as trt
import numpy as np

# Create TensorRT logger and builder
TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
builder = trt.Builder(TRT_LOGGER)
network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
parser = trt.OnnxParser(network, TRT_LOGGER)

# Parse ONNX model
with open('model.onnx', 'rb') as model:
    parser.parse(model.read())

# Configure builder
config = builder.create_builder_config()
config.max_workspace_size = 1 << 28  # 256 MiB
config.set_flag(trt.BuilderFlag.FP16)  # Use FP16 precision for edge GPU

# Build and serialize engine
engine = builder.build_engine(network, config)
with open('model.trt', 'wb') as f:
    f.write(engine.serialize())
```

### Optimizacija CPU

Tudi naprave, ki imajo samo CPU, lahko izkoristijo EdgeAI prek optimiziranih implementacij. Sodobni CPU vkljuÄujejo specializirana navodila za AI delovne obremenitve, programski okviri pa so bili razviti za maksimalno zmogljivost CPU pri sklepanju AI.

```bash
# Example: Using XNNPACK with TFLite for optimized CPU inference
# Compilation command with XNNPACK acceleration enabled

bazel build -c opt --copt=-O3 --copt=-march=native \
  tensorflow/lite/delegates/xnnpack:libxnnpack_delegate.so

# Convert TensorFlow model to TFLite with optimization
tflite_convert \
  --keras_model_file=model.h5 \
  --output_file=model.tflite \
  --inference_type=FLOAT \
  --experimental_new_converter \
  --experimental_new_quantizer
```

Za programske inÅ¾enirje, ki delajo z EdgeAI, je razumevanje, kako izkoristiti te moÅ¾nosti strojne pospeÅ¡itve, kljuÄnega pomena za optimizacijo zmogljivosti sklepanja in energetske uÄinkovitosti na ciljnih napravah.

## Prednosti EdgeAI

### Zasebnost in varnost

Ena najpomembnejÅ¡ih prednosti EdgeAI je izboljÅ¡ana zasebnost in varnost. Z obdelavo podatkov lokalno na napravi obÄutljive informacije nikoli ne zapustijo nadzora uporabnika. To je Å¡e posebej pomembno za aplikacije, ki obravnavajo osebne podatke, medicinske informacije ali zaupne poslovne podatke.

### ZmanjÅ¡ana zakasnitev

EdgeAI odpravlja potrebo po poÅ¡iljanju podatkov na oddaljene streÅ¾nike za obdelavo, kar bistveno zmanjÅ¡uje zakasnitev. To je kljuÄno za aplikacije v realnem Äasu, kot so avtonomna vozila, industrijska avtomatizacija ali interaktivne aplikacije, kjer so potrebni takojÅ¡nji odzivi.

### ZmoÅ¾nost delovanja brez povezave

EdgeAI omogoÄa funkcionalnost AI tudi takrat, ko internetna povezljivost ni na voljo. To je dragoceno za aplikacije na oddaljenih lokacijah, med potovanjem ali v situacijah, kjer je zanesljivost omreÅ¾ja vpraÅ¡ljiva.

### StroÅ¡kovna uÄinkovitost

Z zmanjÅ¡anjem odvisnosti od storitev AI, ki temeljijo na oblaku, lahko EdgeAI pomaga zmanjÅ¡ati operativne stroÅ¡ke, zlasti za aplikacije z velikimi koliÄinami uporabe. Organizacije se lahko izognejo stalnim stroÅ¡kom API in zmanjÅ¡ajo zahteve po pasovni Å¡irini.

### Skalabilnost

EdgeAI porazdeli raÄunalniÅ¡ko obremenitev med robne naprave, namesto da bi jo centraliziral v podatkovnih centrih. To lahko pomaga zmanjÅ¡ati stroÅ¡ke infrastrukture in izboljÅ¡ati sploÅ¡no skalabilnost sistema.

## Aplikacije EdgeAI

### Pametne naprave in IoT

EdgeAI poganja Å¡tevilne funkcije pametnih naprav, od glasovnih asistentov, ki lahko lokalno obdelajo ukaze, do pametnih kamer, ki lahko prepoznajo predmete in ljudi brez poÅ¡iljanja videa v oblak. IoT naprave uporabljajo EdgeAI za prediktivno vzdrÅ¾evanje, spremljanje okolja in avtomatizirano odloÄanje.

### Mobilne aplikacije

Pametni telefoni in tabliÄni raÄunalniki uporabljajo EdgeAI za razliÄne funkcije, vkljuÄno z izboljÅ¡anjem fotografij, prevajanjem v realnem Äasu, razÅ¡irjeno resniÄnostjo in prilagojenimi priporoÄili. Te aplikacije koristijo nizko zakasnitev in prednosti zasebnosti lokalne obdelave.

### Industrijske aplikacije

Proizvodna in industrijska okolja uporabljajo EdgeAI za nadzor kakovosti, prediktivno vzdrÅ¾evanje in optimizacijo procesov. Te aplikacije pogosto zahtevajo obdelavo v realnem Äasu in lahko delujejo v okoljih z omejeno povezljivostjo.

### Zdravstvo

Medicinske napr
- [02: EdgeAI Aplikacije](02.RealWorldCaseStudies.md)

---

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve za prevajanje AI [Co-op Translator](https://github.com/Azure/co-op-translator). ÄŒeprav si prizadevamo za natanÄnost, vas prosimo, da upoÅ¡tevate, da lahko avtomatizirani prevodi vsebujejo napake ali netoÄnosti. Izvirni dokument v njegovem maternem jeziku naj se Å¡teje za avtoritativni vir. Za kljuÄne informacije priporoÄamo profesionalni ÄloveÅ¡ki prevod. Ne odgovarjamo za morebitne nesporazume ali napaÄne razlage, ki izhajajo iz uporabe tega prevoda.