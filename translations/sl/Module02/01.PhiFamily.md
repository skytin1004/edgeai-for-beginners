<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20892f7994d9e5d2473ad19dfa93cf6d",
  "translation_date": "2025-09-18T22:46:00+00:00",
  "source_file": "Module02/01.PhiFamily.md",
  "language_code": "sl"
}
-->
# Poglavje 1: Osnove druÅ¾ine modelov Microsoft Phi

DruÅ¾ina modelov Microsoft Phi predstavlja prelomnico v umetni inteligenci, saj dokazuje, da lahko kompaktni in uÄinkoviti modeli doseÅ¾ejo izjemno zmogljivost, hkrati pa so bistveno bolj varÄni z viri kot tradicionalni veliki jezikovni modeli. Pomembno je razumeti, kako druÅ¾ina Phi omogoÄa zmogljive AI sposobnosti z zmanjÅ¡animi raÄunalniÅ¡kimi zahtevami, pri tem pa ohranja visoko zmogljivost pri razliÄnih nalogah.

## Viri za razvijalce

### Katalog modelov Azure AI Foundry
DruÅ¾ina modelov Phi (razen Phi-silica) je na voljo prek [Azure AI Foundry Model Catalog](https://ai.azure.com/explore/models?q=phi), kar razvijalcem omogoÄa enostaven dostop, prilagoditev in uporabo teh modelov v svojih aplikacijah. Katalog ponuja poenostavljen naÄin za eksperimentiranje z razliÄnimi razliÄicami Phi in njihovo integracijo v projekte.

### Azure AI Foundry
Phi modele lahko namestite in preizkusite prek [Azure AI Foundry](https://ai.azure.com), ki zagotavlja celovito okolje za gradnjo, testiranje in uvajanje AI reÅ¡itev z minimalno pripravo.

### Foundry Local
Za lokalni razvoj in uvajanje si oglejte [Microsoft Foundry Local](https://github.com/microsoft/foundry-local), ki omogoÄa izvajanje modelov Phi na vaÅ¡em razvojnem raÄunalniku z optimiziranimi konfiguracijami.

### Dokumentacija
- [Microsoft Research: Phi Model Technical Reports](https://ai.azure.com/labs/projects/phi-4)
- [Phi Cookbook](https://aka.ms/phicookbook)

## Uvod

V tej lekciji bomo raziskali druÅ¾ino modelov Microsoft Phi in njene temeljne koncepte. Pokrili bomo evolucijo druÅ¾ine Phi, inovativne metode uÄenja, ki omogoÄajo uÄinkovitost modelov Phi, kljuÄne razliÄice v druÅ¾ini ter praktiÄne aplikacije v razliÄnih scenarijih.

## Cilji uÄenja

Do konca te lekcije boste lahko:

- Razumeli filozofijo oblikovanja in evolucijo druÅ¾ine modelov Microsoft Phi.
- Prepoznali kljuÄne inovacije, ki omogoÄajo modelom Phi doseganje visoke zmogljivosti z manj parametri.
- Spoznali prednosti in omejitve razliÄnih razliÄic modelov Phi.
- Uporabili znanje o modelih Phi za izbiro ustreznih razliÄic v realnih scenarijih.

## Razumevanje tradicionalnega pristopa AI modelov

Tradicionalno je za doseganje visoke zmogljivosti pri obdelavi naravnega jezika potrebna uporaba velikih jezikovnih modelov z milijardami ali stotinami milijard parametrov. Organizacije obiÄajno te modele izvajajo na zmogljivih GPU grozdih, dostopajo do njihovih sposobnosti prek API vmesnikov ali specializirane strojne infrastrukture.

Ta pristop dobro deluje za Å¡tevilne aplikacije, vendar ima inherentne omejitve pri praktiÄnih scenarijih uvajanja. Konvencionalna metoda vkljuÄuje uporabo modelov, ki zahtevajo velike raÄunalniÅ¡ke vire, veliko koliÄino pomnilnika in znatno porabo energije. ÄŒeprav ta pristop omogoÄa dostop do najsodobnejÅ¡ih zmogljivosti, ustvarja odvisnost od drage strojne opreme, poveÄuje operativne stroÅ¡ke in omejuje fleksibilnost uvajanja.

## Izziv uÄinkovitega uvajanja AI

Potreba po bolj uÄinkoviti AI postaja vse bolj pomembna v razliÄnih scenarijih. UpoÅ¡tevajte aplikacije, ki zahtevajo lokalno uvajanje zaradi zasebnosti, stroÅ¡kovno obÄutljive implementacije, kjer stroÅ¡ki API v oblaku postanejo previsoki, scenarije robnega raÄunalniÅ¡tva z omejenimi strojno-tehniÄnimi viri ali aplikacije v realnem Äasu, kjer je latenca kljuÄna.

### KljuÄne omejitve uvajanja

Tradicionalna uvajanja velikih modelov se sooÄajo z veÄ temeljnimi omejitvami, ki omejujejo njihovo praktiÄno uporabnost:

- **Omejitve stroÅ¡kov**: Visoki raÄunalniÅ¡ki stroÅ¡ki oteÅ¾ujejo neprekinjeno uvajanje za Å¡tevilne organizacije.
- **Omejitve virov**: Omejen dostop do zmogljive GPU infrastrukture omejuje moÅ¾nosti uvajanja.
- **Zahteve zasebnosti**: ObÄutljive aplikacije zahtevajo lokalno obdelavo za ohranjanje zasebnosti podatkov.
- **ObÄutljivost na latenco**: Aplikacije v realnem Äasu potrebujejo takojÅ¡nje odzive brez zamud pri komunikaciji z oblakom.

## Filozofija modelov Microsoft Phi

DruÅ¾ina modelov Microsoft Phi predstavlja temeljni premik v filozofiji oblikovanja AI modelov, saj daje prednost uÄinkovitosti in praktiÄnemu uvajanju, hkrati pa ohranja moÄne zmogljivostne znaÄilnosti. Modeli Phi to doseÅ¾ejo z inovativnimi arhitekturami, visokokakovostnimi metodami uÄenja in specializiranimi tehnikami optimizacije.

DruÅ¾ina Phi vkljuÄuje razliÄne pristope, zasnovane za maksimizacijo zmogljivosti na parameter, kar omogoÄa uvajanje na standardni strojni opremi, hkrati pa zagotavlja pomembne AI sposobnosti. Cilj je ohraniti konkurenÄno zmogljivost ob drastiÄnem zmanjÅ¡anju raÄunalniÅ¡kih zahtev, porabe pomnilnika in operativnih stroÅ¡kov.

### Temeljna naÄela oblikovanja Phi

Modeli Phi temeljijo na veÄ osnovnih naÄelih, ki jih loÄujejo od tradicionalnih velikih jezikovnih modelov:

- **UÄinkovitost na prvem mestu**: Optimizirani za najveÄjo zmogljivost na parameter, ne pa za absolutno velikost.
- **Kakovostno uÄenje**: OsredotoÄeni na visokokakovostne, kurirane podatke za uÄenje namesto na obseÅ¾ne podatkovne zbirke.
- **Fleksibilnost uvajanja**: Zasnovani za uÄinkovito delovanje na razliÄnih strojnih konfiguracijah.
- **Specializirane sposobnosti**: Pogosto optimizirani za specifiÄne naloge ali domene za maksimalno uÄinkovitost.

## KljuÄne tehnologije, ki omogoÄajo druÅ¾ino Phi

### Pristop "uÄbenik kakovosti" pri uÄenju

Ena najbolj revolucionarnih znaÄilnosti druÅ¾ine Phi je metoda uÄenja "uÄbenik kakovosti". Namesto da bi se uÄili na ogromnih koliÄinah nefiltriranih podatkov z interneta, modeli Phi uporabljajo skrbno kurirane, visokokakovostne izobraÅ¾evalne vsebine, zasnovane za uÄinkovito pouÄevanje razmiÅ¡ljanja, matematike, kodiranja in sploÅ¡nega znanja.

Ta pristop deluje tako, da ustvarja sintetiÄne izobraÅ¾evalne vsebine, ki posnemajo visokokakovostne uÄbenike in akademske materiale. Podatki za uÄenje so posebej zasnovani tako, da so pedagoÅ¡ko ustrezni, osredotoÄeni na jasne razlage, postopno razmiÅ¡ljanje in strukturirano predstavitev znanja.

### Napredno uÄenje razmiÅ¡ljanja

NovejÅ¡i modeli Phi vkljuÄujejo sofisticirane metode uÄenja razmiÅ¡ljanja, ki omogoÄajo kompleksno veÄstopenjsko reÅ¡evanje problemov. Te tehnike vkljuÄujejo:

**UÄenje verige razmiÅ¡ljanja**: Modeli se nauÄijo razÄleniti kompleksne probleme na vmesne korake razmiÅ¡ljanja, kar njihov proces reÅ¡evanja naredi bolj transparenten in zanesljiv.

**Skaliranje med generiranjem**: Modeli ustvarjajo podrobne verige razmiÅ¡ljanja, ki med generiranjem odgovorov izkoristijo dodatne raÄunalniÅ¡ke vire za izboljÅ¡ano natanÄnost.

**UÄenje na robu zmogljivosti**: Podatki za uÄenje so posebej izbrani, da izzovejo model na robu njegovih trenutnih zmogljivosti, kar spodbuja uÄenje kompleksnih vzorcev razmiÅ¡ljanja.

### Arhitekturne inovacije

DruÅ¾ina Phi vkljuÄuje veÄ arhitekturnih optimizacij, zasnovanih posebej za uÄinkovitost:

**UÄinkovitost parametrov**: Skrbne arhitekturne izbire, ki maksimizirajo vpliv vsakega parametra v modelu.

**Integracija veÄ modalnosti**: UÄinkovita integracija obdelave besedila, slike in govora v kompaktnih arhitekturah.

**Optimizacija strojne opreme**: Specializirane razliÄice, optimizirane za specifiÄne strojne platforme in scenarije uvajanja.

## Optimizacija strojne opreme za modele Phi

Sodobna okolja uvajanja koristijo uÄinkovitosti modelov Phi na razliÄnih strojnih konfiguracijah:

### Optimizirano za CPU

Modeli Phi so zasnovani za uÄinkovito delovanje na strojni opremi, ki temelji samo na CPU, kar omogoÄa dostopnost za uvajanje na standardni raÄunalniÅ¡ki infrastrukturi brez potrebe po specializiranih AI pospeÅ¡evalnikih.

### PospeÅ¡evanje z GPU

ÄŒeprav ne zahtevajo zmogljivih GPU-jev, modeli Phi lahko izkoristijo razpoloÅ¾ljive GPU vire za izboljÅ¡ano zmogljivost, kar zagotavlja fleksibilnost pri konfiguracijah uvajanja.

### Integracija na robnih napravah

Specializirane razliÄice, kot je Phi-3-Silica, so optimizirane za specifiÄne platforme robnega raÄunalniÅ¡tva, doseganje izjemnih uÄinkovitostnih metrik, kot je 650 tokenov na sekundo z le 1,5 W porabe energije.

## Prednosti druÅ¾ine modelov Phi

### StroÅ¡kovna uÄinkovitost

Modeli Phi drastiÄno zmanjÅ¡ajo operativne stroÅ¡ke, saj zahtevajo bistveno manj raÄunalniÅ¡ke infrastrukture, hkrati pa ohranjajo konkurenÄno zmogljivost. To omogoÄa dostopnost AI organizacijam z omejenimi proraÄuni ali aplikacijam z velikim obsegom, kjer so stroÅ¡ki na sklep pomembni.

### Fleksibilnost uvajanja

UÄinkovitost modelov Phi omogoÄa uvajanje na Å¡irok spekter strojnih konfiguracij, od osebnih prenosnikov do streÅ¾nikov v podjetjih, kar organizacijam zagotavlja veÄjo fleksibilnost pri izbiri AI infrastrukture.

### Zasebnost in varnost

UÄinkovitost modelov Phi omogoÄa lokalno uvajanje za aplikacije, obÄutljive na zasebnost, kar zagotavlja, da obÄutljivi podatki nikoli ne zapustijo nadzora organizacije, hkrati pa zagotavlja zmogljive AI sposobnosti.

### Zmogljivost v realnem Äasu

ZmanjÅ¡ane raÄunalniÅ¡ke zahteve se prevedejo v hitrejÅ¡e Äase sklepanja, kar omogoÄa aplikacije v realnem Äasu, ki zahtevajo takojÅ¡nje odzive brez kompromisov pri kakovosti AI sposobnosti.

### Dostopna AI

Z zmanjÅ¡anjem ovir za uvajanje AI modeli Phi omogoÄajo dostop do naprednih AI sposobnosti organizacijam z omejenimi viri, kar omogoÄa manjÅ¡im ekipam in posameznim razvijalcem uporabo sofisticiranega razumevanja jezika.

## PraktiÄni primeri in uporabe

Preden se poglobimo v tehniÄno evolucijo, si oglejmo nekaj konkretnih primerov, kaj modeli Phi zmorejo:

### Primer matematiÄnega razmiÅ¡ljanja

Phi-4-mini-reasoning odliÄno obvlada postopno reÅ¡evanje matematiÄnih problemov. Na primer, ko ga vpraÅ¡amo "Kako reÅ¡iti 3*x^2+4*x+5=1?", model poda podrobne korake razmiÅ¡ljanja:

```
<|system|>Your name is Phi, an AI math expert developed by Microsoft.<|end|>
<|user|>How to solve 3*x^2+4*x+5=1?<|end|>
<|assistant|>
I need to solve the quadratic equation 3xÂ² + 4x + 5 = 1.

First, let me rearrange this to standard form:
3xÂ² + 4x + 5 = 1
3xÂ² + 4x + 5 - 1 = 0  
3xÂ² + 4x + 4 = 0

Now I can use the quadratic formula: x = (-b Â± âˆš(bÂ² - 4ac)) / (2a)
Where a = 3, b = 4, c = 4

Let me calculate the discriminant:
bÂ² - 4ac = 4Â² - 4(3)(4) = 16 - 48 = -32

Since the discriminant is negative (-32), this equation has no real solutions.
The solutions are complex: x = (-4 Â± âˆš(-32)) / 6 = (-4 Â± 4iâˆš2) / 6 = (-2 Â± 2iâˆš2) / 3
```

### Primer veÄjeziÄne podpore

Phi-3.5-mini-instruct izkazuje moÄne veÄjeziÄne sposobnosti v razliÄnih jezikih. Tukaj je primer oblike poziva:

```
<|system|>You are a helpful assistant.<|end|>
<|user|>How to explain Internet for a medieval knight?<|end|>
<|assistant|>
Imagine, good sir knight, a vast network of invisible roads that span the entire realm and beyond. The Internet is like a magical system of messenger birds that can carry any message - be it text, images, or even moving pictures - instantly to any castle, village, or hamlet in the world.

Think of it as if every scribe's work could be copied and shared with thousands of people simultaneously, as if you could visit any library in any kingdom without leaving your chambers, or as if you could hold council with knights from distant lands as if they were sitting at your very table.

This "Internet" allows people to:
- Send messages faster than the swiftest horse
- Access knowledge from scholars across all kingdoms
- Trade goods without traveling to distant markets
- Share stories and news from lands you've never seen

'Tis like having a thousand scribes, merchants, and storytellers all working for you at once, good knight!
```

### Primer veÄmodalnih sposobnosti

Phi-4-multimodal lahko hkrati obdeluje besedilo, slike in govor. Tukaj so nekatere praktiÄne uporabe:

**NaÄrtovanje potovanja z zvoÄnim vnosom:**
Oglejte si, kako Phi-4 Multimodal analizira govorjeni jezik za pomoÄ pri naÄrtovanju potovanja v Seattle, kar prikazuje njegove napredne sposobnosti obdelave zvoka in priporoÄanja.

**ReÅ¡evanje matematiÄnih problemov iz slik:**
Oglejte si, kako Phi-4 Multimodal obravnava kompleksne matematiÄne probleme prek vizualnih vnosov, kar prikazuje njegovo sposobnost obdelave in reÅ¡evanja enaÄb, predstavljenih v slikah.

**Primer klicanja funkcij:**
S klicanjem funkcij lahko Phi-4-mini in Phi-4-multimodal razÅ¡irita svoje sposobnosti obdelave besedila z integracijo iskalnikov, povezovanjem razliÄnih orodij in veÄ. Kot je prikazano, model lahko pridobi informacije o tekmah Premier League prek Phi-4-mini, kar prikazuje njegovo sposobnost brezhibne interakcije z zunanjimi viri podatkov.

### Primer generiranja kode

Phi-4-multimodal lahko generira strukturirano projektno kodo na podlagi vsebine slike in podanih pozivov, kot je prikazano v tem praktiÄnem poteku dela:

1. NaloÅ¾ite sliko Å¾iÄne mreÅ¾e ali zasnove
2. Podajte kontekst o zahtevah projekta
3. Model generira popolne, funkcionalne strukture kode
4. Kodo je mogoÄe prilagoditi glede na specifiÄne ogrodja ali jezike

### Primer uvajanja na robnih napravah

Model lahko kvantiziramo za optimizacijo mobilnih naprav. S kombinacijo Microsoft Olive in ONNX GenAI Runtime lahko Phi-4-mini uvedemo na Windows, iPhone, Android in druge naprave. Tukaj je primer, ki deluje na iPhone 12 Pro.

Postopek uvajanja vkljuÄuje:
- Kvantizacijo modela za mobilno optimizacijo
- Integracijo ONNX runtime za zdruÅ¾ljivost med platformami
- Lokalno sklepanje brez povezave z internetom
- Zmogljivost v realnem Äasu z minimalno porabo energije

## Evolucija druÅ¾ine Phi

### Phi-1 in Phi-2: Temeljni modeli

Zgodnji modeli Phi so vzpostavili temeljna naÄela visokokakovostnih podatkov za uÄenje in uÄinkovitih arhitektur:

- **Phi-1 (1,3B parametrov)**: Uvedel koncept kuriranih podatkov za osnovno razumevanje jezika in generiranje kode.
- **Phi-2 (2,7B parametrov)**: IzboljÅ¡al sposobnosti razmiÅ¡ljanja prek sintetiÄnih NLP podatkov in skrbno filtrirane spletne vsebine.

### DruÅ¾ina Phi-3: Glavni sprejem

Serija Phi-3 je pomenila preboj v sposobnostih SLM z veÄ specializiranimi razliÄicami:

- **Phi-3-mini (3,8B parametrov)**: SploÅ¡ne jezikovne naloge z izjemno uÄinkovitostjo, ki prekaÅ¡a modele dvakratne velikosti.
- **Phi-3-small (7B parametrov)**: Napredna zmogljivost, ki premaga GPT-3.5 Turbo na razliÄnih merilih.
- **Phi-3-medium (14B parametrov)**: Zmogljivost na ravni podjetij, ki premaga Gemini 1.0 Pro.
- **Phi-3-vision (4,2B parametrov)**: VeÄmodalne sposobnosti za obdelavo slik in besedila.
- **Phi-3-Silica (3,3B parametrov)**: Specializirana optimizacija za vgrajeno uvajanje v Windows 11.

### DruÅ¾ina Phi-4: Napredno razmiÅ¡ljanje

NajnovejÅ¡a generacija premika meje sposobnosti razmiÅ¡ljanja:

- **Phi-4 (14B parametrov)**: Specializacija za kompleksno razmiÅ¡ljanje, zlasti v matematiki.
- **Phi-4-mini (3,8B parametrov)**: IzboljÅ¡ano razmiÅ¡ljanje s klicanjem funkcij in podporo za dolge kontekste.
- **Phi-4-multimodal**: Hkratna obdelava govora, slike in besedila.
- **Phi-4-reasoning (14B parametrov)**: Specializiran za kompleksne veÄstopenjske naloge razmiÅ¡ljanja.
- **Phi-4-reasoning-plus (14B parametrov)**: IzboljÅ¡ana natanÄnost prek dodatnega uÄenja z okrepitvijo.
- **Phi-4-mini-reasoning (3,8B parametrov)**: MatematiÄno razmiÅ¡ljanje, optimizirano za omejena okolja.

## Uporabe modelov Phi

### Aplikacije v podjetjih

Organizacije uporabljajo modele Phi za analizo dokumentov, avtomatizacijo storitev za stranke, pomoÄ pri generiranju kode in aplikacije poslovne inteligence, ki zahtevajo lokalno uvajanje zaradi skladnosti in varnosti.

### Mobilno in robno raÄunalniÅ¡tvo

Mobilne aplikacije izkoriÅ¡Äajo modele Phi za prevajanje v realnem Äasu, inteligentne asistente, generiranje vsebine in personalizirana priporoÄila brez potrebe po stalni povezavi z internetom.

### IzobraÅ¾evalna tehnologija

IzobraÅ¾evalne platforme uporabljajo modele Phi za personalizirano tutorstvo, avtomatizirano ocenjevanje, generiranje vsebine in interaktivne uÄne izkuÅ¡nje, ki lahko delujejo brez povezave ali v okoljih z nizko povezljivostjo.

### Zdravstvo in skladnost


DruÅ¾ina Phi dokazuje, da prihodnost uvajanja umetne inteligence ne temelji zgolj na gradnji veÄjih modelov, temveÄ na gradnji pametnejÅ¡ih, bolj uÄinkovitih modelov, ki lahko uÄinkovito delujejo v razliÄnih strojnih okoljih, hkrati pa ohranjajo visoke standarde zmogljivosti.

## Primeri razvoja in integracije

### Hiter zaÄetek z Transformers

Tukaj je prikazano, kako zaÄeti z modeli Phi z uporabo knjiÅ¾nice Hugging Face Transformers:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load Phi-4-mini-instruct
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    attn_implementation="flash_attention_2"  # For optimized performance
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")

# Format your prompt using the chat template
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Explain quantum computing in simple terms."}
]

# Apply chat template
input_text = tokenizer.apply_chat_template(messages, tokenize=False)
inputs = tokenizer(input_text, return_tensors="pt")

# Generate response
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)
    
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### Primer prilagoditve

Naslednji primer prikazuje, kako prilagoditi Phi-4-mini-instruct za specifiÄne naloge:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig
from trl import SFTTrainer
from datasets import load_dataset

# Configuration for LoRA fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules="all-linear"
)

# Training configuration optimized for efficiency
training_config = TrainingArguments(
    output_dir="./phi-4-mini-finetuned",
    learning_rate=5.0e-06,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=1,
    num_train_epochs=1,
    bf16=True,
    gradient_checkpointing=True,
    warmup_ratio=0.2,
    save_steps=100
)

# Load model and tokenizer
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")
tokenizer.pad_token = tokenizer.unk_token
tokenizer.padding_side = 'right'

# Load and process dataset
train_dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_config,
    peft_config=peft_config,
    train_dataset=train_dataset,
    max_seq_length=2048,
    tokenizer=tokenizer,
    packing=True
)

# Start fine-tuning
trainer.train()
```

### Specializirani formati pozivov

**Za naloge sklepanja (Phi-4-reasoning-plus):**
```
<|im_start|>system<|im_sep|>
You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions.

Please structure your response into two main sections:
<think>
{Thought section}
</think>
{Solution section}
<|im_end|>
<|im_start|>user<|im_sep|>
What is the derivative of x^2?
<|im_end|>
<|im_start|>assistant<|im_sep|>
```

**Za matematiÄne naloge (Phi-4-mini-reasoning):**
```
<|system|>
Your name is Phi, an AI math expert developed by Microsoft.
<|end|>
<|user|>
Solve this calculus problem: Find the integral of 2x + 3
<|end|>
<|assistant|>
```

### Mobilna uvedba z ONNX

```python
import onnxruntime as ort
import numpy as np

# Load ONNX model for mobile deployment
session = ort.InferenceSession("phi-4-mini-quantized.onnx")

# Prepare input
input_ids = tokenizer.encode("Hello, how are you?", return_tensors="np")

# Run inference
outputs = session.run(None, {"input_ids": input_ids})
predicted_ids = outputs[0]

# Decode response
response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)
```

## Merila zmogljivosti in doseÅ¾ki

DruÅ¾ina modelov Phi je dosegla izjemne rezultate na razliÄnih merilih, pogosto prekaÅ¡a veliko veÄje modele:

### KljuÄni poudarki zmogljivosti

**OdliÄnost v matematiÄnem sklepanju:**
- Phi-4 doseÅ¾e 82,5 % natanÄnost na AIME 2025 (kvalifikacija za matematiÄno olimpijado)
- Phi-4-reasoning (14B) prekaÅ¡a DeepSeek-R1-Distill-70B (5x veÄji) na merilih sklepanja
- Phi-4-mini-reasoning (3,8B) se kosa z modeli, ki so dvakrat veÄji, pri nalogah matematiÄnega sklepanja

**DoseÅ¾ki uÄinkovitosti:**
- Phi-3-Silica doseÅ¾e 650 tokenov na sekundo z le 1,5W porabe energije
- Phi-4-mini (3,8B) dosega podobno zmogljivost kot veliko veÄji modeli

**UspeÅ¡nost na merilih:**
- **MMLU (Massive Multitask Language Understanding)**: KonkurenÄna zmogljivost v 57 akademskih predmetih
- **HumanEval**: MoÄne sposobnosti generiranja kode, zlasti v Pythonu
- **MGSM**: VeÄjeziÄno reÅ¡evanje matematiÄnih nalog osnovne Å¡ole
- **DROP**: Kompleksne naloge razumevanja in sklepanja
- **SimpleQA**: NatanÄnost pri odgovarjanju na dejanska vpraÅ¡anja

### ğŸ“Š Primerjalna matrika modelov

| Model | Parametri | DolÅ¾ina konteksta | KljuÄne prednosti | NajboljÅ¡i primeri uporabe |
|-------|-----------|-------------------|-------------------|---------------------------|
| **Phi-3-mini** | 3,8B | 4K/128K | SploÅ¡na uÄinkovitost | Mobilne aplikacije, osnovni klepetalniki |
| **Phi-3.5-mini** | 3,8B | 128K | VeÄjeziÄna podpora | Mednarodne aplikacije |
| **Phi-4-mini** | 3,8B | 128K | IzboljÅ¡ano sklepanje, klic funkcij | Poslovna avtomatizacija |
| **Phi-4-mini-reasoning** | 3,8B | 128K | MatematiÄno sklepanje | IzobraÅ¾evalne platforme |
| **Phi-4** | 14B | 32K | Kompleksno sklepanje | Raziskave, napredna analiza |
| **Phi-4-reasoning** | 14B | 32K/64K | VeÄstopenjsko sklepanje | Znanstveno raÄunalniÅ¡tvo |
| **Phi-4-reasoning-plus** | 14B | 32K | Maksimalna natanÄnost sklepanja | KritiÄno odloÄanje |
| **Phi-4-multimodal** | 5,6B | Spremenljivo | Govor, vizija, besedilo | Multimedijske aplikacije |

## Vodnik za izbiro modela

### Za osnovne aplikacije
- **Phi-3-mini**: Enostavno generiranje besedila, osnovna vpraÅ¡anja in odgovori, hitri odzivi
- **Phi-4-mini**: IzboljÅ¡ano sklepanje z zmoÅ¾nostmi klicanja funkcij

### Za matematiÄne in sklepalne naloge
- **Phi-4**: Kompleksno reÅ¡evanje matematiÄnih problemov in sklepanje
- **Phi-4-reasoning**: VeÄstopenjsko sklepanje z natanÄnimi razlagami
- **Phi-4-reasoning-plus**: Maksimalna natanÄnost za kritiÄne naloge sklepanja
- **Phi-4-mini-reasoning**: UÄinkovito matematiÄno sklepanje za okolja z omejenimi viri

### Za multimodalne aplikacije
- **Phi-3-vision**: Kombinacije obdelave slik in besedila
- **Phi-4-multimodal**: Celovite zmoÅ¾nosti govora, vizije in besedila

### Za poslovno uvedbo
- **Phi-3-medium**: Napredno razumevanje jezika za poslovne aplikacije
- **Phi-3-Silica**: Optimizirano za specifiÄne strojne platforme

## Platforme za uvedbo in dostopnost

### Oblakovne platforme
- **Azure AI Foundry**: Celovita uvedba z orodji za podjetja
- **Hugging Face**: Odprtokodni repozitorij modelov in skupnostni viri
- **NVIDIA API Catalog**: MoÅ¾nosti uvedbe mikrostoritev

### Okviri za lokalni razvoj
- **Ollama**: Lahek okvir za lokalno uvedbo modelov
- **ONNX Runtime**: Optimizirano za razliÄne strojne konfiguracije  
- **DirectML**: Optimizirana zmogljivost za Windows
- **llama.cpp**: VeÄplatformni pogon za sklepanje

### UÄni viri
- **Phi Portal**: Uradno Microsoftovo srediÅ¡Äe dokumentacije za Phi
- **Phi Cookbook**: Celoviti primeri in vadnice
- **TehniÄna poroÄila**: Poglobljeni raziskovalni Älanki na arxiv
- **Skupnostni prostori**: Interaktivne predstavitve na Hugging Face

### ZaÄetek z modeli Phi

#### Platforme za razvoj
1. **Azure AI Foundry**: Enostaven lokalni CLI in upravljanje modelov.
2. **Hugging Face Transformers**: Hitro lokalno eksperimentiranje
3. **Ollama**: Enostavna lokalna uvedba za testiranje

#### UÄna pot
1. **Razumevanje osnovnih konceptov**: PreuÄite temeljna naÄela oblikovanja
2. **Eksperimentiranje z razliÄicami**: Preizkusite razliÄne modele Phi za razumevanje zmogljivosti
3. **PraktiÄna implementacija**: Uvedite modele v testnih okoljih
4. **RazÅ¡iritev uvedbe**: Postopno poveÄajte uporabo na podlagi uspeÅ¡nih pilotov

#### NajboljÅ¡e prakse
- **ZaÄnite z majhnim**: ZaÄetek z modeli Phi-mini za zaÄetni razvoj
- **Optimizirajte pozive**: Uporabite pravilno oblikovanje klepeta za najboljÅ¡e rezultate
- **Spremljajte zmogljivost**: Spremljajte hitrost sklepanja in metrike natanÄnosti
- **UpoÅ¡tevajte strojno opremo**: Prilagodite velikost modela razpoloÅ¾ljivim raÄunalniÅ¡kim virom

## ZakljuÄek

DruÅ¾ina modelov Microsoft Phi predstavlja revolucionaren pristop k oblikovanju modelov umetne inteligence, ki dokazuje, da lahko manjÅ¡i, bolj uÄinkoviti modeli doseÅ¾ejo izjemne rezultate pri razliÄnih nalogah. Z osredotoÄanjem na visokokakovostne podatke za usposabljanje in optimizacije arhitekture druÅ¾ina Phi zagotavlja izjemne zmogljivosti z bistveno zmanjÅ¡animi raÄunalniÅ¡kimi zahtevami v primerjavi s tradicionalnimi velikimi jezikovnimi modeli.

## KljuÄni uÄni cilji

1. Razumeti filozofijo oblikovanja in razvoj druÅ¾ine modelov Microsoft Phi od Phi-1 do Phi-4
2. Prepoznati kljuÄne inovacije, vkljuÄno s "uÄbenik kakovostjo" usposabljanja in optimizacijami arhitekture
3. Prepoznati prednosti in omejitve razliÄnih razliÄic Phi v razliÄnih scenarijih uvedbe
4. Uporabiti znanje za izbiro ustreznih modelov Phi za specifiÄne primere uporabe in strojne omejitve
5. Izvesti tehnike optimizacije za uvedbo modelov Phi na napravah z omejenimi viri
6. Pojasniti arhitekturne prednosti druÅ¾ine modelov Phi v primerjavi s tradicionalnimi velikimi jezikovnimi modeli
7. Izbrati ustrezno razliÄico Phi glede na specifiÄne zahteve aplikacije in strojne omejitve
8. Uvesti modele Phi v oblaÄnih in robnih scenarijih z optimiziranimi konfiguracijami
9. Uporabiti tehnike kvantizacije in optimizacije za izboljÅ¡anje zmogljivosti modelov Phi na ciljnih napravah
10. Oceniti kompromise med velikostjo modela, zmogljivostjo in zmoÅ¾nostmi v druÅ¾ini Phi

## Kaj sledi

- [02: Osnove druÅ¾ine Qwen](02.QwenFamily.md)

---

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve za prevajanje z umetno inteligenco [Co-op Translator](https://github.com/Azure/co-op-translator). ÄŒeprav si prizadevamo za natanÄnost, vas prosimo, da upoÅ¡tevate, da lahko avtomatizirani prevodi vsebujejo napake ali netoÄnosti. Izvirni dokument v njegovem izvirnem jeziku je treba obravnavati kot avtoritativni vir. Za kljuÄne informacije priporoÄamo profesionalni ÄloveÅ¡ki prevod. Ne prevzemamo odgovornosti za morebitne nesporazume ali napaÄne razlage, ki bi nastale zaradi uporabe tega prevoda.