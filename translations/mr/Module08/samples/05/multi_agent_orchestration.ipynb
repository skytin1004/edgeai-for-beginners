{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b861ae53",
   "metadata": {},
   "source": [
    "# рдирдореБрдирд╛ режрел: рдорд▓реНрдЯреА-рдПрдЬрдВрдЯ рдСрд░реНрдХреЗрд╕реНрдЯреНрд░реЗрд╢рди рд╕рд┐рд╕реНрдЯрдо\n",
    "\n",
    "рд╣реА рдиреЛрдЯрдмреБрдХ Microsoft Foundry Local рд╡рд╛рдкрд░реВрди AI-рд╕рдХреНрд╖рдо рдПрдЬрдВрдЯ рд╕рд┐рд╕реНрдЯрдо рддрдпрд╛рд░ рдХрд░рдгреНрдпрд╛рд╕рд╛рдареА рдкреНрд░рдЧрдд рдорд▓реНрдЯреА-рдПрдЬрдВрдЯ рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдкреНрд░рджрд░реНрд╢рд┐рдд рдХрд░рддреЗ.\n",
    "\n",
    "## рдЖрдврд╛рд╡рд╛\n",
    "\n",
    "рдпрд╛ рдирдореБрдиреНрдпрд╛рдд **рдорд▓реНрдЯреА-рдПрдЬрдВрдЯ рд╕рдордиреНрд╡рдпрдХ** рдЕрдВрдорд▓рд╛рдд рдЖрдгрд▓рд╛ рдЖрд╣реЗ рдЬреЛ рд╡рд┐рд╢реЗрд╖ рдПрдЬрдВрдЯреНрд╕рдЪреЗ рд╕рдордиреНрд╡рдп рдХрд░рддреЛ:\n",
    "\n",
    "- ЁЯФН **рд░рд┐рдЯреНрд░реАрд╡реНрд╣рд▓ рдПрдЬрдВрдЯ**: рдЬреНрдЮрд╛рди рд╕реНрд░реЛрддрд╛рдВрдордзреВрди рд╕рдВрдмрдВрдзрд┐рдд рдорд╛рд╣рд┐рддреА рдХрд╛рдврддреЛ\n",
    "- ЁЯза **рд░рд┐рдЭрдирд┐рдВрдЧ рдПрдЬрдВрдЯ**: рдЪрд░рдг-рджрд░-рдЪрд░рдг рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдЖрдгрд┐ рддрд░реНрдХрд╢рдХреНрддреАрдЪреЗ рдХрд╛рд░реНрдп рдХрд░рддреЛ\n",
    "- тЪб **рдПрдХреНрдЭрд┐рдХреНрдпреБрд╢рди рдПрдЬрдВрдЯ**: рд╕рдВрд░рдЪрд┐рдд рд╕реНрд╡рд░реВрдкрд╛рдд рдХреГрддреАрдпреЛрдЧреНрдп рдпреЛрдЬрдирд╛ рддрдпрд╛рд░ рдХрд░рддреЛ\n",
    "- ЁЯОп **рдХреЛрдСрд░реНрдбрд┐рдиреЗрдЯрд░**: рд╕рдВрдкреВрд░реНрдг рдПрдЬрдВрдЯ рдХрд╛рд░реНрдпрдкреНрд░рд╡рд╛рд╣рд╛рдЪреЗ рд╕рдордиреНрд╡рдп рдХрд░рддреЛ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e840290d",
   "metadata": {},
   "source": [
    "## рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдкреЕрдЯрд░реНрди\n",
    "\n",
    "```\n",
    "User Goal тЖТ Coordinator\n",
    "     тЖУ\n",
    "1. Retrieval Agent тЖТ Context\n",
    "     тЖУ\n",
    "2. Reasoning Agent тЖТ Decision\n",
    "     тЖУ\n",
    "3. Execution Agent тЖТ Actions\n",
    "     тЖУ\n",
    "Structured Result\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240650a",
   "metadata": {},
   "source": [
    "## рдкреВрд░реНрд╡рдЕрдЯ рдЖрдгрд┐ рд╕реЗрдЯрдЕрдк\n",
    "\n",
    "рддреБрдордЪреНрдпрд╛рдХрдбреЗ Foundry Local рд╕рдХреНрд╖рдо рдореЙрдбреЗрд▓рд╕рд╣ рдЪрд╛рд▓реВ рдЖрд╣реЗ рдпрд╛рдЪреА рдЦрд╛рддреНрд░реА рдХрд░рд╛:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc33b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install openai foundry-local-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c6fe9e",
   "metadata": {},
   "source": [
    "## рд▓рд╛рдпрдмреНрд░рд░реА рдЖрдгрд┐ рдХреЙрдиреНрдлрд┐рдЧрд░реЗрд╢рди рдЖрдпрд╛рдд рдХрд░рд╛\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5160a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, Any, List\n",
    "from openai import OpenAI\n",
    "\n",
    "try:\n",
    "    from foundry_local import FoundryLocalManager\n",
    "    FOUNDRY_SDK_AVAILABLE = True\n",
    "    print(\"тЬЕ Foundry Local SDK is available\")\n",
    "except ImportError:\n",
    "    FOUNDRY_SDK_AVAILABLE = False\n",
    "    print(\"тЪая╕П Foundry Local SDK not available, will use manual configuration\")\n",
    "\n",
    "# Configuration\n",
    "MODEL_ALIAS = \"phi-4-mini\"  # Change to your preferred model\n",
    "BASE_URL = \"http://localhost:8000\"\n",
    "API_KEY = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba6a90f",
   "metadata": {},
   "source": [
    "## рдлрд╛рдЙрдВрдбреНрд░реА рдХреНрд▓рд╛рдпрдВрдЯ рд╕реЗрдЯрдЕрдк\n",
    "\n",
    "рд╕рд░реНрд╡ рдПрдЬрдВрдЯреНрд╕рд╕рд╛рдареА рдПрдХ рд╕рд╛рдорд╛рдпрд┐рдХ рдХреНрд▓рд╛рдпрдВрдЯ рддрдпрд╛рд░ рдХрд░рд╛:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc80453",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoundryClient:\n",
    "    \"\"\"Shared client for all specialist agents.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_alias: str = MODEL_ALIAS):\n",
    "        self.client = None\n",
    "        self.model_name = None\n",
    "        self.model_alias = model_alias\n",
    "        self._initialize_client()\n",
    "    \n",
    "    def _initialize_client(self):\n",
    "        \"\"\"Initialize OpenAI client with Foundry Local or fallback configuration.\"\"\"\n",
    "        if FOUNDRY_SDK_AVAILABLE:\n",
    "            try:\n",
    "                print(f\"ЁЯФД Initializing Foundry Local with model: {self.model_alias}...\")\n",
    "                manager = FoundryLocalManager(self.model_alias)\n",
    "                model_info = manager.get_model_info(self.model_alias)\n",
    "                \n",
    "                self.client = OpenAI(\n",
    "                    base_url=manager.endpoint,\n",
    "                    api_key=manager.api_key\n",
    "                )\n",
    "                self.model_name = model_info.id\n",
    "                print(f\"тЬЕ Foundry Local SDK initialized with model: {self.model_name}\")\n",
    "                return\n",
    "            except Exception as e:\n",
    "                print(f\"тЪая╕П Could not use Foundry SDK ({e}), falling back to manual configuration\")\n",
    "        \n",
    "        # Fallback to manual configuration\n",
    "        self.client = OpenAI(\n",
    "            base_url=f\"{BASE_URL}/v1\",\n",
    "            api_key=API_KEY\n",
    "        )\n",
    "        self.model_name = self.model_alias\n",
    "        print(f\"ЁЯФз Manual configuration initialized with model: {self.model_name}\")\n",
    "    \n",
    "    def chat(self, messages: List[Dict[str, str]], max_tokens: int = 300, temperature: float = 0.4) -> str:\n",
    "        \"\"\"Send chat completion request to the model.\"\"\"\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model_name,\n",
    "                messages=messages,\n",
    "                max_tokens=max_tokens,\n",
    "                temperature=temperature\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {str(e)}\"\n",
    "    \n",
    "    def check_health(self) -> bool:\n",
    "        \"\"\"Check if the client is working properly.\"\"\"\n",
    "        try:\n",
    "            test_response = self.chat(\n",
    "                [{\"role\": \"user\", \"content\": \"Say 'OK'\"}],\n",
    "                max_tokens=5\n",
    "            )\n",
    "            return \"OK\" in test_response and \"Error\" not in test_response\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "# Initialize the shared client\n",
    "print(\"Initializing Foundry Client...\")\n",
    "foundry_client = FoundryClient()\n",
    "\n",
    "# Health check\n",
    "if foundry_client.check_health():\n",
    "    print(\"тЬЕ Client health check passed!\")\n",
    "else:\n",
    "    print(\"тЭМ Client health check failed. Please ensure Foundry Local is running with a model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9e6e2b",
   "metadata": {},
   "source": [
    "## рд╡рд┐рд╢реЗрд╖ рдПрдЬрдВрдЯ рд╡рд░реНрдЧ\n",
    "\n",
    "рдкреНрд░рддреНрдпреЗрдХ рдПрдЬрдВрдЯ рд╡рд┐рд╢рд┐рд╖реНрдЯ рд╕рдВрдЬреНрдЮрд╛рдирд╛рддреНрдордХ рдХрд╛рд░реНрдпрд╛рдВрд╕рд╛рдареА рдЕрдиреБрдХреВрд▓рд┐рдд рдЖрд╣реЗ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2ce141",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalAgent:\n",
    "    \"\"\"Agent specialized in retrieving relevant information from knowledge sources.\"\"\"\n",
    "    \n",
    "    SYSTEM = \"\"\"You are a specialized retrieval agent. Your job is to extract and retrieve \n",
    "    the most relevant information from knowledge sources based on a given query. Focus on key facts, \n",
    "    data points, and contextual information that would be useful for decision-making.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: FoundryClient):\n",
    "        self.client = client\n",
    "    \n",
    "    def run(self, query: str) -> str:\n",
    "        \"\"\"Retrieve relevant information based on the query.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.SYSTEM},\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"\"\"Query: {query}\n",
    "\n",
    "Retrieve the most relevant key facts, data points, and contextual information that would \n",
    "help answer this query or support decision-making around it. Provide specific, actionable \n",
    "information rather than general statements.\"\"\"\n",
    "            }\n",
    "        ]\n",
    "        return self.client.chat(messages)\n",
    "\n",
    "\n",
    "class ReasoningAgent:\n",
    "    \"\"\"Agent specialized in step-by-step analysis and reasoning.\"\"\"\n",
    "    \n",
    "    SYSTEM = \"\"\"You are a specialized reasoning agent. Your job is to analyze inputs \n",
    "    step-by-step and produce structured, logical conclusions. Break down complex problems \n",
    "    into manageable parts and provide clear reasoning for your conclusions.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: FoundryClient):\n",
    "        self.client = client\n",
    "    \n",
    "    def run(self, context: str, question: str) -> str:\n",
    "        \"\"\"Analyze context and question to produce structured conclusions.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.SYSTEM},\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"\"\"Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Analyze this step-by-step and provide a structured, logical conclusion with clear reasoning. \n",
    "Break down the problem, consider different angles, and provide a well-reasoned decision or recommendation.\"\"\"\n",
    "            }\n",
    "        ]\n",
    "        return self.client.chat(messages, max_tokens=400)\n",
    "\n",
    "\n",
    "class ExecutionAgent:\n",
    "    \"\"\"Agent specialized in creating actionable execution plans.\"\"\"\n",
    "    \n",
    "    SYSTEM = \"\"\"You are a specialized execution agent. Your job is to transform decisions \n",
    "    and conclusions into concrete, actionable steps. Always format your response as valid JSON \n",
    "    with an array of action items. Each action should be specific, measurable, and achievable.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: FoundryClient):\n",
    "        self.client = client\n",
    "    \n",
    "    def run(self, decision: str) -> str:\n",
    "        \"\"\"Transform decision into actionable steps in JSON format.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.SYSTEM},\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"\"\"Decision/Conclusion:\n",
    "{decision}\n",
    "\n",
    "Create 3-5 specific, actionable steps to implement this decision. Format as JSON with this structure:\n",
    "{{\n",
    "  \"actions\": [\n",
    "    {{\n",
    "      \"step\": 1,\n",
    "      \"description\": \"Specific action description\",\n",
    "      \"priority\": \"high/medium/low\",\n",
    "      \"timeline\": \"timeframe for completion\",\n",
    "      \"resources\": [\"required resources or people\"]\n",
    "    }}\n",
    "  ]\n",
    "}}\"\"\"\n",
    "            }\n",
    "        ]\n",
    "        return self.client.chat(messages, max_tokens=400, temperature=0.3)\n",
    "\n",
    "print(\"тЬЕ Agent classes defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb6288d",
   "metadata": {},
   "source": [
    "## рдорд▓реНрдЯреА-рдПрдЬрдВрдЯ рд╕рдордиреНрд╡рдпрдХ\n",
    "\n",
    "рд╕рдордиреНрд╡рдпрдХ рд╕рд░реНрд╡ рдПрдЬрдВрдЯреНрд╕рдирд╛ рдПрдХрддреНрд░рд┐рдд рдХрд░реВрди рдЬрдЯрд┐рд▓ рдХрд╛рд░реНрдпреЗ рд╣рд╛рддрд╛рд│рддреЛ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e27d7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coordinator:\n",
    "    \"\"\"Multi-agent coordinator that orchestrates specialist agents to handle complex tasks.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: FoundryClient):\n",
    "        \"\"\"Initialize the coordinator with specialist agents.\"\"\"\n",
    "        self.client = client\n",
    "        self.retrieval = RetrievalAgent(client)\n",
    "        self.reasoning = ReasoningAgent(client)\n",
    "        self.execution = ExecutionAgent(client)\n",
    "    \n",
    "    def handle(self, user_goal: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Orchestrate multiple agents to handle a complex user goal.\n",
    "        \n",
    "        Args:\n",
    "            user_goal: The user's high-level goal or request\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing the goal, context, decision, and actions\n",
    "        \"\"\"\n",
    "        print(f\"ЁЯОп **Coordinator:** Processing goal: {user_goal}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Step 1: Retrieve relevant context\n",
    "        print(\"ЁЯУЪ **Step 1:** Retrieving context...\")\n",
    "        context = self.retrieval.run(user_goal)\n",
    "        print(f\"   тЬЕ Context retrieved ({len(context)} chars)\")\n",
    "        print(f\"   ЁЯУД Preview: {context[:150]}...\\n\")\n",
    "        \n",
    "        # Step 2: Analyze and reason about the context\n",
    "        print(\"ЁЯза **Step 2:** Analyzing and reasoning...\")\n",
    "        decision = self.reasoning.run(context, user_goal)\n",
    "        print(f\"   тЬЕ Analysis completed ({len(decision)} chars)\")\n",
    "        print(f\"   ЁЯТб Preview: {decision[:150]}...\\n\")\n",
    "        \n",
    "        # Step 3: Create actionable execution plan\n",
    "        print(\"тЪб **Step 3:** Creating execution plan...\")\n",
    "        actions = self.execution.run(decision)\n",
    "        print(f\"   тЬЕ Execution plan created ({len(actions)} chars)\")\n",
    "        \n",
    "        # Try to parse actions as JSON for preview\n",
    "        try:\n",
    "            actions_json = json.loads(actions)\n",
    "            action_count = len(actions_json.get('actions', []))\n",
    "            print(f\"   ЁЯУЛ Actions planned: {action_count}\\n\")\n",
    "        except:\n",
    "            print(f\"   ЁЯУЛ Actions: {actions[:100]}...\\n\")\n",
    "        \n",
    "        end_time = time.time()\n",
    "        processing_time = end_time - start_time\n",
    "        \n",
    "        result = {\n",
    "            \"goal\": user_goal,\n",
    "            \"context\": context,\n",
    "            \"decision\": decision,\n",
    "            \"actions\": actions,\n",
    "            \"agent_flow\": [\"retrieval\", \"reasoning\", \"execution\"],\n",
    "            \"processing_time\": processing_time,\n",
    "            \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        \n",
    "        print(f\"тЬЕ **Coordination Complete** (тП▒я╕П {processing_time:.2f}s)\")\n",
    "        return result\n",
    "    \n",
    "    def handle_with_feedback(self, user_goal: str, feedback_rounds: int = 1) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Handle a goal with multiple feedback rounds for refinement.\n",
    "        \n",
    "        Args:\n",
    "            user_goal: The user's high-level goal or request\n",
    "            feedback_rounds: Number of feedback rounds to perform\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing the refined result\n",
    "        \"\"\"\n",
    "        result = self.handle(user_goal)\n",
    "        \n",
    "        for round_num in range(feedback_rounds):\n",
    "            print(f\"\\nЁЯФД **Feedback Round {round_num + 1}:**\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            # Use reasoning agent to refine the execution plan\n",
    "            refinement_prompt = f\"\"\"\n",
    "            Original Goal: {user_goal}\n",
    "            Current Decision: {result['decision']}\n",
    "            Current Actions: {result['actions']}\n",
    "            \n",
    "            Review the above and suggest improvements or refinements to make the execution plan more effective.\n",
    "            Consider potential challenges, resource optimization, and success metrics.\n",
    "            \"\"\"\n",
    "            \n",
    "            refined_decision = self.reasoning.run(result['context'], refinement_prompt)\n",
    "            refined_actions = self.execution.run(refined_decision)\n",
    "            \n",
    "            result['decision'] = refined_decision\n",
    "            result['actions'] = refined_actions\n",
    "            result['refinement_rounds'] = round_num + 1\n",
    "            \n",
    "            print(f\"   тЬЕ Round {round_num + 1} refinement completed\")\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Initialize coordinator\n",
    "coordinator = Coordinator(foundry_client)\n",
    "print(\"тЬЕ Multi-agent coordinator initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97499608",
   "metadata": {},
   "source": [
    "## рдЙрджрд╛рд╣рд░рдг 1: рд╡реНрдпрд╡рд╕рд╛рдп рдирд┐рдпреЛрдЬрди\n",
    "\n",
    "рд╡реНрдпрд╡рд╕рд╛рдп рдирд┐рдпреЛрдЬрдирд╛рдЪреНрдпрд╛ рдЙрджреНрджрд┐рд╖реНрдЯрд╛рд╕рд╣ рд╕рдордиреНрд╡рдпрдХрд╛рдЪреА рдЪрд╛рдЪрдгреА рдХрд░реВрдпрд╛:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87106196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business planning example\n",
    "business_goal = \"Create a plan to onboard 5 new customers this month\"\n",
    "\n",
    "print(f\"ЁЯЪА **Business Planning Example**\")\n",
    "print(f\"ЁЯУЛ Goal: {business_goal}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "business_result = coordinator.handle(business_goal)\n",
    "\n",
    "print(\"\\nЁЯУК **Final Result Summary:**\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ЁЯОп **Goal:** {business_result['goal']}\")\n",
    "print(f\"тП▒я╕П **Processing Time:** {business_result['processing_time']:.2f} seconds\")\n",
    "print(f\"ЁЯХТ **Timestamp:** {business_result['timestamp']}\")\n",
    "\n",
    "print(f\"\\nЁЯУЪ **Context (Retrieval Agent):**\")\n",
    "print(business_result['context'])\n",
    "\n",
    "print(f\"\\nЁЯза **Decision (Reasoning Agent):**\")\n",
    "print(business_result['decision'])\n",
    "\n",
    "print(f\"\\nтЪб **Actions (Execution Agent):**\")\n",
    "print(business_result['actions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1159c3",
   "metadata": {},
   "source": [
    "## рдЙрджрд╛рд╣рд░рдг 2: рд░рдгрдиреАрддреА рд╡рд┐рдХрд╛рд╕\n",
    "\n",
    "рдЕрдзрд┐рдХ рдЬрдЯрд┐рд▓ рд░рдгрдиреАрддреА рд╡рд┐рдХрд╛рд╕рд╛рдЪреНрдпрд╛ рдЙрджреНрджрд┐рд╖реНрдЯрд╛рд╕рд╛рдареА рдЪрд╛рдЪрдгреА рдХрд░рд╛:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7532b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy development example\n",
    "strategy_goal = \"Develop a strategy to improve team productivity by 20% while maintaining work-life balance\"\n",
    "\n",
    "print(f\"ЁЯОп **Strategy Development Example**\")\n",
    "print(f\"ЁЯУЛ Goal: {strategy_goal}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "strategy_result = coordinator.handle(strategy_goal)\n",
    "\n",
    "print(\"\\nЁЯУК **Structured Action Plan:**\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Try to parse and display actions in a structured format\n",
    "try:\n",
    "    actions_data = json.loads(strategy_result['actions'])\n",
    "    if 'actions' in actions_data:\n",
    "        for i, action in enumerate(actions_data['actions'], 1):\n",
    "            print(f\"\\nЁЯУМ **Action {i}:**\")\n",
    "            print(f\"   ЁЯУЭ Description: {action.get('description', 'N/A')}\")\n",
    "            print(f\"   ЁЯФе Priority: {action.get('priority', 'N/A')}\")\n",
    "            print(f\"   тП░ Timeline: {action.get('timeline', 'N/A')}\")\n",
    "            print(f\"   ЁЯЫая╕П Resources: {', '.join(action.get('resources', ['N/A']))}\")\n",
    "    else:\n",
    "        print(strategy_result['actions'])\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Raw actions output:\")\n",
    "    print(strategy_result['actions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d46b319",
   "metadata": {},
   "source": [
    "## рдЙрджрд╛рд╣рд░рдг рей: рдЕрднрд┐рдкреНрд░рд╛рдп рдпрдВрддреНрд░рдгрд╛ рд╕реБрдзрд╛рд░рдгрд╛\n",
    "\n",
    "рдкреБрдирд░рд╛рд╡реГрддреНрддреА рд╕реБрдзрд╛рд░рдгреНрдпрд╛рд╕рд╛рдареА рдЕрднрд┐рдкреНрд░рд╛рдп рдпрдВрддреНрд░рдгреЗрдЪреЗ рдкреНрд░рджрд░реНрд╢рди рдХрд░рд╛:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5fb98ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   тЬЕ Round 2 refinement completed\n",
      "\n",
      "ЁЯПЖ **Final Refined Result:**\n",
      "==================================================\n",
      "ЁЯОп **Goal:** Design a customer feedback collection system for a software product\n",
      "ЁЯФД **Refinement Rounds:** 2\n",
      "тП▒я╕П **Total Processing Time:** 559.18 seconds\n",
      "\n",
      "ЁЯза **Final Decision:**\n",
      "The execution plan for designing a customer feedback collection system for a software product is comprehensive, but there are areas where it could be refined for better effectiveness. Here are some suggestions:\n",
      "\n",
      "1. **Review of Existing Feedback Mechanisms**: This step is crucial as it sets the direction for the feedback collection system. However, it could be more effective if it also includes a review of existing feedback mechanisms and their shortcomings. This will help in understanding what can be improved.\n",
      "\n",
      "2. **Survey or Focus Group for Feedback Channels**: While the plan includes a variety of feedback channels, it could be beneficial to conduct a survey or a small focus group with a sample of the target audience to understand their preferred feedback channels. This will ensure that the chosen channels are indeed the most effective for the target audience.\n",
      "\n",
      "3. **User Testing of Feedback Form**: The plan is clear, but it could be improved by including a step for user testing of the feedback form. This will help in identifying any issues with the form's design or content before it is launched.\n",
      "\n",
      "4. **Regular Audits for Data Collection and Storage**: The plan includes compliance with data protection regulations, which is crucial. However, it could be more effective if it also includes a step for regular audits of the data collection and storage system to ensure ongoing compliance.\n",
      "\n",
      "5. **Training on Data Visualization Tools**: The plan is comprehensive, but it could be improved by including a step for training the team on how to use the data visualization tools. This will ensure that the team can effectively interpret and present the data.\n",
      "\n",
      "6. **Tracking System for Implementation of Changes**: The plan includes a feedback loop, which is excellent. However, it could be more effective if it also includes a step for tracking the implementation of changes based on feedback. This will help in understanding the impact of the feedback on the product.\n",
      "\n",
      "Potential challenges could be ensuring the feedback form is user-friendly and concise, maintaining data protection compliance, and effectively tracking the implementation of changes based\n",
      "\n",
      "тЪб **Final Action Plan:**\n",
      "```json\n",
      "{\n",
      "  \"actions\": [\n",
      "    {\n",
      "      \"step\": 1,\n",
      "      \"description\": \"Conduct a comprehensive review of existing feedback mechanisms, including their effectiveness and shortcomings.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"1 week\",\n",
      "      \"resources\": [\"Product management team\", \"Customer service team\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 2,\n",
      "      \"description\": \"Organize a survey or focus group with a sample of the target audience to determine preferred feedback channels.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"2 weeks\",\n",
      "      \"resources\": [\"Survey platform\", \"Focus group participants\", \"Marketing team\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 3,\n",
      "      \"description\": \"Implement user testing for the feedback form with a diverse group of users to identify design and content issues.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"3 weeks\",\n",
      "      \"resources\": [\"UX/UI designers\", \"Test participants\", \"Feedback collection tools\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 4,\n",
      "      \"description\": \"Schedule and conduct regular audits of the data collection and storage system to ensure compliance with data protection regulations.\",\n",
      "      \"priority\": \"medium\",\n",
      "      \"timeline\": \"Quarterly\",\n",
      "      \"resources\": [\"Data protection officer\", \"IT security team\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 5,\n",
      "      \"description\": \"Develop and deliver training sessions for the team on how to use data visualization tools effectively.\",\n",
      "      \"priority\": \"medium\",\n",
      "      \"timeline\": \"1 month\",\n",
      "      \"resources\": [\"Data visualization software\", \"Training materials\", \"Internal trainers or external experts\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 6,\n",
      "      \"description\": \"Create a tracking system to monitor the implementation of changes based on customer feedback and measure the impact.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"2 months\",\n",
      "      \"resources\": [\"Project management software\", \"Product development team\n"
     ]
    }
   ],
   "source": [
    "# Feedback loop example\n",
    "feedback_goal = \"Design a customer feedback collection system for a software product\"\n",
    "\n",
    "print(f\"ЁЯФД **Feedback Loop Refinement Example**\")\n",
    "print(f\"ЁЯУЛ Goal: {feedback_goal}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Process with 2 feedback rounds\n",
    "feedback_result = coordinator.handle_with_feedback(feedback_goal, feedback_rounds=2)\n",
    "\n",
    "print(\"\\nЁЯПЖ **Final Refined Result:**\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ЁЯОп **Goal:** {feedback_result['goal']}\")\n",
    "print(f\"ЁЯФД **Refinement Rounds:** {feedback_result.get('refinement_rounds', 0)}\")\n",
    "print(f\"тП▒я╕П **Total Processing Time:** {feedback_result['processing_time']:.2f} seconds\")\n",
    "\n",
    "print(f\"\\nЁЯза **Final Decision:**\")\n",
    "print(feedback_result['decision'])\n",
    "\n",
    "print(f\"\\nтЪб **Final Action Plan:**\")\n",
    "print(feedback_result['actions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed152f7",
   "metadata": {},
   "source": [
    "## рдЗрдВрдЯрд░рдПрдХреНрдЯрд┐рд╡ рдПрдЬрдВрдЯ рдЪрд╛рдЪрдгреА\n",
    "\n",
    "рд╡реЗрдЧрд╡реЗрдЧрд│реНрдпрд╛ рдПрдЬрдВрдЯреНрд╕ рд╕реНрд╡рддрдВрддреНрд░рдкрдгреЗ рдЪрд╛рдЪрдгреА рдХрд░рд╛ рдЬреЗрдгреЗрдХрд░реВрди рддреНрдпрд╛рдВрдЪреНрдпрд╛ рд╡рд┐рд╢реЗрд╖ рдХреНрд╖рдорддрд╛рдВрдЪрд╛ рд╕рдордЬ рд╣реЛрдИрд▓:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "948c737c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ЁЯзк **Individual Agent Testing**\n",
      "тЭУ Query: How can we reduce customer support response time?\n",
      "============================================================\n",
      "\n",
      "ЁЯФН **Retrieval Agent:**\n",
      "1. Implementing AI-powered chatbots: AI-powered chatbots can handle common customer queries, reducing the workload on human agents and speeding up response times. According to a study by Accenture, AI chatbots can handle 80% of customer interactions, freeing up human agents to handle more complex issues.\n",
      "\n",
      "2. Streamlining the support process: Simplifying the support process and removing unnecessary steps can help reduce response times. This could involve consolidating support channels, creating self-help resources, or automating certain processes.\n",
      "\n",
      "3. Increasing support staff: Hiring additional support staff or training existing staff to handle more complex issues can help reduce response times. A study by Forrester found that increasing the number of support agents by just 10% can reduce average response time by 20%.\n",
      "\n",
      "4. Prioritizing urgent issues: Prioritizing urgent issues and ensuring they are addressed first can help reduce response times. This could involve implementing a ticketing system that prioritizes issues based on their urgency.\n",
      "\n",
      "5. Providing training and resources: Providing support staff with the necessary training and resources can help them handle issues more efficiently, reducing response times. This could involve providing training on specific products or services, or creating a knowledge base that support staff can reference.\n",
      "\n",
      "6. Analyzing and optimizing response times: Regularly analyzing response times and identifying areas for improvement can help reduce response times. This could involve tracking response times for different types of issues, or analyzing the support process to identify bottlenecks.\n",
      "\n",
      "7. Outs\n",
      "\n",
      "ЁЯза **Reasoning Agent:**\n",
      "Step 1: Implementing AI-powered chatbots\n",
      "- Reasoning: AI chatbots can handle common customer queries, freeing up human agents to handle more complex issues. This can significantly reduce response times for routine inquiries.\n",
      "- Conclusion: Implement AI-powered chatbots to handle common customer queries.\n",
      "\n",
      "Step 2: Streamlining the support process\n",
      "- Reasoning: Simplifying the support process and removing unnecessary steps can help reduce response times. This could involve consolidating support channels, creating self-help resources, or automating certain processes.\n",
      "- Conclusion: Streamline the support process by consolidating support channels, creating self-help resources, and automating processes where possible.\n",
      "\n",
      "Step 3: Increasing support staff\n",
      "- Reasoning: Hiring additional support staff or training existing staff to handle more complex issues can help reduce response times. A study by Forrester found that increasing the number of support agents by just 10% can reduce average response time by 20%.\n",
      "- Conclusion: Consider hiring additional support staff or training existing staff to handle more complex issues to reduce response times.\n",
      "\n",
      "Step 4: Prioritizing urgent issues\n",
      "- Reasoning: Prioritizing urgent issues and ensuring they are addressed first can help reduce response times. This could involve implementing a ticketing system that prioritizes issues based on their urgency.\n",
      "- Conclusion: Implement a ticketing system that prioritizes issues based on their urgency to reduce response times.\n",
      "\n",
      "Step 5: Providing training and resources\n",
      "- Reasoning: Providing support staff with the necessary training and resources can help them handle issues more efficiently, reducing response times. This could involve providing training on specific products or services, or creating a knowledge base that support staff can reference.\n",
      "- Conclusion: Provide necessary training and resources to support staff to handle issues more efficiently and reduce response times.\n",
      "\n",
      "Step 6: Analyzing and optimizing response times\n",
      "- Reasoning: Regularly analyzing response times and identifying areas for improvement can help reduce response times. This could involve tracking response times for different types\n",
      "\n",
      "тЪб **Execution Agent:**\n",
      "```json\n",
      "{\n",
      "  \"actions\": [\n",
      "    {\n",
      "      \"step\": 1,\n",
      "      \"description\": \"Select and integrate an AI-powered chatbot platform that fits the company's needs and customer service goals.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"1 month\",\n",
      "      \"resources\": [\"IT team\", \"Customer service manager\", \"AI chatbot platform vendor\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 2,\n",
      "      \"description\": \"Review and streamline the current support process, eliminating redundant steps and consolidating support channels.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"2 weeks\",\n",
      "      \"resources\": [\"Customer service manager\", \"Support team\", \"Process improvement tools\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 3,\n",
      "      \"description\": \"Develop a training program for support staff to enhance their skills in handling complex issues and using the new AI chatbot system.\",\n",
      "      \"priority\": \"medium\",\n",
      "      \"timeline\": \"1 month\",\n",
      "      \"resources\": [\"Training department\", \"Support staff\", \"AI chatbot system documentation\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 4,\n",
      "      \"description\": \"Implement a ticketing system that prioritizes issues based on urgency, ensuring that urgent issues are addressed first.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"3 weeks\",\n",
      "      \"resources\": [\"IT team\", \"Customer service manager\", \"Ticketing system software\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 5,\n",
      "      \"description\": \"Create a comprehensive knowledge base and provide resources to support staff to enable them to resolve issues more efficiently.\",\n",
      "      \"priority\": \"medium\",\n",
      "      \"timeline\": \"2 weeks\",\n",
      "      \"resources\": [\"Content creators\", \"Support staff\", \"Knowledge base platform\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 6,\n",
      "      \"description\": \"Set up a system for regularly analyzing response times and identifying areas for improvement.\",\n",
      "      \"priority\": \"medium\",\n",
      "      \"timeline\": \"Ongoing\",\n",
      "      \"\n"
     ]
    }
   ],
   "source": [
    "def test_individual_agents(query: str):\n",
    "    \"\"\"Test each agent individually with the same query.\"\"\"\n",
    "    print(f\"ЁЯзк **Individual Agent Testing**\")\n",
    "    print(f\"тЭУ Query: {query}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Test Retrieval Agent\n",
    "    print(\"\\nЁЯФН **Retrieval Agent:**\")\n",
    "    retrieval_result = coordinator.retrieval.run(query)\n",
    "    print(retrieval_result)\n",
    "    \n",
    "    # Test Reasoning Agent (using retrieval result as context)\n",
    "    print(\"\\nЁЯза **Reasoning Agent:**\")\n",
    "    reasoning_result = coordinator.reasoning.run(retrieval_result, query)\n",
    "    print(reasoning_result)\n",
    "    \n",
    "    # Test Execution Agent (using reasoning result)\n",
    "    print(\"\\nтЪб **Execution Agent:**\")\n",
    "    execution_result = coordinator.execution.run(reasoning_result)\n",
    "    print(execution_result)\n",
    "\n",
    "# Test with a simple query\n",
    "test_query = \"How can we reduce customer support response time?\"\n",
    "test_individual_agents(test_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccb3f9c",
   "metadata": {},
   "source": [
    "## рдХрд╕реНрдЯрдо рд▓рдХреНрд╖реНрдп рдЪрд╛рдЪрдгреА\n",
    "\n",
    "рддреБрдордЪреНрдпрд╛ рд╕реНрд╡рддрдГрдЪреНрдпрд╛ рдЙрджреНрджрд┐рд╖реНрдЯрд╛рдВрдЪреА рдЪрд╛рдЪрдгреА рдХрд░рдгреНрдпрд╛рд╕рд╛рдареА рдпрд╛ рд╕реЗрд▓рдЪрд╛ рд╡рд╛рдкрд░ рдХрд░рд╛:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea65a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ЁЯОи **Custom Goal Testing**\n",
      "ЁЯУЛ Your Goal: Create a training program for new AI engineers joining our company\n",
      "============================================================\n",
      "ЁЯОп **Coordinator:** Processing goal: Create a training program for new AI engineers joining our company\n",
      "============================================================\n",
      "ЁЯУЪ **Step 1:** Retrieving context...\n",
      "   тЬЕ Context retrieved (1408 chars)\n",
      "   ЁЯУД Preview: 1. **Program Structure**: A modular program with a mix of theoretical and practical sessions. Modules could include:\n",
      "   - Introduction to AI and Machi...\n",
      "\n",
      "ЁЯза **Step 2:** Analyzing and reasoning...\n"
     ]
    }
   ],
   "source": [
    "# Custom goal testing - modify the goal below\n",
    "custom_goal = \"Create a training program for new AI engineers joining our company\"\n",
    "\n",
    "print(f\"ЁЯОи **Custom Goal Testing**\")\n",
    "print(f\"ЁЯУЛ Your Goal: {custom_goal}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Choose processing method\n",
    "use_feedback = True  # Set to True for feedback rounds, False for basic processing\n",
    "feedback_rounds = 1  # Number of feedback rounds if use_feedback is True\n",
    "\n",
    "if use_feedback:\n",
    "    custom_result = coordinator.handle_with_feedback(custom_goal, feedback_rounds=feedback_rounds)\n",
    "    print(f\"\\nтЬи **Result with {feedback_rounds} feedback round(s):**\")\n",
    "else:\n",
    "    custom_result = coordinator.handle(custom_goal)\n",
    "    print(f\"\\nтЬи **Basic Result:**\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"ЁЯУЪ **Context:** {custom_result['context'][:200]}...\")\n",
    "print(f\"\\nЁЯза **Decision:** {custom_result['decision'][:200]}...\")\n",
    "print(f\"\\nтЪб **Actions:** {custom_result['actions'][:200]}...\")\n",
    "\n",
    "# Show processing stats\n",
    "print(f\"\\nЁЯУК **Statistics:**\")\n",
    "print(f\"   тП▒я╕П Processing Time: {custom_result['processing_time']:.2f}s\")\n",
    "print(f\"   ЁЯФД Refinement Rounds: {custom_result.get('refinement_rounds', 0)}\")\n",
    "print(f\"   ЁЯУП Total Content Length: {len(custom_result['context']) + len(custom_result['decision']) + len(custom_result['actions'])} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a6d1c2",
   "metadata": {},
   "source": [
    "## рдХрд╛рд░реНрдпрдХреНрд╖рдорддрд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг\n",
    "\n",
    "рдорд▓реНрдЯреА-рдПрдЬрдВрдЯ рдкреНрд░рдгрд╛рд▓реАрдЪреА рдХрд╛рд░реНрдпрдХреНрд╖рдорддрд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдХрд░рд╛:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef5496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_benchmark(goals: List[str], iterations: int = 2) -> Dict[str, Any]:\n",
    "    \"\"\"Benchmark the coordinator performance with multiple goals.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(f\"ЁЯУК **Performance Benchmark**\")\n",
    "    print(f\"ЁЯОп Goals: {len(goals)}\")\n",
    "    print(f\"ЁЯФД Iterations per goal: {iterations}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i, goal in enumerate(goals, 1):\n",
    "        print(f\"\\nЁЯОп **Goal {i}:** {goal[:50]}...\")\n",
    "        goal_times = []\n",
    "        \n",
    "        for j in range(iterations):\n",
    "            print(f\"   ЁЯФД Iteration {j+1}/{iterations}...\", end=\" \")\n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                result = coordinator.handle(goal)\n",
    "                end_time = time.time()\n",
    "                processing_time = end_time - start_time\n",
    "                goal_times.append(processing_time)\n",
    "                print(f\"тЬЕ {processing_time:.2f}s\")\n",
    "            except Exception as e:\n",
    "                print(f\"тЭМ Error: {e}\")\n",
    "        \n",
    "        if goal_times:\n",
    "            avg_time = sum(goal_times) / len(goal_times)\n",
    "            results.append({\n",
    "                \"goal\": goal,\n",
    "                \"avg_time\": avg_time,\n",
    "                \"min_time\": min(goal_times),\n",
    "                \"max_time\": max(goal_times),\n",
    "                \"times\": goal_times\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Benchmark with different types of goals\n",
    "benchmark_goals = [\n",
    "    \"Create a social media marketing strategy\",\n",
    "    \"Improve employee onboarding process\",\n",
    "    \"Design a mobile app user interface\",\n",
    "    \"Plan a product launch campaign\"\n",
    "]\n",
    "\n",
    "benchmark_results = performance_benchmark(benchmark_goals, iterations=2)\n",
    "\n",
    "# Display benchmark summary\n",
    "print(\"\\nЁЯПЖ **Benchmark Summary:**\")\n",
    "print(\"=\" * 50)\n",
    "for result in benchmark_results:\n",
    "    print(f\"ЁЯУЭ {result['goal'][:40]}...\")\n",
    "    print(f\"   тП▒я╕П Average: {result['avg_time']:.2f}s\")\n",
    "    print(f\"   тЪб Fastest: {result['min_time']:.2f}s\")\n",
    "    print(f\"   ЁЯРМ Slowest: {result['max_time']:.2f}s\")\n",
    "    print()\n",
    "\n",
    "if benchmark_results:\n",
    "    overall_avg = sum(r['avg_time'] for r in benchmark_results) / len(benchmark_results)\n",
    "    print(f\"ЁЯУК **Overall Average Processing Time:** {overall_avg:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49cca35",
   "metadata": {},
   "source": [
    "## рдЙрддреНрдкрд╛рджрди рд╡рд┐рддрд░рдг рд╕рд╣рд╛рдпреНрдпрдХ\n",
    "\n",
    "рдЙрддреНрдкрд╛рджрдирд╛рд╕рд╛рдареА рд╕рдордиреНрд╡рдпрдХ рдХрд╕рд╛ рдЧреБрдВрдбрд╛рд│рд╛рдпрдЪрд╛ рдпрд╛рдЪреЗ рдЙрджрд╛рд╣рд░рдг:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299fed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionCoordinator:\n",
    "    \"\"\"Production-ready wrapper for the multi-agent coordinator.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_alias: str = \"phi-4-mini\"):\n",
    "        self.client = FoundryClient(model_alias)\n",
    "        self.coordinator = Coordinator(self.client)\n",
    "        self.request_count = 0\n",
    "        self.total_processing_time = 0\n",
    "    \n",
    "    def process_goal(self, goal: str, include_feedback: bool = False, feedback_rounds: int = 1) -> Dict[str, Any]:\n",
    "        \"\"\"Process a goal with production monitoring.\"\"\"\n",
    "        self.request_count += 1\n",
    "        \n",
    "        try:\n",
    "            if include_feedback:\n",
    "                result = self.coordinator.handle_with_feedback(goal, feedback_rounds=feedback_rounds)\n",
    "            else:\n",
    "                result = self.coordinator.handle(goal)\n",
    "            \n",
    "            self.total_processing_time += result['processing_time']\n",
    "            \n",
    "            # Add production metadata\n",
    "            result['request_id'] = self.request_count\n",
    "            result['status'] = 'success'\n",
    "            result['model'] = self.client.model_name\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'request_id': self.request_count,\n",
    "                'status': 'error',\n",
    "                'error': str(e),\n",
    "                'goal': goal,\n",
    "                'timestamp': time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get production statistics.\"\"\"\n",
    "        avg_processing_time = self.total_processing_time / max(1, self.request_count)\n",
    "        \n",
    "        return {\n",
    "            'total_requests': self.request_count,\n",
    "            'total_processing_time': self.total_processing_time,\n",
    "            'average_processing_time': avg_processing_time,\n",
    "            'model': self.client.model_name,\n",
    "            'client_healthy': self.client.check_health()\n",
    "        }\n",
    "\n",
    "# Example production usage\n",
    "prod_coordinator = ProductionCoordinator()\n",
    "\n",
    "# Process a goal\n",
    "prod_goal = \"Create a quarterly business review presentation\"\n",
    "prod_result = prod_coordinator.process_goal(prod_goal)\n",
    "\n",
    "print(f\"ЁЯПн **Production Processing Result:**\")\n",
    "print(f\"ЁЯУК Status: {prod_result['status']}\")\n",
    "print(f\"ЁЯФв Request ID: {prod_result['request_id']}\")\n",
    "print(f\"тП▒я╕П Processing Time: {prod_result.get('processing_time', 'N/A')}s\")\n",
    "print(f\"ЁЯдЦ Model: {prod_result.get('model', 'N/A')}\")\n",
    "\n",
    "# Show production stats\n",
    "stats = prod_coordinator.get_stats()\n",
    "print(f\"\\nЁЯУК **Production Statistics:**\")\n",
    "print(f\"   ЁЯУИ Total Requests: {stats['total_requests']}\")\n",
    "print(f\"   тП▒я╕П Average Processing Time: {stats['average_processing_time']:.2f}s\")\n",
    "print(f\"   ЁЯТЪ Client Health: {'тЬЕ Healthy' if stats['client_healthy'] else 'тЭМ Unhealthy'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d3849",
   "metadata": {},
   "source": [
    "## рд╕рд╛рд░рд╛рдВрд╢ рдЖрдгрд┐ рд╕рд░реНрд╡реЛрддреНрддрдо рдкрджреНрдзрддреА\n",
    "\n",
    "рдпрд╛ рдиреЛрдЯрдмреБрдХрдордзреНрдпреЗ рдПрдХ рдкреНрд░рдЧрдд рдорд▓реНрдЯреА-рдПрдЬрдВрдЯ рдСрд░реНрдХреЗрд╕реНрдЯреНрд░реЗрд╢рди рдкреНрд░рдгрд╛рд▓реА рдкреНрд░рджрд░реНрд╢рд┐рдд рдХреЗрд▓реА рдЖрд╣реЗ:\n",
    "\n",
    "### тЬЕ рдкреНрд░рдореБрдЦ рд╡реИрд╢рд┐рд╖реНрдЯреНрдпреЗ рдкреНрд░рджрд░реНрд╢рд┐рдд рдХреЗрд▓реА\n",
    "\n",
    "1. **ЁЯПЧя╕П рдПрдЬрдВрдЯ рд╡рд┐рд╢реЗрд╖рдЬреНрдЮрддрд╛**: рдкреНрд░рддреНрдпреЗрдХ рдПрдЬрдВрдЯ рд╡рд┐рд╢рд┐рд╖реНрдЯ рд╕рдВрдЬреНрдЮрд╛рдирд╛рддреНрдордХ рдХрд╛рд░реНрдпрд╛рдВрд╕рд╛рдареА рдЕрдиреБрдХреВрд▓рд┐рдд\n",
    "2. **ЁЯОп рдХрд╛рд░реНрдпрдкреНрд░рд╡рд╛рд╣ рдСрд░реНрдХреЗрд╕реНрдЯреНрд░реЗрд╢рди**: рд╕рдордиреНрд╡рдпрд┐рдд рдорд▓реНрдЯреА-рд╕реНрдЯреЗрдк рдкреНрд░рдХреНрд░рд┐рдпрд╛\n",
    "3. **ЁЯУЛ рд╕рдВрд░рдЪрд┐рдд рдЖрдЙрдЯрдкреБрдЯ**: JSON-рд╕реНрд╡рд░реВрдкрд┐рдд рдХреГрддреА рдпреЛрдЬрдирд╛\n",
    "4. **ЁЯФД рдлреАрдбрдмреЕрдХ рд▓реВрдкреНрд╕**: рдорд▓реНрдЯреА-рд░рд╛рдЙрдВрдб рд╕реБрдзрд╛рд░рдгрд╛ рдХреНрд╖рдорддрд╛\n",
    "5. **тЪб рдХрд╛рд░реНрдпрдХреНрд╖рдорддрд╛ рдирд┐рд░реАрдХреНрд╖рдг**: рдкреНрд░рдХреНрд░рд┐рдпрд╛ рд╡реЗрд│ рдЖрдгрд┐ рдЖрд░реЛрдЧреНрдп рддрдкрд╛рд╕рдгреА\n",
    "6. **ЁЯПн рдЙрддреНрдкрд╛рджрдирд╛рд╕рд╛рдареА рддрдпрд╛рд░**: рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЭ-рдЧреНрд░реЗрдб рдореЙрдирд┐рдЯрд░рд┐рдВрдЧрд╕рд╣ рд░реЕрдкрд░\n",
    "\n",
    "### ЁЯза рдПрдЬрдВрдЯ рднреВрдорд┐рдХрд╛рдВрдЪрд╛ рд╕рд╛рд░рд╛рдВрд╢\n",
    "\n",
    "| рдПрдЬрдВрдЯ | рдЙрджреНрджреЗрд╢ | рдЗрдирдкреБрдЯ | рдЖрдЙрдЯрдкреБрдЯ |\n",
    "|-------|---------|-------|--------|\n",
    "| **ЁЯФН рд░рд┐рдЯреНрд░реАрд╡реНрд╣рд▓** | рд╕рдВрдмрдВрдзрд┐рдд рдорд╛рд╣рд┐рддреА рдХрд╛рдврдгреЗ | рд╡рд╛рдкрд░рдХрд░реНрддрд╛ рдХреНрд╡реЗрд░реА | рд╕рдВрджрд░реНрднрд╛рддреНрдордХ рддрдереНрдпреЗ рдЖрдгрд┐ рдбреЗрдЯрд╛ |\n",
    "| **ЁЯза рд░рд┐рдЭрдирд┐рдВрдЧ** | рддрд░реНрдХрд╕рдВрдЧрдд рд╡рд┐рд╢реНрд▓реЗрд╖рдг | рд╕рдВрджрд░реНрдн + рдкреНрд░рд╢реНрди | рд╕рдВрд░рдЪрд┐рдд рдирд┐рд░реНрдгрдп |\n",
    "| **тЪб рдПрдХреНрдЭрд┐рдХреНрдпреБрд╢рди** | рдХреГрддреА рдпреЛрдЬрдирд╛ рддрдпрд╛рд░ рдХрд░рдгреЗ | рдирд┐рд░реНрдгрдп | JSON рдХреГрддреА рдЪрд░рдг |\n",
    "| **ЁЯОп рдХреЛрдСрд░реНрдбрд┐рдиреЗрдЯрд░** | рдХрд╛рд░реНрдпрдкреНрд░рд╡рд╛рд╣рд╛рдЪреЗ рд╕рдордиреНрд╡рдп рдХрд░рдгреЗ | рд╡рд╛рдкрд░рдХрд░реНрддрд╛ рдЙрджреНрджрд┐рд╖реНрдЯ | рдкреВрд░реНрдг рдирд┐рдХрд╛рд▓ |\n",
    "\n",
    "### ЁЯЪА рдЙрдкрдпреЛрдЧ рдкреНрд░рдХрд░рдгреЗ\n",
    "\n",
    "- **рд╡реНрдпрд╡рд╕рд╛рдп рдирд┐рдпреЛрдЬрди**: рдзреЛрд░рдгрд╛рддреНрдордХ рдирд┐рдпреЛрдЬрди рдЖрдгрд┐ рдЕрдВрдорд▓рдмрдЬрд╛рд╡рдгреА\n",
    "- **рдкреНрд░рдХрд▓реНрдк рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди**: рдХрд╛рд░реНрдпрд╛рдВрдЪреЗ рд╡рд┐рдШрдЯрди рдЖрдгрд┐ рд╡реЗрд│рд╛рдкрддреНрд░рдХ рддрдпрд╛рд░ рдХрд░рдгреЗ  \n",
    "- **рд╕рдВрд╢реЛрдзрди**: рдорд╛рд╣рд┐рддреА рдЧреЛрд│рд╛ рдХрд░рдгреЗ рдЖрдгрд┐ рд╡рд┐рд╢реНрд▓реЗрд╖рдг\n",
    "- **рдирд┐рд░реНрдгрдп рд╕рдорд░реНрдерди**: рдЬрдЯрд┐рд▓ рдирд┐рд░реНрдгрдп рдкреНрд░рдХреНрд░рд┐рдпреЗрдЪреЗ рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди\n",
    "- **рдХрд╛рд░реНрдпрдкреНрд░рд╡рд╛рд╣ рд╕реНрд╡рдпрдВрдЪрд▓рди**: рдорд▓реНрдЯреА-рд╕реНрдЯреЗрдк рд╡реНрдпрд╡рд╕рд╛рдп рдкреНрд░рдХреНрд░рд┐рдпрд╛\n",
    "\n",
    "### ЁЯТб рд╕рд░реНрд╡реЛрддреНрддрдо рдкрджреНрдзрддреА\n",
    "\n",
    "1. **ЁЯОп рдПрдХрд▓ рдЬрдмрд╛рдмрджрд╛рд░реА**: рдкреНрд░рддреНрдпреЗрдХ рдПрдЬрдВрдЯрдЪреЗ рдПрдХ рд╕реНрдкрд╖реНрдЯ рдЙрджреНрджрд┐рд╖реНрдЯ рдЕрд╕рд╛рд╡реЗ\n",
    "2. **ЁЯФЧ рд╕реНрдкрд╖реНрдЯ рдЗрдВрдЯрд░рдлреЗрд╕**: рдорд╛рдирдХреАрдХреГрдд рдЗрдирдкреБрдЯ/рдЖрдЙрдЯрдкреБрдЯ рд╕реНрд╡рд░реВрдк\n",
    "3. **ЁЯЫбя╕П рддреНрд░реБрдЯреА рд╣рд╛рддрд╛рд│рдгреА**: рдЕрдкрдпрд╢рд╛рдВрд╡рд░ рд╕реМрдореНрдп рдкреНрд░рддрд┐рд╕рд╛рдж\n",
    "4. **ЁЯУК рдирд┐рд░реАрдХреНрд╖рдг**: рд╡реНрдпрд╛рдкрдХ рд▓реЙрдЧрд┐рдВрдЧ рдЖрдгрд┐ рдХрд╛рд░реНрдпрдХреНрд╖рдорддрд╛ рдЯреНрд░реЕрдХрд┐рдВрдЧ\n",
    "5. **ЁЯФД рдлреАрдбрдмреЕрдХ рд▓реВрдкреНрд╕**: рдкреБрдирд░рд╛рд╡реГрддреНрддреА рд╕реБрдзрд╛рд░рдгрд╛ рдпрдВрддреНрд░рдгрд╛\n",
    "6. **тЪЦя╕П рд▓реЛрдб рдмреЕрд▓рдиреНрд╕рд┐рдВрдЧ**: рд╕реНрд╡рддрдВрддреНрд░ рдХрд╛рд░реНрдпрд╛рдВрд╕рд╛рдареА рд╕рдорд╛рдВрддрд░ рдкреНрд░рдХреНрд░рд┐рдпрд╛ рд╡рд┐рдЪрд╛рд░рд╛рдд рдШреНрдпрд╛\n",
    "\n",
    "### ЁЯФо рдкреБрдвреАрд▓ рдкрд╛рд╡рд▓реЗ\n",
    "\n",
    "- **ЁЯФз рдлрдВрдХреНрд╢рди рдХреЙрд▓рд┐рдВрдЧ**: рдмрд╛рд╣реНрдп API рдЖрдгрд┐ рд╕рд╛рдзрдирд╛рдВрд╕рд╣ рд╕рдорд╛рдХрд▓рд┐рдд рдХрд░рд╛\n",
    "- **ЁЯза рдореЗрдорд░реА рдкреНрд░рдгрд╛рд▓реА**: рдПрдЬрдВрдЯрд╕рд╛рдареА рд╕реНрдерд╛рдпреА рдореЗрдорд░реА рдЬреЛрдбрд╛\n",
    "- **ЁЯОн рд╡рд┐рд╢реЗрд╖рдЬреНрдЮ рдореЙрдбреЗрд▓реНрд╕**: рд╡реЗрдЧрд╡реЗрдЧрд│реНрдпрд╛ рдПрдЬрдВрдЯрд╕рд╛рдареА рд╡реЗрдЧрд╡реЗрдЧрд│реЗ рдореЙрдбреЗрд▓ рд╡рд╛рдкрд░рд╛\n",
    "- **ЁЯСе рдорд╛рдирд╡-рдЗрди-рдж-рд▓реВрдк**: рдорд╛рдирд╡реА рдкреБрдирд░рд╛рд╡рд▓реЛрдХрди рдЖрдгрд┐ рдордВрдЬреБрд░реА рдЪрд░рдг рдЬреЛрдбрд╛\n",
    "- **ЁЯУК рдкреНрд░рдЧрдд рд╡рд┐рд╢реНрд▓реЗрд╖рдг**: рд╡реНрдпрд╛рдкрдХ рдирд┐рд░реАрдХреНрд╖рдг рдЖрдгрд┐ рдореЗрдЯреНрд░рд┐рдХреНрд╕\n",
    "\n",
    "рд╣реА рдорд▓реНрдЯреА-рдПрдЬрдВрдЯ рдкреНрд░рдгрд╛рд▓реА рджрд░реНрд╢рд╡рддреЗ рдХреА рдХрд╕реЗ рд╡рд┐рд╢реЗрд╖ рдПрдЬрдВрдЯреНрд╕рдЪреНрдпрд╛ рддрд╛рдХрджреАрдВрдЪрд╛ рдПрдХрддреНрд░рд┐рдд рд╡рд╛рдкрд░ рдХрд░реВрди рдкреНрд░рдЧрдд AI рдХрд╛рд░реНрдпрдкреНрд░рд╡рд╛рд╣ рддрдпрд╛рд░ рдХрд░рддрд╛ рдпреЗрддреЛ, рддрд╕реЗрдЪ Microsoft Foundry Local рдЪреНрдпрд╛ рд╕реНрдерд╛рдирд┐рдХ рдЗрдирдлрд░рдиреНрд╕рдореБрд│реЗ рдЧреЛрдкрдиреАрдпрддрд╛ рдЖрдгрд┐ рдХрд╛рд░реНрдпрдХреНрд╖рдорддрд╛ рдлрд╛рдпрджреЗ рдЯрд┐рдХрд╡реВрди рдареЗрд╡рддрд╛ рдпреЗрддрд╛рдд.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "coopTranslator": {
   "original_hash": "e769e8958054219004d420c9a7b3584b",
   "translation_date": "2025-09-24T15:39:35+00:00",
   "source_file": "Module08/samples/05/multi_agent_orchestration.ipynb",
   "language_code": "mr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}