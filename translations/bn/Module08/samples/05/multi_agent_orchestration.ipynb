{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b861ae53",
   "metadata": {},
   "source": [
    "# ржиржорзБржирж╛ рзжрзл: ржорж╛рж▓рзНржЯрж┐-ржПржЬрзЗржирзНржЯ ржЕрж░рзНржХрзЗрж╕рзНржЯрзНрж░рзЗрж╢ржи рж╕рж┐рж╕рзНржЯрзЗржо\n",
    "\n",
    "ржПржЗ ржирзЛржЯржмрзБржХржЯрж┐ Microsoft Foundry Local ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ AI-ржЪрж╛рж▓рж┐ржд ржПржЬрзЗржирзНржЯ рж╕рж┐рж╕рзНржЯрзЗржо рждрзИрж░рж┐рж░ ржЬржирзНржп ржПржХржЯрж┐ ржЙржирзНржиржд ржорж╛рж▓рзНржЯрж┐-ржПржЬрзЗржирзНржЯ ржЖрж░рзНржХрж┐ржЯрзЗржХржЪрж╛рж░ ржкрзНрж░ржжрж░рзНрж╢ржи ржХрж░рзЗред\n",
    "\n",
    "## рж╕ржВржХрзНрж╖рж┐ржкрзНржд ржмрж┐ржмрж░ржг\n",
    "\n",
    "ржПржЗ ржиржорзБржирж╛ржЯрж┐ ржПржХржЯрж┐ **ржорж╛рж▓рзНржЯрж┐-ржПржЬрзЗржирзНржЯ ржХрзЛржЕрж░рзНржбрж┐ржирзЗржЯрж░** ржмрж╛рж╕рзНрждржмрж╛ржпрж╝ржи ржХрж░рзЗ ржпрж╛ ржмрж┐рж╢рзЗрж╖рж╛ржпрж╝рж┐ржд ржПржЬрзЗржирзНржЯржжрзЗрж░ ржкрж░рж┐ржЪрж╛рж▓ржирж╛ ржХрж░рзЗ:\n",
    "\n",
    "- ЁЯФН **рж░рж┐ржЯрзНрж░рж┐ржнрж╛рж▓ ржПржЬрзЗржирзНржЯ**: ржЬрзНржЮрж╛ржи ржЙрзОрж╕ ржерзЗржХрзЗ ржкрзНрж░рж╛рж╕ржЩрзНржЧрж┐ржХ рждржерзНржп рж╕ржВржЧрзНрж░рж╣ ржХрж░рзЗ\n",
    "- ЁЯза **рж░рж┐ржЬржирж┐ржВ ржПржЬрзЗржирзНржЯ**: ржзрж╛ржкрзЗ ржзрж╛ржкрзЗ ржмрж┐рж╢рзНрж▓рзЗрж╖ржг ржПржмржВ ржпрзМржХрзНрждрж┐ржХ ржЪрж┐ржирзНрждрж╛ржнрж╛ржмржирж╛ ржХрж░рзЗ\n",
    "- тЪб **ржПржХрзНрж╕рж┐ржХрж┐ржЙрж╢ржи ржПржЬрзЗржирзНржЯ**: ржХрж╛ржарж╛ржорзЛржЧржд ржлрж░ржорзНржпрж╛ржЯрзЗ ржХрж╛рж░рзНржпржХрж░рзА ржкрж░рж┐ржХрж▓рзНржкржирж╛ рждрзИрж░рж┐ ржХрж░рзЗ\n",
    "- ЁЯОп **ржХрзЛржЕрж░рзНржбрж┐ржирзЗржЯрж░**: ржкрзБрж░рзЛ ржПржЬрзЗржирзНржЯ ржУржпрж╝рж╛рж░рзНржХржлрзНрж▓рзЛ ржкрж░рж┐ржЪрж╛рж▓ржирж╛ ржХрж░рзЗ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e840290d",
   "metadata": {},
   "source": [
    "## ржЖрж░рзНржХрж┐ржЯрзЗржХржЪрж╛рж░ ржкрзНржпрж╛ржЯрж╛рж░рзНржи\n",
    "\n",
    "```\n",
    "User Goal тЖТ Coordinator\n",
    "     тЖУ\n",
    "1. Retrieval Agent тЖТ Context\n",
    "     тЖУ\n",
    "2. Reasoning Agent тЖТ Decision\n",
    "     тЖУ\n",
    "3. Execution Agent тЖТ Actions\n",
    "     тЖУ\n",
    "Structured Result\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240650a",
   "metadata": {},
   "source": [
    "## ржкрзНрж░ржпрж╝рзЛржЬржирзАржпрж╝рждрж╛ ржПржмржВ рж╕рзЗржЯржЖржк\n",
    "\n",
    "ржирж┐рж╢рзНржЪрж┐ржд ржХрж░рзБржи ржпрзЗ ржЖржкржирж╛рж░ Foundry Local ржПржХржЯрж┐ рж╕ржХрзНрж╖ржо ржоржбрзЗрж▓рзЗрж░ рж╕рж╛ржерзЗ ржЪрж╛рж▓рзБ рж░ржпрж╝рзЗржЫрзЗ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc33b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install openai foundry-local-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c6fe9e",
   "metadata": {},
   "source": [
    "## рж▓рж╛ржЗржмрзНрж░рзЗрж░рж┐ ржЖржоржжрж╛ржирж┐ ржПржмржВ ржХржиржлрж┐ржЧрж╛рж░рзЗрж╢ржи\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5160a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, Any, List\n",
    "from openai import OpenAI\n",
    "\n",
    "try:\n",
    "    from foundry_local import FoundryLocalManager\n",
    "    FOUNDRY_SDK_AVAILABLE = True\n",
    "    print(\"тЬЕ Foundry Local SDK is available\")\n",
    "except ImportError:\n",
    "    FOUNDRY_SDK_AVAILABLE = False\n",
    "    print(\"тЪая╕П Foundry Local SDK not available, will use manual configuration\")\n",
    "\n",
    "# Configuration\n",
    "MODEL_ALIAS = \"phi-4-mini\"  # Change to your preferred model\n",
    "BASE_URL = \"http://localhost:8000\"\n",
    "API_KEY = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba6a90f",
   "metadata": {},
   "source": [
    "## ржлрж╛ржЙржирзНржбрзНрж░рж┐ ржХрзНрж▓рж╛ржпрж╝рзЗржирзНржЯ рж╕рзЗржЯржЖржк\n",
    "\n",
    "рж╕ржорж╕рзНржд ржПржЬрзЗржирзНржЯрзЗрж░ ржЬржирзНржп ржПржХржЯрж┐ рж╢рзЗржпрж╝рж╛рж░рзНржб ржХрзНрж▓рж╛ржпрж╝рзЗржирзНржЯ рждрзИрж░рж┐ ржХрж░рзБржи:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc80453",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoundryClient:\n",
    "    \"\"\"Shared client for all specialist agents.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_alias: str = MODEL_ALIAS):\n",
    "        self.client = None\n",
    "        self.model_name = None\n",
    "        self.model_alias = model_alias\n",
    "        self._initialize_client()\n",
    "    \n",
    "    def _initialize_client(self):\n",
    "        \"\"\"Initialize OpenAI client with Foundry Local or fallback configuration.\"\"\"\n",
    "        if FOUNDRY_SDK_AVAILABLE:\n",
    "            try:\n",
    "                print(f\"ЁЯФД Initializing Foundry Local with model: {self.model_alias}...\")\n",
    "                manager = FoundryLocalManager(self.model_alias)\n",
    "                model_info = manager.get_model_info(self.model_alias)\n",
    "                \n",
    "                self.client = OpenAI(\n",
    "                    base_url=manager.endpoint,\n",
    "                    api_key=manager.api_key\n",
    "                )\n",
    "                self.model_name = model_info.id\n",
    "                print(f\"тЬЕ Foundry Local SDK initialized with model: {self.model_name}\")\n",
    "                return\n",
    "            except Exception as e:\n",
    "                print(f\"тЪая╕П Could not use Foundry SDK ({e}), falling back to manual configuration\")\n",
    "        \n",
    "        # Fallback to manual configuration\n",
    "        self.client = OpenAI(\n",
    "            base_url=f\"{BASE_URL}/v1\",\n",
    "            api_key=API_KEY\n",
    "        )\n",
    "        self.model_name = self.model_alias\n",
    "        print(f\"ЁЯФз Manual configuration initialized with model: {self.model_name}\")\n",
    "    \n",
    "    def chat(self, messages: List[Dict[str, str]], max_tokens: int = 300, temperature: float = 0.4) -> str:\n",
    "        \"\"\"Send chat completion request to the model.\"\"\"\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model_name,\n",
    "                messages=messages,\n",
    "                max_tokens=max_tokens,\n",
    "                temperature=temperature\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {str(e)}\"\n",
    "    \n",
    "    def check_health(self) -> bool:\n",
    "        \"\"\"Check if the client is working properly.\"\"\"\n",
    "        try:\n",
    "            test_response = self.chat(\n",
    "                [{\"role\": \"user\", \"content\": \"Say 'OK'\"}],\n",
    "                max_tokens=5\n",
    "            )\n",
    "            return \"OK\" in test_response and \"Error\" not in test_response\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "# Initialize the shared client\n",
    "print(\"Initializing Foundry Client...\")\n",
    "foundry_client = FoundryClient()\n",
    "\n",
    "# Health check\n",
    "if foundry_client.check_health():\n",
    "    print(\"тЬЕ Client health check passed!\")\n",
    "else:\n",
    "    print(\"тЭМ Client health check failed. Please ensure Foundry Local is running with a model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9e6e2b",
   "metadata": {},
   "source": [
    "## ржмрж┐рж╢рзЗрж╖рж╛ржпрж╝рж┐ржд ржПржЬрзЗржирзНржЯ рж╢рзНрж░рзЗржгрж┐\n",
    "\n",
    "ржкрзНрж░рждрж┐ржЯрж┐ ржПржЬрзЗржирзНржЯ ржирж┐рж░рзНржжрж┐рж╖рзНржЯ ржорж╛ржирж╕рж┐ржХ ржХрж╛ржЬрзЗрж░ ржЬржирзНржп ржЕржкрзНржЯрж┐ржорж╛ржЗржЬ ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2ce141",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalAgent:\n",
    "    \"\"\"Agent specialized in retrieving relevant information from knowledge sources.\"\"\"\n",
    "    \n",
    "    SYSTEM = \"\"\"You are a specialized retrieval agent. Your job is to extract and retrieve \n",
    "    the most relevant information from knowledge sources based on a given query. Focus on key facts, \n",
    "    data points, and contextual information that would be useful for decision-making.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: FoundryClient):\n",
    "        self.client = client\n",
    "    \n",
    "    def run(self, query: str) -> str:\n",
    "        \"\"\"Retrieve relevant information based on the query.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.SYSTEM},\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"\"\"Query: {query}\n",
    "\n",
    "Retrieve the most relevant key facts, data points, and contextual information that would \n",
    "help answer this query or support decision-making around it. Provide specific, actionable \n",
    "information rather than general statements.\"\"\"\n",
    "            }\n",
    "        ]\n",
    "        return self.client.chat(messages)\n",
    "\n",
    "\n",
    "class ReasoningAgent:\n",
    "    \"\"\"Agent specialized in step-by-step analysis and reasoning.\"\"\"\n",
    "    \n",
    "    SYSTEM = \"\"\"You are a specialized reasoning agent. Your job is to analyze inputs \n",
    "    step-by-step and produce structured, logical conclusions. Break down complex problems \n",
    "    into manageable parts and provide clear reasoning for your conclusions.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: FoundryClient):\n",
    "        self.client = client\n",
    "    \n",
    "    def run(self, context: str, question: str) -> str:\n",
    "        \"\"\"Analyze context and question to produce structured conclusions.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.SYSTEM},\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"\"\"Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Analyze this step-by-step and provide a structured, logical conclusion with clear reasoning. \n",
    "Break down the problem, consider different angles, and provide a well-reasoned decision or recommendation.\"\"\"\n",
    "            }\n",
    "        ]\n",
    "        return self.client.chat(messages, max_tokens=400)\n",
    "\n",
    "\n",
    "class ExecutionAgent:\n",
    "    \"\"\"Agent specialized in creating actionable execution plans.\"\"\"\n",
    "    \n",
    "    SYSTEM = \"\"\"You are a specialized execution agent. Your job is to transform decisions \n",
    "    and conclusions into concrete, actionable steps. Always format your response as valid JSON \n",
    "    with an array of action items. Each action should be specific, measurable, and achievable.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: FoundryClient):\n",
    "        self.client = client\n",
    "    \n",
    "    def run(self, decision: str) -> str:\n",
    "        \"\"\"Transform decision into actionable steps in JSON format.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.SYSTEM},\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"\"\"Decision/Conclusion:\n",
    "{decision}\n",
    "\n",
    "Create 3-5 specific, actionable steps to implement this decision. Format as JSON with this structure:\n",
    "{{\n",
    "  \"actions\": [\n",
    "    {{\n",
    "      \"step\": 1,\n",
    "      \"description\": \"Specific action description\",\n",
    "      \"priority\": \"high/medium/low\",\n",
    "      \"timeline\": \"timeframe for completion\",\n",
    "      \"resources\": [\"required resources or people\"]\n",
    "    }}\n",
    "  ]\n",
    "}}\"\"\"\n",
    "            }\n",
    "        ]\n",
    "        return self.client.chat(messages, max_tokens=400, temperature=0.3)\n",
    "\n",
    "print(\"тЬЕ Agent classes defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb6288d",
   "metadata": {},
   "source": [
    "## ржорж╛рж▓рзНржЯрж┐-ржПржЬрзЗржирзНржЯ ржХрзЛржЕрж░рзНржбрж┐ржирзЗржЯрж░\n",
    "\n",
    "ржХрзЛржЕрж░рзНржбрж┐ржирзЗржЯрж░ рж╕ржорж╕рзНржд ржПржЬрзЗржирзНржЯржжрзЗрж░ рж╕ржоржирзНржмржпрж╝ ржХрж░рзЗ ржЬржЯрж┐рж▓ ржХрж╛ржЬржЧрзБрж▓рж┐ ржкрж░рж┐ржЪрж╛рж▓ржирж╛ ржХрж░рзЗ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e27d7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coordinator:\n",
    "    \"\"\"Multi-agent coordinator that orchestrates specialist agents to handle complex tasks.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: FoundryClient):\n",
    "        \"\"\"Initialize the coordinator with specialist agents.\"\"\"\n",
    "        self.client = client\n",
    "        self.retrieval = RetrievalAgent(client)\n",
    "        self.reasoning = ReasoningAgent(client)\n",
    "        self.execution = ExecutionAgent(client)\n",
    "    \n",
    "    def handle(self, user_goal: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Orchestrate multiple agents to handle a complex user goal.\n",
    "        \n",
    "        Args:\n",
    "            user_goal: The user's high-level goal or request\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing the goal, context, decision, and actions\n",
    "        \"\"\"\n",
    "        print(f\"ЁЯОп **Coordinator:** Processing goal: {user_goal}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Step 1: Retrieve relevant context\n",
    "        print(\"ЁЯУЪ **Step 1:** Retrieving context...\")\n",
    "        context = self.retrieval.run(user_goal)\n",
    "        print(f\"   тЬЕ Context retrieved ({len(context)} chars)\")\n",
    "        print(f\"   ЁЯУД Preview: {context[:150]}...\\n\")\n",
    "        \n",
    "        # Step 2: Analyze and reason about the context\n",
    "        print(\"ЁЯза **Step 2:** Analyzing and reasoning...\")\n",
    "        decision = self.reasoning.run(context, user_goal)\n",
    "        print(f\"   тЬЕ Analysis completed ({len(decision)} chars)\")\n",
    "        print(f\"   ЁЯТб Preview: {decision[:150]}...\\n\")\n",
    "        \n",
    "        # Step 3: Create actionable execution plan\n",
    "        print(\"тЪб **Step 3:** Creating execution plan...\")\n",
    "        actions = self.execution.run(decision)\n",
    "        print(f\"   тЬЕ Execution plan created ({len(actions)} chars)\")\n",
    "        \n",
    "        # Try to parse actions as JSON for preview\n",
    "        try:\n",
    "            actions_json = json.loads(actions)\n",
    "            action_count = len(actions_json.get('actions', []))\n",
    "            print(f\"   ЁЯУЛ Actions planned: {action_count}\\n\")\n",
    "        except:\n",
    "            print(f\"   ЁЯУЛ Actions: {actions[:100]}...\\n\")\n",
    "        \n",
    "        end_time = time.time()\n",
    "        processing_time = end_time - start_time\n",
    "        \n",
    "        result = {\n",
    "            \"goal\": user_goal,\n",
    "            \"context\": context,\n",
    "            \"decision\": decision,\n",
    "            \"actions\": actions,\n",
    "            \"agent_flow\": [\"retrieval\", \"reasoning\", \"execution\"],\n",
    "            \"processing_time\": processing_time,\n",
    "            \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        \n",
    "        print(f\"тЬЕ **Coordination Complete** (тП▒я╕П {processing_time:.2f}s)\")\n",
    "        return result\n",
    "    \n",
    "    def handle_with_feedback(self, user_goal: str, feedback_rounds: int = 1) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Handle a goal with multiple feedback rounds for refinement.\n",
    "        \n",
    "        Args:\n",
    "            user_goal: The user's high-level goal or request\n",
    "            feedback_rounds: Number of feedback rounds to perform\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing the refined result\n",
    "        \"\"\"\n",
    "        result = self.handle(user_goal)\n",
    "        \n",
    "        for round_num in range(feedback_rounds):\n",
    "            print(f\"\\nЁЯФД **Feedback Round {round_num + 1}:**\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            # Use reasoning agent to refine the execution plan\n",
    "            refinement_prompt = f\"\"\"\n",
    "            Original Goal: {user_goal}\n",
    "            Current Decision: {result['decision']}\n",
    "            Current Actions: {result['actions']}\n",
    "            \n",
    "            Review the above and suggest improvements or refinements to make the execution plan more effective.\n",
    "            Consider potential challenges, resource optimization, and success metrics.\n",
    "            \"\"\"\n",
    "            \n",
    "            refined_decision = self.reasoning.run(result['context'], refinement_prompt)\n",
    "            refined_actions = self.execution.run(refined_decision)\n",
    "            \n",
    "            result['decision'] = refined_decision\n",
    "            result['actions'] = refined_actions\n",
    "            result['refinement_rounds'] = round_num + 1\n",
    "            \n",
    "            print(f\"   тЬЕ Round {round_num + 1} refinement completed\")\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Initialize coordinator\n",
    "coordinator = Coordinator(foundry_client)\n",
    "print(\"тЬЕ Multi-agent coordinator initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97499608",
   "metadata": {},
   "source": [
    "## ржЙржжрж╛рж╣рж░ржг рзз: ржмрзНржпржмрж╕рж╛ржпрж╝ ржкрж░рж┐ржХрж▓рзНржкржирж╛\n",
    "\n",
    "ржЪрж▓рзБржи рж╕ржоржирзНржмржпрж╝ржХрж╛рж░рзАржХрзЗ ржПржХржЯрж┐ ржмрзНржпржмрж╕рж╛ржпрж╝ ржкрж░рж┐ржХрж▓рзНржкржирж╛рж░ рж▓ржХрзНрж╖рзНржп ржжрж┐ржпрж╝рзЗ ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рж┐:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87106196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business planning example\n",
    "business_goal = \"Create a plan to onboard 5 new customers this month\"\n",
    "\n",
    "print(f\"ЁЯЪА **Business Planning Example**\")\n",
    "print(f\"ЁЯУЛ Goal: {business_goal}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "business_result = coordinator.handle(business_goal)\n",
    "\n",
    "print(\"\\nЁЯУК **Final Result Summary:**\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ЁЯОп **Goal:** {business_result['goal']}\")\n",
    "print(f\"тП▒я╕П **Processing Time:** {business_result['processing_time']:.2f} seconds\")\n",
    "print(f\"ЁЯХТ **Timestamp:** {business_result['timestamp']}\")\n",
    "\n",
    "print(f\"\\nЁЯУЪ **Context (Retrieval Agent):**\")\n",
    "print(business_result['context'])\n",
    "\n",
    "print(f\"\\nЁЯза **Decision (Reasoning Agent):**\")\n",
    "print(business_result['decision'])\n",
    "\n",
    "print(f\"\\nтЪб **Actions (Execution Agent):**\")\n",
    "print(business_result['actions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1159c3",
   "metadata": {},
   "source": [
    "## ржЙржжрж╛рж╣рж░ржг рзи: ржХрзМрж╢рж▓ ржЙржирзНржирзЯржи\n",
    "\n",
    "ржЖрж░ржУ ржЬржЯрж┐рж▓ ржХрзМрж╢рж▓ ржЙржирзНржирзЯржи рж▓ржХрзНрж╖рзНржп ржирж┐рзЯрзЗ ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7532b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy development example\n",
    "strategy_goal = \"Develop a strategy to improve team productivity by 20% while maintaining work-life balance\"\n",
    "\n",
    "print(f\"ЁЯОп **Strategy Development Example**\")\n",
    "print(f\"ЁЯУЛ Goal: {strategy_goal}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "strategy_result = coordinator.handle(strategy_goal)\n",
    "\n",
    "print(\"\\nЁЯУК **Structured Action Plan:**\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Try to parse and display actions in a structured format\n",
    "try:\n",
    "    actions_data = json.loads(strategy_result['actions'])\n",
    "    if 'actions' in actions_data:\n",
    "        for i, action in enumerate(actions_data['actions'], 1):\n",
    "            print(f\"\\nЁЯУМ **Action {i}:**\")\n",
    "            print(f\"   ЁЯУЭ Description: {action.get('description', 'N/A')}\")\n",
    "            print(f\"   ЁЯФе Priority: {action.get('priority', 'N/A')}\")\n",
    "            print(f\"   тП░ Timeline: {action.get('timeline', 'N/A')}\")\n",
    "            print(f\"   ЁЯЫая╕П Resources: {', '.join(action.get('resources', ['N/A']))}\")\n",
    "    else:\n",
    "        print(strategy_result['actions'])\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Raw actions output:\")\n",
    "    print(strategy_result['actions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d46b319",
   "metadata": {},
   "source": [
    "## ржЙржжрж╛рж╣рж░ржг рзй: ржкрзНрж░рждрж┐ржХрзНрж░рж┐ржпрж╝рж╛ рж▓рзБржк ржкрж░рж┐ржорж╛рж░рзНржЬржи\n",
    "\n",
    "ржкрзБржирж░рж╛ржмрзГрждрзНрждрж┐ ржЙржирзНржирждрж┐рж░ ржЬржирзНржп ржкрзНрж░рждрж┐ржХрзНрж░рж┐ржпрж╝рж╛ ржкрзНрж░ржХрзНрж░рж┐ржпрж╝рж╛ ржкрзНрж░ржжрж░рзНрж╢ржи ржХрж░рзБржи:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5fb98ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   тЬЕ Round 2 refinement completed\n",
      "\n",
      "ЁЯПЖ **Final Refined Result:**\n",
      "==================================================\n",
      "ЁЯОп **Goal:** Design a customer feedback collection system for a software product\n",
      "ЁЯФД **Refinement Rounds:** 2\n",
      "тП▒я╕П **Total Processing Time:** 559.18 seconds\n",
      "\n",
      "ЁЯза **Final Decision:**\n",
      "The execution plan for designing a customer feedback collection system for a software product is comprehensive, but there are areas where it could be refined for better effectiveness. Here are some suggestions:\n",
      "\n",
      "1. **Review of Existing Feedback Mechanisms**: This step is crucial as it sets the direction for the feedback collection system. However, it could be more effective if it also includes a review of existing feedback mechanisms and their shortcomings. This will help in understanding what can be improved.\n",
      "\n",
      "2. **Survey or Focus Group for Feedback Channels**: While the plan includes a variety of feedback channels, it could be beneficial to conduct a survey or a small focus group with a sample of the target audience to understand their preferred feedback channels. This will ensure that the chosen channels are indeed the most effective for the target audience.\n",
      "\n",
      "3. **User Testing of Feedback Form**: The plan is clear, but it could be improved by including a step for user testing of the feedback form. This will help in identifying any issues with the form's design or content before it is launched.\n",
      "\n",
      "4. **Regular Audits for Data Collection and Storage**: The plan includes compliance with data protection regulations, which is crucial. However, it could be more effective if it also includes a step for regular audits of the data collection and storage system to ensure ongoing compliance.\n",
      "\n",
      "5. **Training on Data Visualization Tools**: The plan is comprehensive, but it could be improved by including a step for training the team on how to use the data visualization tools. This will ensure that the team can effectively interpret and present the data.\n",
      "\n",
      "6. **Tracking System for Implementation of Changes**: The plan includes a feedback loop, which is excellent. However, it could be more effective if it also includes a step for tracking the implementation of changes based on feedback. This will help in understanding the impact of the feedback on the product.\n",
      "\n",
      "Potential challenges could be ensuring the feedback form is user-friendly and concise, maintaining data protection compliance, and effectively tracking the implementation of changes based\n",
      "\n",
      "тЪб **Final Action Plan:**\n",
      "```json\n",
      "{\n",
      "  \"actions\": [\n",
      "    {\n",
      "      \"step\": 1,\n",
      "      \"description\": \"Conduct a comprehensive review of existing feedback mechanisms, including their effectiveness and shortcomings.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"1 week\",\n",
      "      \"resources\": [\"Product management team\", \"Customer service team\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 2,\n",
      "      \"description\": \"Organize a survey or focus group with a sample of the target audience to determine preferred feedback channels.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"2 weeks\",\n",
      "      \"resources\": [\"Survey platform\", \"Focus group participants\", \"Marketing team\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 3,\n",
      "      \"description\": \"Implement user testing for the feedback form with a diverse group of users to identify design and content issues.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"3 weeks\",\n",
      "      \"resources\": [\"UX/UI designers\", \"Test participants\", \"Feedback collection tools\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 4,\n",
      "      \"description\": \"Schedule and conduct regular audits of the data collection and storage system to ensure compliance with data protection regulations.\",\n",
      "      \"priority\": \"medium\",\n",
      "      \"timeline\": \"Quarterly\",\n",
      "      \"resources\": [\"Data protection officer\", \"IT security team\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 5,\n",
      "      \"description\": \"Develop and deliver training sessions for the team on how to use data visualization tools effectively.\",\n",
      "      \"priority\": \"medium\",\n",
      "      \"timeline\": \"1 month\",\n",
      "      \"resources\": [\"Data visualization software\", \"Training materials\", \"Internal trainers or external experts\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 6,\n",
      "      \"description\": \"Create a tracking system to monitor the implementation of changes based on customer feedback and measure the impact.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"2 months\",\n",
      "      \"resources\": [\"Project management software\", \"Product development team\n"
     ]
    }
   ],
   "source": [
    "# Feedback loop example\n",
    "feedback_goal = \"Design a customer feedback collection system for a software product\"\n",
    "\n",
    "print(f\"ЁЯФД **Feedback Loop Refinement Example**\")\n",
    "print(f\"ЁЯУЛ Goal: {feedback_goal}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Process with 2 feedback rounds\n",
    "feedback_result = coordinator.handle_with_feedback(feedback_goal, feedback_rounds=2)\n",
    "\n",
    "print(\"\\nЁЯПЖ **Final Refined Result:**\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ЁЯОп **Goal:** {feedback_result['goal']}\")\n",
    "print(f\"ЁЯФД **Refinement Rounds:** {feedback_result.get('refinement_rounds', 0)}\")\n",
    "print(f\"тП▒я╕П **Total Processing Time:** {feedback_result['processing_time']:.2f} seconds\")\n",
    "\n",
    "print(f\"\\nЁЯза **Final Decision:**\")\n",
    "print(feedback_result['decision'])\n",
    "\n",
    "print(f\"\\nтЪб **Final Action Plan:**\")\n",
    "print(feedback_result['actions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed152f7",
   "metadata": {},
   "source": [
    "## ржЗржирзНржЯрж╛рж░ржЕрзНржпрж╛ржХржЯрж┐ржн ржПржЬрзЗржирзНржЯ ржЯрзЗрж╕рзНржЯрж┐ржВ\n",
    "\n",
    "ржкрзНрж░рждрзНржпрзЗржХржЯрж┐ ржПржЬрзЗржирзНржЯ ржЖрж▓рж╛ржжрж╛ржнрж╛ржмрзЗ ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи рждрж╛ржжрзЗрж░ ржмрж┐рж╢рзЗрж╖ ржжржХрзНрж╖рждрж╛ ржмрзЛржЭрж╛рж░ ржЬржирзНржп:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "948c737c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ЁЯзк **Individual Agent Testing**\n",
      "тЭУ Query: How can we reduce customer support response time?\n",
      "============================================================\n",
      "\n",
      "ЁЯФН **Retrieval Agent:**\n",
      "1. Implementing AI-powered chatbots: AI-powered chatbots can handle common customer queries, reducing the workload on human agents and speeding up response times. According to a study by Accenture, AI chatbots can handle 80% of customer interactions, freeing up human agents to handle more complex issues.\n",
      "\n",
      "2. Streamlining the support process: Simplifying the support process and removing unnecessary steps can help reduce response times. This could involve consolidating support channels, creating self-help resources, or automating certain processes.\n",
      "\n",
      "3. Increasing support staff: Hiring additional support staff or training existing staff to handle more complex issues can help reduce response times. A study by Forrester found that increasing the number of support agents by just 10% can reduce average response time by 20%.\n",
      "\n",
      "4. Prioritizing urgent issues: Prioritizing urgent issues and ensuring they are addressed first can help reduce response times. This could involve implementing a ticketing system that prioritizes issues based on their urgency.\n",
      "\n",
      "5. Providing training and resources: Providing support staff with the necessary training and resources can help them handle issues more efficiently, reducing response times. This could involve providing training on specific products or services, or creating a knowledge base that support staff can reference.\n",
      "\n",
      "6. Analyzing and optimizing response times: Regularly analyzing response times and identifying areas for improvement can help reduce response times. This could involve tracking response times for different types of issues, or analyzing the support process to identify bottlenecks.\n",
      "\n",
      "7. Outs\n",
      "\n",
      "ЁЯза **Reasoning Agent:**\n",
      "Step 1: Implementing AI-powered chatbots\n",
      "- Reasoning: AI chatbots can handle common customer queries, freeing up human agents to handle more complex issues. This can significantly reduce response times for routine inquiries.\n",
      "- Conclusion: Implement AI-powered chatbots to handle common customer queries.\n",
      "\n",
      "Step 2: Streamlining the support process\n",
      "- Reasoning: Simplifying the support process and removing unnecessary steps can help reduce response times. This could involve consolidating support channels, creating self-help resources, or automating certain processes.\n",
      "- Conclusion: Streamline the support process by consolidating support channels, creating self-help resources, and automating processes where possible.\n",
      "\n",
      "Step 3: Increasing support staff\n",
      "- Reasoning: Hiring additional support staff or training existing staff to handle more complex issues can help reduce response times. A study by Forrester found that increasing the number of support agents by just 10% can reduce average response time by 20%.\n",
      "- Conclusion: Consider hiring additional support staff or training existing staff to handle more complex issues to reduce response times.\n",
      "\n",
      "Step 4: Prioritizing urgent issues\n",
      "- Reasoning: Prioritizing urgent issues and ensuring they are addressed first can help reduce response times. This could involve implementing a ticketing system that prioritizes issues based on their urgency.\n",
      "- Conclusion: Implement a ticketing system that prioritizes issues based on their urgency to reduce response times.\n",
      "\n",
      "Step 5: Providing training and resources\n",
      "- Reasoning: Providing support staff with the necessary training and resources can help them handle issues more efficiently, reducing response times. This could involve providing training on specific products or services, or creating a knowledge base that support staff can reference.\n",
      "- Conclusion: Provide necessary training and resources to support staff to handle issues more efficiently and reduce response times.\n",
      "\n",
      "Step 6: Analyzing and optimizing response times\n",
      "- Reasoning: Regularly analyzing response times and identifying areas for improvement can help reduce response times. This could involve tracking response times for different types\n",
      "\n",
      "тЪб **Execution Agent:**\n",
      "```json\n",
      "{\n",
      "  \"actions\": [\n",
      "    {\n",
      "      \"step\": 1,\n",
      "      \"description\": \"Select and integrate an AI-powered chatbot platform that fits the company's needs and customer service goals.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"1 month\",\n",
      "      \"resources\": [\"IT team\", \"Customer service manager\", \"AI chatbot platform vendor\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 2,\n",
      "      \"description\": \"Review and streamline the current support process, eliminating redundant steps and consolidating support channels.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"2 weeks\",\n",
      "      \"resources\": [\"Customer service manager\", \"Support team\", \"Process improvement tools\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 3,\n",
      "      \"description\": \"Develop a training program for support staff to enhance their skills in handling complex issues and using the new AI chatbot system.\",\n",
      "      \"priority\": \"medium\",\n",
      "      \"timeline\": \"1 month\",\n",
      "      \"resources\": [\"Training department\", \"Support staff\", \"AI chatbot system documentation\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 4,\n",
      "      \"description\": \"Implement a ticketing system that prioritizes issues based on urgency, ensuring that urgent issues are addressed first.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"3 weeks\",\n",
      "      \"resources\": [\"IT team\", \"Customer service manager\", \"Ticketing system software\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 5,\n",
      "      \"description\": \"Create a comprehensive knowledge base and provide resources to support staff to enable them to resolve issues more efficiently.\",\n",
      "      \"priority\": \"medium\",\n",
      "      \"timeline\": \"2 weeks\",\n",
      "      \"resources\": [\"Content creators\", \"Support staff\", \"Knowledge base platform\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 6,\n",
      "      \"description\": \"Set up a system for regularly analyzing response times and identifying areas for improvement.\",\n",
      "      \"priority\": \"medium\",\n",
      "      \"timeline\": \"Ongoing\",\n",
      "      \"\n"
     ]
    }
   ],
   "source": [
    "def test_individual_agents(query: str):\n",
    "    \"\"\"Test each agent individually with the same query.\"\"\"\n",
    "    print(f\"ЁЯзк **Individual Agent Testing**\")\n",
    "    print(f\"тЭУ Query: {query}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Test Retrieval Agent\n",
    "    print(\"\\nЁЯФН **Retrieval Agent:**\")\n",
    "    retrieval_result = coordinator.retrieval.run(query)\n",
    "    print(retrieval_result)\n",
    "    \n",
    "    # Test Reasoning Agent (using retrieval result as context)\n",
    "    print(\"\\nЁЯза **Reasoning Agent:**\")\n",
    "    reasoning_result = coordinator.reasoning.run(retrieval_result, query)\n",
    "    print(reasoning_result)\n",
    "    \n",
    "    # Test Execution Agent (using reasoning result)\n",
    "    print(\"\\nтЪб **Execution Agent:**\")\n",
    "    execution_result = coordinator.execution.run(reasoning_result)\n",
    "    print(execution_result)\n",
    "\n",
    "# Test with a simple query\n",
    "test_query = \"How can we reduce customer support response time?\"\n",
    "test_individual_agents(test_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccb3f9c",
   "metadata": {},
   "source": [
    "## ржХрж╛рж╕рзНржЯржо рж▓ржХрзНрж╖рзНржп ржкрж░рзАржХрзНрж╖рж╛\n",
    "\n",
    "ржПржЗ рж╕рзЗрж▓ржЯрж┐ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ ржЖржкржирж╛рж░ ржирж┐ржЬрж╕рзНржм рж▓ржХрзНрж╖рзНржп ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea65a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ЁЯОи **Custom Goal Testing**\n",
      "ЁЯУЛ Your Goal: Create a training program for new AI engineers joining our company\n",
      "============================================================\n",
      "ЁЯОп **Coordinator:** Processing goal: Create a training program for new AI engineers joining our company\n",
      "============================================================\n",
      "ЁЯУЪ **Step 1:** Retrieving context...\n",
      "   тЬЕ Context retrieved (1408 chars)\n",
      "   ЁЯУД Preview: 1. **Program Structure**: A modular program with a mix of theoretical and practical sessions. Modules could include:\n",
      "   - Introduction to AI and Machi...\n",
      "\n",
      "ЁЯза **Step 2:** Analyzing and reasoning...\n"
     ]
    }
   ],
   "source": [
    "# Custom goal testing - modify the goal below\n",
    "custom_goal = \"Create a training program for new AI engineers joining our company\"\n",
    "\n",
    "print(f\"ЁЯОи **Custom Goal Testing**\")\n",
    "print(f\"ЁЯУЛ Your Goal: {custom_goal}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Choose processing method\n",
    "use_feedback = True  # Set to True for feedback rounds, False for basic processing\n",
    "feedback_rounds = 1  # Number of feedback rounds if use_feedback is True\n",
    "\n",
    "if use_feedback:\n",
    "    custom_result = coordinator.handle_with_feedback(custom_goal, feedback_rounds=feedback_rounds)\n",
    "    print(f\"\\nтЬи **Result with {feedback_rounds} feedback round(s):**\")\n",
    "else:\n",
    "    custom_result = coordinator.handle(custom_goal)\n",
    "    print(f\"\\nтЬи **Basic Result:**\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"ЁЯУЪ **Context:** {custom_result['context'][:200]}...\")\n",
    "print(f\"\\nЁЯза **Decision:** {custom_result['decision'][:200]}...\")\n",
    "print(f\"\\nтЪб **Actions:** {custom_result['actions'][:200]}...\")\n",
    "\n",
    "# Show processing stats\n",
    "print(f\"\\nЁЯУК **Statistics:**\")\n",
    "print(f\"   тП▒я╕П Processing Time: {custom_result['processing_time']:.2f}s\")\n",
    "print(f\"   ЁЯФД Refinement Rounds: {custom_result.get('refinement_rounds', 0)}\")\n",
    "print(f\"   ЁЯУП Total Content Length: {len(custom_result['context']) + len(custom_result['decision']) + len(custom_result['actions'])} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a6d1c2",
   "metadata": {},
   "source": [
    "## ржХрж░рзНржоржХрзНрж╖ржорждрж╛ ржмрж┐рж╢рзНрж▓рзЗрж╖ржг\n",
    "\n",
    "ржорж╛рж▓рзНржЯрж┐-ржПржЬрзЗржирзНржЯ рж╕рж┐рж╕рзНржЯрзЗржорзЗрж░ ржХрж░рзНржоржХрзНрж╖ржорждрж╛ ржмрж┐рж╢рзНрж▓рзЗрж╖ржг ржХрж░рзБржи:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef5496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_benchmark(goals: List[str], iterations: int = 2) -> Dict[str, Any]:\n",
    "    \"\"\"Benchmark the coordinator performance with multiple goals.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(f\"ЁЯУК **Performance Benchmark**\")\n",
    "    print(f\"ЁЯОп Goals: {len(goals)}\")\n",
    "    print(f\"ЁЯФД Iterations per goal: {iterations}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i, goal in enumerate(goals, 1):\n",
    "        print(f\"\\nЁЯОп **Goal {i}:** {goal[:50]}...\")\n",
    "        goal_times = []\n",
    "        \n",
    "        for j in range(iterations):\n",
    "            print(f\"   ЁЯФД Iteration {j+1}/{iterations}...\", end=\" \")\n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                result = coordinator.handle(goal)\n",
    "                end_time = time.time()\n",
    "                processing_time = end_time - start_time\n",
    "                goal_times.append(processing_time)\n",
    "                print(f\"тЬЕ {processing_time:.2f}s\")\n",
    "            except Exception as e:\n",
    "                print(f\"тЭМ Error: {e}\")\n",
    "        \n",
    "        if goal_times:\n",
    "            avg_time = sum(goal_times) / len(goal_times)\n",
    "            results.append({\n",
    "                \"goal\": goal,\n",
    "                \"avg_time\": avg_time,\n",
    "                \"min_time\": min(goal_times),\n",
    "                \"max_time\": max(goal_times),\n",
    "                \"times\": goal_times\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Benchmark with different types of goals\n",
    "benchmark_goals = [\n",
    "    \"Create a social media marketing strategy\",\n",
    "    \"Improve employee onboarding process\",\n",
    "    \"Design a mobile app user interface\",\n",
    "    \"Plan a product launch campaign\"\n",
    "]\n",
    "\n",
    "benchmark_results = performance_benchmark(benchmark_goals, iterations=2)\n",
    "\n",
    "# Display benchmark summary\n",
    "print(\"\\nЁЯПЖ **Benchmark Summary:**\")\n",
    "print(\"=\" * 50)\n",
    "for result in benchmark_results:\n",
    "    print(f\"ЁЯУЭ {result['goal'][:40]}...\")\n",
    "    print(f\"   тП▒я╕П Average: {result['avg_time']:.2f}s\")\n",
    "    print(f\"   тЪб Fastest: {result['min_time']:.2f}s\")\n",
    "    print(f\"   ЁЯРМ Slowest: {result['max_time']:.2f}s\")\n",
    "    print()\n",
    "\n",
    "if benchmark_results:\n",
    "    overall_avg = sum(r['avg_time'] for r in benchmark_results) / len(benchmark_results)\n",
    "    print(f\"ЁЯУК **Overall Average Processing Time:** {overall_avg:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49cca35",
   "metadata": {},
   "source": [
    "## ржкрзНрж░рзЛржбрж╛ржХрж╢ржи ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯ рж╕рж╣рж╛ржпрж╝ржХ\n",
    "\n",
    "ржкрзНрж░рзЛржбрж╛ржХрж╢ржирзЗ ржмрзНржпржмрж╣рж╛рж░рзЗрж░ ржЬржирзНржп ржХрзЛржЕрж░рзНржбрж┐ржирзЗржЯрж░ ржХрзАржнрж╛ржмрзЗ ржорзЛржбрж╝рж╛ржирзЛ ржпрж╛ржпрж╝ рждрж╛рж░ ржЙржжрж╛рж╣рж░ржг:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299fed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionCoordinator:\n",
    "    \"\"\"Production-ready wrapper for the multi-agent coordinator.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_alias: str = \"phi-4-mini\"):\n",
    "        self.client = FoundryClient(model_alias)\n",
    "        self.coordinator = Coordinator(self.client)\n",
    "        self.request_count = 0\n",
    "        self.total_processing_time = 0\n",
    "    \n",
    "    def process_goal(self, goal: str, include_feedback: bool = False, feedback_rounds: int = 1) -> Dict[str, Any]:\n",
    "        \"\"\"Process a goal with production monitoring.\"\"\"\n",
    "        self.request_count += 1\n",
    "        \n",
    "        try:\n",
    "            if include_feedback:\n",
    "                result = self.coordinator.handle_with_feedback(goal, feedback_rounds=feedback_rounds)\n",
    "            else:\n",
    "                result = self.coordinator.handle(goal)\n",
    "            \n",
    "            self.total_processing_time += result['processing_time']\n",
    "            \n",
    "            # Add production metadata\n",
    "            result['request_id'] = self.request_count\n",
    "            result['status'] = 'success'\n",
    "            result['model'] = self.client.model_name\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'request_id': self.request_count,\n",
    "                'status': 'error',\n",
    "                'error': str(e),\n",
    "                'goal': goal,\n",
    "                'timestamp': time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get production statistics.\"\"\"\n",
    "        avg_processing_time = self.total_processing_time / max(1, self.request_count)\n",
    "        \n",
    "        return {\n",
    "            'total_requests': self.request_count,\n",
    "            'total_processing_time': self.total_processing_time,\n",
    "            'average_processing_time': avg_processing_time,\n",
    "            'model': self.client.model_name,\n",
    "            'client_healthy': self.client.check_health()\n",
    "        }\n",
    "\n",
    "# Example production usage\n",
    "prod_coordinator = ProductionCoordinator()\n",
    "\n",
    "# Process a goal\n",
    "prod_goal = \"Create a quarterly business review presentation\"\n",
    "prod_result = prod_coordinator.process_goal(prod_goal)\n",
    "\n",
    "print(f\"ЁЯПн **Production Processing Result:**\")\n",
    "print(f\"ЁЯУК Status: {prod_result['status']}\")\n",
    "print(f\"ЁЯФв Request ID: {prod_result['request_id']}\")\n",
    "print(f\"тП▒я╕П Processing Time: {prod_result.get('processing_time', 'N/A')}s\")\n",
    "print(f\"ЁЯдЦ Model: {prod_result.get('model', 'N/A')}\")\n",
    "\n",
    "# Show production stats\n",
    "stats = prod_coordinator.get_stats()\n",
    "print(f\"\\nЁЯУК **Production Statistics:**\")\n",
    "print(f\"   ЁЯУИ Total Requests: {stats['total_requests']}\")\n",
    "print(f\"   тП▒я╕П Average Processing Time: {stats['average_processing_time']:.2f}s\")\n",
    "print(f\"   ЁЯТЪ Client Health: {'тЬЕ Healthy' if stats['client_healthy'] else 'тЭМ Unhealthy'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d3849",
   "metadata": {},
   "source": [
    "## рж╕рж╛рж░рж╕ржВржХрзНрж╖рзЗржк ржПржмржВ рж╕рзЗрж░рж╛ ржЕржирзБрж╢рзАрж▓ржи\n",
    "\n",
    "ржПржЗ ржирзЛржЯржмрзБржХрзЗ ржПржХржЯрж┐ ржЙржирзНржиржд ржорж╛рж▓рзНржЯрж┐-ржПржЬрзЗржирзНржЯ ржЕрж░рзНржХрзЗрж╕рзНржЯрзНрж░рзЗрж╢ржи рж╕рж┐рж╕рзНржЯрзЗржо ржкрзНрж░ржжрж░рзНрж╢рж┐ржд рж╣ржпрж╝рзЗржЫрзЗ:\n",
    "\n",
    "### тЬЕ ржкрзНрж░ржжрж░рзНрж╢рж┐ржд ржорзВрж▓ ржмрзИрж╢рж┐рж╖рзНржЯрзНржпрж╕ржорзВрж╣\n",
    "\n",
    "1. **ЁЯПЧя╕П ржПржЬрзЗржирзНржЯ ржмрж┐рж╢рзЗрж╖рзАржХрж░ржг**: ржкрзНрж░рждрж┐ржЯрж┐ ржПржЬрзЗржирзНржЯ ржирж┐рж░рзНржжрж┐рж╖рзНржЯ ржЬрзНржЮрж╛ржирзАржпрж╝ ржХрж╛ржЬрзЗрж░ ржЬржирзНржп ржЕржкрзНржЯрж┐ржорж╛ржЗржЬ ржХрж░рж╛\n",
    "2. **ЁЯОп ржУржпрж╝рж╛рж░рзНржХржлрзНрж▓рзЛ ржЕрж░рзНржХрзЗрж╕рзНржЯрзНрж░рзЗрж╢ржи**: рж╕ржоржирзНржмрж┐ржд ржмрж╣рзБ-ржзрж╛ржкрзЗрж░ ржкрзНрж░ржХрзНрж░рж┐ржпрж╝рж╛ржХрж░ржг\n",
    "3. **ЁЯУЛ ржЧржаржиржпрзБржХрзНржд ржЖржЙржЯржкрзБржЯ**: JSON-ржлрж░ржорзНржпрж╛ржЯрзЗржб ржЕрзНржпрж╛ржХрж╢ржи ржкрзНрж▓рзНржпрж╛ржи\n",
    "4. **ЁЯФД ржлрж┐ржбржмрзНржпрж╛ржХ рж▓рзБржк**: ржмрж╣рзБ-рж░рж╛ржЙржирзНржб ржкрж░рж┐ржорж╛рж░рзНржЬржирж╛рж░ ржХрзНрж╖ржорждрж╛\n",
    "5. **тЪб ржХрж░рзНржоржХрзНрж╖ржорждрж╛ ржкрж░рзНржпржмрзЗржХрзНрж╖ржг**: ржкрзНрж░ржХрзНрж░рж┐ржпрж╝рж╛ржХрж░ржг рж╕ржоржпрж╝ ржПржмржВ рж╕рзНржмрж╛рж╕рзНржерзНржп ржкрж░рзАржХрзНрж╖рж╛\n",
    "6. **ЁЯПн ржЙрзОржкрж╛ржжржи ржкрзНрж░рж╕рзНрждрзБржд**: ржоржирж┐ржЯрж░рж┐ржВ рж╕рж╣ ржПржирзНржЯрж╛рж░ржкрзНрж░рж╛ржЗржЬ-ржЧрзНрж░рзЗржб рж░тАНрзНржпрж╛ржкрж╛рж░\n",
    "\n",
    "### ЁЯза ржПржЬрзЗржирзНржЯ ржнрзВржорж┐ржХрж╛рж░ рж╕рж╛рж░рж╕ржВржХрзНрж╖рзЗржк\n",
    "\n",
    "| ржПржЬрзЗржирзНржЯ | ржЙржжрзНржжрзЗрж╢рзНржп | ржЗржиржкрзБржЯ | ржЖржЙржЯржкрзБржЯ |\n",
    "|--------|----------|-------|---------|\n",
    "| **ЁЯФН Retrieval** | ржкрзНрж░рж╛рж╕ржЩрзНржЧрж┐ржХ рждржерзНржп рж╕ржВржЧрзНрж░рж╣ | ржмрзНржпржмрж╣рж╛рж░ржХрж╛рж░рзАрж░ ржкрзНрж░рж╢рзНржи | ржкрзНрж░рж╛рж╕ржЩрзНржЧрж┐ржХ рждржерзНржп ржПржмржВ ржбрзЗржЯрж╛ |\n",
    "| **ЁЯза Reasoning** | ржпрзМржХрзНрждрж┐ржХ ржмрж┐рж╢рзНрж▓рзЗрж╖ржг | ржкрзНрж░рзЗржХрзНрж╖рж╛ржкржЯ + ржкрзНрж░рж╢рзНржи | ржЧржаржиржпрзБржХрзНржд рж╕рж┐ржжрзНржзрж╛ржирзНржд |\n",
    "| **тЪб Execution** | ржЕрзНржпрж╛ржХрж╢ржи ржкрзНрж▓рзНржпрж╛ржи рждрзИрж░рж┐ | рж╕рж┐ржжрзНржзрж╛ржирзНржд | JSON ржЕрзНржпрж╛ржХрж╢ржи ржзрж╛ржк |\n",
    "| **ЁЯОп Coordinator** | ржУржпрж╝рж╛рж░рзНржХржлрзНрж▓рзЛ ржкрж░рж┐ржЪрж╛рж▓ржирж╛ | ржмрзНржпржмрж╣рж╛рж░ржХрж╛рж░рзАрж░ рж▓ржХрзНрж╖рзНржп | рж╕ржорзНржкрзВрж░рзНржг ржлрж▓рж╛ржлрж▓ |\n",
    "\n",
    "### ЁЯЪА ржмрзНржпржмрж╣рж╛рж░ ржХрзНрж╖рзЗрждрзНрж░рж╕ржорзВрж╣\n",
    "\n",
    "- **ржмрзНржпржмрж╕рж╛ржпрж╝рж┐ржХ ржкрж░рж┐ржХрж▓рзНржкржирж╛**: ржХрзМрж╢рж▓ржЧржд ржкрж░рж┐ржХрж▓рзНржкржирж╛ ржПржмржВ ржмрж╛рж╕рзНрждржмрж╛ржпрж╝ржи\n",
    "- **ржкрзНрж░ржХрж▓рзНржк ржмрзНржпржмрж╕рзНржерж╛ржкржирж╛**: ржХрж╛ржЬрзЗрж░ ржмрж┐ржнрж╛ржЬржи ржПржмржВ рж╕ржоржпрж╝рж╕рзВржЪрж┐ рждрзИрж░рж┐  \n",
    "- **ржЧржмрзЗрж╖ржгрж╛**: рждржерзНржп рж╕ржВржЧрзНрж░рж╣ ржПржмржВ ржмрж┐рж╢рзНрж▓рзЗрж╖ржг\n",
    "- **рж╕рж┐ржжрзНржзрж╛ржирзНржд рж╕рж╣рж╛ржпрж╝рждрж╛**: ржЬржЯрж┐рж▓ рж╕рж┐ржжрзНржзрж╛ржирзНржд ржЧрзНрж░рж╣ржгрзЗрж░ ржкрзНрж░ржХрзНрж░рж┐ржпрж╝рж╛\n",
    "- **ржУржпрж╝рж╛рж░рзНржХржлрзНрж▓рзЛ ржЕржЯрзЛржорзЗрж╢ржи**: ржмрж╣рзБ-ржзрж╛ржкрзЗрж░ ржмрзНржпржмрж╕рж╛ржпрж╝рж┐ржХ ржкрзНрж░ржХрзНрж░рж┐ржпрж╝рж╛\n",
    "\n",
    "### ЁЯТб рж╕рзЗрж░рж╛ ржЕржирзБрж╢рзАрж▓ржи\n",
    "\n",
    "1. **ЁЯОп ржПржХржХ ржжрж╛ржпрж╝рж┐рждрзНржм**: ржкрзНрж░рждрж┐ржЯрж┐ ржПржЬрзЗржирзНржЯрзЗрж░ ржПржХржЯрж┐ рж╕рзНржкрж╖рзНржЯ ржЙржжрзНржжрзЗрж╢рзНржп ржерж╛ржХрж╛ ржЙржЪрж┐ржд\n",
    "2. **ЁЯФЧ рж╕рзНржкрж╖рзНржЯ ржЗржирзНржЯрж╛рж░ржлрзЗрж╕**: ржорж╛ржиржХ ржЗржиржкрзБржЯ/ржЖржЙржЯржкрзБржЯ ржлрж░ржорзНржпрж╛ржЯ\n",
    "3. **ЁЯЫбя╕П рждрзНрж░рзБржЯрж┐ ржкрж░рж┐ржЪрж╛рж▓ржирж╛**: ржмрзНржпрж░рзНржерждрж╛рж░ ржХрзНрж╖рзЗрждрзНрж░рзЗ рж╕рзБрж╢рзГржЩрзНржЦрж▓ ржбрж┐ржЧрзНрж░рзЗржбрзЗрж╢ржи\n",
    "4. **ЁЯУК ржкрж░рзНржпржмрзЗржХрзНрж╖ржг**: ржмрж┐рж╕рзНрждрзГржд рж▓ржЧрж┐ржВ ржПржмржВ ржХрж░рзНржоржХрзНрж╖ржорждрж╛ ржЯрзНрж░рзНржпрж╛ржХрж┐ржВ\n",
    "5. **ЁЯФД ржлрж┐ржбржмрзНржпрж╛ржХ рж▓рзБржк**: ржкрзБржирж░рж╛ржмрзГрждрзНрждрж┐ ржЙржирзНржирждрж┐рж░ ржкрзНрж░ржХрзНрж░рж┐ржпрж╝рж╛\n",
    "6. **тЪЦя╕П рж▓рзЛржб ржмрзНржпрж╛рж▓рзЗржирзНрж╕рж┐ржВ**: рж╕рзНржмрж╛ржзрзАржи ржХрж╛ржЬрзЗрж░ ржЬржирзНржп рж╕ржорж╛ржирзНрждрж░рж╛рж▓ ржкрзНрж░ржХрзНрж░рж┐ржпрж╝рж╛ржХрж░ржг ржмрж┐ржмрзЗржЪржирж╛ ржХрж░рзБржи\n",
    "\n",
    "### ЁЯФо ржкрж░ржмрж░рзНрждрзА ржкржжржХрзНрж╖рзЗржк\n",
    "\n",
    "- **ЁЯФз ржлрж╛ржВрж╢ржи ржХрж▓рж┐ржВ**: ржмрж╛рж╣рзНржпрж┐ржХ API ржПржмржВ ржЯрзБрж▓рзЗрж░ рж╕рж╛ржерзЗ ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржи\n",
    "- **ЁЯза ржорзЗржорж░рж┐ рж╕рж┐рж╕рзНржЯрзЗржо**: ржПржЬрзЗржирзНржЯржжрзЗрж░ ржЬржирзНржп рж╕рзНржерж╛ржпрж╝рзА ржорзЗржорж░рж┐ ржпрзЛржЧ ржХрж░рж╛\n",
    "- **ЁЯОн ржмрж┐рж╢рзЗрж╖рж╛ржпрж╝рж┐ржд ржоржбрзЗрж▓**: ржмрж┐ржнрж┐ржирзНржи ржПржЬрзЗржирзНржЯрзЗрж░ ржЬржирзНржп ржмрж┐ржнрж┐ржирзНржи ржоржбрзЗрж▓ ржмрзНржпржмрж╣рж╛рж░\n",
    "- **ЁЯСе ржорж╛ржиржм-ржЗржи-ржжрзНржп-рж▓рзБржк**: ржорж╛ржиржм ржкрж░рзНржпрж╛рж▓рзЛржЪржирж╛ ржПржмржВ ржЕржирзБржорзЛржжржирзЗрж░ ржзрж╛ржк ржпрзЛржЧ ржХрж░рж╛\n",
    "- **ЁЯУК ржЙржирзНржиржд ржмрж┐рж╢рзНрж▓рзЗрж╖ржг**: ржмрж┐рж╕рзНрждрзГржд ржкрж░рзНржпржмрзЗржХрзНрж╖ржг ржПржмржВ ржорзЗржЯрзНрж░рж┐ржХрзНрж╕\n",
    "\n",
    "ржПржЗ ржорж╛рж▓рзНржЯрж┐-ржПржЬрзЗржирзНржЯ рж╕рж┐рж╕рзНржЯрзЗржоржЯрж┐ ржжрзЗржЦрж╛ржпрж╝ ржХрзАржнрж╛ржмрзЗ ржмрж┐рж╢рзЗрж╖рж╛ржпрж╝рж┐ржд ржПржЬрзЗржирзНржЯржжрзЗрж░ рж╢ржХрзНрждрж┐ ржПржХрждрзНрж░рж┐ржд ржХрж░рзЗ ржЙржирзНржиржд AI ржУржпрж╝рж╛рж░рзНржХржлрзНрж▓рзЛ рждрзИрж░рж┐ ржХрж░рж╛ ржпрж╛ржпрж╝, ржПржХржЗ рж╕рж╛ржерзЗ Microsoft Foundry Local-ржПрж░ ржорж╛ржзрзНржпржорзЗ рж╕рзНржерж╛ржирзАржпрж╝ ржЗржиржлрж╛рж░рзЗржирзНрж╕рзЗрж░ ржЧрзЛржкржирзАржпрж╝рждрж╛ ржПржмржВ ржХрж░рзНржоржХрзНрж╖ржорждрж╛рж░ рж╕рзБржмрж┐ржзрж╛ ржмржЬрж╛ржпрж╝ рж░рж╛ржЦрж╛ ржпрж╛ржпрж╝ред\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "coopTranslator": {
   "original_hash": "e769e8958054219004d420c9a7b3584b",
   "translation_date": "2025-09-24T15:38:57+00:00",
   "source_file": "Module08/samples/05/multi_agent_orchestration.ipynb",
   "language_code": "bn"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}