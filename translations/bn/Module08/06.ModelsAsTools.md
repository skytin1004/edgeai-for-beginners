<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "33ecd8ecf0e9347a2b4839a9916e49fb",
  "translation_date": "2025-09-30T23:47:15+00:00",
  "source_file": "Module08/06.ModelsAsTools.md",
  "language_code": "bn"
}
-->
## рж╕ржВржХрзНрж╖рж┐ржкрзНржд ржмрж┐ржмрж░ржг

Foundry Local-ржПрж░ ржорж╛ржзрзНржпржорзЗ AI ржоржбрзЗрж▓ржЧрзБрж▓рзЛржХрзЗ ржоржбрзБрж▓рж╛рж░, ржХрж╛рж╕рзНржЯржорж╛ржЗржЬржпрзЛржЧрзНржп ржЯрзБрж▓ рж╣рж┐рж╕рзЗржмрзЗ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи ржпрж╛ рж╕рж░рж╛рж╕рж░рж┐ ржбрж┐ржнрж╛ржЗрж╕рзЗ ржЪрж▓рзЗред ржПржЗ рж╕рзЗрж╢ржирзЗ ржЧрзЛржкржирзАржпрж╝рждрж╛ рж░ржХрзНрж╖рж╛ ржХрж░рзЗ, ржХржо рж▓рзЗржЯрзЗржирзНрж╕рж┐ ржЗржиржлрж╛рж░рзЗржирзНрж╕рзЗрж░ ржЬржирзНржп ржмрзНржпржмрж╣рж╛рж░рж┐ржХ ржУржпрж╝рж╛рж░рзНржХржлрзНрж▓рзЛ ржПржмржВ SDKs, APIs ржмрж╛ CLI-ржПрж░ ржорж╛ржзрзНржпржорзЗ ржПржЗ ржЯрзБрж▓ржЧрзБрж▓рзЛржХрзЗ ржХрзАржнрж╛ржмрзЗ ржЗржирзНржЯрж┐ржЧрзНрж░рзЗржЯ ржХрж░ржмрзЗржи рждрж╛ ржирж┐ржпрж╝рзЗ ржЖрж▓рзЛржЪржирж╛ ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗред ржПржЫрж╛ржбрж╝рж╛ржУ, ржкрзНрж░ржпрж╝рзЛржЬржирзЗ Azure AI Foundry-рждрзЗ рж╕рзНржХрзЗрж▓ ржХрж░рж╛рж░ ржкржжрзНржзрждрж┐ рж╢рж┐ржЦржмрзЗржиред

> **ЁЯФД ржЖржзрзБржирж┐ржХ SDK-ржПрж░ ржЬржирзНржп ржЖржкржбрзЗржЯ**: ржПржЗ ржоржбрж┐ржЙрж▓ржЯрж┐ рж╕рж░рзНржмрж╢рзЗрж╖ Microsoft Foundry-Local рж░рж┐ржкрзЛржЬрж┐ржЯрж░рж┐ ржкрзНржпрж╛ржЯрж╛рж░рзНржирзЗрж░ рж╕рж╛ржерзЗ рж╕рж╛ржоржЮрзНржЬрж╕рзНржпржкрзВрж░рзНржг ржПржмржВ `samples/06/`-ржП ржмрзБржжрзНржзрж┐ржорж╛ржи рж░рж╛ржЙржЯрж┐ржВ ржЗржоржкрзНрж▓рж┐ржорзЗржирзНржЯрзЗрж╢ржирзЗрж░ рж╕рж╛ржерзЗ ржорж┐рж▓рзЗ ржпрж╛ржпрж╝ред ржЙржжрж╛рж╣рж░ржгржЧрзБрж▓рзЛ ржПржЦржи ржЖржзрзБржирж┐ржХ `foundry-local-sdk` ржПржмржВ ржЙржирзНржиржд ржоржбрзЗрж▓ ржирж┐рж░рзНржмрж╛ржЪржи ржХрзМрж╢рж▓ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗред

**ЁЯПЧя╕П ржЖрж░рзНржХрж┐ржЯрзЗржХржЪрж╛рж░ рж╣рж╛ржЗрж▓рж╛ржЗржЯрж╕:**
- **ржмрзБржжрзНржзрж┐ржорж╛ржи ржоржбрзЗрж▓ рж░рж╛ржЙржЯрж┐ржВ**: рж╕рж╛ржзрж╛рж░ржг, рж░рж┐ржЬржирж┐ржВ, ржХрзЛржб ржПржмржВ ржХрзНрж░рж┐ржпрж╝рзЗржЯрж┐ржн ржоржбрзЗрж▓рзЗрж░ ржоржзрзНржпрзЗ ржХрзАржУржпрж╝рж╛рж░рзНржб-ржнрж┐рждрзНрждрж┐ржХ ржирж┐рж░рзНржмрж╛ржЪржи
- **ржЖржзрзБржирж┐ржХ SDK ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржи**: `FoundryLocalManager` ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝ рж╕рж╛рж░рзНржнрж┐рж╕ ржбрж┐рж╕ржХржнрж╛рж░рж┐
- **ржкрж░рж┐ржмрзЗрж╢ ржХржиржлрж┐ржЧрж╛рж░рзЗрж╢ржи**: ржкрж░рж┐ржмрзЗрж╢ ржнрзЗрж░рж┐ржпрж╝рзЗржмрж▓рзЗрж░ ржорж╛ржзрзНржпржорзЗ ржиржоржирзАржпрж╝ ржоржбрзЗрж▓ ржЕрзНржпрж╛рж╕рж╛ржЗржиржорзЗржирзНржЯ
- **рж╕рзНржмрж╛рж╕рзНржерзНржп ржкрж░рзНржпржмрзЗржХрзНрж╖ржг**: рж╕рж╛рж░рзНржнрж┐рж╕ ржнрзНржпрж╛рж▓рж┐ржбрзЗрж╢ржи ржПржмржВ ржоржбрзЗрж▓рзЗрж░ ржЕрзНржпрж╛ржнрзЗржЗрж▓рзЗржмрж┐рж▓рж┐ржЯрж┐ ржЪрзЗржХрж┐ржВ
- **ржкрзНрж░рзЛржбрж╛ржХрж╢ржи рж░рзЗржбрж┐**: ржмрж┐рж╕рзНрждрзГржд рждрзНрж░рзБржЯрж┐ ржкрж░рж┐ржЪрж╛рж▓ржирж╛ ржПржмржВ ржлрж▓ржмрзНржпрж╛ржХ ржорзЗржХрж╛ржирж┐ржЬржо

**ЁЯУБ рж▓рзЛржХрж╛рж▓ ржЗржоржкрзНрж▓рж┐ржорзЗржирзНржЯрзЗрж╢ржи:**
- `samples/06/router.py` - ржХрзАржУржпрж╝рж╛рж░рзНржб-ржнрж┐рждрзНрждрж┐ржХ ржирж┐рж░рзНржмрж╛ржЪржи рж╕рж╣ ржмрзБржжрзНржзрж┐ржорж╛ржи ржоржбрзЗрж▓ рж░рж╛ржЙржЯрж╛рж░
- `samples/06/model_router.ipynb` - ржЗржирзНржЯрж╛рж░ржЕрзНржпрж╛ржХржЯрж┐ржн ржЙржжрж╛рж╣рж░ржг ржПржмржВ ржмрзЗржЮрзНржЪржорж╛рж░рзНржХ
- `samples/06/README.md` - ржХржиржлрж┐ржЧрж╛рж░рзЗрж╢ржи ржПржмржВ ржмрзНржпржмрж╣рж╛рж░ ржирж┐рж░рзНржжрзЗрж╢рж┐ржХрж╛

рж░рзЗржлрж╛рж░рзЗржирзНрж╕:
- Foundry Local ржбржХрж╕: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
- ржЗржиржлрж╛рж░рзЗржирзНрж╕ SDKs-ржПрж░ рж╕рж╛ржерзЗ ржЗржирзНржЯрж┐ржЧрзНрж░рзЗржЯ ржХрж░рзБржи: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
- Hugging Face ржоржбрзЗрж▓ ржХржорзНржкрж╛ржЗрж▓ ржХрж░рзБржи: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models

## рж╕ржВржХрзНрж╖рж┐ржкрзНржд ржмрж┐ржмрж░ржг

Foundry Local-ржПрж░ ржорж╛ржзрзНржпржорзЗ AI ржоржбрзЗрж▓ржЧрзБрж▓рзЛржХрзЗ ржоржбрзБрж▓рж╛рж░, ржХрж╛рж╕рзНржЯржорж╛ржЗржЬржпрзЛржЧрзНржп ржЯрзБрж▓ рж╣рж┐рж╕рзЗржмрзЗ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи ржпрж╛ рж╕рж░рж╛рж╕рж░рж┐ ржбрж┐ржнрж╛ржЗрж╕рзЗ ржЪрж▓рзЗред ржПржЗ рж╕рзЗрж╢ржирзЗ ржЧрзЛржкржирзАржпрж╝рждрж╛ рж░ржХрзНрж╖рж╛ ржХрж░рзЗ, ржХржо рж▓рзЗржЯрзЗржирзНрж╕рж┐ ржЗржиржлрж╛рж░рзЗржирзНрж╕рзЗрж░ ржЬржирзНржп ржмрзНржпржмрж╣рж╛рж░рж┐ржХ ржУржпрж╝рж╛рж░рзНржХржлрзНрж▓рзЛ ржПржмржВ SDKs, APIs ржмрж╛ CLI-ржПрж░ ржорж╛ржзрзНржпржорзЗ ржПржЗ ржЯрзБрж▓ржЧрзБрж▓рзЛржХрзЗ ржХрзАржнрж╛ржмрзЗ ржЗржирзНржЯрж┐ржЧрзНрж░рзЗржЯ ржХрж░ржмрзЗржи рждрж╛ ржирж┐ржпрж╝рзЗ ржЖрж▓рзЛржЪржирж╛ ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗред ржПржЫрж╛ржбрж╝рж╛ржУ, ржкрзНрж░ржпрж╝рзЛржЬржирзЗ Azure AI Foundry-рждрзЗ рж╕рзНржХрзЗрж▓ ржХрж░рж╛рж░ ржкржжрзНржзрждрж┐ рж╢рж┐ржЦржмрзЗржиред

рж░рзЗржлрж╛рж░рзЗржирзНрж╕:
- Foundry Local ржбржХрж╕: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
- ржЗржиржлрж╛рж░рзЗржирзНрж╕ SDKs-ржПрж░ рж╕рж╛ржерзЗ ржЗржирзНржЯрж┐ржЧрзНрж░рзЗржЯ ржХрж░рзБржи: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
- Hugging Face ржоржбрзЗрж▓ ржХржорзНржкрж╛ржЗрж▓ ржХрж░рзБржи: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models

## рж╢рзЗржЦрж╛рж░ рж▓ржХрзНрж╖рзНржп
- ржбрж┐ржнрж╛ржЗрж╕рзЗ ржоржбрзЗрж▓-ржПржЬ-ржП-ржЯрзБрж▓ ржкрзНржпрж╛ржЯрж╛рж░рзНржи ржбрж┐ржЬрж╛ржЗржи ржХрж░рзБржи
- OpenAI-рж╕рж╛ржоржЮрзНржЬрж╕рзНржпржкрзВрж░рзНржг REST API ржмрж╛ SDKs-ржПрж░ ржорж╛ржзрзНржпржорзЗ ржЗржирзНржЯрж┐ржЧрзНрж░рзЗржЯ ржХрж░рзБржи
- ржоржбрзЗрж▓ржЧрзБрж▓рзЛржХрзЗ ржбрзЛржорзЗржЗржи-ржирж┐рж░рзНржжрж┐рж╖рзНржЯ ржмрзНржпржмрж╣рж╛рж░рзЗрж░ ржЬржирзНржп ржХрж╛рж╕рзНржЯржорж╛ржЗржЬ ржХрж░рзБржи
- Azure AI Foundry-рждрзЗ рж╣рж╛ржЗржмрзНрж░рж┐ржб рж╕рзНржХрзЗрж▓рж┐ржВржпрж╝рзЗрж░ ржкрж░рж┐ржХрж▓рзНржкржирж╛ ржХрж░рзБржи

## ржЕржВрж╢ рзз: ржмрзБржжрзНржзрж┐ржорж╛ржи ржоржбрзЗрж▓ рж░рж╛ржЙржЯрж╛рж░ (ржЖржзрзБржирж┐ржХ ржЗржоржкрзНрж▓рж┐ржорзЗржирзНржЯрзЗрж╢ржи)

рж▓ржХрзНрж╖рзНржп: ржХржирзНржЯрзЗржирзНржЯ ржЕржирзБржпрж╛ржпрж╝рзА рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝ рж░рж╛ржЙржЯрж┐ржВ рж╕рж╣ ржмрзБржжрзНржзрж┐ржорж╛ржи ржоржбрзЗрж▓ ржирж┐рж░рзНржмрж╛ржЪржи ржЗржоржкрзНрж▓рж┐ржорзЗржирзНржЯ ржХрж░рзБржиред

> **ЁЯУЛ ржирзЛржЯ**: ржПржЗ ржЗржоржкрзНрж▓рж┐ржорзЗржирзНржЯрзЗрж╢ржиржЯрж┐ `samples/06/router.py`-ржП ржмрзНржпржмрж╣рзГржд ржкрзНржпрж╛ржЯрж╛рж░рзНржирзЗрж░ рж╕рж╛ржерзЗ ржорж┐рж▓рзЗ ржпрж╛ржпрж╝ ржПржмржВ ржЙржирзНржиржд ржХрзАржУржпрж╝рж╛рж░рзНржб-ржнрж┐рждрзНрждрж┐ржХ ржоржбрзЗрж▓ ржирж┐рж░рзНржмрж╛ржЪржи ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗред

ржзрж╛ржк рзз) FoundryLocalManager ржжрж┐ржпрж╝рзЗ ржЖржзрзБржирж┐ржХ ржоржбрзЗрж▓ рж░рж╛ржЙржЯрж╛рж░ рж╕ржВржЬрзНржЮрж╛ржпрж╝рж┐ржд ржХрж░рзБржи  
```python
# router/intelligent_router.py
from foundry_local import FoundryLocalManager
from openai import OpenAI
from typing import Dict, Any, Optional
import os
import json

class ModelRouter:
    """Intelligent model router that selects appropriate models for different task types."""
    
    def __init__(self):
        self.client = None
        self.base_url = None
        self.tools = self._load_tool_registry()
        self._initialize_client()
    
    def _load_tool_registry(self) -> Dict[str, Dict[str, Any]]:
        """Load tool registry from environment or use defaults."""
        default_tools = {
            "general": {
                "model": os.environ.get("GENERAL_MODEL", "phi-4-mini"),
                "notes": "Fast general-purpose chat and Q&A",
                "temperature": 0.7
            },
            "reasoning": {
                "model": os.environ.get("REASONING_MODEL", "deepseek-r1-7b"),
                "notes": "Step-by-step analysis and logical reasoning",
                "temperature": 0.3
            },
            "code": {
                "model": os.environ.get("CODE_MODEL", "qwen2.5-7b"),
                "notes": "Code generation, debugging, and technical tasks",
                "temperature": 0.2
            },
            "creative": {
                "model": os.environ.get("CREATIVE_MODEL", "phi-4-mini"),
                "notes": "Creative writing and storytelling",
                "temperature": 0.9
            }
        }
        
        # Check for environment override
        tools_env = os.environ.get("TOOL_REGISTRY")
        if tools_env:
            try:
                return json.loads(tools_env)
            except json.JSONDecodeError:
                print("Warning: Invalid TOOL_REGISTRY JSON, using defaults")
        
        return default_tools
```
  
ржзрж╛ржк рзи) ржЖржзрзБржирж┐ржХ SDK ржПржмржВ рж╕рж╛рж░рзНржнрж┐рж╕ ржбрж┐рж╕ржХржнрж╛рж░рж┐ ржжрж┐ржпрж╝рзЗ ржХрзНрж▓рж╛ржпрж╝рзЗржирзНржЯ ржЗржирж┐рж╢рж┐ржпрж╝рж╛рж▓рж╛ржЗржЬ ржХрж░рзБржи  
```python
    def _initialize_client(self):
        """Initialize OpenAI client with Foundry Local or fallback configuration."""
        try:
            from foundry_local import FoundryLocalManager
            # Try to use any available model for client initialization
            first_model = next(iter(self.tools.values()))["model"]
            manager = FoundryLocalManager(first_model)
            
            self.client = OpenAI(
                base_url=manager.endpoint,
                api_key=manager.api_key
            )
            self.base_url = manager.endpoint
            print(f"тЬЕ Foundry Local SDK initialized")
        except Exception as e:
            print(f"Warning: Could not use Foundry SDK ({e}), falling back to manual configuration")
            # Fallback to manual configuration
            self.base_url = os.environ.get("BASE_URL", "http://localhost:8000")
            api_key = os.environ.get("API_KEY", "")
            
            self.client = OpenAI(
                base_url=f"{self.base_url}/v1",
                api_key=api_key
            )
            print(f"Initialized manual configuration at {self.base_url}")
    
    def select_tool(self, user_query: str) -> str:
        """Select the most appropriate tool based on the user query."""
        query_lower = user_query.lower()
        
        # Code-related keywords
        code_keywords = ["code", "python", "function", "class", "method", "bug", "debug", 
                        "programming", "script", "algorithm", "implementation", "refactor"]
        if any(keyword in query_lower for keyword in code_keywords):
            return "code"
        
        # Reasoning keywords
        reasoning_keywords = ["why", "how", "explain", "step-by-step", "reason", "analyze", 
                             "think", "logic", "because", "cause", "compare", "evaluate"]
        if any(keyword in query_lower for keyword in reasoning_keywords):
            return "reasoning"
        
        # Creative keywords
        creative_keywords = ["story", "poem", "creative", "imagine", "write", "tale", 
                           "narrative", "fiction", "character", "plot"]
        if any(keyword in query_lower for keyword in creative_keywords):
            return "creative"
        
        # Default to general
        return "general"
    
    def chat(self, model: str, content: str, max_tokens: int = 300, temperature: Optional[float] = None) -> str:
        """Send chat completion request to the specified model."""
        try:
            params = {
                "model": model,
                "messages": [{"role": "user", "content": content}],
                "max_tokens": max_tokens
            }
            
            if temperature is not None:
                params["temperature"] = temperature
            
            response = self.client.chat.completions.create(**params)
            return response.choices[0].message.content
        except Exception as e:
            return f"Error generating response with model {model}: {str(e)}"
```
  
ржзрж╛ржк рзй) ржмрзБржжрзНржзрж┐ржорж╛ржи рж░рж╛ржЙржЯрж┐ржВ ржПржмржВ ржПржХрзНрж╕рж┐ржХрж┐ржЙрж╢ржи ржЗржоржкрзНрж▓рж┐ржорзЗржирзНржЯ ржХрж░рзБржи (`samples/06/router.py` ржжрзЗржЦрзБржи)  
```python
    def route_and_run(self, prompt: str) -> Dict[str, Any]:
        """Route the prompt to the appropriate model and generate response."""
        tool_key = self.select_tool(prompt)
        tool_config = self.tools[tool_key]
        model = tool_config["model"]
        temperature = tool_config.get("temperature", 0.7)
        
        print(f"ЁЯОп Selected tool: {tool_key} (model: {model})")
        
        answer = self.chat(
            model=model, 
            content=prompt, 
            max_tokens=400, 
            temperature=temperature
        )
        
        return {
            "tool": tool_key,
            "model": model,
            "tool_description": tool_config["notes"],
            "temperature": temperature,
            "answer": answer
        }
    
    def check_service_health(self) -> Dict[str, Any]:
        """Check Foundry Local service health and available models."""
        try:
            models_response = self.client.models.list()
            available_models = [model.id for model in models_response.data]
            
            return {
                "status": "healthy",
                "base_url": self.base_url,
                "available_models": available_models,
                "tools_configured": list(self.tools.keys())
            }
        except Exception as e:
            return {
                "status": "error",
                "base_url": self.base_url,
                "error": str(e)
            }

if __name__ == "__main__":
    # Ensure: foundry model run phi-4-mini
    router = ModelRouter()
    
    # Check health
    health = router.check_service_health()
    print(f"Service Health: {json.dumps(health, indent=2)}")
    
    # Test different query types
    queries = [
        "Write a Python function to calculate fibonacci numbers",  # -> code
        "Explain step-by-step why the sky is blue",  # -> reasoning
        "Tell me a creative story about AI",  # -> creative
        "What's the weather like today?"  # -> general
    ]
    
    for query in queries:
        result = router.route_and_run(query)
        print(f"\nQuery: {query}")
        print(f"Selected: {result['tool']} -> {result['model']}")
        print(f"Answer: {result['answer'][:100]}...")
```
  

## ржЕржВрж╢ рзи: ржЖржзрзБржирж┐ржХ SDK ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржи (ржзрж╛ржкрзЗ ржзрж╛ржкрзЗ)

рж▓ржХрзНрж╖рзНржп: OpenAI Python SDK-ржПрж░ рж╕рж╛ржерзЗ Foundry Local SDK ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ ржирж┐рж░рзНржмрж┐ржШрзНржи ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржиред

ржзрж╛ржк рзз) ржбрж┐ржкрзЗржиржбрзЗржирзНрж╕рж┐ ржЗржирж╕рзНржЯрж▓ ржХрж░рзБржи  
```cmd
cd Module08
.\.venv\Scripts\activate
pip install foundry-local-sdk openai
```
  
ржзрж╛ржк рзи) ржкрж░рж┐ржмрзЗрж╢ ржХржиржлрж┐ржЧрж╛рж░ ржХрж░рзБржи (ржРржЪрзНржЫрж┐ржХ - `samples/06/README.md` ржжрзЗржЦрзБржи)  
```cmd
REM Override default models per tool
set GENERAL_MODEL=phi-4-mini
set REASONING_MODEL=deepseek-r1-7b
set CODE_MODEL=qwen2.5-7b
REM Or provide a full JSON registry
set TOOL_REGISTRY={"general":{"model":"phi-4-mini"},"reasoning":{"model":"deepseek-r1-7b"}}
```
  
ржзрж╛ржк рзй) ржЖржзрзБржирж┐ржХ SDK ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржи  
```python
# modern_sdk_demo.py
from foundry_local import FoundryLocalManager
from openai import OpenAI
import sys

def main():
    """Demonstrate modern SDK integration."""
    try:
        # Initialize with FoundryLocalManager
        alias = "phi-4-mini"
        manager = FoundryLocalManager(alias)
        
        # Create OpenAI client using Foundry Local endpoint
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key
        )
        
        # Get model info
        model_info = manager.get_model_info(alias)
        print(f"Using model: {model_info.id}")
        
        # Make request with streaming
        stream = client.chat.completions.create(
            model=model_info.id,
            messages=[{"role": "user", "content": "Explain edge AI benefits in one paragraph."}],
            stream=True,
            max_tokens=200
        )
        
        print("Response: ", end="")
        for chunk in stream:
            if chunk.choices[0].delta.content:
                print(chunk.choices[0].delta.content, end="", flush=True)
        print()
        
    except Exception as e:
        print(f"Error: {e}")
        print("Ensure Foundry Local is running with: foundry model run phi-4-mini")
        sys.exit(1)

if __name__ == "__main__":
    main()
```
  

## ржЕржВрж╢ рзй: ржбрзЛржорзЗржЗржи ржХрж╛рж╕рзНржЯржорж╛ржЗржЬрзЗрж╢ржи (ржзрж╛ржкрзЗ ржзрж╛ржкрзЗ)

рж▓ржХрзНрж╖рзНржп: ржкрзНрж░ржорзНржкржЯ ржЯрзЗржоржкрзНрж▓рзЗржЯ ржПржмржВ JSON рж╕рзНржХрж┐ржорж╛ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ ржЖржЙржЯржкрзБржЯржЧрзБрж▓рзЛржХрзЗ ржбрзЛржорзЗржЗржирзЗрж░ ржЬржирзНржп ржЙржкржпрзЛржЧрзА ржХрж░рзБржиред

ржзрж╛ржк рзз) ржПржХржЯрж┐ ржбрзЛржорзЗржЗржи ржкрзНрж░ржорзНржкржЯ ржЯрзЗржоржкрзНрж▓рзЗржЯ рждрзИрж░рж┐ ржХрж░рзБржи  
```python
# domain/templates.py
BUSINESS_ANALYST_SYSTEM = """
You are a senior business analyst. Provide:
1) Key insights
2) Risks
3) Next steps
Respond in valid JSON with fields: insights, risks, next_steps.
"""
```
  
ржзрж╛ржк рзи) JSON ржЖржЙржЯржкрзБржЯ ржирж┐рж╢рзНржЪрж┐ржд ржХрж░рзБржи  
```python
# domain/analyst.py
import requests, os, json

BASE_URL = os.getenv("OPENAI_BASE_URL", "http://localhost:8000/v1")
API_KEY = os.getenv("OPENAI_API_KEY", "local-key")
HEADERS = {"Content-Type":"application/json","Authorization":f"Bearer {API_KEY}"}

from domain.templates import BUSINESS_ANALYST_SYSTEM

def analyze(text: str) -> dict:
    messages = [
        {"role":"system","content": BUSINESS_ANALYST_SYSTEM},
        {"role":"user","content": f"Analyze this business text:\n{text}"}
    ]
    r = requests.post(f"{BASE_URL}/chat/completions", json={
    "model":"phi-4-mini",
        "messages": messages,
        "response_format": {"type":"json_object"},
        "temperature": 0.3
    }, headers=HEADERS, timeout=60)
    r.raise_for_status()
    # Parse JSON content
    content = r.json()["choices"][0]["message"]["content"]
    return json.loads(content)

if __name__ == "__main__":
    print(analyze("Sales dipped 12% in Q3 due to supply constraints and marketing cuts."))
```
  

## ржЕржВрж╢ рзк: ржЕржлрж▓рж╛ржЗржи ржПржмржВ рж╕рж┐ржХрж┐ржЙрж░рж┐ржЯрж┐ ржкржЬрж┐рж╢ржи (ржзрж╛ржкрзЗ ржзрж╛ржкрзЗ)

рж▓ржХрзНрж╖рзНржп: ржоржбрзЗрж▓ржЧрзБрж▓рзЛржХрзЗ рж▓рзЛржХрж╛рж▓ ржЯрзБрж▓ рж╣рж┐рж╕рзЗржмрзЗ ржЪрж╛рж▓рж╛ржирзЛрж░ рж╕ржоржпрж╝ ржЧрзЛржкржирзАржпрж╝рждрж╛ ржПржмржВ рж╕рзНржерж┐рждрж┐рж╢рзАрж▓рждрж╛ ржирж┐рж╢рзНржЪрж┐ржд ржХрж░рзБржиред

ржзрж╛ржк рзз) рж▓рзЛржХрж╛рж▓ ржПржирзНржбржкржпрж╝рзЗржирзНржЯ ржкрзНрж░рж┐-ржУржпрж╝рж╛рж░рзНржо ржПржмржВ ржнрзНржпрж╛рж▓рж┐ржбрзЗржЯ ржХрж░рзБржи  
```cmd
foundry model run phi-4-mini
curl http://localhost:8000/v1/models
```
  
ржзрж╛ржк рзи) ржЗржиржкрзБржЯржЧрзБрж▓рзЛ рж╕рзНржпрж╛ржирж┐ржЯрж╛ржЗржЬ ржХрж░рзБржи  
```python
# security/sanitize.py
import re
EMAIL_RE = re.compile(r"[\w\.-]+@[\w\.-]+")
PHONE_RE = re.compile(r"\+?\d[\d\s\-]{7,}\d")

def sanitize(text: str) -> str:
    text = EMAIL_RE.sub("[REDACTED_EMAIL]", text)
    text = PHONE_RE.sub("[REDACTED_PHONE]", text)
    return text
```
  
ржзрж╛ржк рзй) рж▓рзЛржХрж╛рж▓-ржЕржирж▓рж┐ ржлрзНрж▓рзНржпрж╛ржЧ ржПржмржВ рж▓ржЧрж┐ржВ  
```python
# security/local_only.py
import os, json, time
LOG = os.getenv("MODELS_AS_TOOLS_LOG", "./tools_logs.jsonl")

def record(event: dict):
    with open(LOG, "a", encoding="utf-8") as f:
        f.write(json.dumps(event) + "\n")

# Usage before each call
def before_call(tool_name, payload):
    record({"ts": time.time(), "tool": tool_name, "event": "before_call"})

# After each call
def after_call(tool_name, result):
    record({"ts": time.time(), "tool": tool_name, "event": "after_call"})
```
  

## ржЕржВрж╢ рзл: ржкрзНрж░рзЛржбрж╛ржХрж╢ржи ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯ ржПржмржВ рж╕рзНржХрзЗрж▓рж┐ржВ

рж▓ржХрзНрж╖рзНржп: ржоржирж┐ржЯрж░рж┐ржВ ржПржмржВ Azure AI Foundry ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржирзЗрж░ рж╕рж╛ржерзЗ ржмрзБржжрзНржзрж┐ржорж╛ржи рж░рж╛ржЙржЯрж╛рж░ ржбрж┐ржкрзНрж▓ржпрж╝ ржХрж░рзБржиред

> **ЁЯУЛ ржирзЛржЯ**: `samples/06/model_router.ipynb`-ржП рж▓рзЛржХрж╛рж▓ ржЗржоржкрзНрж▓рж┐ржорзЗржирзНржЯрзЗрж╢ржи ржкрзНрж░рзЛржбрж╛ржХрж╢ржи ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯ ржкрзНржпрж╛ржЯрж╛рж░рзНржирзЗрж░ ржмрж┐рж╕рзНрждрзГржд ржЙржжрж╛рж╣рж░ржг ржЕржирзНрждрж░рзНржнрзБржХрзНржд ржХрж░рзЗржЫрзЗред

ржзрж╛ржк рзз) ржоржирж┐ржЯрж░рж┐ржВ рж╕рж╣ ржкрзНрж░рзЛржбрж╛ржХрж╢ржи рж░рж╛ржЙржЯрж╛рж░ (`samples/06/router.py` ржжрзЗржЦрзБржи)  
```python
# production/router.py
from router.intelligent_router import ModelRouter
import json
import time
import sys

class ProductionModelRouter(ModelRouter):
    """Production-ready model router with monitoring and logging."""
    
    def __init__(self):
        super().__init__()
        self.request_count = 0
        self.error_count = 0
        self.start_time = time.time()
    
    def route_and_run_with_monitoring(self, prompt: str) -> Dict[str, Any]:
        """Route with comprehensive monitoring and error handling."""
        start_time = time.time()
        self.request_count += 1
        
        try:
            result = self.route_and_run(prompt)
            processing_time = time.time() - start_time
            
            # Log successful request
            self._log_request({
                "status": "success",
                "tool": result["tool"],
                "model": result["model"],
                "processing_time": processing_time,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            })
            
            result["processing_time"] = processing_time
            return result
            
        except Exception as e:
            self.error_count += 1
            error_result = {
                "status": "error",
                "error": str(e),
                "processing_time": time.time() - start_time,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            }
            
            self._log_request(error_result)
            return error_result
    
    def _log_request(self, data: Dict[str, Any]):
        """Log request data for monitoring."""
        print(f"ЁЯУК {json.dumps(data)}")
    
    def get_stats(self) -> Dict[str, Any]:
        """Get router statistics."""
        uptime = time.time() - self.start_time
        return {
            "uptime_seconds": uptime,
            "total_requests": self.request_count,
            "error_count": self.error_count,
            "success_rate": (self.request_count - self.error_count) / max(1, self.request_count),
            "requests_per_minute": self.request_count / max(1, uptime / 60)
        }

def main():
    """Production router demo."""
    router = ProductionModelRouter()
    
    # Health check
    health = router.check_service_health()
    if health["status"] == "error":
        print(f"тЭМ Service health check failed: {health['error']}")
        sys.exit(1)
    
    print(f"тЬЕ Service healthy with {len(health['available_models'])} models")
    
    # Process user query
    user_prompt = " ".join(sys.argv[1:]) or "Write three benefits of on-device AI in JSON format."
    print(f"\nЁЯОп Processing: {user_prompt}")
    
    result = router.route_and_run_with_monitoring(user_prompt)
    
    if result.get("status") == "error":
        print(f"тЭМ Error: {result['error']}")
    else:
        print(f"\nЁЯУЛ Result:")
        print(f"Tool: {result['tool']} -> Model: {result['model']}")
        print(f"Processing Time: {result['processing_time']:.2f}s")
        print(f"Answer: {result['answer']}")
    
    # Show stats
    stats = router.get_stats()
    print(f"\nЁЯУК Statistics: {json.dumps(stats, indent=2)}")

if __name__ == "__main__":
    main()
```
  

## рж╣рж╛рждрзЗ-ржХрж▓ржорзЗ ржЪрзЗржХрж▓рж┐рж╕рзНржЯ
- [ ] ржХрзАржУржпрж╝рж╛рж░рзНржб-ржнрж┐рждрзНрждрж┐ржХ ржирж┐рж░рзНржмрж╛ржЪржи рж╕рж╣ ржмрзБржжрзНржзрж┐ржорж╛ржи ржоржбрзЗрж▓ рж░рж╛ржЙржЯрж╛рж░ ржЗржоржкрзНрж▓рж┐ржорзЗржирзНржЯ ржХрж░рзБржи (`samples/06/router.py`)
- [ ] ржПржХрж╛ржзрж┐ржХ ржмрж┐рж╢рзЗрж╖рж╛ржпрж╝рж┐ржд ржоржбрзЗрж▓ ржХржиржлрж┐ржЧрж╛рж░ ржХрж░рзБржи (рж╕рж╛ржзрж╛рж░ржг, рж░рж┐ржЬржирж┐ржВ, ржХрзЛржб, ржХрзНрж░рж┐ржпрж╝рзЗржЯрж┐ржн)
- [ ] ржЗржирзНржЯрж╛рж░ржЕрзНржпрж╛ржХржЯрж┐ржн Jupyter ржирзЛржЯржмрзБржХ ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи (`samples/06/model_router.ipynb`)
- [ ] ржкрж░рж┐ржмрзЗрж╢-ржнрж┐рждрзНрждрж┐ржХ ржоржбрзЗрж▓ ржХржиржлрж┐ржЧрж╛рж░рзЗрж╢ржи рж╕рзЗржЯ ржЖржк ржХрж░рзБржи
- [ ] рж╕рж╛рж░рзНржнрж┐рж╕ рж╕рзНржмрж╛рж╕рзНржерзНржп ржкрж░рзНржпржмрзЗржХрзНрж╖ржг ржПржмржВ рждрзНрж░рзБржЯрж┐ ржкрж░рж┐ржЪрж╛рж▓ржирж╛ ржЗржоржкрзНрж▓рж┐ржорзЗржирзНржЯ ржХрж░рзБржи
- [ ] ржмрж┐рж╕рзНрждрзГржд рж▓ржЧрж┐ржВ рж╕рж╣ ржкрзНрж░рзЛржбрж╛ржХрж╢ржи рж░рж╛ржЙржЯрж╛рж░ ржбрж┐ржкрзНрж▓ржпрж╝ ржХрж░рзБржи

## рж▓рзЛржХрж╛рж▓ рж╕рзНржпрж╛ржорзНржкрж▓ ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржи

рж╕ржорзНржкрзВрж░рзНржг ржЗржоржкрзНрж▓рж┐ржорзЗржирзНржЯрзЗрж╢ржи ржЪрж╛рж▓рж╛ржи:  
```cmd
cd Module08
.\.venv\Scripts\activate

REM Start required models
foundry model run phi-4-mini
foundry model run qwen2.5-7b
foundry model run deepseek-r1-7b

REM Test the intelligent router
python samples\06\router.py "Write a Python function to sort a list"
python samples\06\router.py "Explain step-by-step how bubble sort works"
python samples\06\router.py "Tell me a creative story about robots"

REM Explore the interactive notebook
jupyter notebook samples/06/model_router.ipynb
```
  

## рж░рзЗржлрж╛рж░рзЗржирзНрж╕ ржПржмржВ ржкрж░ржмрж░рзНрждрзА ржкржжржХрзНрж╖рзЗржк
- **рж▓рзЛржХрж╛рж▓ ржЗржоржкрзНрж▓рж┐ржорзЗржирзНржЯрзЗрж╢ржи**: `samples/06/` - ржПржХрж╛ржзрж┐ржХ ржоржбрзЗрж▓ рж╕ржорж░рзНржержи рж╕рж╣ рж╕ржорзНржкрзВрж░рзНржг ржмрзБржжрзНржзрж┐ржорж╛ржи рж░рж╛ржЙржЯрж╛рж░
- **Microsoft рж╕рзНржпрж╛ржорзНржкрж▓рж╕**: [Hello Foundry Local](https://github.com/microsoft/Foundry-Local/tree/main/samples/python/hello-foundry-local)
- **ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржи ржбржХрж╕**: [ржЗржиржлрж╛рж░рзЗржирзНрж╕ SDKs-ржПрж░ рж╕рж╛ржерзЗ ржЗржирзНржЯрж┐ржЧрзНрж░рзЗржЯ ржХрж░рзБржи](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks)
- **ржЙржирзНржиржд ржкрзНржпрж╛ржЯрж╛рж░рзНржи**: Module 5-ржП ржлрж╛ржВрж╢ржи ржХрж▓рж┐ржВ ржПржмржВ ржорж╛рж▓рзНржЯрж┐-ржПржЬрзЗржирзНржЯ ржЕрж░рзНржХрзЗрж╕рзНржЯрзНрж░рзЗрж╢ржи ржЕржирзНржмрзЗрж╖ржг ржХрж░рзБржи

## рж╕рж╛рж░рж╕ржВржХрзНрж╖рзЗржк

Foundry Local рж╢ржХрзНрждрж┐рж╢рж╛рж▓рзА ржЕржи-ржбрж┐ржнрж╛ржЗрж╕ AI рж╕ржХрзНрж╖ржо ржХрж░рзЗ ржпрзЗржЦрж╛ржирзЗ ржоржбрзЗрж▓ржЧрзБрж▓рзЛ ржмрзБржжрзНржзрж┐ржорж╛ржи, ржмрж┐рж╢рзЗрж╖рж╛ржпрж╝рж┐ржд ржЯрзБрж▓ рж╣ржпрж╝рзЗ ржУржарзЗред рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝ ржоржбрзЗрж▓ ржирж┐рж░рзНржмрж╛ржЪржи, ржмрж┐рж╕рзНрждрзГржд ржкрж░рзНржпржмрзЗржХрзНрж╖ржг ржПржмржВ ржкрзНрж░рзЛржбрж╛ржХрж╢ржи-рж░рзЗржбрж┐ ржкрзНржпрж╛ржЯрж╛рж░рзНржирзЗрж░ ржорж╛ржзрзНржпржорзЗ, ржЯрж┐ржоржЧрзБрж▓рзЛ ржПржоржи ржЙржирзНржиржд AI ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржи рждрзИрж░рж┐ ржХрж░рждрзЗ ржкрж╛рж░рзЗ ржпрж╛ ржмрж┐ржнрж┐ржирзНржи ржХрж╛ржЬрзЗрж░ ржзрж░ржи ржЕржирзБржпрж╛ржпрж╝рзА ржорж╛ржирж┐ржпрж╝рзЗ ржирж┐рждрзЗ ржкрж╛рж░рзЗ ржПржмржВ ржЧрзЛржкржирзАржпрж╝рждрж╛ ржУ ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржмржЬрж╛ржпрж╝ рж░рж╛ржЦрждрзЗ ржкрж╛рж░рзЗред ржПржЦрж╛ржирзЗ ржкрзНрж░ржжрж░рзНрж╢рж┐ржд ржмрзБржжрзНржзрж┐ржорж╛ржи рж░рж╛ржЙржЯрж╛рж░ ржкрзНржпрж╛ржЯрж╛рж░рзНржиржЯрж┐ ржЬржЯрж┐рж▓ AI рж╕рж┐рж╕рзНржЯрзЗржо рждрзИрж░рж┐рж░ ржЬржирзНржп ржПржХржЯрж┐ ржнрж┐рждрзНрждрж┐ ржкрзНрж░ржжрж╛ржи ржХрж░рзЗ ржпрж╛ рж▓рзЛржХрж╛рж▓ ржбрзЗржнрзЗрж▓ржкржорзЗржирзНржЯ ржерзЗржХрзЗ ржкрзНрж░рзЛржбрж╛ржХрж╢ржи ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯ ржкрж░рзНржпржирзНржд рж╕рзНржХрзЗрж▓ ржХрж░рждрзЗ ржкрж╛рж░рзЗред

---

**ржЕрж╕рзНржмрзАржХрзГрждрж┐**:  
ржПржЗ ржиржерж┐ржЯрж┐ AI ржЕржирзБржмрж╛ржж ржкрж░рж┐рж╖рзЗржмрж╛ [Co-op Translator](https://github.com/Azure/co-op-translator) ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ ржЕржирзБржмрж╛ржж ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗред ржЖржорж░рж╛ ржпржерж╛рж╕ржорзНржнржм рж╕ржарж┐ржХрждрж╛рж░ ржЬржирзНржп ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рж┐, рждржмрзЗ ржЕржирзБржЧрзНрж░рж╣ ржХрж░рзЗ ржоржирзЗ рж░рж╛ржЦржмрзЗржи ржпрзЗ рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝ ржЕржирзБржмрж╛ржжрзЗ рждрзНрж░рзБржЯрж┐ ржмрж╛ ржЕрж╕ржЩрзНржЧрждрж┐ ржерж╛ржХрждрзЗ ржкрж╛рж░рзЗред ржиржерж┐ржЯрж┐рж░ ржорзВрж▓ ржнрж╛рж╖рж╛ржпрж╝ ржерж╛ржХрж╛ ржЖрж╕рж▓ рж╕ржВрж╕рзНржХрж░ржгржХрзЗ ржкрзНрж░рж╛ржорж╛ржгрж┐ржХ ржЙрзОрж╕ рж╣рж┐рж╕рзЗржмрзЗ ржмрж┐ржмрзЗржЪржирж╛ ржХрж░рж╛ ржЙржЪрж┐рждред ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржг рждржерзНржпрзЗрж░ ржЬржирзНржп, ржкрзЗрж╢рж╛ржжрж╛рж░ ржорж╛ржиржм ржЕржирзБржмрж╛ржж рж╕рзБржкрж╛рж░рж┐рж╢ ржХрж░рж╛ рж╣ржпрж╝ред ржПржЗ ржЕржирзБржмрж╛ржж ржмрзНржпржмрж╣рж╛рж░рзЗрж░ ржлрж▓рзЗ ржХрзЛржирзЛ ржнрзБрж▓ ржмрзЛржЭрж╛ржмрзБржЭрж┐ ржмрж╛ ржнрзБрж▓ ржмрзНржпрж╛ржЦрзНржпрж╛ рж╣рж▓рзЗ ржЖржорж░рж╛ ржжрж╛ржпрж╝ржмржжрзНржз ржерж╛ржХржм ржирж╛ред