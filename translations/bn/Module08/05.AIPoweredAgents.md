<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a534c7d108d29f908a8f9f693d694664",
  "translation_date": "2025-09-24T15:02:44+00:00",
  "source_file": "Module08/05.AIPoweredAgents.md",
  "language_code": "bn"
}
-->
# рж╕рзЗрж╢ржи рзл: Foundry Local ржжрж┐рзЯрзЗ ржжрзНрж░рзБржд AI-ржЪрж╛рж▓рж┐ржд ржПржЬрзЗржирзНржЯ рждрзИрж░рж┐ ржХрж░рзБржи

ржирзЛржЯ: Foundry Local-ржП ржПржЬрзЗржирзНржЯрзЗрж░ рж╕ржХрзНрж╖ржорждрж╛ ржкрж░рж┐ржмрж░рзНрждрж┐ржд рж╣рзЯтАФржЙржирзНржиржд ржкрзНржпрж╛ржЯрж╛рж░рзНржи ржкрзНрж░рзЯрзЛржЧрзЗрж░ ржЖржЧрзЗ рж╕рж░рзНржмрж╢рзЗрж╖ рж░рж┐рж▓рж┐ржЬ ржирзЛржЯрзЗ рж╕ржорж░рзНржержи ржирж┐рж╢рзНржЪрж┐ржд ржХрж░рзБржиред

## рж╕ржВржХрзНрж╖рж┐ржкрзНржд ржмрж┐ржмрж░ржг

Foundry Local ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ ржПржЬрзЗржирзНржЯрж┐ржХ ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржи ржжрзНрж░рзБржд ржкрзНрж░рзЛржЯрзЛржЯрж╛ржЗржк ржХрж░рзБржи: рж╕рж┐рж╕рзНржЯрзЗржо ржкрзНрж░ржорзНржкржЯ, ржЧрзНрж░рж╛ржЙржирзНржбрж┐ржВ, ржПржмржВ ржЕрж░рзНржХрзЗрж╕рзНржЯрзНрж░рзЗрж╢ржи ржкрзНржпрж╛ржЯрж╛рж░рзНржиред ржпржЦржи ржПржЬрзЗржирзНржЯ рж╕ржорж░рзНржержи ржЙржкрж▓ржмрзНржз ржерж╛ржХрзЗ, рждржЦржи OpenAI-рж╕рж╛ржоржЮрзНржЬрж╕рзНржпржкрзВрж░рзНржг ржлрж╛ржВрж╢ржи ржХрж▓рж┐ржВрзЯрзЗ ржорж╛ржиржХрж░ржг ржХрж░рждрзЗ ржкрж╛рж░рзЗржи ржЕржержмрж╛ рж╣рж╛ржЗржмрзНрж░рж┐ржб ржбрж┐ржЬрж╛ржЗржирзЗ ржХрзНрж▓рж╛ржЙржб рж╕рж╛ржЗржбрзЗ Azure AI Agents ржмрзНржпржмрж╣рж╛рж░ ржХрж░рждрзЗ ржкрж╛рж░рзЗржиред

> **ЁЯФД ржЖржзрзБржирж┐ржХ SDK-ржПрж░ ржЬржирзНржп ржЖржкржбрзЗржЯ ржХрж░рж╛ рж╣рзЯрзЗржЫрзЗ**: ржПржЗ ржоржбрж┐ржЙрж▓ржЯрж┐ рж╕рж░рзНржмрж╢рзЗрж╖ Microsoft Foundry-Local рж░рж┐ржкрзЛржЬрж┐ржЯрж░рж┐ ржкрзНржпрж╛ржЯрж╛рж░рзНржирзЗрж░ рж╕рж╛ржерзЗ рж╕рж╛ржоржЮрзНржЬрж╕рзНржпржкрзВрж░рзНржг ржПржмржВ `samples/05/`-ржП ржмрзНржпрж╛ржкржХ ржмрж╛рж╕рзНрждржмрж╛рзЯржирзЗрж░ рж╕рж╛ржерзЗ ржорж┐рж▓рзЗ ржпрж╛рзЯред ржЙржжрж╛рж╣рж░ржгржЧрзБрж▓рзЛ ржПржЦржи ржЖржзрзБржирж┐ржХ `foundry-local-sdk` ржПржмржВ `OpenAI` ржХрзНрж▓рж╛рзЯрзЗржирзНржЯ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ, ржорзНржпрж╛ржирзБрзЯрж╛рж▓ ржЕржирзБрж░рзЛржзрзЗрж░ ржкрж░рж┐ржмрж░рзНрждрзЗред

**ЁЯПЧя╕П ржЖрж░рзНржХрж┐ржЯрзЗржХржЪрж╛рж░ рж╣рж╛ржЗрж▓рж╛ржЗржЯрж╕:**
- **ржмрж┐рж╢рзЗрж╖ржЬрзНржЮ ржПржЬрзЗржирзНржЯ**: Retrieval, Reasoning, ржПржмржВ Execution ржПржЬрзЗржирзНржЯрзЗрж░ ржкрзГржержХ рж╕ржХрзНрж╖ржорждрж╛
- **ржХрзЛржЕрж░рзНржбрж┐ржирзЗржЯрж░ ржкрзНржпрж╛ржЯрж╛рж░рзНржи**: ржлрж┐ржбржмрзНржпрж╛ржХ рж▓рзБржк рж╕рж╣ ржмрж╣рзБ-ржПржЬрзЗржирзНржЯ ржУрзЯрж╛рж░рзНржХржлрзНрж▓рзЛ ржЕрж░рзНржХрзЗрж╕рзНржЯрзНрж░рзЗржЯ ржХрж░рзЗ
- **ржЖржзрзБржирж┐ржХ SDK ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржи**: `FoundryLocalManager` ржПржмржВ OpenAI ржХрзНрж▓рж╛рзЯрзЗржирзНржЯ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ
- **ржкрзНрж░рзЛржбрж╛ржХрж╢ржи рж░рзЗржбрж┐**: рждрзНрж░рзБржЯрж┐ ржкрж░рж┐ржЪрж╛рж▓ржирж╛, ржХрж░рзНржоржХрзНрж╖ржорждрж╛ ржкрж░рзНржпржмрзЗржХрзНрж╖ржг, ржПржмржВ рж╕рзНржмрж╛рж╕рзНржерзНржп ржкрж░рзАржХрзНрж╖рж╛ ржЕржирзНрждрж░рзНржнрзБржХрзНржд
- **ржмрзНржпрж╛ржкржХ ржЙржжрж╛рж╣рж░ржг**: ржЙржирзНржиржд ржмрзИрж╢рж┐рж╖рзНржЯрзНржп рж╕рж╣ ржЗржирзНржЯрж╛рж░ржЕрзНржпрж╛ржХржЯрж┐ржн Jupyter ржирзЛржЯржмрзБржХ

**ЁЯУБ рж▓рзЛржХрж╛рж▓ ржмрж╛рж╕рзНрждржмрж╛рзЯржи:**
- `samples/05/multi_agent_orchestration.ipynb` - ржЗржирзНржЯрж╛рж░ржЕрзНржпрж╛ржХржЯрж┐ржн ржЙржжрж╛рж╣рж░ржг ржПржмржВ ржмрзЗржЮрзНржЪржорж╛рж░рзНржХ
- `samples/05/agents/specialists.py` - ржПржЬрзЗржирзНржЯ ржмрж╛рж╕рзНрждржмрж╛рзЯржи
- `samples/05/agents/coordinator.py` - ржЕрж░рзНржХрзЗрж╕рзНржЯрзНрж░рзЗрж╢ржи рж▓ржЬрж┐ржХ

рж░рзЗржлрж╛рж░рзЗржирзНрж╕:
- Foundry Local ржбржХрж╕: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
- Azure AI Foundry Agents: https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- ржлрж╛ржВрж╢ржи ржХрж▓рж┐ржВ ржиржорзБржирж╛ (Foundry Local ржиржорзБржирж╛): https://github.com/microsoft/Foundry-Local/tree/main/samples/python/functioncalling

## рж╢рзЗржЦрж╛рж░ ржЙржжрзНржжрзЗрж╢рзНржп
- ржирж┐рж░рзНржнрж░ржпрзЛржЧрзНржп ржЖржЪрж░ржгрзЗрж░ ржЬржирзНржп рж╕рж┐рж╕рзНржЯрзЗржо ржкрзНрж░ржорзНржкржЯ ржПржмржВ ржЧрзНрж░рж╛ржЙржирзНржбрж┐ржВ ржХрзМрж╢рж▓ ржбрж┐ржЬрж╛ржЗржи ржХрж░рзБржи
- ржлрж╛ржВрж╢ржи ржХрж▓рж┐ржВ (ржЯрзБрж▓ ржмрзНржпржмрж╣рж╛рж░) ржкрзНржпрж╛ржЯрж╛рж░рзНржи ржмрж╛рж╕рзНрждржмрж╛рзЯржи ржХрж░рзБржи
- ржмрж╣рзБ-ржПржЬрзЗржирзНржЯ ржУрзЯрж╛рж░рзНржХржлрзНрж▓рзЛ ржЕрж░рзНржХрзЗрж╕рзНржЯрзНрж░рзЗржЯ ржХрж░рзБржи (рж▓рзЛржХрж╛рж▓ ржПржмржВ рж╣рж╛ржЗржмрзНрж░рж┐ржб)
- ржкрж░рзНржпржмрзЗржХрзНрж╖ржгржпрзЛржЧрзНржпрждрж╛ ржПржмржВ ржирж┐рж░рж╛ржкрждрзНрждрж╛рж░ ржкрж░рж┐ржХрж▓рзНржкржирж╛ ржХрж░рзБржи

## ржЕржВрж╢ рзз: рж╕рж┐рж╕рзНржЯрзЗржо ржкрзНрж░ржорзНржкржЯ ржПржмржВ ржЧрзНрж░рж╛ржЙржирзНржбрж┐ржВ

- ржХржарзЛрж░ ржнрзВржорж┐ржХрж╛, рж╕рзАржорж╛ржмржжрзНржзрждрж╛, ржПржмржВ ржЖржЙржЯржкрзБржЯ рж╕рзНржХрж┐ржорж╛ рж╕ржВржЬрзНржЮрж╛рзЯрж┐ржд ржХрж░рзБржи
- рж▓рзЛржХрж╛рж▓ ржмрж╛ ржПржирзНржЯрж╛рж░ржкрзНрж░рж╛ржЗржЬ ржбрзЗржЯрж╛ ржжрж┐рзЯрзЗ рж░рзЗрж╕ржкржирзНрж╕ ржЧрзНрж░рж╛ржЙржирзНржб ржХрж░рзБржи
- ржбрж╛ржЙржирж╕рзНржЯрзНрж░рж┐ржо ржЕржЯрзЛржорзЗрж╢ржирзЗрж░ ржЬржирзНржп JSON ржЖржЙржЯржкрзБржЯ ржкрзНрж░рзЯрзЛржЧ ржХрж░рзБржи

## ржЕржВрж╢ рзи: ржлрж╛ржВрж╢ржи ржХрж▓рж┐ржВ (ржЖржзрзБржирж┐ржХ SDK ржкржжрзНржзрждрж┐)

```python
# tools.py
import json
from typing import List, Dict, Any

def get_weather(city: str) -> str:
    return f"Weather in {city}: Sunny, 25C"

# Modern tools format for OpenAI API
TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "Get current weather for a city",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {"type": "string", "description": "City name"}
                },
                "required": ["city"]
            }
        }
    }
]
```

```python
# agent.py
from foundry_local import FoundryLocalManager
from openai import OpenAI
import json
from tools import TOOLS, get_weather

# Initialize Foundry Local Manager
alias = "phi-4-mini"
manager = FoundryLocalManager(alias)

# Create OpenAI client using Foundry Local endpoint
client = OpenAI(
    base_url=manager.endpoint,
    api_key=manager.api_key
)

SYSTEM_PROMPT = "You are a helpful assistant. Use tools when needed."

def process_function_call(messages: List[Dict], tools: List[Dict]) -> str:
    """Process function calling with modern OpenAI API."""
    try:
        response = client.chat.completions.create(
            model=manager.get_model_info(alias).id,
            messages=messages,
            tools=tools,
            tool_choice="auto"
        )
        
        message = response.choices[0].message
        
        if message.tool_calls:
            # Handle function calls
            messages.append(message)
            
            for tool_call in message.tool_calls:
                if tool_call.function.name == "get_weather":
                    args = json.loads(tool_call.function.arguments)
                    result = get_weather(args["city"])
                    
                    # Add function result to messages
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": result
                    })
            
            # Get final response
            final_response = client.chat.completions.create(
                model=manager.get_model_info(alias).id,
                messages=messages
            )
            return final_response.choices[0].message.content
        else:
            return message.content
            
    except Exception as e:
        return f"Error: {str(e)}"

# Example usage
messages = [
    {"role": "system", "content": SYSTEM_PROMPT},
    {"role": "user", "content": "What's the weather in Paris?"}
]

result = process_function_call(messages, TOOLS)
print(result)
```

ржЪрж╛рж▓рж╛ржи:
```powershell
# Ensure Foundry Local is running with a model
foundry model run phi-4-mini
python agent.py
```

## ржЕржВрж╢ рзй: ржмрж╣рзБ-ржПржЬрзЗржирзНржЯ ржЕрж░рзНржХрзЗрж╕рзНржЯрзНрж░рзЗрж╢ржи (ржкрзНржпрж╛ржЯрж╛рж░рзНржи)

Foundry Local-ржПрж░ OpenAI-рж╕рж╛ржоржЮрзНржЬрж╕рзНржпржкрзВрж░рзНржг ржПржирзНржбржкрзЯрзЗржирзНржЯ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ Retrieval, Reasoning, Execution ржПржЬрзЗржирзНржЯрзЗрж░ ржХрж╛ржЬ рж╕ржоржирзНржмрзЯ ржХрж░рж╛рж░ ржЬржирзНржп ржПржХржЯрж┐ ржХрзЛржЕрж░рзНржбрж┐ржирзЗржЯрж░ ржбрж┐ржЬрж╛ржЗржи ржХрж░рзБржиред

ржзрж╛ржк рзз) ржЖржзрзБржирж┐ржХ SDK ржжрж┐рзЯрзЗ ржмрж┐рж╢рзЗрж╖ржЬрзНржЮ ржПржЬрзЗржирзНржЯ рж╕ржВржЬрзНржЮрж╛рзЯрж┐ржд ржХрж░рзБржи (ржжрзЗржЦрзБржи `samples/05/agents/specialists.py`)
```python
# agents/specialists.py
from foundry_local import FoundryLocalManager
from openai import OpenAI
from typing import List, Dict, Any

class FoundryClient:
    """Shared client for all specialist agents."""
    
    def __init__(self, model_alias: str = "phi-4-mini"):
        self.client = None
        self.model_name = None
        self.model_alias = model_alias
        self._initialize_client()
    
    def _initialize_client(self):
        """Initialize OpenAI client with Foundry Local."""
        try:
            manager = FoundryLocalManager(self.model_alias)
            model_info = manager.get_model_info(self.model_alias)
            
            self.client = OpenAI(
                base_url=manager.endpoint,
                api_key=manager.api_key
            )
            self.model_name = model_info.id
            print(f"тЬЕ Foundry Local initialized with model: {self.model_name}")
        except Exception as e:
            print(f"тЭМ Error initializing Foundry Local: {e}")
            raise
    
    def chat(self, messages: List[Dict[str, str]], max_tokens: int = 300, temperature: float = 0.4) -> str:
        """Send chat completion request to the model."""
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"Error generating response: {str(e)}"

# Global client instance
_client = FoundryClient()

class RetrievalAgent:
    """Agent specialized in retrieving relevant information from knowledge sources."""
    
    SYSTEM = """You are a specialized retrieval agent. Your job is to extract and retrieve 
    the most relevant information from knowledge sources based on a given query. Focus on key facts, 
    data points, and contextual information that would be useful for decision-making."""
    
    def run(self, query: str) -> str:
        """Retrieve relevant information based on the query."""
        messages = [
            {"role": "system", "content": self.SYSTEM},
            {"role": "user", "content": f"Query: {query}\n\nRetrieve the most relevant key facts, data points, and contextual information that would help answer this query or support decision-making around it."}
        ]
        return _client.chat(messages)

class ReasoningAgent:
    """Agent specialized in step-by-step analysis and reasoning."""
    
    SYSTEM = """You are a specialized reasoning agent. Your job is to analyze inputs 
    step-by-step and produce structured, logical conclusions. Break down complex problems 
    into manageable parts and provide clear reasoning for your conclusions."""
    
    def run(self, context: str, question: str) -> str:
        """Analyze context and question to produce structured conclusions."""
        messages = [
            {"role": "system", "content": self.SYSTEM},
            {"role": "user", "content": f"Context:\n{context}\n\nQuestion: {question}\n\nAnalyze this step-by-step and provide a structured, logical conclusion with clear reasoning."}
        ]
        return _client.chat(messages, max_tokens=400)

class ExecutionAgent:
    """Agent specialized in creating actionable execution plans."""
    
    SYSTEM = """You are a specialized execution agent. Your job is to transform decisions 
    and conclusions into concrete, actionable steps. Always format your response as valid JSON 
    with an array of action items. Each action should be specific, measurable, and achievable."""
    
    def run(self, decision: str) -> str:
        """Transform decision into actionable steps in JSON format."""
        messages = [
            {"role": "system", "content": self.SYSTEM},
            {"role": "user", "content": f"Decision/Conclusion:\n{decision}\n\nCreate 3-5 specific, actionable steps to implement this decision. Format as JSON with this structure:\n{{\"actions\": [{{\"step\": 1, \"description\": \"...\", \"priority\": \"high/medium/low\", \"timeline\": \"...\"}}]}}"}
        ]
        return _client.chat(messages, max_tokens=400, temperature=0.3)
```

ржзрж╛ржк рзи) ржЙржирзНржиржд ржмрзИрж╢рж┐рж╖рзНржЯрзНржп рж╕рж╣ ржХрзЛржЕрж░рзНржбрж┐ржирзЗржЯрж░ рждрзИрж░рж┐ ржХрж░рзБржи
```python
# agents/coordinator.py
from .specialists import RetrievalAgent, ReasoningAgent, ExecutionAgent
from typing import Dict, Any
import time
import json

class Coordinator:
    """Multi-agent coordinator that orchestrates specialist agents to handle complex tasks."""
    
    def __init__(self):
        """Initialize the coordinator with specialist agents."""
        self.retrieval = RetrievalAgent()
        self.reasoning = ReasoningAgent()
        self.execution = ExecutionAgent()
    
    def handle(self, user_goal: str) -> Dict[str, Any]:
        """
        Orchestrate multiple agents to handle a complex user goal.
        
        Args:
            user_goal: The user's high-level goal or request
            
        Returns:
            Dictionary containing the goal, context, decision, and actions
        """
        print(f"ЁЯОп **Coordinator:** Processing goal: {user_goal}")
        print("=" * 60)
        
        start_time = time.time()
        
        # Step 1: Retrieve relevant context
        print("ЁЯУЪ **Step 1:** Retrieving context...")
        context = self.retrieval.run(user_goal)
        print(f"   тЬЕ Context retrieved ({len(context)} chars)")
        
        # Step 2: Analyze and reason about the context
        print("ЁЯза **Step 2:** Analyzing and reasoning...")
        decision = self.reasoning.run(context, user_goal)
        print(f"   тЬЕ Analysis completed ({len(decision)} chars)")
        
        # Step 3: Create actionable execution plan
        print("тЪб **Step 3:** Creating execution plan...")
        actions = self.execution.run(decision)
        print(f"   тЬЕ Execution plan created ({len(actions)} chars)")
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        result = {
            "goal": user_goal,
            "context": context,
            "decision": decision,
            "actions": actions,
            "agent_flow": ["retrieval", "reasoning", "execution"],
            "processing_time": processing_time,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        
        print(f"тЬЕ **Coordination Complete** (тП▒я╕П {processing_time:.2f}s)")
        return result
    
    def handle_with_feedback(self, user_goal: str, feedback_rounds: int = 1) -> Dict[str, Any]:
        """
        Handle a goal with multiple feedback rounds for refinement.
        
        Args:
            user_goal: The user's high-level goal or request
            feedback_rounds: Number of feedback rounds to perform
            
        Returns:
            Dictionary containing the refined result
        """
        result = self.handle(user_goal)
        
        for round_num in range(feedback_rounds):
            print(f"\nЁЯФД **Feedback Round {round_num + 1}:**")
            print("-" * 40)
            
            # Use reasoning agent to refine the execution plan
            refinement_prompt = f"""
            Original Goal: {user_goal}
            Current Decision: {result['decision']}
            Current Actions: {result['actions']}
            
            Review the above and suggest improvements or refinements to make the execution plan more effective.
            """
            
            refined_decision = self.reasoning.run(result['context'], refinement_prompt)
            refined_actions = self.execution.run(refined_decision)
            
            result['decision'] = refined_decision
            result['actions'] = refined_actions
            result['refinement_rounds'] = round_num + 1
            
            print(f"   тЬЕ Round {round_num + 1} refinement completed")
        
        return result

def main():
    """Main function demonstrating the multi-agent coordinator."""
    print("ЁЯдЦ **Multi-Agent Coordinator Demo**")
    print("=" * 50)
    
    # Create coordinator
    coord = Coordinator()
    
    # Example goals
    example_goals = [
        "Create a plan to onboard 5 new customers this month",
        "Develop a strategy to improve team productivity by 20%",
        "Design a customer feedback collection system"
    ]
    
    # Process example with feedback
    goal = example_goals[0]
    print(f"ЁЯОп **Processing Goal:** {goal}")
    print("-" * 50)
    
    try:
        # Basic processing
        result = coord.handle(goal)
        
        # With feedback refinement
        refined_result = coord.handle_with_feedback(goal, feedback_rounds=1)
        
        print("\nЁЯУК **Final Result:**")
        print("=" * 50)
        print(f"**Goal:** {refined_result['goal']}")
        print(f"**Processing Time:** {refined_result['processing_time']:.2f}s")
        
        # Try to parse actions as JSON
        try:
            actions_json = json.loads(refined_result['actions'])
            print(f"\n**Formatted Actions:**")
            print(json.dumps(actions_json, indent=2))
        except (json.JSONDecodeError, TypeError):
            print(f"\n**Actions:** {refined_result['actions']}")
            
    except Exception as e:
        print(f"тЭМ **Error:** {e}")
        print("\nPlease ensure Foundry Local is running with a model loaded.")

if __name__ == "__main__":
    main()
```

ржзрж╛ржк рзй) Foundry Local-ржПрж░ рж╕рж╛ржерзЗ ржпрж╛ржЪрж╛ржЗ ржХрж░рзБржи ржПржмржВ ржиржорзБржирж╛ ржЪрж╛рж▓рж╛ржи
```powershell
REM Confirm the local endpoint and model are available
foundry model list
foundry model run phi-4-mini
curl http://localhost:8000/v1/models

REM Run the coordinator from Module08 directory
cd Module08
python -m samples.05.agents.coordinator

REM Or explore the comprehensive Jupyter notebook
jupyter notebook samples/05/multi_agent_orchestration.ipynb
```

> **ЁЯУЪ рж▓рзЛржХрж╛рж▓ ржиржорзБржирж╛ рж░рзЗржлрж╛рж░рзЗржирзНрж╕:**
> - **ржорзВрж▓ ржмрж╛рж╕рзНрждржмрж╛рзЯржи**: `samples/05/agents/specialists.py` ржПржмржВ `samples/05/agents/coordinator.py`
> - **ржмрзНржпрж╛ржкржХ ржЙржжрж╛рж╣рж░ржг**: `samples/05/multi_agent_orchestration.ipynb`
> - **рж╕рзЗржЯржЖржк ржирж┐рж░рзНржжрзЗрж╢ржирж╛**: `samples/05/README.md`
> 
> **ЁЯФЧ рж╕ржорзНржкрж░рзНржХрж┐ржд Foundry Local ржиржорзБржирж╛:**
> - [ржлрж╛ржВрж╢ржи ржХрж▓рж┐ржВ ржиржорзБржирж╛](https://github.com/microsoft/Foundry-Local/tree/main/samples/python/functioncalling)
> - [Hello Foundry Local](https://github.com/microsoft/Foundry-Local/tree/main/samples/python/hello-foundry-local)

ржирж┐рж░рзНржжрзЗрж╢рж┐ржХрж╛:
- ржПржЬрзЗржирзНржЯрзЗрж░ ржоржзрзНржпрзЗ ржкрзБржирж░рж╛рзЯ ржЪрзЗрж╖рзНржЯрж╛ ржПржмржВ ржЯрж╛ржЗржоржЖржЙржЯ ржкрзНрж░рзЯрзЛржЧ ржХрж░рзБржи
- ржХржерзЛржкржХржержи/ржерзНрж░рзЗржб рж╕рзНржЯрзЗржЯрзЗрж░ ржЬржирзНржп ржПржХржЯрж┐ ржЫрзЛржЯ ржЗржи-ржорзЗржорж░рж┐ рж╕рзНржЯрзЛрж░ (dict) ржпрзЛржЧ ржХрж░рзБржи
- ржПржХрж╛ржзрж┐ржХ ржХрж▓ ржЪрзЗржЗржи ржХрж░рж╛рж░ рж╕ржорзЯ рж░рзЗржЯ-рж▓рж┐ржорж┐ржЯрж┐ржВ ржЪрж╛рж▓рзБ ржХрж░рзБржи

## ржЕржВрж╢ рзк: ржкрж░рзНржпржмрзЗржХрзНрж╖ржгржпрзЛржЧрзНржпрждрж╛ ржПржмржВ ржирж┐рж░рж╛ржкрждрзНрждрж╛

ржкрзНрж░ржорзНржкржЯ, рж░рзЗрж╕ржкржирзНрж╕, ржПржмржВ рждрзНрж░рзБржЯрж┐ рж▓рзЛржХрж╛рж▓ржнрж╛ржмрзЗ ржЯрзНрж░рзНржпрж╛ржХ ржХрж░рзБржи, ржПржЬрзЗржирзНржЯ рж╕рзНржЯрзНржпрж╛ржХрзЗ ржбрзЗржЯрж╛ рж╣рж╛ржЗржЬрж┐ржи ржкрзНрж░рзЯрзЛржЧ ржХрж░рзБржиред

ржзрж╛ржк рзз) рж╣рж╛рж▓ржХрж╛ ржЕржирзБрж░рзЛржз рж▓ржЧрж┐ржВ (ржРржЪрзНржЫрж┐ржХ)

ржирзЛржЯ: ржирж┐ржорзНржирж▓рж┐ржЦрж┐ржд рж╣рзЗрж▓рзНржкрж╛рж░ ржбрж┐ржлрж▓рзНржЯржнрж╛ржмрзЗ ржЕржирзНрждрж░рзНржнрзБржХрзНржд ржирзЯред ржкрж░рзАржХрзНрж╖рж╛рж░ ржЬржирзНржп рж▓рзЛржХрж╛рж▓ JSON рж▓ржЧрж┐ржВ ржХрж░рждрзЗ ржЪрж╛ржЗрж▓рзЗ `infra/obs.py` рждрзИрж░рж┐ ржХрж░рзБржиред
```python
# infra/obs.py
import time, json, os
from datetime import datetime

LOG_DIR = os.getenv("FOUNDRY_AGENT_LOG_DIR", "./agent_logs")
os.makedirs(LOG_DIR, exist_ok=True)

def log_event(kind: str, payload: dict):
    ts = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
    path = os.path.join(LOG_DIR, f"{ts}_{kind}.json")
    with open(path, "w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2)
```

ржПржЬрзЗржирзНржЯрзЗ рж▓ржЧрж┐ржВ ржЗржирзНржЯрж┐ржЧрзНрж░рзЗржЯ ржХрж░рзБржи (ржРржЪрзНржЫрж┐ржХ):
```python
# in agents/specialists.py after receiving content
from infra.obs import log_event
# ... inside chat(...)
resp = r.json()
log_event("chat_request", {"endpoint": f"{BASE_URL}/v1/chat/completions"})
log_event("chat_response", resp)
return resp["choices"][0]["message"]["content"]
```

ржзрж╛ржк рзи) CLI ржжрж┐рзЯрзЗ ржЙржкрж▓ржмрзНржзрждрж╛ ржПржмржВ ржорзМрж▓рж┐ржХ рж╕рзНржмрж╛рж╕рзНржерзНржп ржпрж╛ржЪрж╛ржЗ ржХрж░рзБржи
```powershell
REM Ensure Foundry Local is running a model
foundry model list
foundry model run phi-4-mini

REM Validate the OpenAI-compatible endpoint
curl http://localhost:8000/v1/models
```

ржзрж╛ржк рзй) рж░рзЗржбрж╛ржХрж╢ржи ржПржмржВ PII рж╣рж╛ржЗржЬрж┐ржи
- ржоржбрзЗрж▓рзЗ ржмрж╛рж░рзНрждрж╛ ржкрж╛ржарж╛ржирзЛрж░ ржЖржЧрзЗ рж╕ржВржмрзЗржжржирж╢рзАрж▓ ржХрзНрж╖рзЗрждрзНрж░ (ржЗржорзЗржЗрж▓, ржлрзЛржи ржиржорзНржмрж░, ржЖржЗржбрж┐) ржорзБржЫрзЗ ржлрзЗрж▓рзБржи ржмрж╛ рж╣рзНржпрж╛рж╢ ржХрж░рзБржи
- ржХрж╛ржБржЪрж╛ рж╕рзЛрж░рзНрж╕ ржбрзЗржЯрж╛ ржбрж┐ржнрж╛ржЗрж╕рзЗ рж░рж╛ржЦрзБржи, рж╢рзБржзрзБржорж╛рждрзНрж░ ржкрзНрж░рзЯрзЛржЬржирзАрзЯ ржкрзНрж░рж╕ржЩрзНржЧ рж╕рзНржЯрзНрж░рж┐ржВ ржкрж╛ржарж╛ржи

рж░рзЗржбрж╛ржХрж╢ржи рж╣рзЗрж▓рзНржкрж╛рж░рзЗрж░ ржЙржжрж╛рж╣рж░ржг:
```python
# infra/redact.py
import re
EMAIL_RE = re.compile(r"[\w\.-]+@[\w\.-]+")
PHONE_RE = re.compile(r"\+?\d[\d\s\-]{7,}\d")

def sanitize(text: str) -> str:
    text = EMAIL_RE.sub("[REDACTED_EMAIL]", text)
    text = PHONE_RE.sub("[REDACTED_PHONE]", text)
    return text
```

ржПржЬрзЗржирзНржЯрзЗ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи:
```python
from infra.redact import sanitize
# user_goal = sanitize(user_goal)
# context = sanitize(context)
```

ржзрж╛ржк рзк) рж╕рж╛рж░рзНржХрж┐ржЯ ржмрзНрж░рзЗржХрж╛рж░ ржПржмржВ рждрзНрж░рзБржЯрж┐ ржкрж░рж┐ржЪрж╛рж▓ржирж╛
- ржкрзНрж░рждрж┐ржЯрж┐ ржПржЬрзЗржирзНржЯ ржХрж▓ try/except ржПржмржВ ржПржХрзНрж╕ржкрзЛржирзЗржирж╢рж┐рзЯрж╛рж▓ ржмрзНржпрж╛ржХржЕржл ржжрж┐рзЯрзЗ ржорзЛрзЬрж╛ржи
- ржкрзБржирж░рж╛ржмрзГрждрзНржд рждрзНрж░рзБржЯрж┐рж░ ржХрзНрж╖рзЗрждрзНрж░рзЗ ржкрж╛ржЗржкрж▓рж╛ржЗржи рж╢рж░рзНржЯ-рж╕рж╛рж░рзНржХрж┐ржЯ ржХрж░рзБржи

```python
import time

def with_retry(func, retries=3, base_delay=0.5):
    for i in range(retries):
        try:
            return func()
        except Exception as e:
            if i == retries - 1:
                raise
            time.sleep(base_delay * (2 ** i))
```

ржзрж╛ржк рзл) рж▓рзЛржХрж╛рж▓ ржЕржбрж┐ржЯ ржЯрзНрж░рзЗржЗрж▓ ржПржмржВ ржПржХрзНрж╕ржкрзЛрж░рзНржЯ
- JSON рж▓ржЧ `./agent_logs`-ржП рж╕ржВрж░ржХрзНрж╖ржг ржХрж░рзБржи
- ржирж┐рзЯржорж┐ржд рж▓ржЧ ржХржоржкрзНрж░рзЗрж╕ ржПржмржВ рж░рзЛржЯрзЗржЯ ржХрж░рзБржи
- ржкрж░рзНржпрж╛рж▓рзЛржЪржирж╛рж░ ржЬржирзНржп рж╕рж╛рж░рж╛ржВрж╢ ржПржХрзНрж╕ржкрзЛрж░рзНржЯ ржХрж░рзБржи (ржЧржгржирж╛, ржЧрзЬ рж▓рзЗржЯрзЗржирзНрж╕рж┐, рждрзНрж░рзБржЯрж┐ рж╣рж╛рж░)

ржзрж╛ржк рзм) Microsoft Learn ржбржХрж╕рзЗрж░ рж╕рж╛ржерзЗ ржХрзНрж░рж╕-ржЪрзЗржХ ржХрж░рзБржи
- Foundry Local ржПржХржЯрж┐ OpenAI-рж╕рж╛ржоржЮрзНржЬрж╕рзНржпржкрзВрж░рзНржг API рж╕рж░ржмрж░рж╛рж╣ ржХрж░рзЗ (`curl /v1/models` ржжрж┐рзЯрзЗ ржпрж╛ржЪрж╛ржЗ ржХрж░рж╛ рж╣рзЯрзЗржЫрзЗ)
- ржоржбрзЗрж▓рзЗрж░ ржЙржкрж▓ржмрзНржзрждрж╛ ржирж┐рж╢рзНржЪрж┐ржд ржХрж░рждрзЗ `foundry model run <name>` ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи
- ржХрзНрж▓рж╛рзЯрзЗржирзНржЯ ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржи ржПржмржВ ржиржорзБржирж╛ ржЕрзНржпрж╛ржкрзЗрж░ ржЬржирзНржп ржЕржлрж┐рж╕рж┐рзЯрж╛рж▓ ржирж┐рж░рзНржжрзЗрж╢рж┐ржХрж╛ ржЕржирзБрж╕рж░ржг ржХрж░рзБржи (Open WebUI/how-tos)

рж░рзЗржлрж╛рж░рзЗржирзНрж╕
- **Foundry Local ржбржХрзБржорзЗржирзНржЯрзЗрж╢ржи**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/
- **Azure AI Agents**: https://learn.microsoft.com/en-us/azure/ai-services/agents/overview
- **рж▓рзЛржХрж╛рж▓ ржиржорзБржирж╛**:
  - ржмрж╣рзБ-ржПржЬрзЗржирзНржЯ ржЕрж░рзНржХрзЗрж╕рзНржЯрзНрж░рзЗрж╢ржи: `Module08/samples/05/multi_agent_orchestration.ipynb`
  - ржПржЬрзЗржирзНржЯ ржмрж╛рж╕рзНрждржмрж╛рзЯржи: `Module08/samples/05/agents/`
  - ржиржорзБржирж╛ README: `Module08/samples/05/README.md`
- **ржЕржлрж┐рж╕рж┐рзЯрж╛рж▓ Microsoft ржиржорзБржирж╛**:
  - [ржлрж╛ржВрж╢ржи ржХрж▓рж┐ржВ](https://github.com/microsoft/Foundry-Local/tree/main/samples/python/functioncalling)
  - [Hello Foundry Local](https://github.com/microsoft/Foundry-Local/tree/main/samples/python/hello-foundry-local)
  - [Foundry Local Python SDK](https://github.com/microsoft/Foundry-Local/tree/main/sdk/python)
- **ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржи ржЙржжрж╛рж╣рж░ржг**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-chat-application-with-open-web-ui

## ржкрж░ржмрж░рзНрждрзА ржкржжржХрзНрж╖рзЗржк
- ржХрзНрж▓рж╛ржЙржб-рж╣рзЛрж╕рзНржЯрзЗржб ржЕрж░рзНржХрзЗрж╕рзНржЯрзНрж░рзЗрж╢ржирзЗрж░ ржЬржирзНржп Azure AI Agents ржЕржирзНржмрзЗрж╖ржг ржХрж░рзБржи
- ржПржирзНржЯрж╛рж░ржкрзНрж░рж╛ржЗржЬ ржХрж╛ржирзЗржХрзНржЯрж░ ржпрзЛржЧ ржХрж░рзБржи (Microsoft Graph, Search, ржбрзЗржЯрж╛ржмрзЗрж╕)

---

