<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6503a980cb3bf2b2de2d2bc4ac6acc4c",
  "translation_date": "2025-09-24T15:03:51+00:00",
  "source_file": "Module08/01.FoundryLocalSetup.md",
  "language_code": "bn"
}
-->
# ‡¶∏‡ßá‡¶∂‡¶® ‡ßß: Foundry Local ‡¶è‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ï‡¶∞‡¶æ

## ‡¶∏‡¶Ç‡¶ï‡ßç‡¶∑‡¶ø‡¶™‡ßç‡¶§ ‡¶¨‡¶ø‡¶¨‡¶∞‡¶£

Microsoft Foundry Local ‡¶∏‡¶∞‡¶æ‡¶∏‡¶∞‡¶ø ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ Windows 11 ‡¶°‡ßá‡¶≠‡ßá‡¶≤‡¶™‡¶Æ‡ßá‡¶®‡ßç‡¶ü ‡¶™‡¶∞‡¶ø‡¶¨‡ßá‡¶∂‡ßá Azure AI Foundry ‡¶è‡¶∞ ‡¶ï‡ßç‡¶∑‡¶Æ‡¶§‡¶æ ‡¶®‡¶ø‡¶Ø‡¶º‡ßá ‡¶Ü‡¶∏‡ßá, ‡¶Ø‡¶æ ‡¶ó‡ßã‡¶™‡¶®‡ßÄ‡¶Ø‡¶º‡¶§‡¶æ-‡¶∏‡¶Ç‡¶∞‡¶ï‡ßç‡¶∑‡¶£‡¶ï‡¶æ‡¶∞‡ßÄ, ‡¶ï‡¶Æ-‡¶≤‡ßá‡¶ü‡ßá‡¶®‡ßç‡¶∏‡¶ø AI ‡¶°‡ßá‡¶≠‡ßá‡¶≤‡¶™‡¶Æ‡ßá‡¶®‡ßç‡¶ü‡¶ï‡ßá ‡¶è‡¶®‡ßç‡¶ü‡¶æ‡¶∞‡¶™‡ßç‡¶∞‡¶æ‡¶á‡¶ú-‡¶ó‡ßç‡¶∞‡ßá‡¶° ‡¶ü‡ßÅ‡¶≤‡¶∏‡ßá‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶∏‡¶ï‡ßç‡¶∑‡¶Æ ‡¶ï‡¶∞‡ßá‡•§ ‡¶è‡¶á ‡¶∏‡ßá‡¶∂‡¶®‡ßá ‡¶ú‡¶®‡¶™‡ßç‡¶∞‡¶ø‡¶Ø‡¶º ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶Ø‡ßá‡¶Æ‡¶® phi, qwen, deepseek, ‡¶è‡¶¨‡¶Ç GPT-OSS-20B ‡¶è‡¶∞ ‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶á‡¶®‡¶∏‡ßç‡¶ü‡¶≤‡ßá‡¶∂‡¶®, ‡¶ï‡¶®‡¶´‡¶ø‡¶ó‡¶æ‡¶∞‡ßá‡¶∂‡¶® ‡¶è‡¶¨‡¶Ç ‡¶π‡¶æ‡¶§‡ßá-‡¶ï‡¶≤‡¶Æ‡ßá ‡¶°‡¶ø‡¶™‡ßç‡¶≤‡¶Ø‡¶º‡¶Æ‡ßá‡¶®‡ßç‡¶ü ‡¶ï‡¶≠‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá‡•§

## ‡¶∂‡ßá‡¶ñ‡¶æ‡¶∞ ‡¶≤‡¶ï‡ßç‡¶∑‡ßç‡¶Ø‡¶∏‡¶Æ‡ßÇ‡¶π

‡¶è‡¶á ‡¶∏‡ßá‡¶∂‡¶®‡ßá‡¶∞ ‡¶∂‡ßá‡¶∑‡ßá, ‡¶Ü‡¶™‡¶®‡¶ø:
- Windows 11-‡¶è Foundry Local ‡¶á‡¶®‡¶∏‡ßç‡¶ü‡¶≤ ‡¶è‡¶¨‡¶Ç ‡¶ï‡¶®‡¶´‡¶ø‡¶ó‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶¨‡ßá‡¶®
- CLI ‡¶ï‡¶Æ‡¶æ‡¶®‡ßç‡¶° ‡¶è‡¶¨‡¶Ç ‡¶ï‡¶®‡¶´‡¶ø‡¶ó‡¶æ‡¶∞‡ßá‡¶∂‡¶® ‡¶Ö‡¶™‡¶∂‡¶®‡¶ó‡ßÅ‡¶≤‡ßã ‡¶Ü‡¶Ø‡¶º‡¶§‡ßç‡¶§ ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶¨‡ßá‡¶®
- ‡¶Ö‡¶™‡ßç‡¶ü‡¶ø‡¶Æ‡¶æ‡¶≤ ‡¶™‡¶æ‡¶∞‡¶´‡¶∞‡¶Æ‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶∏‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ï‡ßç‡¶Ø‡¶æ‡¶∂‡¶ø‡¶Ç ‡¶ï‡ßå‡¶∂‡¶≤ ‡¶¨‡ßÅ‡¶ù‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶¨‡ßá‡¶®
- phi, qwen, deepseek, ‡¶è‡¶¨‡¶Ç GPT-OSS-20B ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶∏‡¶´‡¶≤‡¶≠‡¶æ‡¶¨‡ßá ‡¶ö‡¶æ‡¶≤‡¶æ‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶¨‡ßá‡¶®
- Foundry Local ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶•‡¶Æ AI ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶™‡ßç‡¶≤‡¶ø‡¶ï‡ßá‡¶∂‡¶® ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶¨‡ßá‡¶®

## ‡¶™‡ßÇ‡¶∞‡ßç‡¶¨‡¶∂‡¶∞‡ßç‡¶§

### ‡¶∏‡¶ø‡¶∏‡ßç‡¶ü‡ßá‡¶Æ‡ßá‡¶∞ ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ú‡¶®‡ßÄ‡¶Ø‡¶º‡¶§‡¶æ
- **Windows 11**: ‡¶∏‡¶Ç‡¶∏‡ßç‡¶ï‡¶∞‡¶£ 22H2 ‡¶¨‡¶æ ‡¶§‡¶æ‡¶∞ ‡¶™‡¶∞‡¶¨‡¶∞‡ßç‡¶§‡ßÄ
- **RAM**: ‡¶®‡ßç‡¶Ø‡ßÇ‡¶®‡¶§‡¶Æ 16GB, ‡¶∏‡ßÅ‡¶™‡¶æ‡¶∞‡¶ø‡¶∂‡¶ï‡ßÉ‡¶§ 32GB
- **‡¶∏‡ßç‡¶ü‡ßã‡¶∞‡ßá‡¶ú**: ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶è‡¶¨‡¶Ç ‡¶ï‡ßç‡¶Ø‡¶æ‡¶∂‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø 50GB ‡¶´‡ßç‡¶∞‡¶ø ‡¶∏‡ßç‡¶™‡ßá‡¶∏
- **‡¶π‡¶æ‡¶∞‡ßç‡¶°‡¶ì‡¶Ø‡¶º‡ßç‡¶Ø‡¶æ‡¶∞**: NPU- ‡¶¨‡¶æ GPU-‡¶∏‡¶ï‡ßç‡¶∑‡¶Æ ‡¶°‡¶ø‡¶≠‡¶æ‡¶á‡¶∏ (Copilot+ PC ‡¶¨‡¶æ NVIDIA GPU) ‡¶™‡¶õ‡¶®‡ßç‡¶¶‡¶®‡ßÄ‡¶Ø‡¶º
- **‡¶®‡ßá‡¶ü‡¶ì‡¶Ø‡¶º‡¶æ‡¶∞‡ßç‡¶ï**: ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶°‡¶æ‡¶â‡¶®‡¶≤‡ßã‡¶°‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶â‡¶ö‡ßç‡¶ö-‡¶ó‡¶§‡¶ø‡¶∞ ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡¶∞‡¶®‡ßá‡¶ü

### ‡¶°‡ßá‡¶≠‡ßá‡¶≤‡¶™‡¶Æ‡ßá‡¶®‡ßç‡¶ü ‡¶™‡¶∞‡¶ø‡¶¨‡ßá‡¶∂
```powershell
# Verify Windows version
winver

# Check available memory
Get-ComputerInfo | Select-Object TotalPhysicalMemory

# Verify PowerShell version (5.1+ required)
$PSVersionTable.PSVersion

# Set up Python environment (recommended)
py -m venv .venv
.venv\Scripts\activate

# Install required dependencies
pip install openai foundry-local-sdk
```

## ‡¶Ö‡¶Ç‡¶∂ ‡ßß: ‡¶á‡¶®‡¶∏‡ßç‡¶ü‡¶≤‡ßá‡¶∂‡¶® ‡¶è‡¶¨‡¶Ç ‡¶∏‡ßá‡¶ü‡¶Ü‡¶™

### ‡¶ß‡¶æ‡¶™ ‡ßß: Foundry Local ‡¶á‡¶®‡¶∏‡ßç‡¶ü‡¶≤ ‡¶ï‡¶∞‡ßÅ‡¶®

Winget ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶¨‡¶æ GitHub ‡¶•‡ßá‡¶ï‡ßá ‡¶á‡¶®‡¶∏‡ßç‡¶ü‡¶≤‡¶æ‡¶∞ ‡¶°‡¶æ‡¶â‡¶®‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßá Foundry Local ‡¶á‡¶®‡¶∏‡ßç‡¶ü‡¶≤ ‡¶ï‡¶∞‡ßÅ‡¶®:

```powershell
# Winget (Windows)
winget install --id Microsoft.FoundryLocal --source winget

# Alternatively: download installer from the official repo
# https://aka.ms/foundry-local-installer
```

### ‡¶ß‡¶æ‡¶™ ‡ß®: ‡¶á‡¶®‡¶∏‡ßç‡¶ü‡¶≤‡ßá‡¶∂‡¶® ‡¶Ø‡¶æ‡¶ö‡¶æ‡¶á ‡¶ï‡¶∞‡ßÅ‡¶®

```powershell
# Check Foundry Local version
foundry --version

# Verify CLI accessibility and categories
foundry --help
foundry model --help
foundry cache --help
foundry service --help
```

## ‡¶Ö‡¶Ç‡¶∂ ‡ß®: CLI ‡¶¨‡ßÅ‡¶ù‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶æ

### ‡¶Æ‡ßÇ‡¶≤ ‡¶ï‡¶Æ‡¶æ‡¶®‡ßç‡¶°‡ßá‡¶∞ ‡¶ï‡¶æ‡¶†‡¶æ‡¶Æ‡ßã

```powershell
# General command structure
foundry [category] [command] [options]

# Main categories
foundry model   # manage and run models
foundry service # manage the local service
foundry cache   # manage local model cache

# Common commands
foundry model list              # list available models
foundry model run phi-4-mini  # run a model (downloads as needed)
foundry cache ls                # list cached models
```


## ‡¶Ö‡¶Ç‡¶∂ ‡ß©: ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ï‡ßç‡¶Ø‡¶æ‡¶∂‡¶ø‡¶Ç ‡¶è‡¶¨‡¶Ç ‡¶¨‡ßç‡¶Ø‡¶¨‡¶∏‡ßç‡¶•‡¶æ‡¶™‡¶®‡¶æ

Foundry Local ‡¶™‡¶æ‡¶∞‡¶´‡¶∞‡¶Æ‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶∏ ‡¶è‡¶¨‡¶Ç ‡¶∏‡ßç‡¶ü‡ßã‡¶∞‡ßá‡¶ú ‡¶Ö‡¶™‡ßç‡¶ü‡¶ø‡¶Æ‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶¨‡ßÅ‡¶¶‡ßç‡¶ß‡¶ø‡¶Æ‡¶æ‡¶® ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ï‡ßç‡¶Ø‡¶æ‡¶∂‡¶ø‡¶Ç ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ó ‡¶ï‡¶∞‡ßá:

```powershell
# Show cache contents
foundry cache ls

# Optional: change cache directory (advanced)
foundry cache cd "C:\\FoundryLocal\\Cache"
foundry cache ls
```

## ‡¶Ö‡¶Ç‡¶∂ ‡ß™: ‡¶π‡¶æ‡¶§‡ßá-‡¶ï‡¶≤‡¶Æ‡ßá ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶°‡¶ø‡¶™‡ßç‡¶≤‡¶Ø‡¶º‡¶Æ‡ßá‡¶®‡ßç‡¶ü

### Microsoft Phi ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ö‡¶æ‡¶≤‡¶æ‡¶®‡ßã

```powershell
# List catalog and run Phi (auto-downloads best variant for your hardware)
foundry model list
foundry model run phi-4-mini
```

### Qwen ‡¶Æ‡¶°‡ßá‡¶≤‡ßá‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶ï‡¶æ‡¶ú ‡¶ï‡¶∞‡¶æ

```powershell
# Run Qwen2.5 models (downloads on first run)
foundry model run qwen2.5-7b-instruct
foundry model run qwen2.5-14b-instruct
```

### DeepSeek ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ö‡¶æ‡¶≤‡¶æ‡¶®‡ßã

```powershell
# Run DeepSeek model
foundry model run deepseek-r1-distill-qwen-7b
```

### GPT-OSS-20B ‡¶ö‡¶æ‡¶≤‡¶æ‡¶®‡ßã

```powershell
# Run the latest OpenAI open-source model (requires recent Foundry Local and sufficient GPU VRAM)
foundry model run gpt-oss-20b

# Check version if you encounter errors (requires 0.6.87+ per docs)
foundry --version
```

## ‡¶Ö‡¶Ç‡¶∂ ‡ß´: ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶•‡¶Æ ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶™‡ßç‡¶≤‡¶ø‡¶ï‡ßá‡¶∂‡¶® ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶æ

### ‡¶Ü‡¶ß‡ßÅ‡¶®‡¶ø‡¶ï ‡¶ö‡ßç‡¶Ø‡¶æ‡¶ü ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶™‡ßç‡¶≤‡¶ø‡¶ï‡ßá‡¶∂‡¶® (OpenAI SDK + Foundry Local)

Foundry Local ‡¶á‡¶®‡ßç‡¶ü‡¶ø‡¶ó‡ßç‡¶∞‡ßá‡¶∂‡¶® ‡¶∏‡¶π OpenAI SDK ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶è‡¶ï‡¶ü‡¶ø ‡¶™‡ßç‡¶∞‡ßã‡¶°‡¶æ‡¶ï‡¶∂‡¶®-‡¶∞‡ßá‡¶°‡¶ø ‡¶ö‡ßç‡¶Ø‡¶æ‡¶ü ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶™‡ßç‡¶≤‡¶ø‡¶ï‡ßá‡¶∂‡¶® ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®, ‡¶Ü‡¶Æ‡¶æ‡¶¶‡ßá‡¶∞ Sample 01 ‡¶è‡¶∞ ‡¶™‡ßç‡¶Ø‡¶æ‡¶ü‡¶æ‡¶∞‡ßç‡¶® ‡¶Ö‡¶®‡ßÅ‡¶∏‡¶∞‡¶£ ‡¶ï‡¶∞‡ßá‡•§

```python
# chat_quickstart.py (Sample 01 pattern)
import os
import sys
from openai import OpenAI

try:
    from foundry_local import FoundryLocalManager
    FOUNDRY_SDK_AVAILABLE = True
except ImportError:
    FOUNDRY_SDK_AVAILABLE = False
    print("‚ö†Ô∏è Install foundry-local-sdk: pip install foundry-local-sdk")

def create_client():
    """Create OpenAI client with Foundry Local or Azure OpenAI."""
    # Check for Azure OpenAI configuration
    azure_endpoint = os.environ.get("AZURE_OPENAI_ENDPOINT")
    azure_api_key = os.environ.get("AZURE_OPENAI_API_KEY")
    
    if azure_endpoint and azure_api_key:
        # Azure OpenAI path
        model = os.environ.get("MODEL", "your-deployment-name")
        client = OpenAI(
            base_url=f"{azure_endpoint}/openai",
            api_key=azure_api_key,
            default_query={"api-version": "2024-08-01-preview"},
        )
        print(f"üåê Using Azure OpenAI with model: {model}")
        return client, model
    
    # Foundry Local path with SDK management
    alias = os.environ.get("MODEL", "phi-4-mini")
    if FOUNDRY_SDK_AVAILABLE:
        try:
            # Use FoundryLocalManager for proper service management
            manager = FoundryLocalManager(alias)
            model_info = manager.get_model_info(alias)
            
            client = OpenAI(
                base_url=manager.endpoint,
                api_key=manager.api_key
            )
            model = model_info.id
            print(f"üè† Using Foundry Local SDK with model: {model}")
            return client, model
        except Exception as e:
            print(f"‚ö†Ô∏è Foundry SDK failed ({e}), using manual configuration")
    
    # Fallback to manual configuration
    base_url = os.environ.get("BASE_URL", "http://localhost:8000")
    api_key = os.environ.get("API_KEY", "")
    model = alias
    
    client = OpenAI(
        base_url=f"{base_url}/v1",
        api_key=api_key
    )
    print(f"üîß Manual configuration with model: {model}")
    return client, model

def main():
    """Main chat function."""
    client, model = create_client()
    
    print("Foundry Local Chat Interface (type 'quit' to exit)\n")
    conversation_history = []
    
    while True:
        user_input = input("You: ")
        if user_input.lower() == 'quit':
            break
        
        try:
            # Add user message to history
            conversation_history.append({"role": "user", "content": user_input})
            
            # Create chat completion
            response = client.chat.completions.create(
                model=model,
                messages=conversation_history,
                max_tokens=500,
                temperature=0.7
            )
            
            assistant_message = response.choices[0].message.content
            conversation_history.append({"role": "assistant", "content": assistant_message})
            
            print(f"Assistant: {assistant_message}\n")
            
        except Exception as e:
            print(f"Error: {e}\n")

if __name__ == "__main__":
    main()
```

### ‡¶ö‡ßç‡¶Ø‡¶æ‡¶ü ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶™‡ßç‡¶≤‡¶ø‡¶ï‡ßá‡¶∂‡¶® ‡¶ö‡¶æ‡¶≤‡¶æ‡¶®

```powershell
# Ensure the model is running in another terminal
foundry model run phi-4-mini

# Option 1: Using FoundryLocalManager (recommended)
python chat_quickstart.py "Explain what Foundry Local is"

# Option 2: Manual configuration with environment variables
set BASE_URL=http://localhost:8000
set MODEL=phi-4-mini
set API_KEY=
python chat_quickstart.py "Write a welcome message"

# Option 3: Azure OpenAI configuration
set AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
set AZURE_OPENAI_API_KEY=your-api-key
set AZURE_OPENAI_API_VERSION=2024-08-01-preview
set MODEL=your-deployment-name
python chat_quickstart.py "Hello from Azure OpenAI"
```

## ‡¶Ö‡¶Ç‡¶∂ ‡ß¨: ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶è‡¶¨‡¶Ç ‡¶∏‡ßá‡¶∞‡¶æ ‡¶Ö‡¶®‡ßÅ‡¶∂‡ßÄ‡¶≤‡¶®

### ‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶£ ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶®

```powershell
# Issue: "Could not use Foundry SDK" warning
pip install foundry-local-sdk
# Or set environment variables for manual configuration

# Issue: Connection refused
foundry service status
foundry service ps  # Check loaded models

# Issue: Model not found
foundry model list
foundry model run phi-4-mini

# Issue: Cache problems or low disk space
foundry cache ls
foundry cache clean

# Issue: GPT-OSS-20B not supported on your version
foundry --version
winget upgrade --id Microsoft.FoundryLocal

# Test API endpoint
curl http://localhost:8000/v1/models
```

### ‡¶∏‡¶ø‡¶∏‡ßç‡¶ü‡ßá‡¶Æ ‡¶∞‡¶ø‡¶∏‡ßã‡¶∞‡ßç‡¶∏ ‡¶Æ‡¶®‡¶ø‡¶ü‡¶∞‡¶ø‡¶Ç (Windows)

```powershell
# Quick CPU and process view
Get-Process | Sort-Object -Property CPU -Descending | Select-Object -First 10
Get-Counter '\\Processor(_Total)\\% Processor Time' -SampleInterval 1 -MaxSamples 10
```

### ‡¶™‡¶∞‡¶ø‡¶¨‡ßá‡¶∂ ‡¶≠‡ßá‡¶∞‡¶ø‡¶Ø‡¶º‡ßá‡¶¨‡¶≤

| ‡¶≠‡ßá‡¶∞‡¶ø‡¶Ø‡¶º‡ßá‡¶¨‡¶≤ | ‡¶¨‡¶ø‡¶¨‡¶∞‡¶£ | ‡¶°‡¶ø‡¶´‡¶≤‡ßç‡¶ü | ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ú‡¶®‡ßÄ‡¶Ø‡¶º |
|-----------|--------|--------|-------------|
| `MODEL` | ‡¶Æ‡¶°‡ßá‡¶≤‡ßá‡¶∞ ‡¶â‡¶™‡¶®‡¶æ‡¶Æ ‡¶¨‡¶æ ‡¶®‡¶æ‡¶Æ | `phi-4-mini` | ‡¶®‡¶æ |
| `BASE_URL` | Foundry Local ‡¶¨‡ßá‡¶∏ URL | `http://localhost:8000` | ‡¶®‡¶æ |
| `API_KEY` | API ‡¶ï‡ßÄ (‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶£‡¶§ ‡¶≤‡ßã‡¶ï‡¶æ‡¶≤ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ú‡¶® ‡¶π‡¶Ø‡¶º ‡¶®‡¶æ) | `""` | ‡¶®‡¶æ |
| `AZURE_OPENAI_ENDPOINT` | Azure OpenAI ‡¶è‡¶®‡ßç‡¶°‡¶™‡¶Ø‡¶º‡ßá‡¶®‡ßç‡¶ü | - | Azure ‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø |
| `AZURE_OPENAI_API_KEY` | Azure OpenAI API ‡¶ï‡ßÄ | - | Azure ‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø |
| `AZURE_OPENAI_API_VERSION` | Azure API ‡¶∏‡¶Ç‡¶∏‡ßç‡¶ï‡¶∞‡¶£ | `2024-08-01-preview` | ‡¶®‡¶æ |

### ‡¶∏‡ßá‡¶∞‡¶æ ‡¶Ö‡¶®‡ßÅ‡¶∂‡ßÄ‡¶≤‡¶®

- **OpenAI SDK ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®**: ‡¶≠‡¶æ‡¶≤‡ßã ‡¶∞‡¶ï‡ßç‡¶∑‡¶£‡¶æ‡¶¨‡ßá‡¶ï‡ßç‡¶∑‡¶£‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø OpenAI SDK ‡¶ï‡ßá ‡¶ï‡¶æ‡¶Å‡¶ö‡¶æ HTTP ‡¶Ö‡¶®‡ßÅ‡¶∞‡ßã‡¶ß‡ßá‡¶∞ ‡¶â‡¶™‡¶∞ ‡¶™‡ßç‡¶∞‡¶æ‡¶ß‡¶æ‡¶®‡ßç‡¶Ø ‡¶¶‡¶ø‡¶®
- **FoundryLocalManager**: ‡¶â‡¶™‡¶≤‡¶¨‡ßç‡¶ß ‡¶π‡¶≤‡ßá ‡¶∏‡¶æ‡¶∞‡ßç‡¶≠‡¶ø‡¶∏ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶∏‡ßç‡¶•‡¶æ‡¶™‡¶®‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶Ö‡¶´‡¶ø‡¶∏‡¶ø‡¶Ø‡¶º‡¶æ‡¶≤ SDK ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®
- **‡¶§‡ßç‡¶∞‡ßÅ‡¶ü‡¶ø ‡¶™‡¶∞‡¶ø‡¶ö‡¶æ‡¶≤‡¶®‡¶æ**: ‡¶™‡ßç‡¶∞‡ßã‡¶°‡¶æ‡¶ï‡¶∂‡¶® ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶™‡ßç‡¶≤‡¶ø‡¶ï‡ßá‡¶∂‡¶®‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶∏‡¶†‡¶ø‡¶ï ‡¶´‡¶≤‡ßã‡¶¨‡ßç‡¶Ø‡¶æ‡¶ï ‡¶ï‡ßå‡¶∂‡¶≤ ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®
- **‡¶®‡¶ø‡¶Ø‡¶º‡¶Æ‡¶ø‡¶§ ‡¶Ü‡¶™‡¶ó‡ßç‡¶∞‡ßá‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®**: ‡¶®‡¶§‡ßÅ‡¶® ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶è‡¶¨‡¶Ç ‡¶´‡¶ø‡¶ï‡ßç‡¶∏ ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶ï‡ßç‡¶∏‡ßá‡¶∏ ‡¶ï‡¶∞‡¶§‡ßá Foundry Local ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶∞‡¶æ‡¶ñ‡ßÅ‡¶®
- **‡¶õ‡ßã‡¶ü ‡¶•‡ßá‡¶ï‡ßá ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ï‡¶∞‡ßÅ‡¶®**: ‡¶õ‡ßã‡¶ü ‡¶Æ‡¶°‡ßá‡¶≤ (Phi mini, Qwen 7B) ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶è‡¶¨‡¶Ç ‡¶ß‡ßÄ‡¶∞‡ßá ‡¶ß‡ßÄ‡¶∞‡ßá ‡¶∏‡ßç‡¶ï‡ßá‡¶≤ ‡¶ï‡¶∞‡ßÅ‡¶®
- **‡¶∞‡¶ø‡¶∏‡ßã‡¶∞‡ßç‡¶∏ ‡¶Æ‡¶®‡¶ø‡¶ü‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®**: ‡¶™‡ßç‡¶∞‡¶Æ‡ßç‡¶™‡¶ü ‡¶è‡¶¨‡¶Ç ‡¶∏‡ßá‡¶ü‡¶ø‡¶Ç‡¶∏ ‡¶ü‡¶ø‡¶â‡¶® ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º CPU/GPU/‡¶Æ‡ßá‡¶Æ‡ßã‡¶∞‡¶ø ‡¶ü‡ßç‡¶∞‡ßç‡¶Ø‡¶æ‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®

## ‡¶Ö‡¶Ç‡¶∂ ‡ß≠: ‡¶π‡¶æ‡¶§‡ßá-‡¶ï‡¶≤‡¶Æ‡ßá ‡¶Ö‡¶®‡ßÅ‡¶∂‡ßÄ‡¶≤‡¶®

### ‡¶Ö‡¶®‡ßÅ‡¶∂‡ßÄ‡¶≤‡¶® ‡ßß: ‡¶¶‡ßç‡¶∞‡ßÅ‡¶§ ‡¶Æ‡¶æ‡¶≤‡ßç‡¶ü‡¶ø-‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ü‡ßá‡¶∏‡ßç‡¶ü

```powershell
# deploy-models.ps1
$models = @(
    "phi-4-mini",
    "qwen2.5-7b-instruct"
)
foreach ($model in $models) {
    Write-Host "Running $model..."
    foundry model run $model --verbose
}
```

### ‡¶Ö‡¶®‡ßÅ‡¶∂‡ßÄ‡¶≤‡¶® ‡ß®: OpenAI SDK ‡¶á‡¶®‡ßç‡¶ü‡¶ø‡¶ó‡ßç‡¶∞‡ßá‡¶∂‡¶® ‡¶ü‡ßá‡¶∏‡ßç‡¶ü

```python
# sdk_integration_test.py (matching Sample 01 pattern)
import os
from openai import OpenAI
from foundry_local import FoundryLocalManager

def test_model_integration(model_alias):
    """Test OpenAI SDK integration with different models."""
    try:
        # Use FoundryLocalManager for proper setup
        manager = FoundryLocalManager(model_alias)
        model_info = manager.get_model_info(model_alias)
        
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key
        )
        
        # Test basic completion
        response = client.chat.completions.create(
            model=model_info.id,
            messages=[{"role": "user", "content": "Say hello and state your model name."}],
            max_tokens=50
        )
        
        print(f"‚úÖ {model_alias}: {response.choices[0].message.content}")
        return True
    except Exception as e:
        print(f"‚ùå {model_alias}: {e}")
        return False

# Test multiple models
models_to_test = ["phi-4-mini", "qwen2.5-7b-instruct"]
for model in models_to_test:
    test_model_integration(model)
```

### ‡¶Ö‡¶®‡ßÅ‡¶∂‡ßÄ‡¶≤‡¶® ‡ß©: ‡¶∏‡¶æ‡¶∞‡ßç‡¶≠‡¶ø‡¶∏‡ßá‡¶∞ ‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø ‡¶™‡¶∞‡ßÄ‡¶ï‡ßç‡¶∑‡¶æ

```python
# health_check.py
from openai import OpenAI
from foundry_local import FoundryLocalManager

def comprehensive_health_check():
    """Perform comprehensive health check of Foundry Local service."""
    try:
        # Initialize with a common model
        manager = FoundryLocalManager("phi-4-mini")
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key
        )
        
        # 1. Check service connectivity
        models_response = client.models.list()
        available_models = [model.id for model in models_response.data]
        print(f"‚úÖ Service healthy - {len(available_models)} models available")
        
        # 2. Test each available model
        for model_id in available_models:
            try:
                response = client.chat.completions.create(
                    model=model_id,
                    messages=[{"role": "user", "content": "Test"}],
                    max_tokens=10
                )
                print(f"‚úÖ {model_id}: Working")
            except Exception as e:
                print(f"‚ùå {model_id}: {e}")
        
        return True
    except Exception as e:
        print(f"‚ùå Service check failed: {e}")
        return False

comprehensive_health_check()
```

## ‡¶∞‡ßá‡¶´‡¶æ‡¶∞‡ßá‡¶®‡ßç‡¶∏

- **Foundry Local ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ï‡¶∞‡ßÅ‡¶®**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
- **CLI ‡¶∞‡ßá‡¶´‡¶æ‡¶∞‡ßá‡¶®‡ßç‡¶∏ ‡¶è‡¶¨‡¶Ç ‡¶ï‡¶Æ‡¶æ‡¶®‡ßç‡¶°‡ßá‡¶∞ ‡¶ì‡¶≠‡¶æ‡¶∞‡¶≠‡¶ø‡¶â**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
- **OpenAI SDK ‡¶á‡¶®‡ßç‡¶ü‡¶ø‡¶ó‡ßç‡¶∞‡ßá‡¶∂‡¶®**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
- **Hugging Face ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ï‡¶Æ‡ßç‡¶™‡¶æ‡¶á‡¶≤ ‡¶ï‡¶∞‡ßÅ‡¶®**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- **Microsoft Foundry Local GitHub**: https://github.com/microsoft/Foundry-Local
- **OpenAI Python SDK**: https://github.com/openai/openai-python
- **Sample 01: OpenAI SDK ‡¶è‡¶∞ ‡¶Æ‡¶æ‡¶ß‡ßç‡¶Ø‡¶Æ‡ßá ‡¶¶‡ßç‡¶∞‡ßÅ‡¶§ ‡¶ö‡ßç‡¶Ø‡¶æ‡¶ü**: samples/01/README.md
- **Sample 02: ‡¶â‡¶®‡ßç‡¶®‡¶§ SDK ‡¶á‡¶®‡ßç‡¶ü‡¶ø‡¶ó‡ßç‡¶∞‡ßá‡¶∂‡¶®**: samples/02/README.md

---

