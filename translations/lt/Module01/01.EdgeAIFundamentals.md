<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "be25052ac4c842765e7f6f7eb4d7dcc5",
  "translation_date": "2025-10-20T10:05:17+00:00",
  "source_file": "Module01/01.EdgeAIFundamentals.md",
  "language_code": "lt"
}
-->
# 1 skyrius: EdgeAI pagrindai

EdgeAI reiÅ¡kia paradigmos pokytÄ¯ dirbtinio intelekto diegime, kai DI galimybÄ—s perkeliamos tiesiai Ä¯ kraÅ¡tinius Ä¯renginius, o ne remiamasi tik debesÅ³ kompiuterija. Svarbu suprasti, kaip EdgeAI leidÅ¾ia vietinÄ¯ DI apdorojimÄ… ribotÅ³ resursÅ³ Ä¯renginiuose, iÅ¡laikant tinkamÄ… naÅ¡umÄ… ir sprendÅ¾iant tokias problemas kaip privatumas, delsimas ir veikimas neprisijungus.

## Ä®vadas

Å ioje pamokoje nagrinÄ—sime EdgeAI ir jo pagrindines sÄ…vokas. Aptarsime tradicinÄ™ DI kompiuterijos paradigmÄ…, kraÅ¡tinÄ—s kompiuterijos iÅ¡Å¡Å«kius, pagrindines technologijas, leidÅ¾ianÄias EdgeAI, ir praktines taikymo sritis Ä¯vairiose pramonÄ—s Å¡akose.

## Mokymosi tikslai

Pamokos pabaigoje galÄ—site:

- Suprasti skirtumÄ… tarp tradicinio debesÅ³ pagrindu veikianÄio DI ir EdgeAI metodÅ³.
- Identifikuoti pagrindines technologijas, leidÅ¾ianÄias DI apdorojimÄ… kraÅ¡tiniuose Ä¯renginiuose.
- AtpaÅ¾inti EdgeAI Ä¯gyvendinimo privalumus ir apribojimus.
- Taikyti EdgeAI Å¾inias realioms situacijoms ir naudojimo atvejams.

## TradicinÄ—s DI kompiuterijos paradigmos supratimas

TradiciÅ¡kai generatyvios DI programos remiasi aukÅ¡tos naÅ¡umo kompiuterijos infrastruktÅ«ra, kad efektyviai vykdytÅ³ didelius kalbos modelius (LLMs). Organizacijos paprastai diegia Å¡iuos modelius GPU klasteriuose debesÅ³ aplinkoje, pasiekdamos jÅ³ galimybes per API sÄ…sajas.

Å is centralizuotas modelis gerai veikia daugelyje programÅ³, taÄiau turi esminiÅ³ apribojimÅ³ kraÅ¡tinÄ—s kompiuterijos scenarijuose. Tradicinis metodas apima vartotojo uÅ¾klausÅ³ siuntimÄ… Ä¯ nuotolinius serverius, jÅ³ apdorojimÄ… naudojant galingÄ… aparatinÄ™ Ä¯rangÄ… ir rezultatÅ³ grÄ…Å¾inimÄ… internetu. Nors Å¡is metodas suteikia prieigÄ… prie paÅ¾angiausiÅ³ modeliÅ³, jis sukuria priklausomybÄ™ nuo interneto ryÅ¡io, sukelia delsimo problemÅ³ ir kelia privatumo klausimÅ³, kai jautrÅ«s duomenys turi bÅ«ti perduodami iÅ¡oriniams serveriams.

Yra keletas pagrindiniÅ³ sÄ…vokÅ³, kurias reikia suprasti dirbant su tradicinÄ—mis DI kompiuterijos paradigmomis, bÅ«tent:

- **â˜ï¸ DebesÅ³ pagrindu veikiantis apdorojimas**: DI modeliai veikia galingoje serveriÅ³ infrastruktÅ«roje su dideliais skaiÄiavimo resursais.
- **ğŸ”Œ API pagrindu veikianti prieiga**: Programos pasiekia DI galimybes per nuotolinius API iÅ¡kvietimus, o ne vietinÄ¯ apdorojimÄ….
- **ğŸ›ï¸ Centralizuotas modeliÅ³ valdymas**: Modeliai yra palaikomi ir atnaujinami centralizuotai, uÅ¾tikrinant nuoseklumÄ…, bet reikalaujant tinklo ryÅ¡io.
- **ğŸ“ˆ ResursÅ³ skalavimas**: DebesÅ³ infrastruktÅ«ra gali dinamiÅ¡kai prisitaikyti prie kintanÄiÅ³ skaiÄiavimo poreikiÅ³.

## KraÅ¡tinÄ—s kompiuterijos iÅ¡Å¡Å«kiai

KraÅ¡tiniai Ä¯renginiai, tokie kaip neÅ¡iojamieji kompiuteriai, mobilieji telefonai ir daiktÅ³ interneto (IoT) Ä¯renginiai, pvz., Raspberry Pi ir NVIDIA Orin Nano, turi unikalius skaiÄiavimo apribojimus. Å ie Ä¯renginiai paprastai turi maÅ¾esnÄ™ apdorojimo galiÄ…, atmintÄ¯ ir energijos iÅ¡teklius, palyginti su duomenÅ³ centrÅ³ infrastruktÅ«ra.

TradiciÅ¡kai vykdyti didelius kalbos modelius tokiuose Ä¯renginiuose buvo sudÄ—tinga dÄ—l Å¡iÅ³ techninÄ—s Ä¯rangos apribojimÅ³. TaÄiau kraÅ¡tinÄ—s DI apdorojimo poreikis tampa vis svarbesnis Ä¯vairiose situacijose. PavyzdÅ¾iui, kai interneto ryÅ¡ys yra nepatikimas arba nepasiekiamas, kaip nuotolinÄ—se pramonÄ—s vietose, transporto priemonÄ—se kelionÄ—s metu ar vietovÄ—se su prastu tinklo aprÄ—ptimi. Be to, programos, kurioms reikalingi aukÅ¡ti saugumo standartai, tokios kaip medicinos prietaisai, finansÅ³ sistemos ar vyriausybinÄ—s programos, gali reikalauti vietinio jautriÅ³ duomenÅ³ apdorojimo, kad bÅ«tÅ³ uÅ¾tikrintas privatumas ir atitiktis reikalavimams.

### Pagrindiniai kraÅ¡tinÄ—s kompiuterijos apribojimai

KraÅ¡tinÄ—s kompiuterijos aplinkos susiduria su keliais esminiais apribojimais, kuriÅ³ tradicinÄ—s debesÅ³ pagrindu veikianÄios DI sprendimai nepatiria:

- **Ribota apdorojimo galia**: KraÅ¡tiniai Ä¯renginiai paprastai turi maÅ¾iau CPU branduoliÅ³ ir maÅ¾esnÄ¯ taktÅ³ daÅ¾nÄ¯, palyginti su serverio klasÄ—s aparatine Ä¯ranga.
- **Atminties apribojimai**: RAM ir saugojimo talpa kraÅ¡tiniuose Ä¯renginiuose yra Å¾ymiai maÅ¾esnÄ—.
- **Energijos apribojimai**: Baterijomis maitinami Ä¯renginiai turi subalansuoti naÅ¡umÄ… ir energijos suvartojimÄ…, kad veiktÅ³ ilgÄ… laikÄ….
- **Å iluminis valdymas**: KompaktiÅ¡ki formos faktoriai riboja auÅ¡inimo galimybes, paveikdami ilgalaikÄ¯ naÅ¡umÄ… esant apkrovai.

## Kas yra EdgeAI?

### SÄ…voka: EdgeAI apibrÄ—Å¾imas

EdgeAI reiÅ¡kia dirbtinio intelekto algoritmÅ³ diegimÄ… ir vykdymÄ… tiesiogiai kraÅ¡tiniuose Ä¯renginiuose â€“ fizinÄ—je aparatinÄ—je Ä¯rangoje, esanÄioje â€tinklo kraÅ¡teâ€œ, arti duomenÅ³ generavimo ir rinkimo vietos. Å ie Ä¯renginiai apima iÅ¡maniuosius telefonus, IoT jutiklius, iÅ¡maniÄ…sias kameras, autonomines transporto priemones, neÅ¡iojamus Ä¯renginius ir pramoninÄ™ Ä¯rangÄ…. Skirtingai nuo tradiciniÅ³ DI sistemÅ³, kurios remiasi debesÅ³ serveriais apdorojimui, EdgeAI perkelia intelektÄ… tiesiai Ä¯ duomenÅ³ Å¡altinÄ¯.

EdgeAI esmÄ— yra DI apdorojimo decentralizavimas, perkeliant jÄ¯ iÅ¡ centralizuotÅ³ duomenÅ³ centrÅ³ ir paskirstant per plaÄiÄ… Ä¯renginiÅ³ tinklÄ…, sudarantÄ¯ mÅ«sÅ³ skaitmeninÄ™ ekosistemÄ…. Tai reiÅ¡kia esminÄ¯ architektÅ«rinÄ¯ pokytÄ¯, kaip kuriamos ir diegiamos DI sistemos.

Pagrindiniai EdgeAI konceptualÅ«s principai apima:

- **Artumo apdorojimas**: SkaiÄiavimai vyksta fiziÅ¡kai arti duomenÅ³ kilmÄ—s vietos.
- **Decentralizuotas intelektas**: SprendimÅ³ priÄ—mimo galimybÄ—s paskirstomos per kelis Ä¯renginius.
- **DuomenÅ³ suverenitetas**: Informacija lieka vietinÄ—je kontrolÄ—je, daÅ¾nai niekada nepaliekant Ä¯renginio.
- **Autonominis veikimas**: Ä®renginiai gali veikti protingai be nuolatinio ryÅ¡io.
- **Ä®terptinis DI**: Intelektas tampa Ä¯prastÅ³ Ä¯renginiÅ³ esmine savybe.

### EdgeAI architektÅ«ros vizualizacija

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         TRADITIONAL AI ARCHITECTURE                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   Data Transfer  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   API Response   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Edge Devices â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚ Cloud Servers â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ End Users â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     Data                         Model Inference                     Results
   Collection                     High Latency
                                  High Bandwidth
                                  Privacy Concerns
                               
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            EDGE AI ARCHITECTURE                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   Direct Response  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Edge Devices with Embedded AI         â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚ End Users â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â”‚ Sensors â”‚â”€>â”‚ SLM Inference â”‚â”€>â”‚ Local Action â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     Data         Low Latency       Immediate
   Collection     Processing        Response
                  No Data Transfer
                  Enhanced Privacy
```

EdgeAI reiÅ¡kia paradigmos pokytÄ¯ dirbtinio intelekto diegime, perkeliant DI galimybes tiesiai Ä¯ kraÅ¡tinius Ä¯renginius, o ne remiantis tik debesÅ³ kompiuterija. Å is metodas leidÅ¾ia DI modeliams veikti vietoje Ä¯renginiuose su ribotais skaiÄiavimo resursais, suteikiant realaus laiko iÅ¡vadÅ³ galimybes be nuolatinio interneto ryÅ¡io.

EdgeAI apima Ä¯vairias technologijas ir metodus, skirtus DI modeliams padaryti efektyvesnius ir tinkamus diegimui ribotÅ³ resursÅ³ Ä¯renginiuose. Tikslas yra iÅ¡laikyti tinkamÄ… naÅ¡umÄ…, tuo paÄiu Å¾ymiai sumaÅ¾inant DI modeliÅ³ skaiÄiavimo ir atminties reikalavimus.

PaÅ¾velkime Ä¯ pagrindinius metodus, leidÅ¾ianÄius EdgeAI Ä¯gyvendinimÄ… Ä¯vairiuose Ä¯renginiuose ir naudojimo atvejais.

### Pagrindiniai EdgeAI principai

EdgeAI yra pagrÄ¯stas keliais pagrindiniais principais, kurie jÄ¯ skiria nuo tradicinio debesÅ³ pagrindu veikianÄio DI:

- **Vietinis apdorojimas**: DI iÅ¡vados vyksta tiesiogiai kraÅ¡tiniame Ä¯renginyje be iÅ¡orinio ryÅ¡io poreikio.
- **ResursÅ³ optimizavimas**: Modeliai yra specialiai optimizuoti pagal tiksliniÅ³ Ä¯renginiÅ³ techninÄ—s Ä¯rangos apribojimus.
- **Realus laikas**: Apdorojimas vyksta su minimaliu delsimu laiko jautrioms programoms.
- **Privatumas pagal dizainÄ…**: JautrÅ«s duomenys lieka Ä¯renginyje, didinant saugumÄ… ir atitiktÄ¯.

## PagrindinÄ—s technologijos, leidÅ¾ianÄios EdgeAI

### Modelio kvantavimas

Viena svarbiausiÅ³ EdgeAI technikÅ³ yra modelio kvantavimas. Å is procesas apima modelio parametrÅ³ tikslumo sumaÅ¾inimÄ…, paprastai nuo 32 bitÅ³ slankiojo kablelio skaiÄiÅ³ iki 8 bitÅ³ sveikÅ³jÅ³ skaiÄiÅ³ ar net maÅ¾esnio tikslumo formatÅ³. Nors Å¡is tikslumo sumaÅ¾inimas gali atrodyti nerimÄ… keliantis, tyrimai parodÄ—, kad daugelis DI modeliÅ³ gali iÅ¡laikyti savo naÅ¡umÄ… net ir esant Å¾ymiai sumaÅ¾intam tikslumui.

Kvantavimas veikia, susiedamas slankiojo kablelio reikÅ¡miÅ³ diapazonÄ… su maÅ¾esniu diskreÄiÅ³ reikÅ¡miÅ³ rinkiniu. PavyzdÅ¾iui, vietoj 32 bitÅ³ naudojimo kiekvienam parametrui, kvantavimas gali naudoti tik 8 bitus, taip sumaÅ¾inant atminties reikalavimus 4 kartus ir daÅ¾nai paspartinant iÅ¡vadÅ³ laikÄ….

```python
# Example: PyTorch model quantization 
import torch

# Load a pre-trained model
model = torch.load('large_model.pth')

# Quantize the model to INT8
quantized_model = torch.quantization.quantize_dynamic(
    model,  # model to quantize
    {torch.nn.Linear, torch.nn.Conv2d},  # layers to quantize
    dtype=torch.qint8  # quantization data type
)

# Save the quantized model
torch.save(quantized_model, 'quantized_model.pth')

# Memory usage comparison
original_size = model.size()
quantized_size = quantized_model.size()
print(f"Memory reduction: {original_size / quantized_size:.2f}x")
```

Skirtingos kvantavimo technikos apima:

- **Po treniravimo kvantavimas (PTQ)**: Taikomas po modelio treniravimo, nereikalaujant pakartotinio treniravimo.
- **Kvantavimo suvokimo treniravimas (QAT)**: Ä®traukia kvantavimo efektus treniravimo metu, siekiant geresnio tikslumo.
- **Dinaminis kvantavimas**: Kvantuoja svorius Ä¯ int8, bet aktyvacijas skaiÄiuoja dinamiÅ¡kai.
- **Statinis kvantavimas**: IÅ¡ anksto apskaiÄiuoja visus kvantavimo parametrus tiek svoriams, tiek aktyvacijoms.

EdgeAI diegimui tinkamos kvantavimo strategijos pasirinkimas priklauso nuo konkreÄios modelio architektÅ«ros, naÅ¡umo reikalavimÅ³ ir tikslinio Ä¯renginio techninÄ—s Ä¯rangos galimybiÅ³.

### Modelio suspaudimas ir optimizavimas

Be kvantavimo, Ä¯vairios suspaudimo technikos padeda sumaÅ¾inti modelio dydÄ¯ ir skaiÄiavimo reikalavimus. Tai apima:

**Pruning**: Å i technika paÅ¡alina nereikalingus ryÅ¡ius ar neuronus iÅ¡ neuroniniÅ³ tinklÅ³. Identifikuojant ir paÅ¡alinant parametrus, kurie maÅ¾ai prisideda prie modelio naÅ¡umo, pruning gali Å¾ymiai sumaÅ¾inti modelio dydÄ¯, iÅ¡laikant tikslumÄ….

```python
# Example: Neural network pruning in TensorFlow
import tensorflow as tf
import tensorflow_model_optimization as tfmot

# Define the model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Apply pruning during training
pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(
    initial_sparsity=0.0,
    final_sparsity=0.5,  # 50% of connections will be pruned
    begin_step=0,
    end_step=10000
)

pruned_model = tfmot.sparsity.keras.prune_low_magnitude(
    model, pruning_schedule=pruning_schedule
)

# Compile the pruned model
pruned_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model while pruning
pruned_model.fit(x_train, y_train, epochs=10)

# Convert to a smaller model for deployment
final_model = tfmot.sparsity.keras.strip_pruning(pruned_model)
```

**Å½iniÅ³ distiliacija**: Å is metodas apima maÅ¾esnio â€studentoâ€œ modelio treniravimÄ…, kad jis imituotÅ³ didesnio â€mokytojoâ€œ modelio elgesÄ¯. StudentÅ³ modelis mokosi apytiksliai atkartoti mokytojo rezultatus, daÅ¾nai pasiekdamas panaÅ¡Å³ naÅ¡umÄ… su Å¾ymiai maÅ¾esniais parametrais.

**Modelio architektÅ«ros optimizavimas**: TyrÄ—jai sukÅ«rÄ— specializuotas architektÅ«ras, skirtas kraÅ¡tiniam diegimui, tokias kaip MobileNets, EfficientNets ir kitas lengvas architektÅ«ras, kurios subalansuoja naÅ¡umÄ… su skaiÄiavimo efektyvumu.

### MaÅ¾i kalbos modeliai (SLMs)

Auganti EdgeAI tendencija yra maÅ¾Å³ kalbos modeliÅ³ (SLMs) kÅ«rimas. Å ie modeliai yra sukurti nuo pat pradÅ¾iÅ³, kad bÅ«tÅ³ kompaktiÅ¡ki ir efektyvÅ«s, tuo paÄiu teikiant reikÅ¡mingas natÅ«ralios kalbos galimybes. SLMs tai pasiekia per kruopÅ¡Äiai parinktas architektÅ«ras, efektyvius treniravimo metodus ir orientuotÄ… treniravimÄ… konkreÄiose srityse ar uÅ¾duotyse.

Skirtingai nuo tradiciniÅ³ metodÅ³, kurie apima dideliÅ³ modeliÅ³ suspaudimÄ…, SLMs daÅ¾nai treniruojami su maÅ¾esniais duomenÅ³ rinkiniais ir optimizuotomis architektÅ«romis, specialiai sukurtomis kraÅ¡tiniam diegimui. Å is metodas gali sukurti modelius, kurie yra ne tik maÅ¾esni, bet ir efektyvesni konkretiems naudojimo atvejams.

## AparatinÄ—s Ä¯rangos pagreitinimas EdgeAI

Å iuolaikiniai kraÅ¡tiniai Ä¯renginiai vis daÅ¾niau apima specializuotÄ… aparatinÄ™ Ä¯rangÄ…, skirtÄ… DI darbo krÅ«viams pagreitinti:

### NeuronÅ³ apdorojimo vienetai (NPUs)

NPUs yra specializuoti procesoriai, skirti neuroniniÅ³ tinklÅ³ skaiÄiavimams. Å ie lustai gali vykdyti DI iÅ¡vadÅ³ uÅ¾duotis daug efektyviau nei tradiciniai CPU, daÅ¾nai su maÅ¾esniu energijos suvartojimu. Daugelis Å¡iuolaikiniÅ³ iÅ¡maniÅ³jÅ³ telefonÅ³, neÅ¡iojamÅ³jÅ³ kompiuteriÅ³ ir IoT Ä¯renginiÅ³ dabar apima NPUs, kad bÅ«tÅ³ galima vykdyti DI apdorojimÄ… Ä¯renginyje.

```csharp
// Example: Using Windows ML to target NPU acceleration in C#
using Microsoft.ML.OnnxRuntime;

// Create session options with NPU provider
var sessionOptions = new SessionOptions();
sessionOptions.AppendExecutionProvider_DmlExecutionProvider();  // DirectML for NPU

// Load the ONNX model
using var session = new InferenceSession("model.onnx", sessionOptions);

// Create input tensor
var inputTensor = new DenseTensor<float>(new[] { 1, 3, 224, 224 });  // Example input shape
var inputs = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor("input", inputTensor) };

// Run inference with NPU acceleration
using var results = session.Run(inputs);
var output = results.First().AsTensor<float>();

// Process output
Console.WriteLine($"Inference result: {output[0]}");
```

Ä®renginiai su NPUs apima:

- **Apple**: A serijos ir M serijos lustai su Neural Engine
- **Qualcomm**: Snapdragon procesoriai su Hexagon DSP/NPU
- **Samsung**: Exynos procesoriai su NPU
- **Intel**: Movidius VPUs ir Habana Labs akceleratoriai
- **Microsoft**: Windows Copilot+ kompiuteriai su NPUs

### ğŸ® GPU pagreitinimas

Nors kraÅ¡tiniai Ä¯renginiai gali neturÄ—ti galingÅ³ GPU, esanÄiÅ³ duomenÅ³ centruose, daugelis vis dar apima integruotus arba atskirus GPU, kurie gali pagreitinti DI darbo krÅ«vius. Å iuolaikiniai mobilieji GPU ir integruoti grafikos procesoriai gali suteikti reikÅ¡mingÄ… naÅ¡umo pagerÄ—jimÄ… DI iÅ¡vadÅ³ uÅ¾duotims.

```python
# Example: Using TensorRT for GPU acceleration on edge devices
import tensorrt as trt
import numpy as np

# Create TensorRT logger and builder
TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
builder = trt.Builder(TRT_LOGGER)
network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
parser = trt.OnnxParser(network, TRT_LOGGER)

# Parse ONNX model
with open('model.onnx', 'rb') as model:
    parser.parse(model.read())

# Configure builder
config = builder.create_builder_config()
config.max_workspace_size = 1 << 28  # 256 MiB
config.set_flag(trt.BuilderFlag.FP16)  # Use FP16 precision for edge GPU

# Build and serialize engine
engine = builder.build_engine(network, config)
with open('model.trt', 'wb') as f:
    f.write(engine.serialize())
```

### CPU optimizavimas

Net tik CPU turintys Ä¯renginiai gali pasinaudoti EdgeAI per optimizuotas Ä¯gyvendinimo strategijas. Å iuolaikiniai CPU apima specializuotas instrukcijas DI darbo krÅ«viams, o programinÄ—s Ä¯rangos pagrindai buvo sukurti siekiant maksimaliai padidinti CPU naÅ¡umÄ… DI iÅ¡vadoms.

```bash
# Example: Using XNNPACK with TFLite for optimized CPU inference
# Compilation command with XNNPACK acceleration enabled

bazel build -c opt --copt=-O3 --copt=-march=native \
  tensorflow/lite/delegates/xnnpack:libxnnpack_delegate.so

# Convert TensorFlow model to TFLite with optimization
tflite_convert \
  --keras_model_file=model.h5 \
  --output_file=model.tflite \
  --inference_type=FLOAT \
  --experimental_new_converter \
  --experimental_new_quantizer
```

PrograminÄ—s Ä¯rangos inÅ¾inieriams, dirbantiems su EdgeAI, supratimas, kaip pasinaudoti Å¡iais aparatinÄ—s Ä¯rangos pagreitinimo pasirinkimais, yra labai svarbus optimizuojant iÅ¡vadÅ³ naÅ¡umÄ… ir energijos efektyvumÄ… tiksliniuose Ä¯renginiuose.

## EdgeAI privalumai

### Privatumas ir saugumas

Vienas iÅ¡ didÅ¾iausiÅ³ EdgeAI privalumÅ³ yra pagerintas privatumas ir saugumas. Apdorojant duomenis vietoje Ä¯renginyje, jautri informacija niekada nepalieka vartotojo kontrolÄ—s. Tai ypaÄ svarbu programoms, tvarkanÄioms asmeninius duomenis, medicininÄ™ informacijÄ… ar konfidencialius verslo duomenis.

### SumaÅ¾intas delsimas

EdgeAI paÅ¡alina poreikÄ¯ siÅ³sti duomenis Ä¯ nuotolinius serverius apdorojimui, Å¾ymiai sumaÅ¾indamas delsÄ…. Tai labai svarbu realaus laiko programoms, tokioms kaip autonominÄ—s transporto priemonÄ—s, pramoninÄ— automatizacija ar interaktyvios programos, kuriose reikalingi greiti atsakymai.

### Veikimas neprisijungus

EdgeAI leidÅ¾ia DI funkcionalumÄ… net tada, kai interneto ryÅ¡ys yra nepasiekiamas. Tai vertinga programoms atokiose vietovÄ—se, kelioniÅ³ metu ar situacijose, kai tinklo patikimumas kelia susirÅ«pinimÄ….

### Ekonominis efektyvumas

SumaÅ¾inus priklausomybÄ™
- [02: EdgeAI Pritaikymas](02.RealWorldCaseStudies.md)

---

**AtsakomybÄ—s apribojimas**:  
Å is dokumentas buvo iÅ¡verstas naudojant AI vertimo paslaugÄ… [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, praÅ¡ome atkreipti dÄ—mesÄ¯, kad automatiniai vertimai gali turÄ—ti klaidÅ³ ar netikslumÅ³. Originalus dokumentas jo gimtÄ…ja kalba turÄ—tÅ³ bÅ«ti laikomas autoritetingu Å¡altiniu. DÄ—l svarbios informacijos rekomenduojama profesionali Å¾mogaus vertimo paslauga. Mes neprisiimame atsakomybÄ—s uÅ¾ nesusipratimus ar neteisingus aiÅ¡kinimus, atsiradusius naudojant Å¡Ä¯ vertimÄ….