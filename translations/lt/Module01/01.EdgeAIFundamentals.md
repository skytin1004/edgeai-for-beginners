<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "76b134be93f45283a2df8f8a93717d06",
  "translation_date": "2025-10-17T10:21:51+00:00",
  "source_file": "Module01/01.EdgeAIFundamentals.md",
  "language_code": "lt"
}
-->
# 1 skyrius: EdgeAI pagrindai

EdgeAI reiÅ¡kia paradigmos pokytÄ¯ dirbtinio intelekto diegime, perkeliant AI galimybes tiesiai Ä¯ kraÅ¡tinius Ä¯renginius, o ne pasikliaujant vien debesÅ³ pagrindu veikianÄiu apdorojimu. Svarbu suprasti, kaip EdgeAI leidÅ¾ia vietinÄ¯ AI apdorojimÄ… ribotÅ³ resursÅ³ Ä¯renginiuose, iÅ¡laikant tinkamÄ… naÅ¡umÄ… ir sprendÅ¾iant tokias problemas kaip privatumas, delsimas ir veikimas neprisijungus.

## Ä®vadas

Å ioje pamokoje nagrinÄ—sime EdgeAI ir jo pagrindines sÄ…vokas. Aptarsime tradicinÄ™ AI skaiÄiavimo paradigmÄ…, kraÅ¡tinio skaiÄiavimo iÅ¡Å¡Å«kius, pagrindines technologijas, leidÅ¾ianÄias EdgeAI, ir praktines taikymo sritis Ä¯vairiose pramonÄ—s Å¡akose.

## Mokymosi tikslai

Pamokos pabaigoje galÄ—site:

- Suprasti skirtumÄ… tarp tradicinio debesÅ³ pagrindu veikianÄio AI ir EdgeAI poÅ¾iÅ«riÅ³.
- Identifikuoti pagrindines technologijas, leidÅ¾ianÄias AI apdorojimÄ… kraÅ¡tiniuose Ä¯renginiuose.
- AtpaÅ¾inti EdgeAI Ä¯gyvendinimo privalumus ir apribojimus.
- Pritaikyti EdgeAI Å¾inias realioms situacijoms ir naudojimo atvejams.

## TradicinÄ—s AI skaiÄiavimo paradigmos supratimas

TradiciÅ¡kai generatyvios AI programos remiasi aukÅ¡tos naÅ¡umo skaiÄiavimo infrastruktÅ«ra, kad efektyviai vykdytÅ³ didelius kalbos modelius (LLMs). Organizacijos paprastai diegia Å¡iuos modelius GPU klasteriuose debesÅ³ aplinkoje, pasiekdamos jÅ³ galimybes per API sÄ…sajas.

Å is centralizuotas modelis gerai veikia daugelyje programÅ³, taÄiau turi esminiÅ³ apribojimÅ³ kraÅ¡tinio skaiÄiavimo scenarijuose. Tradicinis poÅ¾iÅ«ris apima vartotojo uÅ¾klausÅ³ siuntimÄ… Ä¯ nuotolinius serverius, jÅ³ apdorojimÄ… naudojant galingÄ… aparatinÄ™ Ä¯rangÄ… ir rezultatÅ³ grÄ…Å¾inimÄ… internetu. Nors Å¡is metodas suteikia prieigÄ… prie paÅ¾angiausiÅ³ modeliÅ³, jis sukuria priklausomybÄ™ nuo interneto ryÅ¡io, sukelia delsimo problemas ir kelia privatumo klausimus, kai jautri informacija turi bÅ«ti perduodama iÅ¡oriniams serveriams.

Yra keletas pagrindiniÅ³ sÄ…vokÅ³, kurias reikia suprasti dirbant su tradicinÄ—mis AI skaiÄiavimo paradigmomis, bÅ«tent:

- **â˜ï¸ DebesÅ³ pagrindu veikianÄio apdorojimo**: AI modeliai veikia galingoje serveriÅ³ infrastruktÅ«roje su dideliais skaiÄiavimo resursais.
- **ğŸ”Œ API pagrindu veikianÄio prieigos**: Programos pasiekia AI galimybes per nuotolinius API skambuÄius, o ne vietinÄ¯ apdorojimÄ….
- **ğŸ›ï¸ Centralizuotas modeliÅ³ valdymas**: Modeliai yra centralizuotai priÅ¾iÅ«rimi ir atnaujinami, uÅ¾tikrinant nuoseklumÄ…, bet reikalaujant tinklo ryÅ¡io.
- **ğŸ“ˆ ResursÅ³ mastelio keitimas**: DebesÅ³ infrastruktÅ«ra gali dinamiÅ¡kai prisitaikyti prie kintanÄiÅ³ skaiÄiavimo poreikiÅ³.

## KraÅ¡tinio skaiÄiavimo iÅ¡Å¡Å«kiai

KraÅ¡tiniai Ä¯renginiai, tokie kaip neÅ¡iojamieji kompiuteriai, mobilieji telefonai ir daiktÅ³ interneto (IoT) Ä¯renginiai, pvz., Raspberry Pi ir NVIDIA Orin Nano, turi unikalius skaiÄiavimo apribojimus. Å ie Ä¯renginiai paprastai turi maÅ¾esnÄ™ apdorojimo galiÄ…, atmintÄ¯ ir energijos resursus, palyginti su duomenÅ³ centrÅ³ infrastruktÅ«ra.

TradiciÅ¡kai LLM vykdymas tokiuose Ä¯renginiuose buvo sudÄ—tingas dÄ—l Å¡iÅ³ aparatinÄ—s Ä¯rangos apribojimÅ³. TaÄiau kraÅ¡tinio AI apdorojimo poreikis tampa vis svarbesnis Ä¯vairiose situacijose. Apsvarstykite situacijas, kai interneto ryÅ¡ys yra nepatikimas arba nepasiekiamas, pvz., atokiose pramonÄ—s vietose, transporto priemonÄ—se kelionÄ—s metu arba vietovÄ—se su prastu tinklo aprÄ—ptimi. Be to, programos, kurioms reikalingi aukÅ¡ti saugumo standartai, pvz., medicinos prietaisai, finansÅ³ sistemos ar vyriausybÄ—s programos, gali reikalauti vietinio jautrios informacijos apdorojimo, kad bÅ«tÅ³ uÅ¾tikrintas privatumas ir atitiktis.

### Pagrindiniai kraÅ¡tinio skaiÄiavimo apribojimai

KraÅ¡tinio skaiÄiavimo aplinkos susiduria su keliais pagrindiniais apribojimais, kuriÅ³ tradiciniai debesÅ³ pagrindu veikiantys AI sprendimai nepatiria:

- **Ribota apdorojimo galia**: KraÅ¡tiniai Ä¯renginiai paprastai turi maÅ¾iau CPU branduoliÅ³ ir maÅ¾esnÄ¯ taktÅ³ daÅ¾nÄ¯, palyginti su serverio klasÄ—s aparatine Ä¯ranga.
- **Atminties apribojimai**: RAM ir saugojimo talpa kraÅ¡tiniuose Ä¯renginiuose yra Å¾ymiai maÅ¾esnÄ—.
- **Energijos apribojimai**: Baterijomis maitinami Ä¯renginiai turi subalansuoti naÅ¡umÄ… su energijos suvartojimu, kad veiktÅ³ ilgiau.
- **Å ilumos valdymas**: KompaktiÅ¡ki formos faktoriai riboja auÅ¡inimo galimybes, paveikdami ilgalaikÄ¯ naÅ¡umÄ… esant apkrovai.

## Kas yra EdgeAI?

### SÄ…voka: EdgeAI apibrÄ—Å¾imas

EdgeAI reiÅ¡kia dirbtinio intelekto algoritmÅ³ diegimÄ… ir vykdymÄ… tiesiai kraÅ¡tiniuose Ä¯renginiuose â€“ fizinÄ—je aparatinÄ—je Ä¯rangoje, esanÄioje tinklo â€kraÅ¡teâ€œ, arti vietos, kur generuojami ir renkami duomenys. Å ie Ä¯renginiai apima iÅ¡maniuosius telefonus, IoT jutiklius, iÅ¡maniÄ…sias kameras, autonomines transporto priemones, neÅ¡iojamus prietaisus ir pramoninÄ™ Ä¯rangÄ…. Skirtingai nuo tradiciniÅ³ AI sistemÅ³, kurios remiasi debesÅ³ serveriais apdorojimui, EdgeAI perkelia intelektÄ… tiesiai Ä¯ duomenÅ³ Å¡altinÄ¯.

EdgeAI esmÄ— yra AI apdorojimo decentralizavimas, perkeliant jÄ¯ iÅ¡ centralizuotÅ³ duomenÅ³ centrÅ³ ir paskirstant per plaÄiÄ… Ä¯renginiÅ³ tinklÄ…, sudarantÄ¯ mÅ«sÅ³ skaitmeninÄ™ ekosistemÄ…. Tai reiÅ¡kia esminÄ¯ architektÅ«rinÄ¯ pokytÄ¯, kaip AI sistemos yra kuriamos ir diegiamos.

Pagrindiniai EdgeAI konceptualÅ«s principai apima:

- **Artumo apdorojimas**: SkaiÄiavimas vyksta fiziÅ¡kai arti vietos, kur generuojami duomenys.
- **Decentralizuotas intelektas**: SprendimÅ³ priÄ—mimo galimybÄ—s paskirstomos per kelis Ä¯renginius.
- **DuomenÅ³ suverenitetas**: Informacija lieka vietinÄ—je kontrolÄ—je, daÅ¾nai niekada nepaliekant Ä¯renginio.
- **Autonominis veikimas**: Ä®renginiai gali veikti protingai be nuolatinio ryÅ¡io.
- **Ä®terptinis AI**: Intelektas tampa Ä¯prasta kasdieniniÅ³ Ä¯renginiÅ³ savybe.

### EdgeAI architektÅ«ros vizualizacija

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         TRADITIONAL AI ARCHITECTURE                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   Data Transfer  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   API Response   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Edge Devices â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚ Cloud Servers â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ End Users â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     Data                         Model Inference                     Results
   Collection                     High Latency
                                  High Bandwidth
                                  Privacy Concerns
                               
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            EDGE AI ARCHITECTURE                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   Direct Response  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Edge Devices with Embedded AI         â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚ End Users â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â”‚ Sensors â”‚â”€>â”‚ SLM Inference â”‚â”€>â”‚ Local Action â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     Data         Low Latency       Immediate
   Collection     Processing        Response
                  No Data Transfer
                  Enhanced Privacy
```

EdgeAI reiÅ¡kia paradigmos pokytÄ¯ dirbtinio intelekto diegime, perkeliant AI galimybes tiesiai Ä¯ kraÅ¡tinius Ä¯renginius, o ne pasikliaujant vien debesÅ³ pagrindu veikianÄiu apdorojimu. Å is poÅ¾iÅ«ris leidÅ¾ia AI modeliams veikti vietoje Ä¯renginiuose su ribotais skaiÄiavimo resursais, suteikiant realaus laiko iÅ¡vadÅ³ galimybes be nuolatinio interneto ryÅ¡io.

EdgeAI apima Ä¯vairias technologijas ir metodus, skirtus AI modeliams padaryti efektyvesnius ir tinkamus diegti ribotÅ³ resursÅ³ Ä¯renginiuose. Tikslas yra iÅ¡laikyti tinkamÄ… naÅ¡umÄ…, tuo paÄiu Å¾ymiai sumaÅ¾inant AI modeliÅ³ skaiÄiavimo ir atminties reikalavimus.

PaÅ¾velkime Ä¯ pagrindinius poÅ¾iÅ«rius, leidÅ¾ianÄius EdgeAI diegimÄ… Ä¯vairiuose Ä¯renginiuose ir naudojimo atvejais.

### Pagrindiniai EdgeAI principai

EdgeAI yra pagrÄ¯stas keliais pagrindiniais principais, kurie jÄ¯ iÅ¡skiria iÅ¡ tradicinio debesÅ³ pagrindu veikianÄio AI:

- **Vietinis apdorojimas**: AI iÅ¡vados vyksta tiesiai kraÅ¡tiniame Ä¯renginyje, nereikalaujant iÅ¡orinio ryÅ¡io.
- **ResursÅ³ optimizavimas**: Modeliai yra specialiai optimizuoti pagal tiksliniÅ³ Ä¯renginiÅ³ aparatinÄ—s Ä¯rangos apribojimus.
- **Realaus laiko naÅ¡umas**: Apdorojimas vyksta su minimaliu delsimu, skirtas laiko atÅ¾vilgiu jautrioms programoms.
- **Privatumas pagal dizainÄ…**: JautrÅ«s duomenys lieka Ä¯renginyje, didinant saugumÄ… ir atitiktÄ¯.

## PagrindinÄ—s technologijos, leidÅ¾ianÄios EdgeAI

### Modelio kvantavimas

Viena iÅ¡ svarbiausiÅ³ EdgeAI technikÅ³ yra modelio kvantavimas. Å is procesas apima modelio parametrÅ³ tikslumo sumaÅ¾inimÄ…, paprastai nuo 32 bitÅ³ slankiojo kablelio skaiÄiÅ³ iki 8 bitÅ³ sveikÅ³jÅ³ skaiÄiÅ³ arba dar maÅ¾esnio tikslumo formatÅ³. Nors Å¡is tikslumo sumaÅ¾inimas gali atrodyti nerimÄ… keliantis, tyrimai parodÄ—, kad daugelis AI modeliÅ³ gali iÅ¡laikyti savo naÅ¡umÄ… net ir esant Å¾ymiai sumaÅ¾intam tikslumui.

Kvantavimas veikia, susiedamas slankiojo kablelio reikÅ¡miÅ³ diapazonÄ… su maÅ¾esniu diskreÄiÅ³ reikÅ¡miÅ³ rinkiniu. PavyzdÅ¾iui, vietoj 32 bitÅ³ naudojimo kiekvienam parametrui, kvantavimas gali naudoti tik 8 bitus, dÄ—l to sumaÅ¾Ä—ja atminties reikalavimai 4 kartus ir daÅ¾nai pasiekiamas greitesnis iÅ¡vadÅ³ laikas.

```python
# Example: PyTorch model quantization 
import torch

# Load a pre-trained model
model = torch.load('large_model.pth')

# Quantize the model to INT8
quantized_model = torch.quantization.quantize_dynamic(
    model,  # model to quantize
    {torch.nn.Linear, torch.nn.Conv2d},  # layers to quantize
    dtype=torch.qint8  # quantization data type
)

# Save the quantized model
torch.save(quantized_model, 'quantized_model.pth')

# Memory usage comparison
original_size = model.size()
quantized_size = quantized_model.size()
print(f"Memory reduction: {original_size / quantized_size:.2f}x")
```

Skirtingos kvantavimo technikos apima:

- **Po treniravimo kvantavimas (PTQ)**: Taikomas po modelio treniravimo, nereikalaujant pakartotinio treniravimo.
- **Kvantavimo suvokimo treniravimas (QAT)**: Ä®traukia kvantavimo efektus treniravimo metu, siekiant geresnio tikslumo.
- **Dinaminis kvantavimas**: Kvantuoja svorius Ä¯ int8, bet aktyvacijas skaiÄiuoja dinamiÅ¡kai.
- **Statinis kvantavimas**: IÅ¡ anksto apskaiÄiuoja visus kvantavimo parametrus tiek svoriams, tiek aktyvacijoms.

EdgeAI diegimui tinkamos kvantavimo strategijos pasirinkimas priklauso nuo konkreÄios modelio architektÅ«ros, naÅ¡umo reikalavimÅ³ ir tikslinio Ä¯renginio aparatinÄ—s Ä¯rangos galimybiÅ³.

### Modelio suspaudimas ir optimizavimas

Be kvantavimo, Ä¯vairios suspaudimo technikos padeda sumaÅ¾inti modelio dydÄ¯ ir skaiÄiavimo reikalavimus. Tai apima:

**Pruning**: Å i technika paÅ¡alina nereikalingus ryÅ¡ius arba neuronus iÅ¡ neuroniniÅ³ tinklÅ³. Identifikuojant ir paÅ¡alinant parametrus, kurie maÅ¾ai prisideda prie modelio naÅ¡umo, pruning gali Å¾ymiai sumaÅ¾inti modelio dydÄ¯, iÅ¡laikant tikslumÄ….

```python
# Example: Neural network pruning in TensorFlow
import tensorflow as tf
import tensorflow_model_optimization as tfmot

# Define the model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Apply pruning during training
pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(
    initial_sparsity=0.0,
    final_sparsity=0.5,  # 50% of connections will be pruned
    begin_step=0,
    end_step=10000
)

pruned_model = tfmot.sparsity.keras.prune_low_magnitude(
    model, pruning_schedule=pruning_schedule
)

# Compile the pruned model
pruned_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model while pruning
pruned_model.fit(x_train, y_train, epochs=10)

# Convert to a smaller model for deployment
final_model = tfmot.sparsity.keras.strip_pruning(pruned_model)
```

**Å½iniÅ³ distiliacija**: Å is metodas apima maÅ¾esnio â€studentoâ€œ modelio treniravimÄ…, kad jis imituotÅ³ didesnio â€mokytojoâ€œ modelio elgesÄ¯. Studentas mokosi apytiksliai atkartoti mokytojo iÅ¡vestis, daÅ¾nai pasiekdamas panaÅ¡Å³ naÅ¡umÄ… su Å¾ymiai maÅ¾esniais parametrais.

**Modelio architektÅ«ros optimizavimas**: TyrÄ—jai sukÅ«rÄ— specializuotas architektÅ«ras, skirtas kraÅ¡tiniam diegimui, tokias kaip MobileNets, EfficientNets ir kitas lengvas architektÅ«ras, kurios subalansuoja naÅ¡umÄ… su skaiÄiavimo efektyvumu.

### MaÅ¾i kalbos modeliai (SLMs)

Kylanti EdgeAI tendencija yra maÅ¾Å³ kalbos modeliÅ³ (SLMs) kÅ«rimas. Å ie modeliai yra sukurti nuo pat pradÅ¾iÅ³, kad bÅ«tÅ³ kompaktiÅ¡ki ir efektyvÅ«s, tuo paÄiu teikiant reikÅ¡mingas natÅ«ralios kalbos galimybes. SLMs tai pasiekia per kruopÅ¡Äius architektÅ«rinius sprendimus, efektyvias treniravimo technikas ir orientuotÄ… treniravimÄ… konkreÄiose srityse ar uÅ¾duotyse.

Skirtingai nuo tradiciniÅ³ metodÅ³, kurie apima dideliÅ³ modeliÅ³ suspaudimÄ…, SLMs daÅ¾nai treniruojami su maÅ¾esniais duomenÅ³ rinkiniais ir optimizuotomis architektÅ«romis, specialiai sukurtomis kraÅ¡tiniam diegimui. Å is poÅ¾iÅ«ris gali sukurti modelius, kurie yra ne tik maÅ¾esni, bet ir efektyvesni konkretiems naudojimo atvejams.

## AparatinÄ—s Ä¯rangos pagreitinimas EdgeAI

Å iuolaikiniai kraÅ¡tiniai Ä¯renginiai vis daÅ¾niau apima specializuotÄ… aparatinÄ™ Ä¯rangÄ…, skirtÄ… AI darbo krÅ«viams pagreitinti:

### NeuronÅ³ apdorojimo vienetai (NPUs)

NPUs yra specializuoti procesoriai, skirti neuroniniÅ³ tinklÅ³ skaiÄiavimams. Å ie lustai gali vykdyti AI iÅ¡vadÅ³ uÅ¾duotis daug efektyviau nei tradiciniai CPU, daÅ¾nai su maÅ¾esniu energijos suvartojimu. Daugelis Å¡iuolaikiniÅ³ iÅ¡maniÅ³jÅ³ telefonÅ³, neÅ¡iojamÅ³jÅ³ kompiuteriÅ³ ir IoT Ä¯renginiÅ³ dabar apima NPUs, kad bÅ«tÅ³ galima vykdyti AI apdorojimÄ… Ä¯renginyje.

```csharp
// Example: Using Windows ML to target NPU acceleration in C#
using Microsoft.ML.OnnxRuntime;

// Create session options with NPU provider
var sessionOptions = new SessionOptions();
sessionOptions.AppendExecutionProvider_DmlExecutionProvider();  // DirectML for NPU

// Load the ONNX model
using var session = new InferenceSession("model.onnx", sessionOptions);

// Create input tensor
var inputTensor = new DenseTensor<float>(new[] { 1, 3, 224, 224 });  // Example input shape
var inputs = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor("input", inputTensor) };

// Run inference with NPU acceleration
using var results = session.Run(inputs);
var output = results.First().AsTensor<float>();

// Process output
Console.WriteLine($"Inference result: {output[0]}");
```

Ä®renginiai su NPUs apima:

- **Apple**: A serijos ir M serijos lustai su Neural Engine
- **Qualcomm**: Snapdragon procesoriai su Hexagon DSP/NPU
- **Samsung**: Exynos procesoriai su NPU
- **Intel**: Movidius VPUs ir Habana Labs pagreitinimo Ä¯renginiai
- **Microsoft**: Windows Copilot+ kompiuteriai su NPUs

### ğŸ® GPU pagreitinimas

Nors kraÅ¡tiniai Ä¯renginiai gali neturÄ—ti galingÅ³ GPU, esanÄiÅ³ duomenÅ³ centruose, daugelis vis tiek apima integruotus arba atskirus GPU, kurie gali pagreitinti AI darbo krÅ«vius. Å iuolaikiniai mobilieji GPU ir integruoti grafikos procesoriai gali suteikti reikÅ¡mingÄ… naÅ¡umo pagerÄ—jimÄ… AI iÅ¡vadÅ³ uÅ¾duotims.

```python
# Example: Using TensorRT for GPU acceleration on edge devices
import tensorrt as trt
import numpy as np

# Create TensorRT logger and builder
TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
builder = trt.Builder(TRT_LOGGER)
network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
parser = trt.OnnxParser(network, TRT_LOGGER)

# Parse ONNX model
with open('model.onnx', 'rb') as model:
    parser.parse(model.read())

# Configure builder
config = builder.create_builder_config()
config.max_workspace_size = 1 << 28  # 256 MiB
config.set_flag(trt.BuilderFlag.FP16)  # Use FP16 precision for edge GPU

# Build and serialize engine
engine = builder.build_engine(network, config)
with open('model.trt', 'wb') as f:
    f.write(engine.serialize())
```

### CPU optimizavimas

Net CPU tik Ä¯renginiai gali pasinaudoti EdgeAI per optimizuotas Ä¯gyvendinimo strategijas. Å iuolaikiniai CPU apima specializuotas instrukcijas AI darbo krÅ«viams, o programinÄ—s Ä¯rangos sistemos buvo sukurtos maksimaliai iÅ¡naudoti CPU naÅ¡umÄ… AI iÅ¡vadoms.

```bash
# Example: Using XNNPACK with TFLite for optimized CPU inference
# Compilation command with XNNPACK acceleration enabled

bazel build -c opt --copt=-O3 --copt=-march=native \
  tensorflow/lite/delegates/xnnpack:libxnnpack_delegate.so

# Convert TensorFlow model to TFLite with optimization
tflite_convert \
  --keras_model_file=model.h5 \
  --output_file=model.tflite \
  --inference_type=FLOAT \
  --experimental_new_converter \
  --experimental_new_quantizer
```

PrograminÄ—s Ä¯rangos inÅ¾inieriams, dirbantiems su EdgeAI, supratimas, kaip pasinaudoti Å¡iais aparatinÄ—s Ä¯rangos pagreitinimo pasirinkimais, yra labai svarbus optimizuojant iÅ¡vadÅ³ naÅ¡umÄ… ir energijos efektyvumÄ… tiksliniuose Ä¯renginiuose.

## EdgeAI privalumai

### Privatumas ir saugumas

Vienas iÅ¡ didÅ¾iausiÅ³ EdgeAI privalumÅ³ yra sustiprintas privatumas ir saugumas. Apdorojant duomenis vietoje Ä¯renginyje, jautri informacija niekada nepalieka vartotojo kontrolÄ—s. Tai ypaÄ svarbu programoms, tvarkanÄioms asmeninius duomenis, medicininÄ™ informacijÄ… ar konfidencialius verslo duomenis.

### SumaÅ¾intas delsimas

EdgeAI paÅ¡alina poreikÄ¯ siÅ³sti duomenis Ä¯ nuotolinius serverius apdorojimui, Å¾ymiai sumaÅ¾indamas delsÄ…. Tai labai svarbu realaus laiko programoms, tokioms kaip autonominÄ—s transporto priemonÄ—s, pramoninÄ— automatizacija ar interaktyvios programos, kuriose reikalingi greiti atsakymai.

### Veikimas neprisijungus

EdgeAI leidÅ¾ia AI funkcionalumÄ… net ir tada, kai interneto ryÅ¡ys yra nepasiekiamas. Tai vertinga programoms atokiose vietose, kelionÄ—s metu arba situacijose
- [02: EdgeAI Pritaikymas](02.RealWorldCaseStudies.md)

---

**AtsakomybÄ—s apribojimas**:  
Å is dokumentas buvo iÅ¡verstas naudojant AI vertimo paslaugÄ… [Co-op Translator](https://github.com/Azure/co-op-translator). Nors stengiamÄ—s uÅ¾tikrinti tikslumÄ…, praÅ¡ome atkreipti dÄ—mesÄ¯, kad automatiniai vertimai gali turÄ—ti klaidÅ³ ar netikslumÅ³. Originalus dokumentas jo gimtÄ…ja kalba turÄ—tÅ³ bÅ«ti laikomas autoritetingu Å¡altiniu. Kritinei informacijai rekomenduojama naudoti profesionalÅ³ Å¾mogaus vertimÄ…. Mes neprisiimame atsakomybÄ—s uÅ¾ nesusipratimus ar neteisingus interpretavimus, atsiradusius dÄ—l Å¡io vertimo naudojimo.