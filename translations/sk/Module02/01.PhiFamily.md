<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20892f7994d9e5d2473ad19dfa93cf6d",
  "translation_date": "2025-09-18T18:23:02+00:00",
  "source_file": "Module02/01.PhiFamily.md",
  "language_code": "sk"
}
-->
# Sekcia 1: Z√°klady modelovej rodiny Microsoft Phi

Modelov√° rodina Microsoft Phi predstavuje z√°sadn√Ω posun v oblasti umelej inteligencie, ukazuj√∫c, ≈æe kompaktn√© a efekt√≠vne modely m√¥≈æu dosiahnu≈• pozoruhodn√Ω v√Ωkon, priƒçom s√∫ v√Ωrazne √∫spornej≈°ie na zdroje ne≈æ tradiƒçn√© veƒæk√© jazykov√© modely. Je d√¥le≈æit√© pochopi≈•, ako rodina Phi umo≈æ≈àuje v√Ωkonn√© schopnosti AI s ni≈æ≈°√≠mi v√Ωpoƒçtov√Ωmi po≈æiadavkami, priƒçom si zachov√°va vysok√Ω v√Ωkon naprieƒç r√¥znymi √∫lohami.

## Zdroje pre v√Ωvoj√°rov

### Katal√≥g modelov Azure AI Foundry
Modely rodiny Phi (okrem Phi-silica) s√∫ dostupn√© prostredn√≠ctvom [Azure AI Foundry Model Catalog](https://ai.azure.com/explore/models?q=phi), ƒço v√Ωvoj√°rom uƒæahƒçuje pr√≠stup, doladenie a nasadenie t√Ωchto modelov do ich aplik√°ci√≠. Katal√≥g poskytuje jednoduch√Ω sp√¥sob experimentovania s r√¥znymi variantmi Phi a ich integr√°ciu do projektov.

### Azure AI Foundry
Modely Phi m√¥≈æete nasadi≈• a experimentova≈• s nimi pomocou [Azure AI Foundry](https://ai.azure.com), ktor√© poskytuje komplexn√© prostredie na tvorbu, testovanie a nasadenie AI rie≈°en√≠ s minim√°lnym nastaven√≠m.

### Foundry Local
Pre lok√°lny v√Ωvoj a nasadenie si pozrite [Microsoft Foundry Local](https://github.com/microsoft/foundry-local), ktor√© umo≈æ≈àuje sp√∫≈°≈•a≈• modely Phi na va≈°om v√Ωvojovom zariaden√≠ s optimalizovan√Ωmi konfigur√°ciami.

### Dokumentaƒçn√© zdroje
- [Microsoft Research: Phi Model Technical Reports](https://ai.azure.com/labs/projects/phi-4)
- [Phi Cookbook](https://aka.ms/phicookbook)

## √övod

V tejto lekcii presk√∫mame modelov√∫ rodinu Microsoft Phi a jej z√°kladn√© koncepty. Budeme sa venova≈• evol√∫cii rodiny Phi, inovat√≠vnym metodik√°m tr√©ningu, ktor√© robia modely Phi efekt√≠vnymi, kƒæ√∫ƒçov√Ωm variantom v rodine a praktick√Ωm aplik√°ci√°m v r√¥znych scen√°roch.

## Ciele uƒçenia

Na konci tejto lekcie budete schopn√≠:

- Pochopi≈• filozofiu dizajnu a evol√∫ciu modelovej rodiny Microsoft Phi.
- Identifikova≈• kƒæ√∫ƒçov√© inov√°cie, ktor√© umo≈æ≈àuj√∫ modelom Phi dosiahnu≈• vysok√Ω v√Ωkon s men≈°√≠m poƒçtom parametrov.
- Rozpozna≈• v√Ωhody a obmedzenia r√¥znych variantov modelov Phi.
- Aplikova≈• znalosti o modeloch Phi na v√Ωber vhodn√Ωch variantov pre re√°lne scen√°re.

## Porozumenie tradiƒçn√©mu AI modelov√©mu paradigmatu

Tradiƒçne dosiahnutie vysok√©ho v√Ωkonu v spracovan√≠ prirodzen√©ho jazyka vy≈æadovalo mas√≠vne jazykov√© modely s miliardami alebo stovkami mili√°rd parametrov. Organiz√°cie zvyƒçajne nasadzuj√∫ tieto modely na v√Ωkonn√Ωch GPU klastroch, priƒçom ich schopnosti vyu≈æ√≠vaj√∫ prostredn√≠ctvom API rozhran√≠ alebo ≈°pecializovanej hardv√©rovej infra≈°trukt√∫ry.

Tento pr√≠stup funguje dobre pre mnoh√© aplik√°cie, ale m√° inherentn√© obmedzenia, pokiaƒæ ide o praktick√© scen√°re nasadenia. Konvenƒçn√° met√≥da zah≈ï≈àa pou≈æ√≠vanie modelov, ktor√© vy≈æaduj√∫ znaƒçn√© v√Ωpoƒçtov√© zdroje, veƒæk√© mno≈æstvo pam√§te a v√Ωznamn√∫ spotrebu energie. Hoci tento pr√≠stup poskytuje pr√≠stup k najmodernej≈°√≠m schopnostiam, vytv√°ra z√°vislos≈• na drahom hardv√©ri, zvy≈°uje prev√°dzkov√© n√°klady a obmedzuje flexibilitu nasadenia.

## V√Ωzva efekt√≠vneho nasadenia AI

Potreba efekt√≠vnej≈°ej AI sa st√°va ƒçoraz d√¥le≈æitej≈°ou v r√¥znych scen√°roch. Zv√°≈æte aplik√°cie vy≈æaduj√∫ce lok√°lne nasadenie z d√¥vodu ochrany s√∫kromia, n√°kladovo citliv√© implement√°cie, kde sa n√°klady na cloudov√© API st√°vaj√∫ ne√∫nosn√Ωmi, scen√°re edge computingu s obmedzen√Ωmi hardv√©rov√Ωmi zdrojmi alebo aplik√°cie v re√°lnom ƒçase, kde je latencia kritick√°.

### Kƒæ√∫ƒçov√© obmedzenia nasadenia

Tradiƒçn√© nasadenie veƒæk√Ωch modelov ƒçel√≠ niekoƒæk√Ωm z√°kladn√Ωm obmedzeniam, ktor√© limituj√∫ ich praktick√∫ pou≈æiteƒænos≈•:

- **N√°kladov√© obmedzenia**: Vysok√© v√Ωpoƒçtov√© n√°klady robia kontinu√°lne nasadenie drah√Ωm pre mnoh√© organiz√°cie.
- **Obmedzenia zdrojov**: Obmedzen√Ω pr√≠stup k ≈°piƒçkovej GPU infra≈°trukt√∫re obmedzuje mo≈ænosti nasadenia.
- **Po≈æiadavky na s√∫kromie**: Citliv√© aplik√°cie vy≈æaduj√∫ lok√°lne spracovanie na zachovanie ochrany √∫dajov.
- **Citlivos≈• na latenciu**: Aplik√°cie v re√°lnom ƒçase potrebuj√∫ okam≈æit√© odpovede bez oneskoren√≠ sp√¥soben√Ωch cloudov√Ωm prenosom.

## Filozofia modelov Microsoft Phi

Modelov√° rodina Microsoft Phi predstavuje z√°sadn√Ω posun v dizajnovej filozofii AI modelov, uprednost≈àuj√∫c efekt√≠vnos≈• a praktick√© nasadenie, priƒçom si zachov√°va siln√© v√Ωkonov√© charakteristiky. Modely Phi to dosahuj√∫ prostredn√≠ctvom inovat√≠vnych architekt√∫r, kvalitn√Ωch metod√≠k tr√©ningu a ≈°pecializovan√Ωch optimalizaƒçn√Ωch techn√≠k.

Rodina Phi zah≈ï≈àa r√¥zne pr√≠stupy navrhnut√© na maximaliz√°ciu v√Ωkonu na parameter, umo≈æ≈àuj√∫c nasadenie na ≈°tandardnom hardv√©ri, priƒçom poskytuje zmyslupln√© schopnosti AI. Cieƒæom je udr≈æa≈• konkurencieschopn√Ω v√Ωkon pri dramatickom zn√≠≈æen√≠ v√Ωpoƒçtov√Ωch po≈æiadaviek, vyu≈æitia pam√§te a prev√°dzkov√Ωch n√°kladov.

### Z√°kladn√© princ√≠py dizajnu Phi

Modely Phi s√∫ postaven√© na niekoƒæk√Ωch z√°kladn√Ωch princ√≠poch, ktor√© ich odli≈°uj√∫ od tradiƒçn√Ωch veƒæk√Ωch jazykov√Ωch modelov:

- **Efektivita na prvom mieste**: Optimalizovan√© na maxim√°lny v√Ωkon na parameter namiesto absol√∫tneho rozsahu.
- **Kvalitn√Ω tr√©ning**: Zameranie na kvalitn√©, kur√°torsk√© tr√©ningov√© d√°ta namiesto mas√≠vnych datasetov.
- **Flexibilita nasadenia**: Navrhnut√© na efekt√≠vne fungovanie na r√¥znych hardv√©rov√Ωch konfigur√°ci√°ch.
- **≈†pecializovan√© schopnosti**: ƒåasto optimalizovan√© na konkr√©tne √∫lohy alebo dom√©ny na maximaliz√°ciu efekt√≠vnosti.

## Kƒæ√∫ƒçov√© technol√≥gie umo≈æ≈àuj√∫ce rodinu Phi

### Pr√≠stup ‚Äûuƒçebnicov√©ho‚Äú tr√©ningu

Jedn√Ωm z najrevoluƒçnej≈°√≠ch aspektov rodiny Phi je metodika tr√©ningu ‚Äûuƒçebnicovej kvality‚Äú. Namiesto tr√©ningu na mas√≠vnom mno≈æstve nevyfiltrovan√Ωch internetov√Ωch d√°t modely Phi pou≈æ√≠vaj√∫ starostlivo kur√°torsk√©, kvalitn√© vzdel√°vacie obsahy navrhnut√© na efekt√≠vne uƒçenie sa logiky, matematiky, k√≥dovania a v≈°eobecn√Ωch znalost√≠.

Tento pr√≠stup funguje vytv√°ran√≠m syntetick√©ho vzdel√°vacieho obsahu, ktor√Ω zrkadl√≠ kvalitn√© uƒçebnice a akademick√© materi√°ly. Tr√©ningov√© d√°ta s√∫ ≈°pecificky navrhnut√© tak, aby boli pedagogicky spr√°vne, zameran√© na jasn√© vysvetlenia, krok za krokom logiku a ≈°trukt√∫rovan√∫ prezent√°ciu znalost√≠.

### Pokroƒçil√Ω tr√©ning logiky

Ned√°vne modely Phi zah≈ï≈àaj√∫ sofistikovan√© metodiky tr√©ningu logiky, ktor√© umo≈æ≈àuj√∫ komplexn√© rie≈°enie probl√©mov v niekoƒæk√Ωch krokoch. Tieto techniky zah≈ï≈àaj√∫:

**Tr√©ning ‚ÄûChain-of-Thought‚Äú**: Modely sa uƒçia rozklada≈• komplexn√© probl√©my na medzistupne logiky, ƒç√≠m sa ich proces rie≈°enia st√°va transparentnej≈°√≠m a spoƒæahlivej≈°√≠m.

**≈†k√°lovanie poƒças inferencie**: Modely generuj√∫ podrobn√© logick√© re≈•azce, ktor√© vyu≈æ√≠vaj√∫ dodatoƒçn√© v√Ωpoƒçtov√© zdroje poƒças generovania odpoved√≠ na zlep≈°enie presnosti.

**Tr√©ning na hranici schopnost√≠**: Tr√©ningov√© d√°ta s√∫ ≈°pecificky vybran√© tak, aby model vyzvali na hranici jeho aktu√°lnych schopnost√≠, ƒç√≠m sa podporuje uƒçenie komplexn√Ωch logick√Ωch vzorcov.

### Architektonick√© inov√°cie

Rodina Phi zah≈ï≈àa niekoƒæko architektonick√Ωch optimaliz√°ci√≠ navrhnut√Ωch ≈°peci√°lne na efektivitu:

**Efektivita parametrov**: Starostliv√© architektonick√© voƒæby, ktor√© maximalizuj√∫ vplyv ka≈æd√©ho parametra v modeli.

**Multimod√°lna integr√°cia**: Efekt√≠vna integr√°cia spracovania textu, obrazu a reƒçi v kompaktn√Ωch architekt√∫rach.

**Optimaliz√°cia hardv√©ru**: ≈†pecializovan√© varianty optimalizovan√© na konkr√©tne hardv√©rov√© platformy a scen√°re nasadenia.

## Optimaliz√°cia hardv√©ru pre modely Phi

Modern√© prostredia nasadenia profituj√∫ z efektivity modelov Phi naprieƒç r√¥znymi hardv√©rov√Ωmi konfigur√°ciami:

### Nasadenie optimalizovan√© na CPU

Modely Phi s√∫ navrhnut√© tak, aby efekt√≠vne fungovali na hardv√©ri iba s CPU, ƒço ich rob√≠ dostupn√Ωmi na nasadenie na ≈°tandardnej v√Ωpoƒçtovej infra≈°trukt√∫re bez potreby ≈°pecializovan√Ωch AI akceler√°torov.

### GPU akceler√°cia

Hoci nevy≈æaduj√∫ v√Ωkonn√© GPU, modely Phi m√¥≈æu vyu≈æ√≠va≈• dostupn√© GPU zdroje na zlep≈°en√Ω v√Ωkon, poskytuj√∫c flexibilitu v konfigur√°ci√°ch nasadenia.

### Integr√°cia na edge zariadeniach

≈†pecializovan√© varianty ako Phi-3-Silica s√∫ optimalizovan√© na konkr√©tne platformy edge computingu, dosahuj√∫c pozoruhodn√© efekt√≠vne metriky, ako napr√≠klad 650 tokenov za sekundu pri spotrebe iba 1,5 W.

## V√Ωhody modelovej rodiny Phi

### N√°kladov√° efekt√≠vnos≈•

Modely Phi dramaticky zni≈æuj√∫ prev√°dzkov√© n√°klady t√Ωm, ≈æe vy≈æaduj√∫ v√Ωrazne menej v√Ωpoƒçtovej infra≈°trukt√∫ry, priƒçom si zachov√°vaj√∫ konkurencieschopn√Ω v√Ωkon. To rob√≠ AI dostupnou pre organiz√°cie s obmedzen√Ωmi rozpoƒçtami alebo aplik√°cie s vysok√Ωm objemom, kde z√°le≈æ√≠ na n√°kladoch na inferenciu.

### Flexibilita nasadenia

Efektivita modelov Phi umo≈æ≈àuje nasadenie naprieƒç ≈°irokou ≈°k√°lou hardv√©rov√Ωch konfigur√°ci√≠, od osobn√Ωch laptopov po podnikov√© servery, poskytuj√∫c organiz√°ci√°m v√§ƒç≈°iu flexibilitu vo v√Ωbere AI infra≈°trukt√∫ry.

### Ochrana s√∫kromia a bezpeƒçnos≈•

Efektivita modelov Phi umo≈æ≈àuje lok√°lne nasadenie pre aplik√°cie citliv√© na s√∫kromie, ƒç√≠m sa zabezpeƒç√≠, ≈æe citliv√© √∫daje nikdy neopustia kontrolu organiz√°cie, priƒçom st√°le poskytuj√∫ v√Ωkonn√© schopnosti AI.

### V√Ωkon v re√°lnom ƒçase

Zn√≠≈æen√© v√Ωpoƒçtov√© po≈æiadavky sa premietaj√∫ do r√Ωchlej≈°√≠ch ƒçasov inferencie, umo≈æ≈àuj√∫c aplik√°cie v re√°lnom ƒçase, ktor√© vy≈æaduj√∫ okam≈æit√© odpovede bez kompromisov v kvalite schopnost√≠ AI.

### Pr√≠stupn√° AI

Zn√≠≈æen√≠m bari√©r pre nasadenie AI modely Phi spr√≠stup≈àuj√∫ pokroƒçil√© schopnosti AI organiz√°ci√°m s obmedzen√Ωmi zdrojmi, umo≈æ≈àuj√∫c men≈°√≠m t√≠mom a jednotliv√Ωm v√Ωvoj√°rom vyu≈æ√≠va≈• sofistikovan√© porozumenie jazyka.

## Praktick√© pr√≠klady a pou≈æitia

Predt√Ωm, ne≈æ sa ponor√≠me do technickej evol√∫cie, presk√∫majme niekoƒæko konkr√©tnych pr√≠kladov toho, ƒço modely Phi dok√°≈æu:

### Pr√≠klad matematick√©ho uva≈æovania

Phi-4-mini-reasoning vynik√° v krok za krokom rie≈°en√≠ matematick√Ωch probl√©mov. Napr√≠klad, keƒè sa op√Ωta ‚ÄûAko vyrie≈°i≈• 3*x^2+4*x+5=1?‚Äú, model poskytne podrobn√© kroky uva≈æovania:

```
<|system|>Your name is Phi, an AI math expert developed by Microsoft.<|end|>
<|user|>How to solve 3*x^2+4*x+5=1?<|end|>
<|assistant|>
I need to solve the quadratic equation 3x¬≤ + 4x + 5 = 1.

First, let me rearrange this to standard form:
3x¬≤ + 4x + 5 = 1
3x¬≤ + 4x + 5 - 1 = 0  
3x¬≤ + 4x + 4 = 0

Now I can use the quadratic formula: x = (-b ¬± ‚àö(b¬≤ - 4ac)) / (2a)
Where a = 3, b = 4, c = 4

Let me calculate the discriminant:
b¬≤ - 4ac = 4¬≤ - 4(3)(4) = 16 - 48 = -32

Since the discriminant is negative (-32), this equation has no real solutions.
The solutions are complex: x = (-4 ¬± ‚àö(-32)) / 6 = (-4 ¬± 4i‚àö2) / 6 = (-2 ¬± 2i‚àö2) / 3
```

### Pr√≠klad viacjazyƒçnej podpory

Phi-3.5-mini-instruct demon≈°truje siln√© viacjazyƒçn√© schopnosti naprieƒç r√¥znymi jazykmi. Tu je pr√≠klad form√°tu v√Ωzvy:

```
<|system|>You are a helpful assistant.<|end|>
<|user|>How to explain Internet for a medieval knight?<|end|>
<|assistant|>
Imagine, good sir knight, a vast network of invisible roads that span the entire realm and beyond. The Internet is like a magical system of messenger birds that can carry any message - be it text, images, or even moving pictures - instantly to any castle, village, or hamlet in the world.

Think of it as if every scribe's work could be copied and shared with thousands of people simultaneously, as if you could visit any library in any kingdom without leaving your chambers, or as if you could hold council with knights from distant lands as if they were sitting at your very table.

This "Internet" allows people to:
- Send messages faster than the swiftest horse
- Access knowledge from scholars across all kingdoms
- Trade goods without traveling to distant markets
- Share stories and news from lands you've never seen

'Tis like having a thousand scribes, merchants, and storytellers all working for you at once, good knight!
```

### Pr√≠klad multimod√°lnych schopnost√≠

Phi-4-multimodal dok√°≈æe spracova≈• text, obr√°zky a reƒç s√∫ƒçasne. Tu s√∫ niektor√© praktick√© aplik√°cie:

**Pl√°novanie cesty s audio vstupom:**
Sledujte, ako Phi-4 Multimodal analyzuje hovoren√Ω jazyk na pomoc pri pl√°novan√≠ cesty do Seattlu, demon≈°truj√∫c jeho pokroƒçil√© schopnosti spracovania zvuku a odpor√∫ƒçania.

**Rie≈°enie matematick√Ωch probl√©mov z obr√°zkov:**
Pozrite sa, ako Phi-4 Multimodal rie≈°i komplexn√© matematick√© probl√©my prostredn√≠ctvom vizu√°lnych vstupov, demon≈°truj√∫c jeho schopnos≈• spracova≈• a vyrie≈°i≈• rovnice prezentovan√© na obr√°zkoch.

**Pr√≠klad volania funkci√≠:**
S volan√≠m funkci√≠ m√¥≈æu Phi-4-mini a Phi-4-multimodal roz≈°√≠ri≈• svoje schopnosti spracovania textu integr√°ciou vyhƒæad√°vaƒçov, pripojen√≠m r√¥znych n√°strojov a ƒèal≈°√≠ch. Ako je ilustrovan√©, model dok√°≈æe z√≠ska≈• inform√°cie o z√°pasoch Premier League prostredn√≠ctvom Phi-4-mini, ukazuj√∫c jeho schopnos≈• bezprobl√©movo interagova≈• s extern√Ωmi zdrojmi √∫dajov.

### Pr√≠klad generovania k√≥du

Phi-4-multimodal dok√°≈æe generova≈• ≈°trukt√∫rovan√Ω projektov√Ω k√≥d na z√°klade obsahu obr√°zkov a poskytnut√Ωch v√Ωziev, ako je uk√°zan√© v tomto praktickom pracovnom postupe:

1. Nahrajte obr√°zok dr√¥ten√©ho modelu alebo n√°vrhu
2. Poskytnite kontext o po≈æiadavk√°ch projektu
3. Model generuje kompletn√©, funkƒçn√© ≈°trukt√∫ry k√≥du
4. K√≥d m√¥≈æe by≈• prisp√¥soben√Ω na z√°klade konkr√©tnych r√°mcov alebo jazykov

### Pr√≠klad nasadenia na edge zariadeniach

M√¥≈æeme nasadi≈• kvantizovan√Ω model na edge zariadeniach. Kombin√°ciou Microsoft Olive a ONNX GenAI Runtime m√¥≈æeme nasadi≈• Phi-4-mini na Windows, iPhone, Android a ƒèal≈°ie zariadenia. Toto je pr√≠klad be≈æiaci na iPhone 12 Pro.

Proces nasadenia zah≈ï≈àa:
- Kvantiz√°ciu modelu na mobiln√∫ optimaliz√°ciu
- Integr√°ciu ONNX runtime na kompatibilitu naprieƒç platformami
- Lok√°lnu inferenciu bez internetov√©ho pripojenia
- V√Ωkon v re√°lnom ƒçase s minim√°lnou spotrebou energie

## Evol√∫cia rodiny Phi

### Phi-1 a Phi-2: Z√°kladn√© modely

Skor√© modely Phi stanovili z√°kladn√© princ√≠py kvalitn√Ωch tr√©ningov√Ωch d√°t a efekt√≠vnych architekt√∫r:

- **Phi-1 (1,3B parametrov)**: Zaviedol koncept kur√°torsk√Ωch tr√©ningov√Ωch d√°t na z√°kladn√© porozumenie jazyka a generovanie k√≥du.
- **Phi-2 (2,7B parametrov)**: Zlep≈°il schopnosti logiky prostredn√≠ctvom syntetick√Ωch NLP d√°t a starostlivo filtrovan√©ho webov√©ho obsahu.

### Rodina Phi-3: Hlavn√Ω pr√∫d

S√©ria Phi-3 znamenala prielom v schopnostiach SLM s viacer√Ωmi ≈°pecializovan√Ωmi variantmi:

- **Phi-3-mini (3,8B parametrov)**: V≈°eobecn√© jazykov√© √∫lohy s v√Ωnimoƒçnou efektivitou, prekon√°vaj√∫c modely dvojn√°sobnej veƒækosti.
- **Phi-3-small (7B parametrov)**: Pokroƒçil√Ω v√Ωkon prekon√°vaj√∫ci GPT-3.5 Turbo na r√¥znych benchmarkoch.
- **Phi-3-medium (14B parametrov)**: V√Ωkon na √∫rovni podniku prekon√°vaj√∫ci Gemini 1.0 Pro.
- **Phi-3-vision (4,2B parametrov)**: Multimod√°lne schopnosti na spracovanie obrazu a textu.
- **Phi-3-Silica (3,3B parametrov)**: ≈†pecializovan√° optimaliz√°cia na zabudovan√© nasadenie vo Windows 11.

### Rodina Phi-4: Pokroƒçil√° logika

Najnov≈°ia gener√°cia pos√∫va hranice schopnost√≠ logiky:

- **Phi-4 (14B parametrov)**: ≈†pecializ√°cia na komplexn√∫ logiku, najm√§ v matematike.
- **Phi-4-mini (3,8B parametrov)**: Zlep≈°en√° logika s volan√≠m funkci√≠ a podporou dlh√©ho kontextu.
- **Phi-4-multimodal**: S√∫ƒçasn√© spracovanie reƒçi, obrazu a textu
Rodina Phi ukazuje, ≈æe bud√∫cnos≈• nasadenia AI nespoƒç√≠va len v budovan√≠ v√§ƒç≈°√≠ch modelov, ale v budovan√≠ inteligentnej≈°√≠ch, efekt√≠vnej≈°√≠ch modelov, ktor√© dok√°≈æu efekt√≠vne fungova≈• na r√¥znych hardv√©rov√Ωch platform√°ch pri zachovan√≠ vysok√Ωch ≈°tandardov v√Ωkonu.

## Pr√≠klady v√Ωvoja a integr√°cie

### R√Ωchly ≈°tart s Transformers

Tu je n√°vod, ako zaƒça≈• s modelmi Phi pomocou kni≈ænice Hugging Face Transformers:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load Phi-4-mini-instruct
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    attn_implementation="flash_attention_2"  # For optimized performance
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")

# Format your prompt using the chat template
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Explain quantum computing in simple terms."}
]

# Apply chat template
input_text = tokenizer.apply_chat_template(messages, tokenize=False)
inputs = tokenizer(input_text, return_tensors="pt")

# Generate response
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)
    
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### Pr√≠klad jemn√©ho doladenia

Nasleduj√∫ci pr√≠klad ukazuje, ako jemne doladi≈• Phi-4-mini-instruct pre konkr√©tne √∫lohy:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig
from trl import SFTTrainer
from datasets import load_dataset

# Configuration for LoRA fine-tuning
peft_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules="all-linear"
)

# Training configuration optimized for efficiency
training_config = TrainingArguments(
    output_dir="./phi-4-mini-finetuned",
    learning_rate=5.0e-06,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=1,
    num_train_epochs=1,
    bf16=True,
    gradient_checkpointing=True,
    warmup_ratio=0.2,
    save_steps=100
)

# Load model and tokenizer
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-4-mini-instruct",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")
tokenizer.pad_token = tokenizer.unk_token
tokenizer.padding_side = 'right'

# Load and process dataset
train_dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

# Initialize trainer
trainer = SFTTrainer(
    model=model,
    args=training_config,
    peft_config=peft_config,
    train_dataset=train_dataset,
    max_seq_length=2048,
    tokenizer=tokenizer,
    packing=True
)

# Start fine-tuning
trainer.train()
```

### ≈†pecializovan√© form√°ty promptov

**Pre √∫lohy vy≈æaduj√∫ce logick√© uva≈æovanie (Phi-4-reasoning-plus):**
```
<|im_start|>system<|im_sep|>
You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions.

Please structure your response into two main sections:
<think>
{Thought section}
</think>
{Solution section}
<|im_end|>
<|im_start|>user<|im_sep|>
What is the derivative of x^2?
<|im_end|>
<|im_start|>assistant<|im_sep|>
```

**Pre matematick√© √∫lohy (Phi-4-mini-reasoning):**
```
<|system|>
Your name is Phi, an AI math expert developed by Microsoft.
<|end|>
<|user|>
Solve this calculus problem: Find the integral of 2x + 3
<|end|>
<|assistant|>
```

### Nasadenie na mobiln√Ωch zariadeniach pomocou ONNX

```python
import onnxruntime as ort
import numpy as np

# Load ONNX model for mobile deployment
session = ort.InferenceSession("phi-4-mini-quantized.onnx")

# Prepare input
input_ids = tokenizer.encode("Hello, how are you?", return_tensors="np")

# Run inference
outputs = session.run(None, {"input_ids": input_ids})
predicted_ids = outputs[0]

# Decode response
response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)
```

## V√Ωkonnostn√© ukazovatele a √∫spechy

Rodina modelov Phi dosiahla pozoruhodn√© v√Ωsledky v r√¥znych benchmarkoch, ƒçasto prekon√°vaj√∫c oveƒæa v√§ƒç≈°ie modely:

### Hlavn√© v√Ωkonnostn√© √∫spechy

**Excelentnos≈• v matematickom uva≈æovan√≠:**
- Phi-4 dosahuje 82,5 % presnos≈• na AIME 2025 (kvalifik√°cia na matematick√∫ olympi√°du)
- Phi-4-reasoning (14B) prekon√°va DeepSeek-R1-Distill-70B (5x v√§ƒç≈°√≠) v benchmarkoch logick√©ho uva≈æovania
- Phi-4-mini-reasoning (3,8B) konkuruje modelom dvojn√°sobnej veƒækosti v √∫loh√°ch matematick√©ho uva≈æovania

**√öspechy v efektivite:**
- Phi-3-Silica dosahuje 650 tokenov za sekundu pri spotrebe iba 1,5W
- Phi-4-mini (3,8B) dosahuje podobn√Ω v√Ωkon ako oveƒæa v√§ƒç≈°ie modely

**V√Ωkonnos≈• v benchmarkoch:**
- **MMLU (Massive Multitask Language Understanding)**: Konkurenƒçn√Ω v√Ωkon v 57 akademick√Ωch predmetoch
- **HumanEval**: Siln√© schopnosti generovania k√≥du, najm√§ v Pythone
- **MGSM**: Multilingv√°lne rie≈°enie matematick√Ωch √∫loh na √∫rovni z√°kladnej ≈°koly
- **DROP**: Komplexn√© √∫lohy porozumenia a uva≈æovania
- **SimpleQA**: Presnos≈• faktick√Ωch odpoved√≠

### üìä Porovn√°vacia tabuƒæka modelov

| Model | Parametre | Dƒ∫≈æka kontextu | Kƒæ√∫ƒçov√© siln√© str√°nky | Najlep≈°ie pou≈æitie |
|-------|-----------|----------------|-----------------------|--------------------|
| **Phi-3-mini** | 3,8B | 4K/128K | V≈°eobecn√° efektivita | Mobiln√© aplik√°cie, z√°kladn√© chatboty |
| **Phi-3.5-mini** | 3,8B | 128K | Multilingv√°lna podpora | Medzin√°rodn√© aplik√°cie |
| **Phi-4-mini** | 3,8B | 128K | Vylep≈°en√© uva≈æovanie, volanie funkci√≠ | Automatiz√°cia podnikania |
| **Phi-4-mini-reasoning** | 3,8B | 128K | Matematick√© uva≈æovanie | Vzdel√°vacie platformy |
| **Phi-4** | 14B | 32K | Komplexn√© uva≈æovanie | V√Ωskum, pokroƒçil√° anal√Ωza |
| **Phi-4-reasoning** | 14B | 32K/64K | Viackrokov√© uva≈æovanie | Vedeck√© v√Ωpoƒçty |
| **Phi-4-reasoning-plus** | 14B | 32K | Maxim√°lna presnos≈• uva≈æovania | Kritick√© rozhodovanie |
| **Phi-4-multimodal** | 5,6B | Premenn√° | Reƒç, vizu√°l, text | Multimedi√°lne aplik√°cie |

## Sprievodca v√Ωberom modelu

### Pre z√°kladn√© aplik√°cie
- **Phi-3-mini**: Jednoduch√© generovanie textu, z√°kladn√© ot√°zky a odpovede, r√Ωchle reakcie
- **Phi-4-mini**: Vylep≈°en√© uva≈æovanie s mo≈ænos≈•ou volania funkci√≠

### Pre matematick√© a logick√© √∫lohy
- **Phi-4**: Komplexn√© rie≈°enie matematick√Ωch probl√©mov a uva≈æovanie
- **Phi-4-reasoning**: Viackrokov√© uva≈æovanie s podrobn√Ωmi vysvetleniami
- **Phi-4-reasoning-plus**: Maxim√°lna presnos≈• pre kritick√© aplik√°cie uva≈æovania
- **Phi-4-mini-reasoning**: Efekt√≠vne matematick√© uva≈æovanie pre prostredia s obmedzen√Ωmi zdrojmi

### Pre multimedi√°lne aplik√°cie
- **Phi-3-vision**: Kombin√°cia spracovania obrazu a textu
- **Phi-4-multimodal**: Komplexn√© schopnosti v oblasti reƒçi, vizu√°lu a textu

### Pre podnikov√© nasadenie
- **Phi-3-medium**: Pokroƒçil√© porozumenie jazyka pre podnikov√© aplik√°cie
- **Phi-3-Silica**: Optimalizovan√© pre konkr√©tne hardv√©rov√© platformy

## Platformy nasadenia a dostupnos≈•

### Cloudov√© platformy
- **Azure AI Foundry**: Kompletn√© nasadenie s podnikateƒæsk√Ωmi n√°strojmi
- **Hugging Face**: Open-source √∫lo≈æisko modelov a komunitn√© zdroje
- **NVIDIA API Catalog**: Mo≈ænosti nasadenia mikroservisov

### Lok√°lne v√Ωvojov√© r√°mce
- **Ollama**: ƒΩahk√Ω r√°mec pre lok√°lne nasadenie modelov
- **ONNX Runtime**: Optimalizovan√© pre r√¥zne hardv√©rov√© konfigur√°cie  
- **DirectML**: Optimalizovan√Ω v√Ωkon pre Windows
- **llama.cpp**: Multiplatformov√Ω inferenƒçn√Ω engine

### Vzdel√°vacie zdroje
- **Phi Portal**: Ofici√°lny dokumentaƒçn√Ω port√°l Microsoft Phi
- **Phi Cookbook**: Komplexn√© pr√≠klady a n√°vody
- **Technick√© spr√°vy**: Hƒ∫bkov√© v√Ωskumn√© ƒçl√°nky na arxiv
- **Komunitn√© priestory**: Interakt√≠vne uk√°≈æky na Hugging Face

### Zaƒç√≠name s modelmi Phi

#### V√Ωvojov√© platformy
1. **Azure AI Foundry**: Jednoduch√© lok√°lne CLI a spr√°va modelov.
2. **Hugging Face Transformers**: R√Ωchle lok√°lne experimentovanie
3. **Ollama**: Jednoduch√© lok√°lne nasadenie na testovanie

#### Vzdel√°vacia cesta
1. **Pochopenie z√°kladn√Ωch konceptov**: ≈†t√∫dium z√°kladn√Ωch princ√≠pov dizajnu
2. **Experimentovanie s variantmi**: Sk√∫≈°anie r√¥znych modelov Phi na pochopenie schopnost√≠
3. **Praktick√° implement√°cia**: Nasadenie modelov v testovac√≠ch prostrediach
4. **≈†k√°lovanie nasadenia**: Postupn√© roz≈°irovanie pou≈æitia na z√°klade √∫spe≈°n√Ωch pilotov

#### Najlep≈°ie postupy
- **Zaƒçnite s mal√Ωmi modelmi**: Pou≈æite Phi-mini modely na poƒçiatoƒçn√Ω v√Ωvoj
- **Optimalizujte prompty**: Pou≈æ√≠vajte spr√°vne form√°tovanie chatu pre najlep≈°ie v√Ωsledky
- **Monitorujte v√Ωkon**: Sledujte r√Ωchlos≈• inferencie a presnos≈•
- **Zohƒæadnite hardv√©r**: Prisp√¥sobte veƒækos≈• modelu dostupn√Ωm v√Ωpoƒçtov√Ωm zdrojom

## Z√°ver

Rodina modelov Microsoft Phi predstavuje revoluƒçn√Ω pr√≠stup k dizajnu AI modelov, dokazuj√∫c, ≈æe men≈°ie, efekt√≠vnej≈°ie modely m√¥≈æu dosiahnu≈• pozoruhodn√Ω v√Ωkon v r√¥znych √∫loh√°ch. Zameran√≠m sa na kvalitn√© tr√©ningov√© d√°ta a optimaliz√°cie architekt√∫ry prin√°≈°a rodina Phi v√Ωnimoƒçn√© schopnosti s v√Ωrazne zn√≠≈æen√Ωmi v√Ωpoƒçtov√Ωmi po≈æiadavkami v porovnan√≠ s tradiƒçn√Ωmi veƒæk√Ωmi jazykov√Ωmi modelmi.

## Kƒæ√∫ƒçov√© vzdel√°vacie ciele

1. Pochopi≈• filozofiu dizajnu a v√Ωvoj rodiny modelov Microsoft Phi od Phi-1 po Phi-4
2. Identifikova≈• kƒæ√∫ƒçov√© inov√°cie, vr√°tane tr√©ningu na "uƒçebnicovej kvalite" d√°t a optimaliz√°ci√≠ architekt√∫ry
3. Rozpozna≈• v√Ωhody a obmedzenia r√¥znych variantov Phi v r√¥znych scen√°roch nasadenia
4. Aplikova≈• znalosti na v√Ωber vhodn√Ωch modelov Phi pre konkr√©tne pr√≠pady pou≈æitia a hardv√©rov√© obmedzenia
5. Implementova≈• optimalizaƒçn√© techniky na nasadenie modelov Phi na zariadeniach s obmedzen√Ωmi zdrojmi
6. Vysvetli≈• architektonick√© v√Ωhody rodiny modelov Phi oproti tradiƒçn√Ωm veƒæk√Ωm jazykov√Ωm modelom
7. Vybra≈• vhodn√Ω variant Phi na z√°klade konkr√©tnych po≈æiadaviek aplik√°cie a hardv√©rov√Ωch obmedzen√≠
8. Implementova≈• modely Phi v cloudov√Ωch aj edge scen√°roch nasadenia s optimalizovan√Ωmi konfigur√°ciami
9. Aplikova≈• kvantizaƒçn√© a optimalizaƒçn√© techniky na zlep≈°enie v√Ωkonu modelov Phi na cieƒæov√Ωch zariadeniach
10. Vyhodnoti≈• kompromisy medzi veƒækos≈•ou modelu, v√Ωkonom a schopnos≈•ami v r√°mci rodiny Phi

## ƒåo ƒèalej

- [02: Z√°klady rodiny Qwen](02.QwenFamily.md)

---

**Upozornenie**:  
Tento dokument bol prelo≈æen√Ω pomocou slu≈æby AI prekladu [Co-op Translator](https://github.com/Azure/co-op-translator). Hoci sa sna≈æ√≠me o presnos≈•, pros√≠m, berte na vedomie, ≈æe automatizovan√© preklady m√¥≈æu obsahova≈• chyby alebo nepresnosti. P√¥vodn√Ω dokument v jeho p√¥vodnom jazyku by mal by≈• pova≈æovan√Ω za autoritat√≠vny zdroj. Pre kritick√© inform√°cie sa odpor√∫ƒça profesion√°lny ƒæudsk√Ω preklad. Nie sme zodpovedn√≠ za ≈æiadne nedorozumenia alebo nespr√°vne interpret√°cie vypl√Ωvaj√∫ce z pou≈æitia tohto prekladu.