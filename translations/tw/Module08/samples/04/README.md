<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2f1754a482b6a84e07287a5b775e65b6",
  "translation_date": "2025-09-30T23:30:38+00:00",
  "source_file": "Module08/samples/04/README.md",
  "language_code": "tw"
}
-->
# ç¯„ä¾‹ 04ï¼šä½¿ç”¨ Chainlit å»ºç«‹ç”Ÿç”¢ç´šèŠå¤©æ‡‰ç”¨ç¨‹å¼

ä¸€å€‹å…¨é¢çš„ç¯„ä¾‹ï¼Œå±•ç¤ºäº†ä½¿ç”¨ Microsoft Foundry Local å»ºç«‹ç”Ÿç”¢ç´šèŠå¤©æ‡‰ç”¨ç¨‹å¼çš„å¤šç¨®æ–¹æ³•ï¼ŒåŒ…å«ç¾ä»£åŒ–çš„ç¶²é ä»‹é¢ã€ä¸²æµå›æ‡‰ä»¥åŠå°–ç«¯çš„ç€è¦½å™¨æŠ€è¡“ã€‚

## åŒ…å«å…§å®¹

- **ğŸš€ Chainlit èŠå¤©æ‡‰ç”¨ç¨‹å¼** (`app.py`)ï¼šå…·å‚™ä¸²æµåŠŸèƒ½çš„ç”Ÿç”¢ç´šèŠå¤©æ‡‰ç”¨ç¨‹å¼
- **ğŸŒ WebGPU ç¤ºç¯„** (`webgpu-demo/`)ï¼šåŸºæ–¼ç€è¦½å™¨çš„ AI æ¨è«–ï¼Œæ”¯æ´ç¡¬é«”åŠ é€Ÿ
- **ğŸ¨ Open WebUI æ•´åˆ** (`open-webui-guide.md`)ï¼šå°ˆæ¥­çš„ ChatGPT é¢¨æ ¼ä»‹é¢
- **ğŸ“š æ•™è‚²ç­†è¨˜æœ¬** (`chainlit_app.ipynb`)ï¼šäº’å‹•å¼å­¸ç¿’ææ–™

## å¿«é€Ÿé–‹å§‹

### 1. Chainlit èŠå¤©æ‡‰ç”¨ç¨‹å¼

```cmd
# Navigate to Module08 directory
cd Module08

# Start your model
foundry model run phi-4-mini

# Run Chainlit app (using port 8080 to avoid conflicts)
chainlit run samples\04\app.py -w --port 8080
```

é–‹å•Ÿç¶²å€ï¼š`http://localhost:8080`

### 2. WebGPU ç€è¦½å™¨ç¤ºç¯„

```cmd
# Navigate to WebGPU demo
cd Module08\samples\04\webgpu-demo

# Serve the demo
python -m http.server 5173
```

é–‹å•Ÿç¶²å€ï¼š`http://localhost:5173`

### 3. Open WebUI è¨­å®š

```cmd
# Run Open WebUI with Docker
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

é–‹å•Ÿç¶²å€ï¼š`http://localhost:3000`

## æ¶æ§‹æ¨¡å¼

### æœ¬åœ°èˆ‡é›²ç«¯æ±ºç­–çŸ©é™£

| æƒ…å¢ƒ | å»ºè­° | åŸå›  |
|------|------|------|
| **éš±ç§æ•æ„Ÿè³‡æ–™** | ğŸ  æœ¬åœ° (Foundry) | è³‡æ–™ä¸æœƒé›¢é–‹è¨­å‚™ |
| **è¤‡é›œæ¨ç†** | â˜ï¸ é›²ç«¯ (Azure OpenAI) | å¯ä½¿ç”¨æ›´å¤§å‹çš„æ¨¡å‹ |
| **å³æ™‚èŠå¤©** | ğŸ  æœ¬åœ° (Foundry) | ä½å»¶é²ï¼Œå›æ‡‰æ›´å¿« |
| **æ–‡ä»¶åˆ†æ** | ğŸ”„ æ··åˆ | æœ¬åœ°é€²è¡Œæå–ï¼Œé›²ç«¯é€²è¡Œåˆ†æ |
| **ç¨‹å¼ç¢¼ç”Ÿæˆ** | ğŸ  æœ¬åœ° (Foundry) | éš±ç§ + å°ˆç”¨æ¨¡å‹ |
| **ç ”ç©¶ä»»å‹™** | â˜ï¸ é›²ç«¯ (Azure OpenAI) | éœ€è¦å»£æ³›çš„çŸ¥è­˜åº« |

### æŠ€è¡“æ¯”è¼ƒ

| æŠ€è¡“ | ä½¿ç”¨æƒ…å¢ƒ | å„ªé» | ç¼ºé» |
|------|----------|------|------|
| **Chainlit** | Python é–‹ç™¼è€…ï¼Œå¿«é€ŸåŸå‹è¨­è¨ˆ | ç°¡æ˜“è¨­å®šï¼Œæ”¯æ´ä¸²æµ | åƒ…é™ Python |
| **WebGPU** | æœ€å¤§éš±ç§ï¼Œé›¢ç·šæƒ…å¢ƒ | ç€è¦½å™¨åŸç”Ÿï¼Œç„¡éœ€ä¼ºæœå™¨ | æ¨¡å‹å¤§å°æœ‰é™ |
| **Open WebUI** | ç”Ÿç”¢éƒ¨ç½²ï¼Œåœ˜éšŠä½¿ç”¨ | å°ˆæ¥­ UIï¼Œä½¿ç”¨è€…ç®¡ç† | éœ€è¦ Docker |

## å…ˆæ±ºæ¢ä»¶

- **Foundry Local**ï¼šå·²å®‰è£ä¸¦é‹è¡Œ ([ä¸‹è¼‰](https://aka.ms/foundry-local-installer))
- **Python**ï¼š3.10+ ä¸¦å•Ÿç”¨è™›æ“¬ç’°å¢ƒ
- **æ¨¡å‹**ï¼šè‡³å°‘è¼‰å…¥ä¸€å€‹ (`foundry model run phi-4-mini`)
- **ç€è¦½å™¨**ï¼šæ”¯æ´ WebGPU çš„ Chrome/Edge ç”¨æ–¼ç¤ºç¯„
- **Docker**ï¼šç”¨æ–¼ Open WebUI (å¯é¸)

## å®‰è£èˆ‡è¨­å®š

### 1. Python ç’°å¢ƒè¨­å®š

```cmd
# Navigate to Module08 directory
cd Module08

# Create and activate virtual environment
py -m venv .venv
.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Foundry Local è¨­å®š

```cmd
# Verify Foundry Local installation
foundry --version

# Start the service
foundry service start

# Load a model
foundry model run phi-4-mini

# Verify model is running
foundry service ps
```

## ç¯„ä¾‹æ‡‰ç”¨ç¨‹å¼

### Chainlit èŠå¤©æ‡‰ç”¨ç¨‹å¼

**åŠŸèƒ½ç‰¹è‰²ï¼š**
- ğŸš€ **å³æ™‚ä¸²æµ**ï¼šç”Ÿæˆçš„ Token å³æ™‚é¡¯ç¤º
- ğŸ›¡ï¸ **å¼·å¤§çš„éŒ¯èª¤è™•ç†**ï¼šå„ªé›…é™ç´šèˆ‡æ¢å¾©
- ğŸ¨ **ç¾ä»£åŒ– UI**ï¼šå…§å»ºå°ˆæ¥­èŠå¤©ä»‹é¢
- ğŸ”§ **éˆæ´»é…ç½®**ï¼šæ”¯æ´ç’°å¢ƒè®Šæ•¸èˆ‡è‡ªå‹•æª¢æ¸¬
- ğŸ“± **éŸ¿æ‡‰å¼è¨­è¨ˆ**ï¼šé©ç”¨æ–¼æ¡Œé¢èˆ‡è¡Œå‹•è£ç½®

**å¿«é€Ÿé–‹å§‹ï¼š**
```cmd
# Run with default settings (recommended)
chainlit run samples\04\app.py -w --port 8080

# Use specific model
set MODEL=qwen2.5-7b
chainlit run samples\04\app.py -w --port 8080

# Manual endpoint configuration
set BASE_URL=http://localhost:51211
set API_KEY=your-api-key
chainlit run samples\04\app.py -w --port 8080
```

### WebGPU ç€è¦½å™¨ç¤ºç¯„

**åŠŸèƒ½ç‰¹è‰²ï¼š**
- ğŸŒ **ç€è¦½å™¨åŸç”Ÿ AI**ï¼šç„¡éœ€ä¼ºæœå™¨ï¼Œå®Œå…¨åœ¨ç€è¦½å™¨ä¸­é‹è¡Œ
- âš¡ **WebGPU åŠ é€Ÿ**ï¼šæ”¯æ´ç¡¬é«”åŠ é€Ÿ
- ğŸ”’ **æœ€å¤§éš±ç§**ï¼šè³‡æ–™ä¸æœƒé›¢é–‹æ‚¨çš„è¨­å‚™
- ğŸ¯ **é›¶å®‰è£**ï¼šé©ç”¨æ–¼ä»»ä½•ç›¸å®¹çš„ç€è¦½å™¨
- ğŸ”„ **å„ªé›…å›é€€**ï¼šè‹¥ WebGPU ä¸å¯ç”¨ï¼Œå‰‡å›é€€è‡³ CPU

**é‹è¡Œæ–¹å¼ï¼š**
```cmd
cd samples\04\webgpu-demo
python -m http.server 5173
# Open http://localhost:5173
```

### Open WebUI æ•´åˆ

**åŠŸèƒ½ç‰¹è‰²ï¼š**
- ğŸ¨ **ChatGPT é¢¨æ ¼ä»‹é¢**ï¼šå°ˆæ¥­ä¸”ç†Ÿæ‚‰çš„ UI
- ğŸ‘¥ **å¤šä½¿ç”¨è€…æ”¯æ´**ï¼šä½¿ç”¨è€…å¸³è™Ÿèˆ‡å°è©±æ­·å²
- ğŸ“ **æ–‡ä»¶è™•ç†**ï¼šä¸Šå‚³ä¸¦åˆ†ææ–‡ä»¶
- ğŸ”„ **æ¨¡å‹åˆ‡æ›**ï¼šè¼•é¬†åˆ‡æ›ä¸åŒæ¨¡å‹
- ğŸ³ **Docker éƒ¨ç½²**ï¼šç”Ÿç”¢ç´šå®¹å™¨åŒ–è¨­å®š

**å¿«é€Ÿè¨­å®šï¼š**
```cmd
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

## é…ç½®åƒè€ƒ

### ç’°å¢ƒè®Šæ•¸

| è®Šæ•¸ | æè¿° | é è¨­å€¼ | ç¯„ä¾‹ |
|------|------|--------|------|
| `MODEL` | ä½¿ç”¨çš„æ¨¡å‹åˆ¥å | `phi-4-mini` | `qwen2.5-7b` |
| `BASE_URL` | Foundry Local ç«¯é» | è‡ªå‹•æª¢æ¸¬ | `http://localhost:51211` |
| `API_KEY` | API é‡‘é‘° (æœ¬åœ°å¯é¸) | `""` | `your-api-key` |

## ç–‘é›£æ’è§£

### å¸¸è¦‹å•é¡Œ

**Chainlit æ‡‰ç”¨ç¨‹å¼ï¼š**

1. **æœå‹™ä¸å¯ç”¨ï¼š**
   ```cmd
   # Check Foundry Local status
   foundry service status
   foundry service ps
   
   # Validate API endpoint (note: port 51211)
   curl http://localhost:51211/v1/models
   ```

2. **åŸ è¡çªï¼š**
   ```cmd
   # Check what's using port 8080
   netstat -ano | findstr :8080
   
   # Use different port if needed
   chainlit run samples\04\app.py -w --port 3000
   ```

3. **Python ç’°å¢ƒå•é¡Œï¼š**
   ```cmd
   # Verify correct interpreter in VS Code
   # Ctrl+Shift+P â†’ Python: Select Interpreter
   # Choose: Module08/.venv/Scripts/python.exe
   
   # Reinstall dependencies
   pip install -r requirements.txt
   ```

**WebGPU ç¤ºç¯„ï¼š**

1. **WebGPU ä¸æ”¯æ´ï¼š**
   - æ›´æ–°è‡³ Chrome/Edge 113+
   - å•Ÿç”¨ WebGPUï¼š`chrome://flags/#enable-unsafe-webgpu`
   - æª¢æŸ¥ GPU ç‹€æ…‹ï¼š`chrome://gpu`
   - ç¤ºç¯„å°‡è‡ªå‹•å›é€€è‡³ CPU

2. **æ¨¡å‹è¼‰å…¥éŒ¯èª¤ï¼š**
   - ç¢ºä¿ç¶²è·¯é€£ç·šä»¥ä¸‹è¼‰æ¨¡å‹
   - æª¢æŸ¥ç€è¦½å™¨ä¸»æ§å°æ˜¯å¦æœ‰ CORS éŒ¯èª¤
   - ç¢ºä¿ä½¿ç”¨ HTTP æä¾›æœå‹™ (é file://)

**Open WebUIï¼š**

1. **é€£ç·šè¢«æ‹’ï¼š**
   ```cmd
   # Check Docker is running
   docker --version
   
   # Check container status
   docker ps | findstr open-webui
   
   # View container logs
   docker logs open-webui
   ```

2. **æ¨¡å‹æœªé¡¯ç¤ºï¼š**
   ```cmd
   # Verify Foundry Local endpoint
   curl http://localhost:51211/v1/models
   
   # Restart Open WebUI
   docker restart open-webui
   ```

### é©—è­‰æ¸…å–®

```cmd
# âœ… 1. Foundry Local Setup
foundry --version                    # Should show version
foundry service status               # Should show "running"
foundry model list                   # Should show loaded models
curl http://localhost:51211/v1/models  # Should return JSON

# âœ… 2. Python Environment  
python --version                     # Should be 3.10+
pip list | findstr chainlit         # Should show chainlit package
pip list | findstr openai           # Should show openai package

# âœ… 3. Application Testing
chainlit run samples\04\app.py -w --port 8080  # Should open browser
# Test WebGPU demo at localhost:5173
# Test Open WebUI at localhost:3000
```

## é€²éšä½¿ç”¨

### æ€§èƒ½å„ªåŒ–

**Chainlitï¼š**
- ä½¿ç”¨ä¸²æµä»¥æå‡æ„ŸçŸ¥æ€§èƒ½
- å¯¦æ–½é€£ç·šæ± ä»¥æ”¯æ´é«˜ä½µç™¼
- å¿«å–æ¨¡å‹å›æ‡‰ä»¥è™•ç†é‡è¤‡æŸ¥è©¢
- ç›£æ§å¤§å‹å°è©±æ­·å²çš„è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³

**WebGPUï¼š**
- ä½¿ç”¨ WebGPU ä»¥ç²å¾—æœ€å¤§éš±ç§èˆ‡é€Ÿåº¦
- å¯¦æ–½æ¨¡å‹é‡åŒ–ä»¥ç¸®å°æ¨¡å‹å¤§å°
- ä½¿ç”¨ Web Workers é€²è¡ŒèƒŒæ™¯è™•ç†
- åœ¨ç€è¦½å™¨å­˜å„²ä¸­å¿«å–å·²ç·¨è­¯çš„æ¨¡å‹

**Open WebUIï¼š**
- ä½¿ç”¨æŒä¹…åŒ–å·ä¿å­˜å°è©±æ­·å²
- ç‚º Docker å®¹å™¨é…ç½®è³‡æºé™åˆ¶
- å¯¦æ–½ä½¿ç”¨è€…è³‡æ–™çš„å‚™ä»½ç­–ç•¥
- è¨­ç½®åå‘ä»£ç†ä»¥é€²è¡Œ SSL çµ‚æ­¢

### æ•´åˆæ¨¡å¼

**æœ¬åœ°/é›²ç«¯æ··åˆï¼š**
```python
# Route based on complexity and privacy requirements
async def intelligent_routing(prompt: str, metadata: dict):
    if metadata.get("contains_pii"):
        return await foundry_local_completion(prompt)  # Privacy-sensitive
    elif len(prompt.split()) > 200:
        return await azure_openai_completion(prompt)   # Complex reasoning
    else:
        return await foundry_local_completion(prompt)  # Default local
```

**å¤šæ¨¡æ…‹ç®¡é“ï¼š**
```python
# Combine different AI capabilities
async def analyze_document(file_path: str):
    # 1. OCR with WebGPU (browser-based)
    text = await webgpu_ocr(file_path)
    
    # 2. Analysis with Foundry Local (private)
    summary = await foundry_local_analyze(text)
    
    # 3. Enhancement with cloud (if needed)
    if summary.confidence < 0.8:
        summary = await azure_openai_enhance(summary)
    
    return summary
```

## ç”Ÿç”¢éƒ¨ç½²

### å®‰å…¨è€ƒé‡

- **API é‡‘é‘°**ï¼šä½¿ç”¨ç’°å¢ƒè®Šæ•¸ï¼Œåˆ‡å‹¿ç¡¬ç·¨ç¢¼
- **ç¶²è·¯**ï¼šåœ¨ç”Ÿç”¢ç’°å¢ƒä¸­ä½¿ç”¨ HTTPSï¼Œè€ƒæ…®ä½¿ç”¨ VPN ä¾›åœ˜éšŠå­˜å–
- **å­˜å–æ§åˆ¶**ï¼šç‚º Open WebUI å¯¦æ–½èº«ä»½é©—è­‰
- **è³‡æ–™éš±ç§**ï¼šå¯©æ ¸å“ªäº›è³‡æ–™ç•™åœ¨æœ¬åœ°ï¼Œå“ªäº›ç™¼é€è‡³é›²ç«¯
- **æ›´æ–°**ï¼šä¿æŒ Foundry Local å’Œå®¹å™¨çš„æœ€æ–°ç‰ˆæœ¬

### ç›£æ§èˆ‡ç¶­è­·

- **å¥åº·æª¢æŸ¥**ï¼šå¯¦æ–½ç«¯é»ç›£æ§
- **æ—¥èªŒ**ï¼šé›†ä¸­ç®¡ç†æ‰€æœ‰å…ƒä»¶çš„æ—¥èªŒ
- **æŒ‡æ¨™**ï¼šè¿½è¹¤å›æ‡‰æ™‚é–“ã€éŒ¯èª¤ç‡ã€è³‡æºä½¿ç”¨æƒ…æ³
- **å‚™ä»½**ï¼šå®šæœŸå‚™ä»½å°è©±è³‡æ–™èˆ‡é…ç½®

## åƒè€ƒèˆ‡è³‡æº

### æ–‡ä»¶
- [Chainlit æ–‡ä»¶](https://docs.chainlit.io/) - å®Œæ•´æ¡†æ¶æŒ‡å—
- [Foundry Local æ–‡ä»¶](https://learn.microsoft.com/azure/ai-foundry/foundry-local/) - å¾®è»Ÿå®˜æ–¹æ–‡ä»¶
- [ONNX Runtime Web](https://onnxruntime.ai/docs/get-started/with-javascript/web.html) - WebGPU æ•´åˆ
- [Open WebUI æ–‡ä»¶](https://docs.openwebui.com/) - é«˜ç´šé…ç½®æŒ‡å—

### ç¯„ä¾‹æª”æ¡ˆ
- [`app.py`](../../../../../Module08/samples/04/app.py) - ç”Ÿç”¢ç´š Chainlit æ‡‰ç”¨ç¨‹å¼
- [`chainlit_app.ipynb`](./chainlit_app.ipynb) - æ•™è‚²ç­†è¨˜æœ¬
- [`webgpu-demo/`](../../../../../Module08/samples/04/webgpu-demo) - åŸºæ–¼ç€è¦½å™¨çš„ AI æ¨è«–
- [`open-webui-guide.md`](./open-webui-guide.md) - å®Œæ•´çš„ Open WebUI è¨­å®šæŒ‡å—

### ç›¸é—œç¯„ä¾‹
- [Session 4 æ–‡ä»¶](../../04.CuttingEdgeModels.md) - å®Œæ•´çš„èª²ç¨‹æŒ‡å—
- [Foundry Local ç¯„ä¾‹](https://github.com/microsoft/foundry-local/tree/main/samples) - å®˜æ–¹ç¯„ä¾‹

---

**å…è²¬è²æ˜**ï¼š  
æœ¬æ–‡ä»¶å·²ä½¿ç”¨ AI ç¿»è­¯æœå‹™ [Co-op Translator](https://github.com/Azure/co-op-translator) é€²è¡Œç¿»è­¯ã€‚é›–ç„¶æˆ‘å€‘è‡´åŠ›æ–¼æä¾›æº–ç¢ºçš„ç¿»è­¯ï¼Œä½†è«‹æ³¨æ„ï¼Œè‡ªå‹•ç¿»è­¯å¯èƒ½åŒ…å«éŒ¯èª¤æˆ–ä¸æº–ç¢ºä¹‹è™•ã€‚åŸå§‹æ–‡ä»¶çš„æ¯èªç‰ˆæœ¬æ‡‰è¢«è¦–ç‚ºæ¬Šå¨ä¾†æºã€‚å°æ–¼é—œéµè³‡è¨Šï¼Œå»ºè­°ä½¿ç”¨å°ˆæ¥­äººå·¥ç¿»è­¯ã€‚æˆ‘å€‘å°å› ä½¿ç”¨æ­¤ç¿»è­¯è€Œç”¢ç”Ÿçš„ä»»ä½•èª¤è§£æˆ–éŒ¯èª¤è§£é‡‹ä¸æ‰¿æ“”è²¬ä»»ã€‚