{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b861ae53",
   "metadata": {},
   "source": [
    "# ç¯„ä¾‹ 05ï¼šå¤šä»£ç†å”ä½œç³»çµ±\n",
    "\n",
    "æ­¤ç­†è¨˜æœ¬å±•ç¤ºäº†ä¸€å€‹å…ˆé€²çš„å¤šä»£ç†æ¶æ§‹ï¼Œç”¨æ–¼ä½¿ç”¨ Microsoft Foundry Local å»ºç«‹ AI é©…å‹•çš„ä»£ç†ç³»çµ±ã€‚\n",
    "\n",
    "## æ¦‚è¿°\n",
    "\n",
    "æ­¤ç¯„ä¾‹å¯¦ç¾äº†ä¸€å€‹**å¤šä»£ç†å”èª¿å™¨**ï¼Œè² è²¬å”ä½œå°ˆæ¥­åŒ–çš„ä»£ç†ï¼š\n",
    "\n",
    "- ğŸ” **æª¢ç´¢ä»£ç†**ï¼šå¾çŸ¥è­˜ä¾†æºä¸­æå–ç›¸é—œè³‡è¨Š\n",
    "- ğŸ§  **æ¨ç†ä»£ç†**ï¼šåŸ·è¡Œé€æ­¥åˆ†æå’Œé‚è¼¯æ¨ç†\n",
    "- âš¡ **åŸ·è¡Œä»£ç†**ï¼šä»¥çµæ§‹åŒ–æ ¼å¼å‰µå»ºå¯æ“ä½œçš„è¨ˆåŠƒ\n",
    "- ğŸ¯ **å”èª¿å™¨**ï¼šå”èª¿æ•´å€‹ä»£ç†å·¥ä½œæµç¨‹\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e840290d",
   "metadata": {},
   "source": [
    "## æ¶æ§‹æ¨¡å¼\n",
    "\n",
    "```\n",
    "User Goal â†’ Coordinator\n",
    "     â†“\n",
    "1. Retrieval Agent â†’ Context\n",
    "     â†“\n",
    "2. Reasoning Agent â†’ Decision\n",
    "     â†“\n",
    "3. Execution Agent â†’ Actions\n",
    "     â†“\n",
    "Structured Result\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240650a",
   "metadata": {},
   "source": [
    "## å…ˆæ±ºæ¢ä»¶èˆ‡è¨­ç½®\n",
    "\n",
    "ç¢ºä¿æ‚¨å·²å•Ÿå‹• Foundry Local ä¸¦ä½¿ç”¨ä¸€å€‹åŠŸèƒ½å¼·å¤§çš„æ¨¡å‹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc33b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install openai foundry-local-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c6fe9e",
   "metadata": {},
   "source": [
    "## åŒ¯å…¥åº«å’Œé…ç½®\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5160a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, Any, List\n",
    "from openai import OpenAI\n",
    "\n",
    "try:\n",
    "    from foundry_local import FoundryLocalManager\n",
    "    FOUNDRY_SDK_AVAILABLE = True\n",
    "    print(\"âœ… Foundry Local SDK is available\")\n",
    "except ImportError:\n",
    "    FOUNDRY_SDK_AVAILABLE = False\n",
    "    print(\"âš ï¸ Foundry Local SDK not available, will use manual configuration\")\n",
    "\n",
    "# Configuration\n",
    "MODEL_ALIAS = \"phi-4-mini\"  # Change to your preferred model\n",
    "BASE_URL = \"http://localhost:8000\"\n",
    "API_KEY = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba6a90f",
   "metadata": {},
   "source": [
    "## Foundry å®¢æˆ¶ç«¯è¨­ç½®\n",
    "\n",
    "ç‚ºæ‰€æœ‰ä»£ç†å‰µå»ºä¸€å€‹å…±äº«å®¢æˆ¶ç«¯ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc80453",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoundryClient:\n",
    "    \"\"\"Shared client for all specialist agents.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_alias: str = MODEL_ALIAS):\n",
    "        self.client = None\n",
    "        self.model_name = None\n",
    "        self.model_alias = model_alias\n",
    "        self._initialize_client()\n",
    "    \n",
    "    def _initialize_client(self):\n",
    "        \"\"\"Initialize OpenAI client with Foundry Local or fallback configuration.\"\"\"\n",
    "        if FOUNDRY_SDK_AVAILABLE:\n",
    "            try:\n",
    "                print(f\"ğŸ”„ Initializing Foundry Local with model: {self.model_alias}...\")\n",
    "                manager = FoundryLocalManager(self.model_alias)\n",
    "                model_info = manager.get_model_info(self.model_alias)\n",
    "                \n",
    "                self.client = OpenAI(\n",
    "                    base_url=manager.endpoint,\n",
    "                    api_key=manager.api_key\n",
    "                )\n",
    "                self.model_name = model_info.id\n",
    "                print(f\"âœ… Foundry Local SDK initialized with model: {self.model_name}\")\n",
    "                return\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Could not use Foundry SDK ({e}), falling back to manual configuration\")\n",
    "        \n",
    "        # Fallback to manual configuration\n",
    "        self.client = OpenAI(\n",
    "            base_url=f\"{BASE_URL}/v1\",\n",
    "            api_key=API_KEY\n",
    "        )\n",
    "        self.model_name = self.model_alias\n",
    "        print(f\"ğŸ”§ Manual configuration initialized with model: {self.model_name}\")\n",
    "    \n",
    "    def chat(self, messages: List[Dict[str, str]], max_tokens: int = 300, temperature: float = 0.4) -> str:\n",
    "        \"\"\"Send chat completion request to the model.\"\"\"\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model_name,\n",
    "                messages=messages,\n",
    "                max_tokens=max_tokens,\n",
    "                temperature=temperature\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {str(e)}\"\n",
    "    \n",
    "    def check_health(self) -> bool:\n",
    "        \"\"\"Check if the client is working properly.\"\"\"\n",
    "        try:\n",
    "            test_response = self.chat(\n",
    "                [{\"role\": \"user\", \"content\": \"Say 'OK'\"}],\n",
    "                max_tokens=5\n",
    "            )\n",
    "            return \"OK\" in test_response and \"Error\" not in test_response\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "# Initialize the shared client\n",
    "print(\"Initializing Foundry Client...\")\n",
    "foundry_client = FoundryClient()\n",
    "\n",
    "# Health check\n",
    "if foundry_client.check_health():\n",
    "    print(\"âœ… Client health check passed!\")\n",
    "else:\n",
    "    print(\"âŒ Client health check failed. Please ensure Foundry Local is running with a model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9e6e2b",
   "metadata": {},
   "source": [
    "## å°ˆé–€ä»£ç†é¡åˆ¥\n",
    "\n",
    "æ¯å€‹ä»£ç†éƒ½é‡å°ç‰¹å®šçš„èªçŸ¥ä»»å‹™é€²è¡Œå„ªåŒ–ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2ce141",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalAgent:\n",
    "    \"\"\"Agent specialized in retrieving relevant information from knowledge sources.\"\"\"\n",
    "    \n",
    "    SYSTEM = \"\"\"You are a specialized retrieval agent. Your job is to extract and retrieve \n",
    "    the most relevant information from knowledge sources based on a given query. Focus on key facts, \n",
    "    data points, and contextual information that would be useful for decision-making.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: FoundryClient):\n",
    "        self.client = client\n",
    "    \n",
    "    def run(self, query: str) -> str:\n",
    "        \"\"\"Retrieve relevant information based on the query.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.SYSTEM},\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"\"\"Query: {query}\n",
    "\n",
    "Retrieve the most relevant key facts, data points, and contextual information that would \n",
    "help answer this query or support decision-making around it. Provide specific, actionable \n",
    "information rather than general statements.\"\"\"\n",
    "            }\n",
    "        ]\n",
    "        return self.client.chat(messages)\n",
    "\n",
    "\n",
    "class ReasoningAgent:\n",
    "    \"\"\"Agent specialized in step-by-step analysis and reasoning.\"\"\"\n",
    "    \n",
    "    SYSTEM = \"\"\"You are a specialized reasoning agent. Your job is to analyze inputs \n",
    "    step-by-step and produce structured, logical conclusions. Break down complex problems \n",
    "    into manageable parts and provide clear reasoning for your conclusions.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: FoundryClient):\n",
    "        self.client = client\n",
    "    \n",
    "    def run(self, context: str, question: str) -> str:\n",
    "        \"\"\"Analyze context and question to produce structured conclusions.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.SYSTEM},\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"\"\"Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Analyze this step-by-step and provide a structured, logical conclusion with clear reasoning. \n",
    "Break down the problem, consider different angles, and provide a well-reasoned decision or recommendation.\"\"\"\n",
    "            }\n",
    "        ]\n",
    "        return self.client.chat(messages, max_tokens=400)\n",
    "\n",
    "\n",
    "class ExecutionAgent:\n",
    "    \"\"\"Agent specialized in creating actionable execution plans.\"\"\"\n",
    "    \n",
    "    SYSTEM = \"\"\"You are a specialized execution agent. Your job is to transform decisions \n",
    "    and conclusions into concrete, actionable steps. Always format your response as valid JSON \n",
    "    with an array of action items. Each action should be specific, measurable, and achievable.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: FoundryClient):\n",
    "        self.client = client\n",
    "    \n",
    "    def run(self, decision: str) -> str:\n",
    "        \"\"\"Transform decision into actionable steps in JSON format.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.SYSTEM},\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"\"\"Decision/Conclusion:\n",
    "{decision}\n",
    "\n",
    "Create 3-5 specific, actionable steps to implement this decision. Format as JSON with this structure:\n",
    "{{\n",
    "  \"actions\": [\n",
    "    {{\n",
    "      \"step\": 1,\n",
    "      \"description\": \"Specific action description\",\n",
    "      \"priority\": \"high/medium/low\",\n",
    "      \"timeline\": \"timeframe for completion\",\n",
    "      \"resources\": [\"required resources or people\"]\n",
    "    }}\n",
    "  ]\n",
    "}}\"\"\"\n",
    "            }\n",
    "        ]\n",
    "        return self.client.chat(messages, max_tokens=400, temperature=0.3)\n",
    "\n",
    "print(\"âœ… Agent classes defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb6288d",
   "metadata": {},
   "source": [
    "## å¤šä»£ç†å”èª¿å™¨\n",
    "\n",
    "å”èª¿å™¨è² è²¬æŒ‡æ®æ‰€æœ‰ä»£ç†ä»¥è™•ç†è¤‡é›œä»»å‹™ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e27d7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coordinator:\n",
    "    \"\"\"Multi-agent coordinator that orchestrates specialist agents to handle complex tasks.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: FoundryClient):\n",
    "        \"\"\"Initialize the coordinator with specialist agents.\"\"\"\n",
    "        self.client = client\n",
    "        self.retrieval = RetrievalAgent(client)\n",
    "        self.reasoning = ReasoningAgent(client)\n",
    "        self.execution = ExecutionAgent(client)\n",
    "    \n",
    "    def handle(self, user_goal: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Orchestrate multiple agents to handle a complex user goal.\n",
    "        \n",
    "        Args:\n",
    "            user_goal: The user's high-level goal or request\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing the goal, context, decision, and actions\n",
    "        \"\"\"\n",
    "        print(f\"ğŸ¯ **Coordinator:** Processing goal: {user_goal}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Step 1: Retrieve relevant context\n",
    "        print(\"ğŸ“š **Step 1:** Retrieving context...\")\n",
    "        context = self.retrieval.run(user_goal)\n",
    "        print(f\"   âœ… Context retrieved ({len(context)} chars)\")\n",
    "        print(f\"   ğŸ“„ Preview: {context[:150]}...\\n\")\n",
    "        \n",
    "        # Step 2: Analyze and reason about the context\n",
    "        print(\"ğŸ§  **Step 2:** Analyzing and reasoning...\")\n",
    "        decision = self.reasoning.run(context, user_goal)\n",
    "        print(f\"   âœ… Analysis completed ({len(decision)} chars)\")\n",
    "        print(f\"   ğŸ’¡ Preview: {decision[:150]}...\\n\")\n",
    "        \n",
    "        # Step 3: Create actionable execution plan\n",
    "        print(\"âš¡ **Step 3:** Creating execution plan...\")\n",
    "        actions = self.execution.run(decision)\n",
    "        print(f\"   âœ… Execution plan created ({len(actions)} chars)\")\n",
    "        \n",
    "        # Try to parse actions as JSON for preview\n",
    "        try:\n",
    "            actions_json = json.loads(actions)\n",
    "            action_count = len(actions_json.get('actions', []))\n",
    "            print(f\"   ğŸ“‹ Actions planned: {action_count}\\n\")\n",
    "        except:\n",
    "            print(f\"   ğŸ“‹ Actions: {actions[:100]}...\\n\")\n",
    "        \n",
    "        end_time = time.time()\n",
    "        processing_time = end_time - start_time\n",
    "        \n",
    "        result = {\n",
    "            \"goal\": user_goal,\n",
    "            \"context\": context,\n",
    "            \"decision\": decision,\n",
    "            \"actions\": actions,\n",
    "            \"agent_flow\": [\"retrieval\", \"reasoning\", \"execution\"],\n",
    "            \"processing_time\": processing_time,\n",
    "            \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        \n",
    "        print(f\"âœ… **Coordination Complete** (â±ï¸ {processing_time:.2f}s)\")\n",
    "        return result\n",
    "    \n",
    "    def handle_with_feedback(self, user_goal: str, feedback_rounds: int = 1) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Handle a goal with multiple feedback rounds for refinement.\n",
    "        \n",
    "        Args:\n",
    "            user_goal: The user's high-level goal or request\n",
    "            feedback_rounds: Number of feedback rounds to perform\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing the refined result\n",
    "        \"\"\"\n",
    "        result = self.handle(user_goal)\n",
    "        \n",
    "        for round_num in range(feedback_rounds):\n",
    "            print(f\"\\nğŸ”„ **Feedback Round {round_num + 1}:**\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            # Use reasoning agent to refine the execution plan\n",
    "            refinement_prompt = f\"\"\"\n",
    "            Original Goal: {user_goal}\n",
    "            Current Decision: {result['decision']}\n",
    "            Current Actions: {result['actions']}\n",
    "            \n",
    "            Review the above and suggest improvements or refinements to make the execution plan more effective.\n",
    "            Consider potential challenges, resource optimization, and success metrics.\n",
    "            \"\"\"\n",
    "            \n",
    "            refined_decision = self.reasoning.run(result['context'], refinement_prompt)\n",
    "            refined_actions = self.execution.run(refined_decision)\n",
    "            \n",
    "            result['decision'] = refined_decision\n",
    "            result['actions'] = refined_actions\n",
    "            result['refinement_rounds'] = round_num + 1\n",
    "            \n",
    "            print(f\"   âœ… Round {round_num + 1} refinement completed\")\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Initialize coordinator\n",
    "coordinator = Coordinator(foundry_client)\n",
    "print(\"âœ… Multi-agent coordinator initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97499608",
   "metadata": {},
   "source": [
    "## ç¯„ä¾‹ 1ï¼šå•†æ¥­è¦åŠƒ\n",
    "\n",
    "è®“æˆ‘å€‘ä»¥å•†æ¥­è¦åŠƒç›®æ¨™ä¾†æ¸¬è©¦å”èª¿è€…ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87106196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business planning example\n",
    "business_goal = \"Create a plan to onboard 5 new customers this month\"\n",
    "\n",
    "print(f\"ğŸš€ **Business Planning Example**\")\n",
    "print(f\"ğŸ“‹ Goal: {business_goal}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "business_result = coordinator.handle(business_goal)\n",
    "\n",
    "print(\"\\nğŸ“Š **Final Result Summary:**\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ğŸ¯ **Goal:** {business_result['goal']}\")\n",
    "print(f\"â±ï¸ **Processing Time:** {business_result['processing_time']:.2f} seconds\")\n",
    "print(f\"ğŸ•’ **Timestamp:** {business_result['timestamp']}\")\n",
    "\n",
    "print(f\"\\nğŸ“š **Context (Retrieval Agent):**\")\n",
    "print(business_result['context'])\n",
    "\n",
    "print(f\"\\nğŸ§  **Decision (Reasoning Agent):**\")\n",
    "print(business_result['decision'])\n",
    "\n",
    "print(f\"\\nâš¡ **Actions (Execution Agent):**\")\n",
    "print(business_result['actions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1159c3",
   "metadata": {},
   "source": [
    "## ç¯„ä¾‹ 2ï¼šç­–ç•¥åˆ¶å®š\n",
    "\n",
    "ä»¥æ›´è¤‡é›œçš„ç­–ç•¥åˆ¶å®šç›®æ¨™é€²è¡Œæ¸¬è©¦ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7532b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy development example\n",
    "strategy_goal = \"Develop a strategy to improve team productivity by 20% while maintaining work-life balance\"\n",
    "\n",
    "print(f\"ğŸ¯ **Strategy Development Example**\")\n",
    "print(f\"ğŸ“‹ Goal: {strategy_goal}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "strategy_result = coordinator.handle(strategy_goal)\n",
    "\n",
    "print(\"\\nğŸ“Š **Structured Action Plan:**\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Try to parse and display actions in a structured format\n",
    "try:\n",
    "    actions_data = json.loads(strategy_result['actions'])\n",
    "    if 'actions' in actions_data:\n",
    "        for i, action in enumerate(actions_data['actions'], 1):\n",
    "            print(f\"\\nğŸ“Œ **Action {i}:**\")\n",
    "            print(f\"   ğŸ“ Description: {action.get('description', 'N/A')}\")\n",
    "            print(f\"   ğŸ”¥ Priority: {action.get('priority', 'N/A')}\")\n",
    "            print(f\"   â° Timeline: {action.get('timeline', 'N/A')}\")\n",
    "            print(f\"   ğŸ› ï¸ Resources: {', '.join(action.get('resources', ['N/A']))}\")\n",
    "    else:\n",
    "        print(strategy_result['actions'])\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Raw actions output:\")\n",
    "    print(strategy_result['actions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d46b319",
   "metadata": {},
   "source": [
    "## ç¯„ä¾‹ 3ï¼šåé¥‹è¿´åœˆæ”¹é€²\n",
    "\n",
    "å±•ç¤ºç”¨æ–¼è¿­ä»£æ”¹é€²çš„åé¥‹æ©Ÿåˆ¶ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5fb98ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Round 2 refinement completed\n",
      "\n",
      "ğŸ† **Final Refined Result:**\n",
      "==================================================\n",
      "ğŸ¯ **Goal:** Design a customer feedback collection system for a software product\n",
      "ğŸ”„ **Refinement Rounds:** 2\n",
      "â±ï¸ **Total Processing Time:** 559.18 seconds\n",
      "\n",
      "ğŸ§  **Final Decision:**\n",
      "The execution plan for designing a customer feedback collection system for a software product is comprehensive, but there are areas where it could be refined for better effectiveness. Here are some suggestions:\n",
      "\n",
      "1. **Review of Existing Feedback Mechanisms**: This step is crucial as it sets the direction for the feedback collection system. However, it could be more effective if it also includes a review of existing feedback mechanisms and their shortcomings. This will help in understanding what can be improved.\n",
      "\n",
      "2. **Survey or Focus Group for Feedback Channels**: While the plan includes a variety of feedback channels, it could be beneficial to conduct a survey or a small focus group with a sample of the target audience to understand their preferred feedback channels. This will ensure that the chosen channels are indeed the most effective for the target audience.\n",
      "\n",
      "3. **User Testing of Feedback Form**: The plan is clear, but it could be improved by including a step for user testing of the feedback form. This will help in identifying any issues with the form's design or content before it is launched.\n",
      "\n",
      "4. **Regular Audits for Data Collection and Storage**: The plan includes compliance with data protection regulations, which is crucial. However, it could be more effective if it also includes a step for regular audits of the data collection and storage system to ensure ongoing compliance.\n",
      "\n",
      "5. **Training on Data Visualization Tools**: The plan is comprehensive, but it could be improved by including a step for training the team on how to use the data visualization tools. This will ensure that the team can effectively interpret and present the data.\n",
      "\n",
      "6. **Tracking System for Implementation of Changes**: The plan includes a feedback loop, which is excellent. However, it could be more effective if it also includes a step for tracking the implementation of changes based on feedback. This will help in understanding the impact of the feedback on the product.\n",
      "\n",
      "Potential challenges could be ensuring the feedback form is user-friendly and concise, maintaining data protection compliance, and effectively tracking the implementation of changes based\n",
      "\n",
      "âš¡ **Final Action Plan:**\n",
      "```json\n",
      "{\n",
      "  \"actions\": [\n",
      "    {\n",
      "      \"step\": 1,\n",
      "      \"description\": \"Conduct a comprehensive review of existing feedback mechanisms, including their effectiveness and shortcomings.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"1 week\",\n",
      "      \"resources\": [\"Product management team\", \"Customer service team\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 2,\n",
      "      \"description\": \"Organize a survey or focus group with a sample of the target audience to determine preferred feedback channels.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"2 weeks\",\n",
      "      \"resources\": [\"Survey platform\", \"Focus group participants\", \"Marketing team\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 3,\n",
      "      \"description\": \"Implement user testing for the feedback form with a diverse group of users to identify design and content issues.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"3 weeks\",\n",
      "      \"resources\": [\"UX/UI designers\", \"Test participants\", \"Feedback collection tools\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 4,\n",
      "      \"description\": \"Schedule and conduct regular audits of the data collection and storage system to ensure compliance with data protection regulations.\",\n",
      "      \"priority\": \"medium\",\n",
      "      \"timeline\": \"Quarterly\",\n",
      "      \"resources\": [\"Data protection officer\", \"IT security team\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 5,\n",
      "      \"description\": \"Develop and deliver training sessions for the team on how to use data visualization tools effectively.\",\n",
      "      \"priority\": \"medium\",\n",
      "      \"timeline\": \"1 month\",\n",
      "      \"resources\": [\"Data visualization software\", \"Training materials\", \"Internal trainers or external experts\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 6,\n",
      "      \"description\": \"Create a tracking system to monitor the implementation of changes based on customer feedback and measure the impact.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"2 months\",\n",
      "      \"resources\": [\"Project management software\", \"Product development team\n"
     ]
    }
   ],
   "source": [
    "# Feedback loop example\n",
    "feedback_goal = \"Design a customer feedback collection system for a software product\"\n",
    "\n",
    "print(f\"ğŸ”„ **Feedback Loop Refinement Example**\")\n",
    "print(f\"ğŸ“‹ Goal: {feedback_goal}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Process with 2 feedback rounds\n",
    "feedback_result = coordinator.handle_with_feedback(feedback_goal, feedback_rounds=2)\n",
    "\n",
    "print(\"\\nğŸ† **Final Refined Result:**\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ğŸ¯ **Goal:** {feedback_result['goal']}\")\n",
    "print(f\"ğŸ”„ **Refinement Rounds:** {feedback_result.get('refinement_rounds', 0)}\")\n",
    "print(f\"â±ï¸ **Total Processing Time:** {feedback_result['processing_time']:.2f} seconds\")\n",
    "\n",
    "print(f\"\\nğŸ§  **Final Decision:**\")\n",
    "print(feedback_result['decision'])\n",
    "\n",
    "print(f\"\\nâš¡ **Final Action Plan:**\")\n",
    "print(feedback_result['actions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed152f7",
   "metadata": {},
   "source": [
    "## äº’å‹•ä»£ç†æ¸¬è©¦\n",
    "\n",
    "åˆ†åˆ¥æ¸¬è©¦å„å€‹ä»£ç†ï¼Œä»¥äº†è§£å…¶å°ˆé–€èƒ½åŠ›ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "948c737c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª **Individual Agent Testing**\n",
      "â“ Query: How can we reduce customer support response time?\n",
      "============================================================\n",
      "\n",
      "ğŸ” **Retrieval Agent:**\n",
      "1. Implementing AI-powered chatbots: AI-powered chatbots can handle common customer queries, reducing the workload on human agents and speeding up response times. According to a study by Accenture, AI chatbots can handle 80% of customer interactions, freeing up human agents to handle more complex issues.\n",
      "\n",
      "2. Streamlining the support process: Simplifying the support process and removing unnecessary steps can help reduce response times. This could involve consolidating support channels, creating self-help resources, or automating certain processes.\n",
      "\n",
      "3. Increasing support staff: Hiring additional support staff or training existing staff to handle more complex issues can help reduce response times. A study by Forrester found that increasing the number of support agents by just 10% can reduce average response time by 20%.\n",
      "\n",
      "4. Prioritizing urgent issues: Prioritizing urgent issues and ensuring they are addressed first can help reduce response times. This could involve implementing a ticketing system that prioritizes issues based on their urgency.\n",
      "\n",
      "5. Providing training and resources: Providing support staff with the necessary training and resources can help them handle issues more efficiently, reducing response times. This could involve providing training on specific products or services, or creating a knowledge base that support staff can reference.\n",
      "\n",
      "6. Analyzing and optimizing response times: Regularly analyzing response times and identifying areas for improvement can help reduce response times. This could involve tracking response times for different types of issues, or analyzing the support process to identify bottlenecks.\n",
      "\n",
      "7. Outs\n",
      "\n",
      "ğŸ§  **Reasoning Agent:**\n",
      "Step 1: Implementing AI-powered chatbots\n",
      "- Reasoning: AI chatbots can handle common customer queries, freeing up human agents to handle more complex issues. This can significantly reduce response times for routine inquiries.\n",
      "- Conclusion: Implement AI-powered chatbots to handle common customer queries.\n",
      "\n",
      "Step 2: Streamlining the support process\n",
      "- Reasoning: Simplifying the support process and removing unnecessary steps can help reduce response times. This could involve consolidating support channels, creating self-help resources, or automating certain processes.\n",
      "- Conclusion: Streamline the support process by consolidating support channels, creating self-help resources, and automating processes where possible.\n",
      "\n",
      "Step 3: Increasing support staff\n",
      "- Reasoning: Hiring additional support staff or training existing staff to handle more complex issues can help reduce response times. A study by Forrester found that increasing the number of support agents by just 10% can reduce average response time by 20%.\n",
      "- Conclusion: Consider hiring additional support staff or training existing staff to handle more complex issues to reduce response times.\n",
      "\n",
      "Step 4: Prioritizing urgent issues\n",
      "- Reasoning: Prioritizing urgent issues and ensuring they are addressed first can help reduce response times. This could involve implementing a ticketing system that prioritizes issues based on their urgency.\n",
      "- Conclusion: Implement a ticketing system that prioritizes issues based on their urgency to reduce response times.\n",
      "\n",
      "Step 5: Providing training and resources\n",
      "- Reasoning: Providing support staff with the necessary training and resources can help them handle issues more efficiently, reducing response times. This could involve providing training on specific products or services, or creating a knowledge base that support staff can reference.\n",
      "- Conclusion: Provide necessary training and resources to support staff to handle issues more efficiently and reduce response times.\n",
      "\n",
      "Step 6: Analyzing and optimizing response times\n",
      "- Reasoning: Regularly analyzing response times and identifying areas for improvement can help reduce response times. This could involve tracking response times for different types\n",
      "\n",
      "âš¡ **Execution Agent:**\n",
      "```json\n",
      "{\n",
      "  \"actions\": [\n",
      "    {\n",
      "      \"step\": 1,\n",
      "      \"description\": \"Select and integrate an AI-powered chatbot platform that fits the company's needs and customer service goals.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"1 month\",\n",
      "      \"resources\": [\"IT team\", \"Customer service manager\", \"AI chatbot platform vendor\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 2,\n",
      "      \"description\": \"Review and streamline the current support process, eliminating redundant steps and consolidating support channels.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"2 weeks\",\n",
      "      \"resources\": [\"Customer service manager\", \"Support team\", \"Process improvement tools\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 3,\n",
      "      \"description\": \"Develop a training program for support staff to enhance their skills in handling complex issues and using the new AI chatbot system.\",\n",
      "      \"priority\": \"medium\",\n",
      "      \"timeline\": \"1 month\",\n",
      "      \"resources\": [\"Training department\", \"Support staff\", \"AI chatbot system documentation\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 4,\n",
      "      \"description\": \"Implement a ticketing system that prioritizes issues based on urgency, ensuring that urgent issues are addressed first.\",\n",
      "      \"priority\": \"high\",\n",
      "      \"timeline\": \"3 weeks\",\n",
      "      \"resources\": [\"IT team\", \"Customer service manager\", \"Ticketing system software\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 5,\n",
      "      \"description\": \"Create a comprehensive knowledge base and provide resources to support staff to enable them to resolve issues more efficiently.\",\n",
      "      \"priority\": \"medium\",\n",
      "      \"timeline\": \"2 weeks\",\n",
      "      \"resources\": [\"Content creators\", \"Support staff\", \"Knowledge base platform\"]\n",
      "    },\n",
      "    {\n",
      "      \"step\": 6,\n",
      "      \"description\": \"Set up a system for regularly analyzing response times and identifying areas for improvement.\",\n",
      "      \"priority\": \"medium\",\n",
      "      \"timeline\": \"Ongoing\",\n",
      "      \"\n"
     ]
    }
   ],
   "source": [
    "def test_individual_agents(query: str):\n",
    "    \"\"\"Test each agent individually with the same query.\"\"\"\n",
    "    print(f\"ğŸ§ª **Individual Agent Testing**\")\n",
    "    print(f\"â“ Query: {query}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Test Retrieval Agent\n",
    "    print(\"\\nğŸ” **Retrieval Agent:**\")\n",
    "    retrieval_result = coordinator.retrieval.run(query)\n",
    "    print(retrieval_result)\n",
    "    \n",
    "    # Test Reasoning Agent (using retrieval result as context)\n",
    "    print(\"\\nğŸ§  **Reasoning Agent:**\")\n",
    "    reasoning_result = coordinator.reasoning.run(retrieval_result, query)\n",
    "    print(reasoning_result)\n",
    "    \n",
    "    # Test Execution Agent (using reasoning result)\n",
    "    print(\"\\nâš¡ **Execution Agent:**\")\n",
    "    execution_result = coordinator.execution.run(reasoning_result)\n",
    "    print(execution_result)\n",
    "\n",
    "# Test with a simple query\n",
    "test_query = \"How can we reduce customer support response time?\"\n",
    "test_individual_agents(test_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccb3f9c",
   "metadata": {},
   "source": [
    "## è‡ªè¨‚ç›®æ¨™æ¸¬è©¦\n",
    "\n",
    "ä½¿ç”¨æ­¤å€å¡Šä¾†æ¸¬è©¦æ‚¨è‡ªå·±çš„ç›®æ¨™ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea65a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¨ **Custom Goal Testing**\n",
      "ğŸ“‹ Your Goal: Create a training program for new AI engineers joining our company\n",
      "============================================================\n",
      "ğŸ¯ **Coordinator:** Processing goal: Create a training program for new AI engineers joining our company\n",
      "============================================================\n",
      "ğŸ“š **Step 1:** Retrieving context...\n",
      "   âœ… Context retrieved (1408 chars)\n",
      "   ğŸ“„ Preview: 1. **Program Structure**: A modular program with a mix of theoretical and practical sessions. Modules could include:\n",
      "   - Introduction to AI and Machi...\n",
      "\n",
      "ğŸ§  **Step 2:** Analyzing and reasoning...\n"
     ]
    }
   ],
   "source": [
    "# Custom goal testing - modify the goal below\n",
    "custom_goal = \"Create a training program for new AI engineers joining our company\"\n",
    "\n",
    "print(f\"ğŸ¨ **Custom Goal Testing**\")\n",
    "print(f\"ğŸ“‹ Your Goal: {custom_goal}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Choose processing method\n",
    "use_feedback = True  # Set to True for feedback rounds, False for basic processing\n",
    "feedback_rounds = 1  # Number of feedback rounds if use_feedback is True\n",
    "\n",
    "if use_feedback:\n",
    "    custom_result = coordinator.handle_with_feedback(custom_goal, feedback_rounds=feedback_rounds)\n",
    "    print(f\"\\nâœ¨ **Result with {feedback_rounds} feedback round(s):**\")\n",
    "else:\n",
    "    custom_result = coordinator.handle(custom_goal)\n",
    "    print(f\"\\nâœ¨ **Basic Result:**\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"ğŸ“š **Context:** {custom_result['context'][:200]}...\")\n",
    "print(f\"\\nğŸ§  **Decision:** {custom_result['decision'][:200]}...\")\n",
    "print(f\"\\nâš¡ **Actions:** {custom_result['actions'][:200]}...\")\n",
    "\n",
    "# Show processing stats\n",
    "print(f\"\\nğŸ“Š **Statistics:**\")\n",
    "print(f\"   â±ï¸ Processing Time: {custom_result['processing_time']:.2f}s\")\n",
    "print(f\"   ğŸ”„ Refinement Rounds: {custom_result.get('refinement_rounds', 0)}\")\n",
    "print(f\"   ğŸ“ Total Content Length: {len(custom_result['context']) + len(custom_result['decision']) + len(custom_result['actions'])} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a6d1c2",
   "metadata": {},
   "source": [
    "## æ€§èƒ½åˆ†æ\n",
    "\n",
    "åˆ†æå¤šä»£ç†ç³»çµ±çš„æ€§èƒ½ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef5496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_benchmark(goals: List[str], iterations: int = 2) -> Dict[str, Any]:\n",
    "    \"\"\"Benchmark the coordinator performance with multiple goals.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(f\"ğŸ“Š **Performance Benchmark**\")\n",
    "    print(f\"ğŸ¯ Goals: {len(goals)}\")\n",
    "    print(f\"ğŸ”„ Iterations per goal: {iterations}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i, goal in enumerate(goals, 1):\n",
    "        print(f\"\\nğŸ¯ **Goal {i}:** {goal[:50]}...\")\n",
    "        goal_times = []\n",
    "        \n",
    "        for j in range(iterations):\n",
    "            print(f\"   ğŸ”„ Iteration {j+1}/{iterations}...\", end=\" \")\n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                result = coordinator.handle(goal)\n",
    "                end_time = time.time()\n",
    "                processing_time = end_time - start_time\n",
    "                goal_times.append(processing_time)\n",
    "                print(f\"âœ… {processing_time:.2f}s\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error: {e}\")\n",
    "        \n",
    "        if goal_times:\n",
    "            avg_time = sum(goal_times) / len(goal_times)\n",
    "            results.append({\n",
    "                \"goal\": goal,\n",
    "                \"avg_time\": avg_time,\n",
    "                \"min_time\": min(goal_times),\n",
    "                \"max_time\": max(goal_times),\n",
    "                \"times\": goal_times\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Benchmark with different types of goals\n",
    "benchmark_goals = [\n",
    "    \"Create a social media marketing strategy\",\n",
    "    \"Improve employee onboarding process\",\n",
    "    \"Design a mobile app user interface\",\n",
    "    \"Plan a product launch campaign\"\n",
    "]\n",
    "\n",
    "benchmark_results = performance_benchmark(benchmark_goals, iterations=2)\n",
    "\n",
    "# Display benchmark summary\n",
    "print(\"\\nğŸ† **Benchmark Summary:**\")\n",
    "print(\"=\" * 50)\n",
    "for result in benchmark_results:\n",
    "    print(f\"ğŸ“ {result['goal'][:40]}...\")\n",
    "    print(f\"   â±ï¸ Average: {result['avg_time']:.2f}s\")\n",
    "    print(f\"   âš¡ Fastest: {result['min_time']:.2f}s\")\n",
    "    print(f\"   ğŸŒ Slowest: {result['max_time']:.2f}s\")\n",
    "    print()\n",
    "\n",
    "if benchmark_results:\n",
    "    overall_avg = sum(r['avg_time'] for r in benchmark_results) / len(benchmark_results)\n",
    "    print(f\"ğŸ“Š **Overall Average Processing Time:** {overall_avg:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49cca35",
   "metadata": {},
   "source": [
    "## ç”Ÿç”¢éƒ¨ç½²åŠ©æ‰‹\n",
    "\n",
    "ä»¥ä¸‹æ˜¯å¦‚ä½•å°‡å”èª¿å™¨åŒ…è£ç”¨æ–¼ç”Ÿç”¢ç’°å¢ƒçš„ç¤ºä¾‹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299fed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionCoordinator:\n",
    "    \"\"\"Production-ready wrapper for the multi-agent coordinator.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_alias: str = \"phi-4-mini\"):\n",
    "        self.client = FoundryClient(model_alias)\n",
    "        self.coordinator = Coordinator(self.client)\n",
    "        self.request_count = 0\n",
    "        self.total_processing_time = 0\n",
    "    \n",
    "    def process_goal(self, goal: str, include_feedback: bool = False, feedback_rounds: int = 1) -> Dict[str, Any]:\n",
    "        \"\"\"Process a goal with production monitoring.\"\"\"\n",
    "        self.request_count += 1\n",
    "        \n",
    "        try:\n",
    "            if include_feedback:\n",
    "                result = self.coordinator.handle_with_feedback(goal, feedback_rounds=feedback_rounds)\n",
    "            else:\n",
    "                result = self.coordinator.handle(goal)\n",
    "            \n",
    "            self.total_processing_time += result['processing_time']\n",
    "            \n",
    "            # Add production metadata\n",
    "            result['request_id'] = self.request_count\n",
    "            result['status'] = 'success'\n",
    "            result['model'] = self.client.model_name\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'request_id': self.request_count,\n",
    "                'status': 'error',\n",
    "                'error': str(e),\n",
    "                'goal': goal,\n",
    "                'timestamp': time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get production statistics.\"\"\"\n",
    "        avg_processing_time = self.total_processing_time / max(1, self.request_count)\n",
    "        \n",
    "        return {\n",
    "            'total_requests': self.request_count,\n",
    "            'total_processing_time': self.total_processing_time,\n",
    "            'average_processing_time': avg_processing_time,\n",
    "            'model': self.client.model_name,\n",
    "            'client_healthy': self.client.check_health()\n",
    "        }\n",
    "\n",
    "# Example production usage\n",
    "prod_coordinator = ProductionCoordinator()\n",
    "\n",
    "# Process a goal\n",
    "prod_goal = \"Create a quarterly business review presentation\"\n",
    "prod_result = prod_coordinator.process_goal(prod_goal)\n",
    "\n",
    "print(f\"ğŸ­ **Production Processing Result:**\")\n",
    "print(f\"ğŸ“Š Status: {prod_result['status']}\")\n",
    "print(f\"ğŸ”¢ Request ID: {prod_result['request_id']}\")\n",
    "print(f\"â±ï¸ Processing Time: {prod_result.get('processing_time', 'N/A')}s\")\n",
    "print(f\"ğŸ¤– Model: {prod_result.get('model', 'N/A')}\")\n",
    "\n",
    "# Show production stats\n",
    "stats = prod_coordinator.get_stats()\n",
    "print(f\"\\nğŸ“Š **Production Statistics:**\")\n",
    "print(f\"   ğŸ“ˆ Total Requests: {stats['total_requests']}\")\n",
    "print(f\"   â±ï¸ Average Processing Time: {stats['average_processing_time']:.2f}s\")\n",
    "print(f\"   ğŸ’š Client Health: {'âœ… Healthy' if stats['client_healthy'] else 'âŒ Unhealthy'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d3849",
   "metadata": {},
   "source": [
    "## æ‘˜è¦èˆ‡æœ€ä½³å¯¦è¸\n",
    "\n",
    "æ­¤ç­†è¨˜æœ¬å±•ç¤ºäº†ä¸€å€‹å…ˆé€²çš„å¤šä»£ç†å”ä½œç³»çµ±ï¼š\n",
    "\n",
    "### âœ… å±•ç¤ºçš„ä¸»è¦åŠŸèƒ½\n",
    "\n",
    "1. **ğŸ—ï¸ ä»£ç†å°ˆæ¥­åŒ–**ï¼šæ¯å€‹ä»£ç†é‡å°ç‰¹å®šèªçŸ¥ä»»å‹™é€²è¡Œå„ªåŒ–  \n",
    "2. **ğŸ¯ å·¥ä½œæµç¨‹å”ä½œ**ï¼šå”èª¿å¤šæ­¥é©Ÿè™•ç†  \n",
    "3. **ğŸ“‹ çµæ§‹åŒ–è¼¸å‡º**ï¼šJSON æ ¼å¼çš„è¡Œå‹•è¨ˆåŠƒ  \n",
    "4. **ğŸ”„ åé¥‹è¿´è·¯**ï¼šå¤šè¼ªæ¬¡çš„æ”¹é€²èƒ½åŠ›  \n",
    "5. **âš¡ æ€§èƒ½ç›£æ§**ï¼šè™•ç†æ™‚é–“èˆ‡å¥åº·ç‹€æ…‹æª¢æŸ¥  \n",
    "6. **ğŸ­ å¯æŠ•å…¥ç”Ÿç”¢**ï¼šå…·å‚™ç›£æ§åŠŸèƒ½çš„ä¼æ¥­ç´šå°è£  \n",
    "\n",
    "### ğŸ§  ä»£ç†è§’è‰²æ‘˜è¦\n",
    "\n",
    "| ä»£ç† | ç›®çš„ | è¼¸å…¥ | è¼¸å‡º |\n",
    "|------|------|------|------|\n",
    "| **ğŸ” æª¢ç´¢** | æå–ç›¸é—œè³‡è¨Š | ä½¿ç”¨è€…æŸ¥è©¢ | æƒ…å¢ƒåŒ–çš„äº‹å¯¦èˆ‡æ•¸æ“š |\n",
    "| **ğŸ§  æ¨ç†** | é‚è¼¯åˆ†æ | æƒ…å¢ƒ + å•é¡Œ | çµæ§‹åŒ–æ±ºç­– |\n",
    "| **âš¡ åŸ·è¡Œ** | åˆ¶å®šè¡Œå‹•è¨ˆåŠƒ | æ±ºç­– | JSON æ ¼å¼çš„è¡Œå‹•æ­¥é©Ÿ |\n",
    "| **ğŸ¯ å”èª¿è€…** | å”ä½œå·¥ä½œæµç¨‹ | ä½¿ç”¨è€…ç›®æ¨™ | å®Œæ•´çµæœ |\n",
    "\n",
    "### ğŸš€ ä½¿ç”¨æ¡ˆä¾‹\n",
    "\n",
    "- **å•†æ¥­è¦åŠƒ**ï¼šç­–ç•¥è¦åŠƒèˆ‡åŸ·è¡Œ  \n",
    "- **å°ˆæ¡ˆç®¡ç†**ï¼šä»»å‹™åˆ†è§£èˆ‡æ’ç¨‹  \n",
    "- **ç ”ç©¶**ï¼šè³‡è¨Šæ”¶é›†èˆ‡åˆ†æ  \n",
    "- **æ±ºç­–æ”¯æŒ**ï¼šè¤‡é›œçš„æ±ºç­–éç¨‹  \n",
    "- **å·¥ä½œæµç¨‹è‡ªå‹•åŒ–**ï¼šå¤šæ­¥é©Ÿçš„å•†æ¥­æµç¨‹  \n",
    "\n",
    "### ğŸ’¡ æœ€ä½³å¯¦è¸\n",
    "\n",
    "1. **ğŸ¯ å–®ä¸€è²¬ä»»**ï¼šæ¯å€‹ä»£ç†æœ‰æ˜ç¢ºçš„å–®ä¸€ç›®çš„  \n",
    "2. **ğŸ”— æ¸…æ™°ä»‹é¢**ï¼šæ¨™æº–åŒ–çš„è¼¸å…¥/è¼¸å‡ºæ ¼å¼  \n",
    "3. **ğŸ›¡ï¸ éŒ¯èª¤è™•ç†**ï¼šæ•…éšœæ™‚çš„å¹³ç©©é™ç´š  \n",
    "4. **ğŸ“Š ç›£æ§**ï¼šå…¨é¢çš„æ—¥èªŒè¨˜éŒ„èˆ‡æ€§èƒ½è¿½è¹¤  \n",
    "5. **ğŸ”„ åé¥‹è¿´è·¯**ï¼šè¿­ä»£æ”¹é€²æ©Ÿåˆ¶  \n",
    "6. **âš–ï¸ è² è¼‰å¹³è¡¡**ï¼šå°ç¨ç«‹ä»»å‹™è€ƒæ…®ä¸¦è¡Œè™•ç†  \n",
    "\n",
    "### ğŸ”® ä¸‹ä¸€æ­¥\n",
    "\n",
    "- **ğŸ”§ å‡½æ•¸èª¿ç”¨**ï¼šæ•´åˆå¤–éƒ¨ API èˆ‡å·¥å…·  \n",
    "- **ğŸ§  è¨˜æ†¶ç³»çµ±**ï¼šç‚ºä»£ç†æ·»åŠ æŒä¹…è¨˜æ†¶åŠŸèƒ½  \n",
    "- **ğŸ­ å°ˆæ¥­åŒ–æ¨¡å‹**ï¼šç‚ºä¸åŒä»£ç†ä½¿ç”¨ä¸åŒæ¨¡å‹  \n",
    "- **ğŸ‘¥ äººé¡ä»‹å…¥**ï¼šæ·»åŠ äººé¡å¯©æŸ¥èˆ‡æ‰¹å‡†æ­¥é©Ÿ  \n",
    "- **ğŸ“Š é«˜ç´šåˆ†æ**ï¼šå…¨é¢çš„ç›£æ§èˆ‡æŒ‡æ¨™è¿½è¹¤  \n",
    "\n",
    "æ­¤å¤šä»£ç†ç³»çµ±å±•ç¤ºäº†å¦‚ä½•æ§‹å»ºè¤‡é›œçš„ AI å·¥ä½œæµç¨‹ï¼Œçµåˆå°ˆæ¥­åŒ–ä»£ç†çš„å„ªå‹¢ï¼ŒåŒæ™‚ä¿æŒ Microsoft Foundry Local æä¾›çš„æœ¬åœ°æ¨ç†éš±ç§èˆ‡æ€§èƒ½æ•ˆç›Šã€‚\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "coopTranslator": {
   "original_hash": "e769e8958054219004d420c9a7b3584b",
   "translation_date": "2025-09-24T10:05:04+00:00",
   "source_file": "Module08/samples/05/multi_agent_orchestration.ipynb",
   "language_code": "tw"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}