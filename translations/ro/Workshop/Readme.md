<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8b994c57f1207012e4d7f58b7c0d1ae7",
  "translation_date": "2025-10-17T10:07:18+00:00",
  "source_file": "Workshop/Readme.md",
  "language_code": "ro"
}
-->
# EdgeAI pentru ÃncepÄƒtori - Atelier

> **Cale de Ã®nvÄƒÈ›are practicÄƒ pentru construirea aplicaÈ›iilor Edge AI gata de producÈ›ie**
>
> StÄƒpÃ¢neÈ™te implementarea AI localÄƒ cu Microsoft Foundry Local, de la prima completare de chat la orchestrarea multi-agent Ã®n 6 sesiuni progresive.

---

## ğŸ¯ Introducere

Bine ai venit la **Atelierul EdgeAI pentru ÃncepÄƒtori** - ghidul tÄƒu practic pentru construirea aplicaÈ›iilor inteligente care ruleazÄƒ complet pe hardware local. Acest atelier transformÄƒ conceptele teoretice ale Edge AI Ã®n abilitÄƒÈ›i reale prin exerciÈ›ii progresiv provocatoare utilizÃ¢nd Microsoft Foundry Local È™i Small Language Models (SLMs).

### De ce acest atelier?

**RevoluÈ›ia Edge AI este aici**

OrganizaÈ›iile din Ã®ntreaga lume trec de la AI dependent de cloud la calculul edge din trei motive critice:

1. **ConfidenÈ›ialitate & Conformitate** - ProceseazÄƒ date sensibile local, fÄƒrÄƒ transmitere Ã®n cloud (HIPAA, GDPR, reglementÄƒri financiare)
2. **PerformanÈ›Äƒ** - EliminÄƒ latenÈ›a reÈ›elei (50-500ms local vs 500-2000ms tur-retur Ã®n cloud)
3. **Controlul Costurilor** - EliminÄƒ costurile API per-token È™i scaleazÄƒ fÄƒrÄƒ cheltuieli de cloud

**Dar Edge AI este diferit**

Rularea AI on-premises necesitÄƒ abilitÄƒÈ›i noi:
- Selectarea È™i optimizarea modelelor pentru constrÃ¢ngeri de resurse
- Managementul serviciilor locale È™i accelerarea hardware
- Ingineria prompturilor pentru modele mai mici
- Modele de implementare pentru dispozitive edge

**Acest atelier oferÄƒ aceste abilitÄƒÈ›i**

Ãn 6 sesiuni concentrate (~3 ore Ã®n total), vei progresa de la "Hello World" la implementarea sistemelor multi-agent gata de producÈ›ie - toate rulÃ¢nd local pe maÈ™ina ta.

---

## ğŸ“š Obiective de ÃnvÄƒÈ›are

DupÄƒ finalizarea acestui atelier, vei putea:

### CompetenÈ›e de bazÄƒ
1. **Implementa È™i gestiona servicii AI locale**
   - InstaleazÄƒ È™i configureazÄƒ Microsoft Foundry Local
   - SelecteazÄƒ modele adecvate pentru implementarea edge
   - GestioneazÄƒ ciclul de viaÈ›Äƒ al modelelor (descÄƒrcare, Ã®ncÄƒrcare, cache)
   - MonitorizeazÄƒ utilizarea resurselor È™i optimizeazÄƒ performanÈ›a

2. **ConstruieÈ™te aplicaÈ›ii alimentate de AI**
   - ImplementeazÄƒ completÄƒri de chat compatibile cu OpenAI local
   - ProiecteazÄƒ prompturi eficiente pentru Small Language Models
   - GestioneazÄƒ rÄƒspunsuri Ã®n streaming pentru o experienÈ›Äƒ mai bunÄƒ
   - IntegreazÄƒ modele locale Ã®n aplicaÈ›ii existente

3. **CreeazÄƒ sisteme RAG (Retrieval Augmented Generation)**
   - ConstruieÈ™te cÄƒutare semanticÄƒ cu embeddings
   - FundamenteazÄƒ rÄƒspunsurile LLM Ã®n cunoÈ™tinÈ›e specifice domeniului
   - EvalueazÄƒ calitatea RAG cu metrici standard din industrie
   - ScaleazÄƒ de la prototip la producÈ›ie

4. **OptimizeazÄƒ performanÈ›a modelelor**
   - EvalueazÄƒ mai multe modele pentru cazul tÄƒu de utilizare
   - MÄƒsoarÄƒ latenÈ›a, debitul È™i timpul primului token
   - SelecteazÄƒ modele optime bazate pe compromisuri vitezÄƒ/calitate
   - ComparÄƒ compromisurile SLM vs LLM Ã®n scenarii reale

5. **OrchestreazÄƒ sisteme multi-agent**
   - ProiecteazÄƒ agenÈ›i specializaÈ›i pentru diferite sarcini
   - ImplementeazÄƒ memorie È™i gestionarea contextului pentru agenÈ›i
   - CoordoneazÄƒ agenÈ›i Ã®n fluxuri de lucru complexe
   - DirecÈ›ioneazÄƒ cereri inteligent Ã®ntre mai multe modele

6. **Implementa soluÈ›ii gata de producÈ›ie**
   - ImplementeazÄƒ gestionarea erorilor È™i logica de retry
   - MonitorizeazÄƒ utilizarea tokenurilor È™i resursele sistemului
   - ConstruieÈ™te arhitecturi scalabile cu modele ca instrumente
   - PlanificÄƒ cÄƒi de migrare de la edge la hibrid (edge + cloud)

---

## ğŸ“ Rezultate de ÃnvÄƒÈ›are

### Ce vei construi

PÃ¢nÄƒ la finalul acestui atelier, vei fi creat:

| Sesiune | Rezultat | AbilitÄƒÈ›i Demonstrate |
|---------|----------|-----------------------|
| **1** | AplicaÈ›ie de chat cu streaming | Configurare serviciu, completÄƒri de bazÄƒ, UX streaming |
| **2** | Sistem RAG cu evaluare | Embeddings, cÄƒutare semanticÄƒ, metrici de calitate |
| **3** | SuitÄƒ de benchmark multi-model | MÄƒsurarea performanÈ›ei, compararea modelelor |
| **4** | Comparator SLM vs LLM | Analiza compromisurilor, strategii de optimizare |
| **5** | Orchestrator multi-agent | Proiectare agenÈ›i, gestionarea memoriei, coordonare |
| **6** | Sistem de rutare inteligent | Detectarea intenÈ›iei, selecÈ›ia modelului, scalabilitate |

### Matrice de CompetenÈ›e

| Nivel de AbilitÄƒÈ›i | Sesiunea 1-2 | Sesiunea 3-4 | Sesiunea 5-6 |
|--------------------|--------------|--------------|--------------|
| **ÃncepÄƒtor** | âœ… Configurare & bazÄƒ | âš ï¸ Provocator | âŒ Prea avansat |
| **Intermediar** | âœ… Revizuire rapidÄƒ | âœ… ÃnvÄƒÈ›are de bazÄƒ | âš ï¸ Obiective extinse |
| **Avansat** | âœ… UÈ™or de parcurs | âœ… PerfecÈ›ionare | âœ… Modele de producÈ›ie |

### AbilitÄƒÈ›i PregÄƒtite pentru CarierÄƒ

**DupÄƒ acest atelier, vei fi pregÄƒtit sÄƒ:**

âœ… **ConstruieÈ™ti AplicaÈ›ii Centrate pe ConfidenÈ›ialitate**
- AplicaÈ›ii de sÄƒnÄƒtate care gestioneazÄƒ PHI/PII local
- Servicii financiare cu cerinÈ›e de conformitate
- Sisteme guvernamentale cu nevoi de suveranitate a datelor

âœ… **Optimizezi pentru Medii Edge**
- Dispozitive IoT cu resurse limitate
- AplicaÈ›ii mobile offline-first
- Sisteme Ã®n timp real cu latenÈ›Äƒ redusÄƒ

âœ… **Proiectezi Arhitecturi Inteligente**
- Sisteme multi-agent pentru fluxuri de lucru complexe
- ImplementÄƒri hibride edge-cloud
- InfrastructurÄƒ AI optimizatÄƒ pentru costuri

âœ… **Conduci IniÈ›iative Edge AI**
- EvalueazÄƒ fezabilitatea Edge AI pentru proiecte
- SelecteazÄƒ modele È™i cadre adecvate
- ProiecteazÄƒ soluÈ›ii AI locale scalabile

---

## ğŸ—ºï¸ Structura Atelierului

### Prezentare GeneralÄƒ a Sesiunilor (6 Sesiuni Ã— 30 Minute = 3 Ore)

| Sesiune | Subiect | Focus | DuratÄƒ |
|---------|---------|-------|--------|
| **1** | Ãnceput cu Foundry Local | Instalare, validare, primele completÄƒri | 30 min |
| **2** | Construirea SoluÈ›iilor AI cu RAG | Ingineria prompturilor, embeddings, evaluare | 30 min |
| **3** | Modele Open Source | Descoperirea modelelor, benchmarking, selecÈ›ie | 30 min |
| **4** | Modele de UltimÄƒ GeneraÈ›ie | SLM vs LLM, optimizare, cadre | 30 min |
| **5** | AgenÈ›i AlimentaÈ›i de AI | Proiectare agenÈ›i, orchestrare, memorie | 30 min |
| **6** | Modele ca Instrumente | Rutare, lanÈ›uri, strategii de scalare | 30 min |

---

## ğŸš€ Ãnceput Rapid

### CerinÈ›e Prealabile

**CerinÈ›e de Sistem:**
- **OS**: Windows 10/11, macOS 11+ sau Linux (Ubuntu 20.04+)
- **RAM**: Minim 8GB, recomandat 16GB+
- **SpaÈ›iu de stocare**: Minim 10GB liber pentru modele
- **CPU**: Procesor modern cu suport AVX2
- **GPU** (opÈ›ional): Compatibil CUDA sau Qualcomm NPU pentru accelerare

**CerinÈ›e Software:**
- **Python 3.8+** ([DescÄƒrcare](https://www.python.org/downloads/))
- **Microsoft Foundry Local** ([Ghid de Instalare](../../../Workshop))
- **Git** ([DescÄƒrcare](https://git-scm.com/downloads))
- **Visual Studio Code** (recomandat) ([DescÄƒrcare](https://code.visualstudio.com/))

### Configurare Ã®n 3 PaÈ™i

#### 1. InstaleazÄƒ Foundry Local

**Windows:**
```powershell
winget install Microsoft.FoundryLocal
```

**macOS:**
```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

**VerificÄƒ Instalarea:**
```bash
foundry --version
foundry service status
```

**AsigurÄƒ-te cÄƒ Azure AI Foundry Local ruleazÄƒ cu un port fix**

```bash
# Set FoundryLocal to use port 58123 (default)
foundry service set --port 58123 --show

# Or use a different port
foundry service set --port 58000 --show
```

**VerificÄƒ funcÈ›ionarea:**
```bash
# Check service status
foundry service status

# Test the endpoint
curl http://127.0.0.1:58123/v1/models
```
**GÄƒsirea Modelelor Disponibile**
Pentru a vedea ce modele sunt disponibile Ã®n instanÈ›a ta Foundry Local, poÈ›i interoga endpoint-ul modelelor:

```bash
# cmd/bash/powershell
foundry model list
```

UtilizÃ¢nd Endpoint Web 

```bash
# Windows PowerShell
powershell -Command "Invoke-RestMethod -Uri 'http://127.0.0.1:58123/v1/models' -Method Get"

# Or using curl (if available)
curl http://127.0.0.1:58123/v1/models
```

#### 2. CloneazÄƒ Repozitoriul & InstaleazÄƒ DependenÈ›ele

```bash
# Clone repository
git clone https://github.com/microsoft/edgeai-for-beginners.git
cd edgeai-for-beginners/Workshop

# Create virtual environment
python -m venv .venv

# Activate virtual environment
# Windows:
.\.venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

#### 3. RuleazÄƒ Primul Exemplu

```bash
# Start Foundry Local and load a model
foundry model run phi-4-mini

# Run the chat bootstrap sample
cd samples/session01
python chat_bootstrap.py "What is edge AI?"
```

**âœ… Succes!** Ar trebui sÄƒ vezi un rÄƒspuns Ã®n streaming despre Edge AI.

---

## ğŸ“¦ Resurse Atelier

### Exemple Python

Exemple progresive hands-on care demonstreazÄƒ fiecare concept:

| Sesiune | Exemplu | Descriere | Timp de Rulare |
|---------|---------|-----------|----------------|
| 1 | [`chat_bootstrap.py`](../../../Workshop/samples/session01/chat_bootstrap.py) | Chat de bazÄƒ & streaming | ~30s |
| 2 | [`rag_pipeline.py`](../../../Workshop/samples/session02/rag_pipeline.py) | RAG cu embeddings | ~45s |
| 2 | [`rag_eval_ragas.py`](../../../Workshop/samples/session02/rag_eval_ragas.py) | Evaluarea calitÄƒÈ›ii RAG | ~60s |
| 3 | [`benchmark_oss_models.py`](../../../Workshop/samples/session03/benchmark_oss_models.py) | Benchmarking multi-model | ~2-3m |
| 4 | [`model_compare.py`](../../../Workshop/samples/session04/model_compare.py) | Comparare SLM vs LLM | ~45s |
| 5 | [`agents_orchestrator.py`](../../../Workshop/samples/session05/agents_orchestrator.py) | Sistem multi-agent | ~60s |
| 6 | [`models_router.py`](../../../Workshop/samples/session06/models_router.py) | Rutare bazatÄƒ pe intenÈ›ie | ~45s |
| 6 | [`models_pipeline.py`](../../../Workshop/samples/session06/models_pipeline.py) | Pipeline multi-pas | ~60s |

### Jupyter Notebooks

Explorare interactivÄƒ cu explicaÈ›ii È™i vizualizÄƒri:

| Sesiune | Notebook | Descriere | Dificultate |
|---------|----------|-----------|-------------|
| 1 | [`session01_chat_bootstrap.ipynb`](./notebooks/session01_chat_bootstrap.ipynb) | Bazele chatului & streaming | â­ ÃncepÄƒtor |
| 2 | [`session02_rag_pipeline.ipynb`](./notebooks/session02_rag_pipeline.ipynb) | Construirea sistemului RAG | â­â­ Intermediar |
| 2 | [`session02_rag_eval_ragas.ipynb`](./notebooks/session02_rag_eval_ragas.ipynb) | Evaluarea calitÄƒÈ›ii RAG | â­â­ Intermediar |
| 3 | [`session03_benchmark_oss_models.ipynb`](./notebooks/session03_benchmark_oss_models.ipynb) | Benchmarking modele | â­â­ Intermediar |
| 4 | [`session04_model_compare.ipynb`](./notebooks/session04_model_compare.ipynb) | Compararea modelelor | â­â­ Intermediar |
| 5 | [`session05_agents_orchestrator.ipynb`](./notebooks/session05_agents_orchestrator.ipynb) | Orchestrarea agenÈ›ilor | â­â­â­ Avansat |
| 6 | [`session06_models_router.ipynb`](./notebooks/session06_models_router.ipynb) | Rutare bazatÄƒ pe intenÈ›ie | â­â­â­ Avansat |
| 6 | [`session06_models_pipeline.ipynb`](./notebooks/session06_models_pipeline.ipynb) | Orchestrarea pipeline-ului | â­â­â­ Avansat |

### DocumentaÈ›ie

Ghiduri È™i referinÈ›e complete:

| Document | Descriere | Utilizare |
|----------|-----------|-----------|
| [QUICK_START.md](./QUICK_START.md) | Ghid de configurare rapidÄƒ | ÃncepÃ¢nd de la zero |
| [QUICK_REFERENCE.md](./QUICK_REFERENCE.md) | Foaie de parcurs pentru comenzi & API | Ai nevoie de rÄƒspunsuri rapide |
| [FOUNDRY_SDK_QUICKREF.md](./FOUNDRY_SDK_QUICKREF.md) | Modele SDK & exemple | Scrierea codului |
| [ENV_CONFIGURATION.md](./ENV_CONFIGURATION.md) | Ghid pentru variabilele de mediu | Configurarea exemplelor |
| [SAMPLES_UPDATE_SUMMARY.md](./SAMPLES_UPDATE_SUMMARY.md) | ÃmbunÄƒtÄƒÈ›iri recente ale exemplelor | ÃnÈ›elegerea schimbÄƒrilor |
| [SDK_MIGRATION_NOTES.md](./SDK_MIGRATION_NOTES.md) | Ghid de migrare | Actualizarea codului |
| [notebooks/TROUBLESHOOTING.md](./notebooks/TROUBLESHOOTING.md) | Probleme comune & soluÈ›ii | Depanarea problemelor |

---

## ğŸ“ RecomandÄƒri pentru Calea de ÃnvÄƒÈ›are

### Pentru ÃncepÄƒtori (3-4 ore)
1. âœ… Sesiunea 1: Ãnceput (focus pe configurare È™i chat de bazÄƒ)
2. âœ… Sesiunea 2: Bazele RAG (sari peste evaluare iniÈ›ial)
3. âœ… Sesiunea 3: Benchmarking simplu (doar 2 modele)
4. â­ï¸ Sari peste Sesiunile 4-6 pentru moment
5. ğŸ”„ Revino la Sesiunile 4-6 dupÄƒ construirea primei aplicaÈ›ii

### Pentru Dezvoltatori Intermediari (3 ore)
1. âš¡ Sesiunea 1: Validare rapidÄƒ a configurÄƒrii
2. âœ… Sesiunea 2: Pipeline complet RAG cu evaluare
3. âœ… Sesiunea 3: SuitÄƒ completÄƒ de benchmarking
4. âœ… Sesiunea 4: Optimizarea modelelor
5. âœ… Sesiunile 5-6: Focus pe modele de arhitecturÄƒ

### Pentru Practicieni AvansaÈ›i (2-3 ore)
1. âš¡ Sesiunile 1-3: Revizuire rapidÄƒ È™i validare
2. âœ… Sesiunea 4: Detalii despre optimizare
3. âœ… Sesiunea 5: ArhitecturÄƒ multi-agent
4. âœ… Sesiunea 6: Modele de producÈ›ie È™i scalare
5. ğŸš€ Extinde: ConstruieÈ™te logicÄƒ de rutare personalizatÄƒ È™i implementÄƒri hibride

---

## Pachet de Sesiuni Atelier (Laboratoare Concentrate de 30 de Minute)

DacÄƒ urmezi formatul condensat de atelier cu 6 sesiuni, foloseÈ™te aceste ghiduri dedicate (fiecare se potriveÈ™te È™i completeazÄƒ documentele modulelor mai largi de mai sus):

| Sesiune Atelier | Ghid | Focus Principal |
|-----------------|------|-----------------|
| 1 | [Session01-GettingStartedFoundryLocal](./Session01-GettingStartedFoundryLocal.md) | Instalare, validare, rulare phi & GPT-OSS-20B, accelerare |
| 2 | [Session02-BuildAISolutionsRAG](./Session02-BuildAISolutionsRAG.md) | Ingineria prompturilor, modele RAG, CSV & documente fundamentale, migrare |
| 3 | [Session03-OpenSourceModels](./Session03-OpenSourceModels.md) | Integrare Hugging Face, benchmarking, selecÈ›ie modele |
| 4 | [Session04-CuttingEdgeModels](./Session04-CuttingEdgeModels.md) | SLM vs LLM, WebGPU, Chainlit RAG, accelerare ONNX |
| 5 | [Session05-AIPoweredAgents](./Session05-AIPoweredAgents.md) | Roluri ale agenÈ›ilor, memorie, unelte, orchestrare |
| 6 | [Session06-ModelsAsTools](./Session06-ModelsAsTools.md) | Rutare, lanÈ›uri, scalare cÄƒtre Azure |

Fiecare fiÈ™ier de sesiune include: rezumat, obiective de Ã®nvÄƒÈ›are, demonstraÈ›ie de 30 de minute, proiect de Ã®nceput, listÄƒ de verificare pentru validare, depanare È™i referinÈ›e la SDK-ul oficial Foundry Local Python.

### Scripturi Exemple

Instalare dependenÈ›e workshop (Windows):

```powershell
cd Workshop
py -m venv .venv
.\.venv\Scripts\activate
pip install -r requirements.txt
```

macOS / Linux:

```bash
cd Workshop
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

DacÄƒ serviciul Foundry Local ruleazÄƒ pe o altÄƒ maÈ™inÄƒ (Windows) sau VM de pe macOS, exportaÈ›i endpoint-ul:

```bash
export FOUNDRY_LOCAL_ENDPOINT=http://<windows-host>:5273/v1
```

| Sesiune | Script(uri) | Descriere |
|---------|-------------|-----------|
| 1 | `samples/session01/chat_bootstrap.py` | Bootstrap serviciu & chat streaming |
| 2 | `samples/session02/rag_pipeline.py` | RAG minimal (Ã®n memorie, embeddings) |
|   | `samples/session02/rag_eval_ragas.py` | Evaluare RAG cu metrici ragas |
| 3 | `samples/session03/benchmark_oss_models.py` | Benchmarking pentru latenÈ›Äƒ & throughput multi-model |
| 4 | `samples/session04/model_compare.py` | ComparaÈ›ie SLM vs LLM (latenÈ›Äƒ & rezultate exemplu) |
| 5 | `samples/session05/agents_orchestrator.py` | Pipeline de cercetare â†’ editorial cu doi agenÈ›i |
| 6 | `samples/session06/models_router.py` | DemonstraÈ›ie de rutare bazatÄƒ pe intenÈ›ie |
|   | `samples/session06/models_pipeline.py` | LanÈ› multi-pas planificare/executare/perfecÈ›ionare |

### Variabile de Mediu (Comune pentru Exemple)

| VariabilÄƒ | Scop | Exemplu |
|-----------|------|---------|
| `FOUNDRY_LOCAL_ALIAS` | Alias unic pentru modelul de bazÄƒ Ã®n exemple simple | `phi-4-mini` |
| `SLM_ALIAS` / `LLM_ALIAS` | SLM explicit vs model mai mare pentru comparaÈ›ie | `phi-4-mini` / `gpt-oss-20b` |
| `BENCH_MODELS` | ListÄƒ de aliasuri pentru benchmark | `qwen2.5-0.5b,gemma-2-2b,mistral-7b` |
| `BENCH_ROUNDS` | RepetiÈ›ii de benchmark per model | `3` |
| `BENCH_PROMPT` | Prompt utilizat Ã®n benchmark | `Explain retrieval augmented generation briefly.` |
| `EMBED_MODEL` | Model de embedding pentru sentence-transformers | `sentence-transformers/all-MiniLM-L6-v2` |
| `RAG_QUESTION` | Suprascriere query de test pentru pipeline-ul RAG | `Why use RAG with local inference?` |
| `AGENT_QUESTION` | Suprascriere query pentru pipeline-ul agenÈ›ilor | `Explain why edge AI matters for compliance.` |
| `AGENT_MODEL_PRIMARY` | Alias model pentru agentul de cercetare | `phi-4-mini` |
| `AGENT_MODEL_EDITOR` | Alias model pentru agentul editor (poate fi diferit) | `gpt-oss-20b` |
| `SHOW_USAGE` | CÃ¢nd este `1`, afiÈ™eazÄƒ utilizarea tokenilor per completare | `1` |
| `RETRY_ON_FAIL` | CÃ¢nd este `1`, reÃ®ncearcÄƒ o datÄƒ la erori tranzitorii de chat | `1` |
| `RETRY_BACKOFF` | Secunde de aÈ™teptare Ã®nainte de reÃ®ncercare | `1.0` |

DacÄƒ o variabilÄƒ nu este setatÄƒ, scripturile folosesc valori implicite rezonabile. Pentru demonstraÈ›iile cu un singur model, de obicei aveÈ›i nevoie doar de `FOUNDRY_LOCAL_ALIAS`.

### Modul Utilitar

Toate exemplele Ã®mpÄƒrtÄƒÈ™esc acum un helper `samples/workshop_utils.py` care oferÄƒ:

* Creare cache pentru `FoundryLocalManager` + client OpenAI
* Helper `chat_once()` cu opÈ›iuni de retry + afiÈ™are utilizare
* Raportare simplÄƒ a utilizÄƒrii tokenilor (activatÄƒ prin `SHOW_USAGE=1`)

Acest lucru reduce duplicarea È™i evidenÈ›iazÄƒ cele mai bune practici pentru orchestrarea eficientÄƒ a modelelor locale.

## ÃmbunÄƒtÄƒÈ›iri OpÈ›ionale (Ãntre Sesiuni)

| TemÄƒ | ÃmbunÄƒtÄƒÈ›ire | Sesiuni | Env / Toggle |
|------|--------------|---------|--------------|
| Determinism | TemperaturÄƒ fixÄƒ + seturi stabile de prompturi | 1â€“6 | Setare `temperature=0`, `top_p=1` |
| Vizibilitate Utilizare Tokeni | Predare consistentÄƒ a costului/eficienÈ›ei | 1â€“6 | `SHOW_USAGE=1` |
| Streaming Primul Token | MetricÄƒ de latenÈ›Äƒ perceputÄƒ | 1,3,4,6 | `BENCH_STREAM=1` (benchmark) |
| RezilienÈ›Äƒ la Retry | Gestionare pornire rece tranzitorie | Toate | `RETRY_ON_FAIL=1` + `RETRY_BACKOFF` |
| AgenÈ›i Multi-Model | Specializare roluri eterogene | 5 | `AGENT_MODEL_PRIMARY`, `AGENT_MODEL_EDITOR` |
| Rutare AdaptivÄƒ | IntenÈ›ie + euristici de cost | 6 | Extinderea routerului cu logicÄƒ de escaladare |
| Memorie VectorialÄƒ | Recapitulare semanticÄƒ pe termen lung | 2,5,6 | Integrare FAISS/Chroma embedding index |
| Export UrmÄƒrire | Auditare & evaluare | 2,5,6 | AdÄƒugare JSON per pas |
| Rubrici de Calitate | UrmÄƒrire calitativÄƒ | 3â€“6 | Prompturi secundare de evaluare |
| Teste de Fum | Validare rapidÄƒ pre-workshop | Toate | `python Workshop/tests/smoke.py` |

### Start Rapid Determinist

```powershell
set FOUNDRY_LOCAL_ALIAS=phi-4-mini
set SHOW_USAGE=1
python Workshop\tests\smoke.py
```

AÈ™teptaÈ›i numÄƒr stabil de tokeni pentru intrÄƒri identice repetate.

### Evaluare RAG (Sesiunea 2)

UtilizaÈ›i `rag_eval_ragas.py` pentru a calcula relevanÈ›a rÄƒspunsului, fidelitatea È™i precizia contextului pe un set de date sintetic mic:

```powershell
python samples/session02/rag_eval_ragas.py
```

ExtindeÈ›i prin furnizarea unui JSONL mai mare de Ã®ntrebÄƒri, contexte È™i adevÄƒruri de bazÄƒ, apoi convertiÈ›i-l Ã®ntr-un `Dataset` Hugging Face.

## AnexÄƒ Comenzi CLI Precise

Workshop-ul foloseÈ™te deliberat doar comenzi CLI Foundry Local documentate / stabile.

### Comenzi Stabile Referite

| Categorie | ComandÄƒ | Scop |
|-----------|---------|------|
| Core | `foundry --version` | AfiÈ™eazÄƒ versiunea instalatÄƒ |
| Core | `foundry init` | IniÈ›ializeazÄƒ configuraÈ›ia |
| Serviciu | `foundry service start` | PorneÈ™te serviciul local (dacÄƒ nu este auto) |
| Serviciu | `foundry status` | AfiÈ™eazÄƒ statusul serviciului |
| Modele | `foundry model list` | ListeazÄƒ catalogul / modelele disponibile |
| Modele | `foundry model download <alias>` | DescarcÄƒ greutÄƒÈ›ile modelului Ã®n cache |
| Modele | `foundry model run <alias>` | RuleazÄƒ (Ã®ncarcÄƒ) un model local; combinÄƒ cu `--prompt` pentru o singurÄƒ execuÈ›ie |
| Modele | `foundry model unload <alias>` / `foundry model stop <alias>` | DezÃ®ncarcÄƒ un model din memorie (dacÄƒ este suportat) |
| Cache | `foundry cache list` | ListeazÄƒ modelele cache-uite (descÄƒrcate) |
| Sistem | `foundry system info` | Snapshot capacitÄƒÈ›i hardware & accelerare |
| Sistem | `foundry system gpu-info` | Info diagnostic GPU |
| Config | `foundry config list` | AfiÈ™eazÄƒ valorile configuraÈ›iei curente |
| Config | `foundry config set <key> <value>` | ActualizeazÄƒ configuraÈ›ia |

### Model Prompt Oneâ€‘Shot

Ãn loc de subcomanda `model chat` depreciatÄƒ, utilizaÈ›i:

```powershell
foundry model run <alias> --prompt "Your question here"
```

Aceasta executÄƒ un ciclu prompt/rÄƒspuns unic È™i apoi se Ã®nchide.

### Modele / Pattern-uri Evitate

| Depreciat / Nondocumentat | Ãnlocuire / Ghid |
|---------------------------|------------------|
| `foundry model chat <model> "..."` | `foundry model run <model> --prompt "..."` |
| `foundry model list --running` | UtilizaÈ›i `foundry model list` + activitate recentÄƒ / loguri |
| `foundry model list --cached` | `foundry cache list` |
| `foundry model stats <model>` | UtilizaÈ›i scriptul de benchmark Python + unelte OS (Task Manager / `nvidia-smi`) |
| `foundry model benchmark ...` | `samples/session03/benchmark_oss_models.py` |

### Benchmarking & Telemetrie

- LatenÈ›Äƒ, p95, tokens/sec: `samples/session03/benchmark_oss_models.py`
- LatenÈ›Äƒ primului token (streaming): setaÈ›i `BENCH_STREAM=1`
- Utilizare resurse: monitoare OS (Task Manager, Activity Monitor, `nvidia-smi`) + `foundry system info`.

Pe mÄƒsurÄƒ ce noi comenzi CLI de telemetrie se stabilizeazÄƒ, acestea pot fi integrate cu modificÄƒri minime Ã®n markdown-urile sesiunilor.

### Lint Automatizat

Un linter automat previne reintroducerea pattern-urilor CLI depreciate Ã®n interiorul blocurilor de cod din fiÈ™ierele markdown:

Script: `Workshop/scripts/lint_markdown_cli.py`

Pattern-urile depreciate sunt blocate Ã®n interiorul blocurilor de cod.

Ãnlocuiri recomandate:
| Depreciat | Ãnlocuire |
|-----------|-----------|
| `foundry model chat <a> "..."` | `foundry model run <a> --prompt "..."` |
| `model list --running` | `model list` |
| `model list --cached` | `cache list` |
| `model stats` | Script de benchmark + unelte de sistem |
| `model benchmark` | `samples/session03/benchmark_oss_models.py` |
| `model list --available` | `model list` |

RuleazÄƒ local:
```powershell
python Workshop\scripts\lint_markdown_cli.py --verbose
```

GitHub Action: `.github/workflows/markdown-cli-lint.yml` ruleazÄƒ la fiecare push & PR.

Hook opÈ›ional pre-commit:
```bash
echo "python Workshop/scripts/lint_markdown_cli.py" > .git/hooks/pre-commit
chmod +x .git/hooks/pre-commit
```

## Tabel Rapid Migrare CLI â†’ SDK

| SarcinÄƒ | CLI One-Liner | Echivalent SDK (Python) | Note |
|--------|---------------|-------------------------|------|
| RuleazÄƒ un model o datÄƒ (prompt) | `foundry model run phi-4-mini --prompt "Hello"` | `manager=FoundryLocalManager("phi-4-mini"); client=OpenAI(base_url=manager.endpoint, api_key=manager.api_key or "not-needed"); client.chat.completions.create(model=manager.get_model_info("phi-4-mini").id, messages=[{"role":"user","content":"Hello"}])` | SDK iniÈ›ializeazÄƒ automat serviciul & cache-ul |
| DescarcÄƒ (cache) model | `foundry model download qwen2.5-0.5b` | `FoundryLocalManager("qwen2.5-0.5b")  # triggers download/load` | Managerul alege cea mai bunÄƒ variantÄƒ dacÄƒ aliasul se mapazÄƒ la mai multe versiuni |
| ListeazÄƒ catalogul | `foundry model list` | `# folosiÈ›i managerul pentru fiecare alias sau menÈ›ineÈ›i o listÄƒ cunoscutÄƒ` | CLI agregÄƒ; SDK Ã®n prezent instanÈ›iere per-alias |
| ListeazÄƒ modelele cache-uite | `foundry cache list` | `manager.list_cached_models()` | DupÄƒ iniÈ›ializarea managerului (orice alias) |
| ActiveazÄƒ accelerarea GPU | `foundry config set compute.onnx.enable_gpu true` | `# AcÈ›iune CLI; SDK presupune cÄƒ configuraÈ›ia este deja aplicatÄƒ` | ConfiguraÈ›ia este un efect extern |
| ObÈ›ine URL-ul endpoint-ului | (implicit) | `manager.endpoint` | Utilizat pentru a crea un client compatibil OpenAI |
| ÃncÄƒlzeÈ™te un model | `foundry model run <alias>` apoi primul prompt | `chat_once(alias, messages=[...])` (utilitar) | Utilitarele gestioneazÄƒ iniÈ›ializarea latenÈ›ei reci |
| MÄƒsoarÄƒ latenÈ›a | `python benchmark_oss_models.py` | `import benchmark_oss_models` (sau un nou script de export) | PreferÄƒ scriptul pentru metrici consistente |
| OpreÈ™te / dezÃ®ncarcÄƒ modelul | `foundry model unload <alias>` | (Nu este expus â€“ reporniÈ›i serviciul / procesul) | De obicei, nu este necesar pentru fluxul workshop-ului |
| RecupereazÄƒ utilizarea tokenilor | (vizualizaÈ›i output-ul) | `resp.usage.total_tokens` | Furnizat dacÄƒ backend-ul returneazÄƒ obiectul de utilizare |

## Export Markdown Benchmark

UtilizaÈ›i scriptul `Workshop/scripts/export_benchmark_markdown.py` pentru a rula un benchmark proaspÄƒt (aceeaÈ™i logicÄƒ ca `samples/session03/benchmark_oss_models.py`) È™i pentru a genera un tabel Markdown prietenos cu GitHub plus JSON brut.

### Exemplu

```powershell
python Workshop\scripts\export_benchmark_markdown.py --models "qwen2.5-0.5b,gemma-2-2b,mistral-7b" --prompt "Explain retrieval augmented generation briefly." --rounds 3 --output benchmark_report.md
```

FiÈ™iere generate:
| FiÈ™ier | ConÈ›inut |
|--------|----------|
| `benchmark_report.md` | Tabel Markdown + indicaÈ›ii de interpretare |
| `benchmark_report.json` | Array de metrici brute (pentru comparare / urmÄƒrirea tendinÈ›elor) |

SetaÈ›i `BENCH_STREAM=1` Ã®n mediu pentru a include latenÈ›a primului token, dacÄƒ este suportatÄƒ.

---

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). DeÈ™i ne strÄƒduim sÄƒ asigurÄƒm acurateÈ›ea, vÄƒ rugÄƒm sÄƒ fiÈ›i conÈ™tienÈ›i cÄƒ traducerile automate pot conÈ›ine erori sau inexactitÄƒÈ›i. Documentul original Ã®n limba sa maternÄƒ ar trebui considerat sursa autoritarÄƒ. Pentru informaÈ›ii critice, se recomandÄƒ traducerea profesionalÄƒ realizatÄƒ de un specialist uman. Nu ne asumÄƒm responsabilitatea pentru eventualele neÃ®nÈ›elegeri sau interpretÄƒri greÈ™ite care pot apÄƒrea din utilizarea acestei traduceri.