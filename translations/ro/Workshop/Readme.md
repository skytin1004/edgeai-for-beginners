<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "48d0fb38be925084a6ebd957d4b045e5",
  "translation_date": "2025-10-08T15:22:58+00:00",
  "source_file": "Workshop/Readme.md",
  "language_code": "ro"
}
-->
# EdgeAI pentru ÃncepÄƒtori - Atelier

> **Cale de Ã®nvÄƒÈ›are practicÄƒ pentru construirea aplicaÈ›iilor Edge AI gata de producÈ›ie**
>
> StÄƒpÃ¢neÈ™te implementarea AI localÄƒ cu Microsoft Foundry Local, de la prima completare de chat la orchestrarea multi-agent Ã®n 6 sesiuni progresive.

---

## ğŸ¯ Introducere

Bine aÈ›i venit la **Atelierul EdgeAI pentru ÃncepÄƒtori** - ghidul dumneavoastrÄƒ practic pentru a construi aplicaÈ›ii inteligente care ruleazÄƒ complet pe hardware local. Acest atelier transformÄƒ conceptele teoretice ale Edge AI Ã®n abilitÄƒÈ›i practice prin exerciÈ›ii progresive folosind Microsoft Foundry Local È™i Small Language Models (SLMs).

### De ce acest atelier?

**RevoluÈ›ia Edge AI este aici**

OrganizaÈ›iile din Ã®ntreaga lume trec de la AI dependent de cloud la calculul la margine (edge computing) din trei motive critice:

1. **ConfidenÈ›ialitate & Conformitate** - Procesarea datelor sensibile local, fÄƒrÄƒ transmiterea lor Ã®n cloud (HIPAA, GDPR, reglementÄƒri financiare)
2. **PerformanÈ›Äƒ** - Eliminarea latenÈ›ei reÈ›elei (50-500ms local vs 500-2000ms tur-retur Ã®n cloud)
3. **Controlul costurilor** - Eliminarea costurilor per token ale API-urilor È™i scalarea fÄƒrÄƒ cheltuieli de cloud

**Dar Edge AI este diferit**

Rularea AI-ului local necesitÄƒ abilitÄƒÈ›i noi:
- Selectarea È™i optimizarea modelelor pentru constrÃ¢ngeri de resurse
- Gestionarea serviciilor locale È™i accelerarea hardware-ului
- Ingineria prompturilor pentru modele mai mici
- Modele de implementare Ã®n producÈ›ie pentru dispozitive edge

**Acest atelier vÄƒ oferÄƒ aceste abilitÄƒÈ›i**

Ãn 6 sesiuni concentrate (~3 ore Ã®n total), veÈ›i progresa de la "Hello World" la implementarea sistemelor multi-agent gata de producÈ›ie - toate rulÃ¢nd local pe maÈ™ina dumneavoastrÄƒ.

---

## ğŸ“š Obiectivele de Ã®nvÄƒÈ›are

Prin completarea acestui atelier, veÈ›i putea:

### CompetenÈ›e de bazÄƒ
1. **ImplementaÈ›i È™i gestionaÈ›i servicii AI locale**
   - InstalaÈ›i È™i configuraÈ›i Microsoft Foundry Local
   - SelectaÈ›i modelele potrivite pentru implementarea la margine
   - GestionaÈ›i ciclul de viaÈ›Äƒ al modelului (descÄƒrcare, Ã®ncÄƒrcare, cache)
   - MonitorizaÈ›i utilizarea resurselor È™i optimizaÈ›i performanÈ›a

2. **ConstruiÈ›i aplicaÈ›ii alimentate de AI**
   - ImplementaÈ›i completÄƒri de chat compatibile cu OpenAI local
   - ProiectaÈ›i prompturi eficiente pentru Small Language Models
   - GestionaÈ›i rÄƒspunsurile Ã®n flux pentru o experienÈ›Äƒ mai bunÄƒ a utilizatorului
   - IntegraÈ›i modelele locale Ã®n aplicaÈ›iile existente

3. **CreaÈ›i sisteme RAG (Retrieval Augmented Generation)**
   - ConstruiÈ›i cÄƒutÄƒri semantice cu embeddings
   - FundamentaÈ›i rÄƒspunsurile LLM Ã®n cunoÈ™tinÈ›e specifice domeniului
   - EvaluaÈ›i calitatea RAG cu metrici standard din industrie
   - ScalaÈ›i de la prototip la producÈ›ie

4. **OptimizaÈ›i performanÈ›a modelului**
   - EvaluaÈ›i mai multe modele pentru cazul dumneavoastrÄƒ de utilizare
   - MÄƒsuraÈ›i latenÈ›a, debitul È™i timpul primului token
   - SelectaÈ›i modelele optime pe baza compromisurilor vitezÄƒ/calitate
   - ComparaÈ›i compromisurile SLM vs LLM Ã®n scenarii reale

5. **OrchestraÈ›i sisteme multi-agent**
   - ProiectaÈ›i agenÈ›i specializaÈ›i pentru diferite sarcini
   - ImplementaÈ›i memoria agenÈ›ilor È™i gestionarea contextului
   - CoordonaÈ›i agenÈ›ii Ã®n fluxuri de lucru complexe
   - DirecÈ›ionaÈ›i cererile inteligent Ã®ntre mai multe modele

6. **ImplementaÈ›i soluÈ›ii gata de producÈ›ie**
   - ImplementaÈ›i gestionarea erorilor È™i logica de retry
   - MonitorizaÈ›i utilizarea token-urilor È™i resursele sistemului
   - ConstruiÈ›i arhitecturi scalabile cu modele ca instrumente
   - PlanificaÈ›i cÄƒile de migrare de la margine la hibrid (margine + cloud)

---

## ğŸ“ Rezultatele Ã®nvÄƒÈ›Äƒrii

### Ce veÈ›i construi

PÃ¢nÄƒ la finalul acestui atelier, veÈ›i fi creat:

| Sesiune | Rezultat | AbilitÄƒÈ›i demonstrate |
|---------|----------|------------------------|
| **1** | AplicaÈ›ie de chat cu streaming | Configurare serviciu, completÄƒri de bazÄƒ, UX streaming |
| **2** | Sistem RAG cu evaluare | Embeddings, cÄƒutare semanticÄƒ, metrici de calitate |
| **3** | SuitÄƒ de benchmark multi-model | MÄƒsurarea performanÈ›ei, compararea modelelor |
| **4** | Comparator SLM vs LLM | Analiza compromisurilor, strategii de optimizare |
| **5** | Orchestrator multi-agent | Proiectare agenÈ›i, gestionarea memoriei, coordonare |
| **6** | Sistem de rutare inteligentÄƒ | Detectarea intenÈ›iei, selecÈ›ia modelului, scalabilitate |

### Matricea competenÈ›elor

| Nivel de abilitÄƒÈ›i | Sesiunea 1-2 | Sesiunea 3-4 | Sesiunea 5-6 |
|---------------------|--------------|--------------|--------------|
| **ÃncepÄƒtor** | âœ… Configurare & bazÄƒ | âš ï¸ Provocator | âŒ Prea avansat |
| **Intermediar** | âœ… Revizuire rapidÄƒ | âœ… ÃnvÄƒÈ›are de bazÄƒ | âš ï¸ Obiective avansate |
| **Avansat** | âœ… UÈ™or de parcurs | âœ… PerfecÈ›ionare | âœ… Modele de producÈ›ie |

### AbilitÄƒÈ›i pentru carierÄƒ

**DupÄƒ acest atelier, veÈ›i fi pregÄƒtit sÄƒ:**

âœ… **ConstruiÈ›i aplicaÈ›ii orientate pe confidenÈ›ialitate**
- AplicaÈ›ii de sÄƒnÄƒtate care gestioneazÄƒ PHI/PII local
- Servicii financiare cu cerinÈ›e de conformitate
- Sisteme guvernamentale cu cerinÈ›e de suveranitate a datelor

âœ… **OptimizaÈ›i pentru medii Edge**
- Dispozitive IoT cu resurse limitate
- AplicaÈ›ii mobile offline-first
- Sisteme Ã®n timp real cu latenÈ›Äƒ scÄƒzutÄƒ

âœ… **ProiectaÈ›i arhitecturi inteligente**
- Sisteme multi-agent pentru fluxuri de lucru complexe
- ImplementÄƒri hibride margine-cloud
- InfrastructurÄƒ AI optimizatÄƒ pentru costuri

âœ… **ConduceÈ›i iniÈ›iative Edge AI**
- EvaluaÈ›i fezabilitatea Edge AI pentru proiecte
- SelectaÈ›i modelele È™i cadrele potrivite
- ArhitecturaÈ›i soluÈ›ii AI locale scalabile

---

## ğŸ—ºï¸ Structura atelierului

### Prezentare generalÄƒ a sesiunilor (6 sesiuni Ã— 30 minute = 3 ore)

| Sesiune | Subiect | Focus | DuratÄƒ |
|---------|---------|-------|--------|
| **1** | ÃncepeÈ›i cu Foundry Local | Instalare, validare, primele completÄƒri | 30 min |
| **2** | Construirea soluÈ›iilor AI cu RAG | Ingineria prompturilor, embeddings, evaluare | 30 min |
| **3** | Modele Open Source | Descoperirea modelelor, benchmarking, selecÈ›ie | 30 min |
| **4** | Modele de ultimÄƒ generaÈ›ie | SLM vs LLM, optimizare, cadre | 30 min |
| **5** | AgenÈ›i alimentaÈ›i de AI | Proiectare agenÈ›i, orchestrare, memorie | 30 min |
| **6** | Modele ca instrumente | Rutare, lanÈ›uri, strategii de scalare | 30 min |

---

## ğŸš€ Ãnceput rapid

### CerinÈ›e preliminare

**CerinÈ›e de sistem:**
- **OS**: Windows 10/11, macOS 11+ sau Linux (Ubuntu 20.04+)
- **RAM**: minim 8GB, recomandat 16GB+
- **SpaÈ›iu de stocare**: minim 10GB liber pentru modele
- **CPU**: Procesor modern cu suport AVX2
- **GPU** (opÈ›ional): Compatibil CUDA sau Qualcomm NPU pentru accelerare

**CerinÈ›e software:**
- **Python 3.8+** ([DescarcÄƒ](https://www.python.org/downloads/))
- **Microsoft Foundry Local** ([Ghid de instalare](../../../Workshop))
- **Git** ([DescarcÄƒ](https://git-scm.com/downloads))
- **Visual Studio Code** (recomandat) ([DescarcÄƒ](https://code.visualstudio.com/))

### Configurare Ã®n 3 paÈ™i

#### 1. InstalaÈ›i Foundry Local

**Windows:**
```powershell
winget install Microsoft.FoundryLocal
```

**macOS:**
```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

**VerificaÈ›i instalarea:**
```bash
foundry --version
foundry service status
```

#### 2. ClonaÈ›i Repozitoriul & InstalaÈ›i DependenÈ›ele

```bash
# Clone repository
git clone https://github.com/microsoft/edgeai-for-beginners.git
cd edgeai-for-beginners/Workshop

# Create virtual environment
python -m venv .venv

# Activate virtual environment
# Windows:
.\.venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

#### 3. RulaÈ›i primul exemplu

```bash
# Start Foundry Local and load a model
foundry model run phi-4-mini

# Run the chat bootstrap sample
cd samples/session01
python chat_bootstrap.py "What is edge AI?"
```

**âœ… Succes!** Ar trebui sÄƒ vedeÈ›i un rÄƒspuns Ã®n flux despre Edge AI.

---

## ğŸ“¦ Resursele atelierului

### Exemple Python

Exemple practice progresive care demonstreazÄƒ fiecare concept:

| Sesiune | Exemplu | Descriere | Timp de rulare |
|---------|---------|-----------|----------------|
| 1 | [`chat_bootstrap.py`](../../../Workshop/samples/session01/chat_bootstrap.py) | Chat de bazÄƒ & streaming | ~30s |
| 2 | [`rag_pipeline.py`](../../../Workshop/samples/session02/rag_pipeline.py) | RAG cu embeddings | ~45s |
| 2 | [`rag_eval_ragas.py`](../../../Workshop/samples/session02/rag_eval_ragas.py) | Evaluarea calitÄƒÈ›ii RAG | ~60s |
| 3 | [`benchmark_oss_models.py`](../../../Workshop/samples/session03/benchmark_oss_models.py) | Benchmarking multi-model | ~2-3m |
| 4 | [`model_compare.py`](../../../Workshop/samples/session04/model_compare.py) | ComparaÈ›ie SLM vs LLM | ~45s |
| 5 | [`agents_orchestrator.py`](../../../Workshop/samples/session05/agents_orchestrator.py) | Sistem multi-agent | ~60s |
| 6 | [`models_router.py`](../../../Workshop/samples/session06/models_router.py) | Rutare bazatÄƒ pe intenÈ›ie | ~45s |
| 6 | [`models_pipeline.py`](../../../Workshop/samples/session06/models_pipeline.py) | Orchestrare pipeline multi-pas | ~60s |

### Jupyter Notebooks

Explorare interactivÄƒ cu explicaÈ›ii È™i vizualizÄƒri:

| Sesiune | Notebook | Descriere | Dificultate |
|---------|----------|-----------|-------------|
| 1 | [`session01_chat_bootstrap.ipynb`](./notebooks/session01_chat_bootstrap.ipynb) | Bazele chat-ului & streaming | â­ ÃncepÄƒtor |
| 2 | [`session02_rag_pipeline.ipynb`](./notebooks/session02_rag_pipeline.ipynb) | Construirea unui sistem RAG | â­â­ Intermediar |
| 2 | [`session02_rag_eval_ragas.ipynb`](./notebooks/session02_rag_eval_ragas.ipynb) | Evaluarea calitÄƒÈ›ii RAG | â­â­ Intermediar |
| 3 | [`session03_benchmark_oss_models.ipynb`](./notebooks/session03_benchmark_oss_models.ipynb) | Benchmarking modele | â­â­ Intermediar |
| 4 | [`session04_model_compare.ipynb`](./notebooks/session04_model_compare.ipynb) | ComparaÈ›ie modele | â­â­ Intermediar |
| 5 | [`session05_agents_orchestrator.ipynb`](./notebooks/session05_agents_orchestrator.ipynb) | Orchestrarea agenÈ›ilor | â­â­â­ Avansat |
| 6 | [`session06_models_router.ipynb`](./notebooks/session06_models_router.ipynb) | Rutare pe baza intenÈ›iei | â­â­â­ Avansat |
| 6 | [`session06_models_pipeline.ipynb`](./notebooks/session06_models_pipeline.ipynb) | Orchestrare pipeline | â­â­â­ Avansat |

### DocumentaÈ›ie

Ghiduri È™i referinÈ›e complete:

| Document | Descriere | CÃ¢nd sÄƒ-l folosiÈ›i |
|----------|-----------|--------------------|
| [QUICK_START.md](./QUICK_START.md) | Ghid rapid de configurare | La Ã®nceput |
| [QUICK_REFERENCE.md](./QUICK_REFERENCE.md) | FiÈ™Äƒ de referinÈ›Äƒ pentru comenzi & API | CÃ¢nd aveÈ›i nevoie de rÄƒspunsuri rapide |
| [FOUNDRY_SDK_QUICKREF.md](./FOUNDRY_SDK_QUICKREF.md) | Modele È™i exemple SDK | Scrierea codului |
| [ENV_CONFIGURATION.md](./ENV_CONFIGURATION.md) | Ghid pentru variabilele de mediu | Configurarea exemplelor |
| [SAMPLES_UPDATE_SUMMARY.md](./SAMPLES_UPDATE_SUMMARY.md) | ÃmbunÄƒtÄƒÈ›iri recente ale exemplelor | ÃnÈ›elegerea schimbÄƒrilor |
| [SDK_MIGRATION_NOTES.md](./SDK_MIGRATION_NOTES.md) | Ghid de migrare | Actualizarea codului |
| [notebooks/TROUBLESHOOTING.md](./notebooks/TROUBLESHOOTING.md) | Probleme comune & soluÈ›ii | Depanarea problemelor |

---

## ğŸ“ RecomandÄƒri pentru calea de Ã®nvÄƒÈ›are

### Pentru ÃncepÄƒtori (3-4 ore)
1. âœ… Sesiunea 1: ÃncepeÈ›i (focus pe configurare È™i chat de bazÄƒ)
2. âœ… Sesiunea 2: Bazele RAG (sÄƒriÈ›i peste evaluare iniÈ›ial)
3. âœ… Sesiunea 3: Benchmarking simplu (doar 2 modele)
4. â­ï¸ SÄƒriÈ›i peste sesiunile 4-6 pentru moment
5. ğŸ”„ Revenire la sesiunile 4-6 dupÄƒ construirea primei aplicaÈ›ii

### Pentru Dezvoltatori Intermediari (3 ore)
1. âš¡ Sesiunea 1: Validare rapidÄƒ a configurÄƒrii
2. âœ… Sesiunea 2: FinalizaÈ›i pipeline-ul RAG cu evaluare
3. âœ… Sesiunea 3: SuitÄƒ completÄƒ de benchmarking
4. âœ… Sesiunea 4: Optimizarea modelului
5. âœ… Sesiunile 5-6: Focus pe modelele arhitecturale

### Pentru Practicieni AvansaÈ›i (2-3 ore)
1. âš¡ Sesiunile 1-3: Revizuire È™i validare rapidÄƒ
2. âœ… Sesiunea 4: Detalii despre optimizare
3. âœ… Sesiunea 5: ArhitecturÄƒ multi-agent
4. âœ… Sesiunea 6: Modele de producÈ›ie È™i scalare
5. ğŸš€ Extindere: ConstruiÈ›i logica personalizatÄƒ de rutare È™i implementÄƒri hibride

---

## Pachetul de sesiuni ale atelierului (Laboratoare concentrate de 30 de minute)

DacÄƒ urmaÈ›i formatul condensat al atelierului de 6 sesiuni, utilizaÈ›i aceste ghiduri dedicate (fiecare se coreleazÄƒ È™i completeazÄƒ documentaÈ›ia mai amplÄƒ de mai sus):

| Sesiunea atelierului | Ghid | Focus principal |
|----------------------|------|-----------------|
| 1 | [Session01-GettingStartedFoundryLocal](./Session01-GettingStartedFoundryLocal.md) | Instalare, validare, rulare phi & GPT-OSS-20B, accelerare |
| 2 | [Session02-BuildAISolutionsRAG](./Session02-BuildAISolutionsRAG.md) | Ingineria prompturilor, modele RAG, fundamentare CSV & documente, migrare |
| 3 | [Session03-OpenSourceModels](./Session03-OpenSourceModels.md) | Integrare Hugging Face, benchmarking, selecÈ›ia modelelor |
| 4 | [Session04-CuttingEdgeModels](./Session04-CuttingEdgeModels.md) | SLM vs LLM, WebGPU, Chainlit RAG, accelerare ONNX |
| 5 | [Session05-AIPoweredAgents](./Session05-AIPoweredAgents.md) | Roluri agenÈ›i, memorie, instrumente, orchestrare |
| 6 | [Session06-ModelsAsTools](./Session06-ModelsAsTools.md) | Rutare, lanÈ›uri, strategii de scalare cÄƒtre Azure |
Fiecare fiÈ™ier de sesiune include: rezumat, obiective de Ã®nvÄƒÈ›are, flux demo de 30 de minute, proiect de Ã®nceput, listÄƒ de verificare pentru validare, depanare È™i referinÈ›e la SDK-ul oficial Foundry Local Python.

### Scripturi Exemplu

Instalare dependenÈ›e pentru workshop (Windows):

```powershell
cd Workshop
py -m venv .venv
.\.venv\Scripts\activate
pip install -r requirements.txt
```

macOS / Linux:

```bash
cd Workshop
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

DacÄƒ serviciul Foundry Local ruleazÄƒ pe o altÄƒ maÈ™inÄƒ (Windows) sau VM de pe macOS, exportaÈ›i endpoint-ul:

```bash
export FOUNDRY_LOCAL_ENDPOINT=http://<windows-host>:5273/v1
```

| Sesiune | Script(uri) | Descriere |
|---------|-------------|-----------|
| 1 | `samples/session01/chat_bootstrap.py` | Bootstrap service & streaming chat |
| 2 | `samples/session02/rag_pipeline.py` | RAG minimal (embedding-uri Ã®n memorie) |
|   | `samples/session02/rag_eval_ragas.py` | Evaluare RAG cu metrici ragas |
| 3 | `samples/session03/benchmark_oss_models.py` | Benchmarking multi-model pentru latenÈ›Äƒ È™i debit |
| 4 | `samples/session04/model_compare.py` | ComparaÈ›ie SLM vs LLM (latenÈ›Äƒ & ieÈ™ire exemplu) |
| 5 | `samples/session05/agents_orchestrator.py` | Pipeline de cercetare cu doi agenÈ›i â†’ editorial |
| 6 | `samples/session06/models_router.py` | Demo de rutare bazatÄƒ pe intenÈ›ie |
|   | `samples/session06/models_pipeline.py` | LanÈ› multi-pas planificare/executare/perfecÈ›ionare |

### Variabile de Mediu (Comune pentru Exemple)

| VariabilÄƒ | Scop | Exemplu |
|-----------|------|---------|
| `FOUNDRY_LOCAL_ALIAS` | Alias implicit pentru un singur model Ã®n exemplele de bazÄƒ | `phi-4-mini` |
| `SLM_ALIAS` / `LLM_ALIAS` | SLM explicit vs model mai mare pentru comparaÈ›ie | `phi-4-mini` / `gpt-oss-20b` |
| `BENCH_MODELS` | ListÄƒ de aliasuri pentru benchmark | `qwen2.5-0.5b,gemma-2-2b,mistral-7b` |
| `BENCH_ROUNDS` | RepetiÈ›ii benchmark per model | `3` |
| `BENCH_PROMPT` | Prompt utilizat Ã®n benchmark | `Explain retrieval augmented generation briefly.` |
| `EMBED_MODEL` | Model de embedding pentru sentence-transformers | `sentence-transformers/all-MiniLM-L6-v2` |
| `RAG_QUESTION` | Suprascriere query test pentru pipeline-ul RAG | `Why use RAG with local inference?` |
| `AGENT_QUESTION` | Suprascriere query pentru pipeline-ul agenÈ›ilor | `Explain why edge AI matters for compliance.` |
| `AGENT_MODEL_PRIMARY` | Alias model pentru agentul de cercetare | `phi-4-mini` |
| `AGENT_MODEL_EDITOR` | Alias model pentru agentul editor (poate fi diferit) | `gpt-oss-20b` |
| `SHOW_USAGE` | CÃ¢nd este `1`, afiÈ™eazÄƒ utilizarea token-urilor per completare | `1` |
| `RETRY_ON_FAIL` | CÃ¢nd este `1`, reÃ®ncearcÄƒ o datÄƒ Ã®n caz de erori temporare de chat | `1` |
| `RETRY_BACKOFF` | Secunde de aÈ™teptare Ã®nainte de reÃ®ncercare | `1.0` |

DacÄƒ o variabilÄƒ nu este setatÄƒ, scripturile vor folosi valori implicite rezonabile. Pentru demo-urile cu un singur model, de obicei aveÈ›i nevoie doar de `FOUNDRY_LOCAL_ALIAS`.

### Modul Utilitar

Toate exemplele Ã®mpÄƒrtÄƒÈ™esc acum un helper `samples/workshop_utils.py` care oferÄƒ:

* Crearea cache-ului pentru `FoundryLocalManager` + client OpenAI
* Helper `chat_once()` cu retry opÈ›ional + afiÈ™are utilizare
* Raportare simplÄƒ a utilizÄƒrii token-urilor (activatÄƒ prin `SHOW_USAGE=1`)

Acest lucru reduce duplicarea È™i evidenÈ›iazÄƒ cele mai bune practici pentru orchestrarea eficientÄƒ a modelelor locale.

## ÃmbunÄƒtÄƒÈ›iri OpÈ›ionale (Ãntre Sesiuni)

| TemÄƒ | ÃmbunÄƒtÄƒÈ›ire | Sesiuni | Env / Toggle |
|------|--------------|---------|--------------|
| Determinism | TemperaturÄƒ fixÄƒ + seturi de prompt stabile | 1â€“6 | SeteazÄƒ `temperature=0`, `top_p=1` |
| Vizibilitate Utilizare Token-uri | Predare consistentÄƒ a costului/eficienÈ›ei | 1â€“6 | `SHOW_USAGE=1` |
| Streaming Primul Token | MetricÄƒ de latenÈ›Äƒ perceputÄƒ | 1,3,4,6 | `BENCH_STREAM=1` (benchmark) |
| RezilienÈ›Äƒ la Retry | GestioneazÄƒ pornirea lentÄƒ temporarÄƒ | Toate | `RETRY_ON_FAIL=1` + `RETRY_BACKOFF` |
| AgenÈ›i Multi-Model | Specializare pe roluri eterogene | 5 | `AGENT_MODEL_PRIMARY`, `AGENT_MODEL_EDITOR` |
| Rutare AdaptivÄƒ | IntenÈ›ie + euristici de cost | 6 | Extinde router-ul cu logicÄƒ de escaladare |
| Memorie VectorialÄƒ | Rechemare semanticÄƒ pe termen lung | 2,5,6 | IntegreazÄƒ index embedding FAISS/Chroma |
| Export Traseu | Auditare & evaluare | 2,5,6 | AdaugÄƒ linii JSON per pas |
| Rubrici de Calitate | UrmÄƒrire calitativÄƒ | 3â€“6 | Prompts secundare pentru scorare |
| Teste Smoke | Validare rapidÄƒ pre-workshop | Toate | `python Workshop/tests/smoke.py` |

### Start Rapid Determinist

```powershell
set FOUNDRY_LOCAL_ALIAS=phi-4-mini
set SHOW_USAGE=1
python Workshop\tests\smoke.py
```

AÈ™teptaÈ›i numÄƒr stabil de token-uri pentru intrÄƒri identice repetate.

### Evaluare RAG (Sesiunea 2)

UtilizaÈ›i `rag_eval_ragas.py` pentru a calcula relevanÈ›a rÄƒspunsului, fidelitatea È™i precizia contextului pe un set de date sintetic mic:

```powershell
python samples/session02/rag_eval_ragas.py
```

ExtindeÈ›i furnizÃ¢nd un JSONL mai mare cu Ã®ntrebÄƒri, contexte È™i adevÄƒruri de bazÄƒ, apoi convertiÈ›i-l Ã®ntr-un `Dataset` Hugging Face.

## AnexÄƒ Comenzi CLI Precise

Workshop-ul foloseÈ™te deliberat doar comenzi CLI Foundry Local documentate / stabile.

### Comenzi Stabile Referite

| Categorie | ComandÄƒ | Scop |
|-----------|---------|------|
| BazÄƒ | `foundry --version` | AfiÈ™eazÄƒ versiunea instalatÄƒ |
| BazÄƒ | `foundry init` | IniÈ›ializeazÄƒ configuraÈ›ia |
| Serviciu | `foundry service start` | PorneÈ™te serviciul local (dacÄƒ nu este auto) |
| Serviciu | `foundry status` | AfiÈ™eazÄƒ statusul serviciului |
| Modele | `foundry model list` | ListeazÄƒ catalogul / modelele disponibile |
| Modele | `foundry model download <alias>` | DescarcÄƒ greutÄƒÈ›ile modelului Ã®n cache |
| Modele | `foundry model run <alias>` | RuleazÄƒ (Ã®ncarcÄƒ) un model local; combinÄƒ cu `--prompt` pentru one-shot |
| Modele | `foundry model unload <alias>` / `foundry model stop <alias>` | DezÃ®ncarcÄƒ un model din memorie (dacÄƒ este suportat) |
| Cache | `foundry cache list` | ListeazÄƒ modelele cache-uite (descÄƒrcate) |
| Sistem | `foundry system info` | Snapshot capabilitÄƒÈ›i hardware & accelerare |
| Sistem | `foundry system gpu-info` | Info diagnostic GPU |
| Config | `foundry config list` | AfiÈ™eazÄƒ valorile de configurare curente |
| Config | `foundry config set <key> <value>` | ActualizeazÄƒ configuraÈ›ia |

### Model Oneâ€‘Shot Prompt

Ãn loc de subcomanda `model chat` depreciatÄƒ, utilizaÈ›i:

```powershell
foundry model run <alias> --prompt "Your question here"
```

Aceasta executÄƒ un ciclu prompt/rÄƒspuns unic È™i apoi se Ã®nchide.

### Modele Depreciate / Evitate

| Depreciat / Nedocumentat | Ãnlocuire / Ghidare |
|--------------------------|---------------------|
| `foundry model chat <model> "..."` | `foundry model run <model> --prompt "..."` |
| `foundry model list --running` | UtilizaÈ›i `foundry model list` simplu + activitate recentÄƒ / loguri |
| `foundry model list --cached` | `foundry cache list` |
| `foundry model stats <model>` | UtilizaÈ›i scriptul benchmark Python + unelte OS (Task Manager / `nvidia-smi`) |
| `foundry model benchmark ...` | `samples/session03/benchmark_oss_models.py` |

### Benchmarking & Telemetrie

- LatenÈ›Äƒ, p95, tokens/sec: `samples/session03/benchmark_oss_models.py`
- LatenÈ›Äƒ primul token (streaming): setaÈ›i `BENCH_STREAM=1`
- Utilizare resurse: monitoare OS (Task Manager, Activity Monitor, `nvidia-smi`) + `foundry system info`.

Pe mÄƒsurÄƒ ce noi comenzi CLI de telemetrie se stabilizeazÄƒ, acestea pot fi integrate cu modificÄƒri minime Ã®n markdown-urile sesiunilor.

### Lint Automatizat

Un linter automat previne reintroducerea modelelor CLI depreciate Ã®n interiorul blocurilor de cod din fiÈ™ierele markdown:

Script: `Workshop/scripts/lint_markdown_cli.py`

Modelele depreciate sunt blocate Ã®n interiorul blocurilor de cod.

Ãnlocuiri recomandate:
| Depreciat | Ãnlocuire |
|-----------|-----------|
| `foundry model chat <a> "..."` | `foundry model run <a> --prompt "..."` |
| `model list --running` | `model list` |
| `model list --cached` | `cache list` |
| `model stats` | Script benchmark + unelte sistem |
| `model benchmark` | `samples/session03/benchmark_oss_models.py` |
| `model list --available` | `model list` |

RulaÈ›i local:
```powershell
python Workshop\scripts\lint_markdown_cli.py --verbose
```

GitHub Action: `.github/workflows/markdown-cli-lint.yml` ruleazÄƒ la fiecare push & PR.

Hook opÈ›ional pre-commit:
```bash
echo "python Workshop/scripts/lint_markdown_cli.py" > .git/hooks/pre-commit
chmod +x .git/hooks/pre-commit
```

## Tabel Rapid Migrare CLI â†’ SDK

| SarcinÄƒ | Linie CLI | Echivalent SDK (Python) | Note |
|---------|-----------|--------------------------|------|
| RuleazÄƒ un model o datÄƒ (prompt) | `foundry model run phi-4-mini --prompt "Hello"` | `manager=FoundryLocalManager("phi-4-mini"); client=OpenAI(base_url=manager.endpoint, api_key=manager.api_key or "not-needed"); client.chat.completions.create(model=manager.get_model_info("phi-4-mini").id, messages=[{"role":"user","content":"Hello"}])` | SDK iniÈ›ializeazÄƒ automat serviciul & cache-ul |
| DescarcÄƒ (cache) model | `foundry model download qwen2.5-0.5b` | `FoundryLocalManager("qwen2.5-0.5b")  # declanÈ™eazÄƒ descÄƒrcare/Ã®ncÄƒrcare` | Managerul alege cea mai bunÄƒ variantÄƒ dacÄƒ aliasul corespunde mai multor versiuni |
| ListeazÄƒ catalogul | `foundry model list` | `# folosiÈ›i manager pentru fiecare alias sau menÈ›ineÈ›i o listÄƒ cunoscutÄƒ` | CLI agregÄƒ; SDK Ã®n prezent instanÈ›iere per-alias |
| ListeazÄƒ modelele cache-uite | `foundry cache list` | `manager.list_cached_models()` | DupÄƒ iniÈ›ializarea managerului (orice alias) |
| ActiveazÄƒ accelerarea GPU | `foundry config set compute.onnx.enable_gpu true` | `# AcÈ›iune CLI; SDK presupune cÄƒ setarea este deja aplicatÄƒ` | ConfiguraÈ›ia este un efect extern |
| ObÈ›ine URL endpoint | (implicit) | `manager.endpoint` | Utilizat pentru a crea un client compatibil OpenAI |
| ÃncÄƒlzeÈ™te un model | `foundry model run <alias>` apoi primul prompt | `chat_once(alias, messages=[...])` (utilitar) | Utilitarele gestioneazÄƒ Ã®ncÄƒlzirea iniÈ›ialÄƒ a latenÈ›ei |
| MÄƒsoarÄƒ latenÈ›a | `python benchmark_oss_models.py` | `import benchmark_oss_models` (sau un nou script exportator) | PreferÄƒ scriptul pentru metrici consistente |
| OpreÈ™te / dezÃ®ncarcÄƒ modelul | `foundry model unload <alias>` | (Nu este expus â€“ reporniÈ›i serviciul / procesul) | De obicei, nu este necesar pentru fluxul workshop-ului |
| RecupereazÄƒ utilizarea token-urilor | (vizualizaÈ›i ieÈ™irea) | `resp.usage.total_tokens` | Furnizat dacÄƒ backend-ul returneazÄƒ obiectul de utilizare |

## Export Markdown Benchmark

UtilizaÈ›i scriptul `Workshop/scripts/export_benchmark_markdown.py` pentru a rula un benchmark proaspÄƒt (aceeaÈ™i logicÄƒ ca `samples/session03/benchmark_oss_models.py`) È™i pentru a genera un tabel Markdown prietenos cu GitHub plus JSON brut.

### Exemplu

```powershell
python Workshop\scripts\export_benchmark_markdown.py --models "qwen2.5-0.5b,gemma-2-2b,mistral-7b" --prompt "Explain retrieval augmented generation briefly." --rounds 3 --output benchmark_report.md
```

FiÈ™iere generate:
| FiÈ™ier | ConÈ›inut |
|--------|----------|
| `benchmark_report.md` | Tabel Markdown + sugestii de interpretare |
| `benchmark_report.json` | Array de metrici brute (pentru comparare / urmÄƒrirea tendinÈ›elor) |

SetaÈ›i `BENCH_STREAM=1` Ã®n mediu pentru a include latenÈ›a primului token, dacÄƒ este suportatÄƒ.

---

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). DeÈ™i ne strÄƒduim sÄƒ asigurÄƒm acurateÈ›ea, vÄƒ rugÄƒm sÄƒ fiÈ›i conÈ™tienÈ›i cÄƒ traducerile automate pot conÈ›ine erori sau inexactitÄƒÈ›i. Documentul original Ã®n limba sa natalÄƒ ar trebui considerat sursa autoritarÄƒ. Pentru informaÈ›ii critice, se recomandÄƒ traducerea profesionalÄƒ realizatÄƒ de un specialist. Nu ne asumÄƒm responsabilitatea pentru eventualele neÃ®nÈ›elegeri sau interpretÄƒri greÈ™ite care pot apÄƒrea din utilizarea acestei traduceri.