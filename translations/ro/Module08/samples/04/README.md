<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "562ac0eae12d808c9f45fbb77eb5c84f",
  "translation_date": "2025-09-25T01:38:32+00:00",
  "source_file": "Module08/samples/04/README.md",
  "language_code": "ro"
}
-->
# Exemplu 04: AplicaÈ›ii de Chat pentru ProducÈ›ie cu Chainlit

Un exemplu cuprinzÄƒtor care demonstreazÄƒ multiple abordÄƒri pentru construirea aplicaÈ›iilor de chat pregÄƒtite pentru producÈ›ie folosind Microsoft Foundry Local, incluzÃ¢nd interfeÈ›e web moderne, rÄƒspunsuri Ã®n flux È™i tehnologii avansate pentru browser.

## Ce este inclus

- **ðŸš€ AplicaÈ›ie de Chat Chainlit** (`app.py`): AplicaÈ›ie de chat pregÄƒtitÄƒ pentru producÈ›ie cu streaming
- **ðŸŒ Demo WebGPU** (`webgpu-demo/`): InferenÈ›Äƒ AI bazatÄƒ pe browser cu accelerare hardware
- **ðŸŽ¨ Integrare Open WebUI** (`open-webui-guide.md`): InterfaÈ›Äƒ profesionalÄƒ asemÄƒnÄƒtoare ChatGPT
- **ðŸ“š Notebook EducaÈ›ional** (`chainlit_app.ipynb`): Materiale interactive de Ã®nvÄƒÈ›are

## Start Rapid

### 1. AplicaÈ›ia de Chat Chainlit

```cmd
# Navigate to Module08 directory
cd Module08

# Start your model
foundry model run phi-4-mini

# Run Chainlit app (using port 8080 to avoid conflicts)
chainlit run samples\04\app.py -w --port 8080
```

Se deschide la: `http://localhost:8080`

### 2. Demo WebGPU Ã®n Browser

```cmd
# Navigate to WebGPU demo
cd Module08\samples\04\webgpu-demo

# Serve the demo
python -m http.server 5173
```

Se deschide la: `http://localhost:5173`

### 3. Configurare Open WebUI

```cmd
# Run Open WebUI with Docker
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

Se deschide la: `http://localhost:3000`

## Modele de ArhitecturÄƒ

### Matrice de Decizie Local vs Cloud

| Scenariu | Recomandare | Motiv |
|----------|-------------|-------|
| **Date Sensibile** | ðŸ  Local (Foundry) | Datele nu pÄƒrÄƒsesc dispozitivul |
| **RaÈ›ionament Complex** | â˜ï¸ Cloud (Azure OpenAI) | Acces la modele mai mari |
| **Chat Ã®n Timp Real** | ðŸ  Local (Foundry) | LatenÈ›Äƒ redusÄƒ, rÄƒspunsuri rapide |
| **Analiza Documentelor** | ðŸ”„ Hibrid | Local pentru extragere, cloud pentru analizÄƒ |
| **Generare de Cod** | ðŸ  Local (Foundry) | ConfidenÈ›ialitate + modele specializate |
| **Sarcini de Cercetare** | â˜ï¸ Cloud (Azure OpenAI) | NecesitÄƒ o bazÄƒ largÄƒ de cunoÈ™tinÈ›e |

### ComparaÈ›ie TehnologicÄƒ

| Tehnologie | Caz de Utilizare | Avantaje | Dezavantaje |
|------------|------------------|----------|-------------|
| **Chainlit** | Dezvoltatori Python, prototipare rapidÄƒ | Configurare uÈ™oarÄƒ, suport pentru streaming | Doar Python |
| **WebGPU** | ConfidenÈ›ialitate maximÄƒ, scenarii offline | Nativ pentru browser, fÄƒrÄƒ server necesar | Dimensiune limitatÄƒ a modelului |
| **Open WebUI** | Implementare pentru producÈ›ie, echipe | InterfaÈ›Äƒ profesionalÄƒ, gestionare utilizatori | NecesitÄƒ Docker |

## CerinÈ›e Prealabile

- **Foundry Local**: InstalatÄƒ È™i rulÃ¢nd ([Download](https://aka.ms/foundry-local-installer))
- **Python**: Versiunea 3.10+ cu mediu virtual
- **Model**: Cel puÈ›in unul Ã®ncÄƒrcat (`foundry model run phi-4-mini`)
- **Browser**: Chrome/Edge cu suport WebGPU pentru demo-uri
- **Docker**: Pentru Open WebUI (opÈ›ional)

## Instalare È™i Configurare

### 1. Configurare Mediu Python

```cmd
# Navigate to Module08 directory
cd Module08

# Create and activate virtual environment
py -m venv .venv
.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Configurare Foundry Local

```cmd
# Verify Foundry Local installation
foundry --version

# Start the service
foundry service start

# Load a model
foundry model run phi-4-mini

# Verify model is running
foundry service ps
```

## AplicaÈ›ii Exemplu

### AplicaÈ›ia de Chat Chainlit

**FuncÈ›ionalitÄƒÈ›i:**
- ðŸš€ **Streaming Ã®n Timp Real**: Token-urile apar pe mÄƒsurÄƒ ce sunt generate
- ðŸ›¡ï¸ **Gestionare RobustÄƒ a Erorilor**: Degradare È™i recuperare graÈ›ioasÄƒ
- ðŸŽ¨ **InterfaÈ›Äƒ ModernÄƒ**: InterfaÈ›Äƒ profesionalÄƒ de chat gata de utilizare
- ðŸ”§ **Configurare FlexibilÄƒ**: Variabile de mediu È™i detectare automatÄƒ
- ðŸ“± **Design Responsiv**: FuncÈ›ioneazÄƒ pe desktop È™i dispozitive mobile

**Start Rapid:**
```cmd
# Run with default settings (recommended)
chainlit run samples\04\app.py -w --port 8080

# Use specific model
set MODEL=qwen2.5-7b-instruct
chainlit run samples\04\app.py -w --port 8080

# Manual endpoint configuration
set BASE_URL=http://localhost:51211
set API_KEY=your-api-key
chainlit run samples\04\app.py -w --port 8080
```

### Demo WebGPU Ã®n Browser

**FuncÈ›ionalitÄƒÈ›i:**
- ðŸŒ **AI Nativ pentru Browser**: FÄƒrÄƒ server necesar, ruleazÄƒ complet Ã®n browser
- âš¡ **Accelerare WebGPU**: Accelerare hardware cÃ¢nd este disponibilÄƒ
- ðŸ”’ **ConfidenÈ›ialitate MaximÄƒ**: Datele nu pÄƒrÄƒsesc niciodatÄƒ dispozitivul
- ðŸŽ¯ **Zero Instalare**: FuncÈ›ioneazÄƒ Ã®n orice browser compatibil
- ðŸ”„ **Fallback GraÈ›ios**: Revine la CPU dacÄƒ WebGPU nu este disponibil

**Rulare:**
```cmd
cd samples\04\webgpu-demo
python -m http.server 5173
# Open http://localhost:5173
```

### Integrare Open WebUI

**FuncÈ›ionalitÄƒÈ›i:**
- ðŸŽ¨ **InterfaÈ›Äƒ AsemÄƒnÄƒtoare ChatGPT**: UI profesional, familiar
- ðŸ‘¥ **Suport Multi-utilizator**: Conturi de utilizator È™i istoric conversaÈ›ii
- ðŸ“ **Procesare FiÈ™iere**: ÃŽncÄƒrcare È™i analizÄƒ documente
- ðŸ”„ **Schimbare Modele**: Comutare uÈ™oarÄƒ Ã®ntre diferite modele
- ðŸ³ **Implementare Docker**: Configurare containerizatÄƒ pregÄƒtitÄƒ pentru producÈ›ie

**Configurare RapidÄƒ:**
```cmd
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

## ReferinÈ›Äƒ Configurare

### Variabile de Mediu

| VariabilÄƒ | Descriere | Implicit | Exemplu |
|-----------|-----------|----------|---------|
| `MODEL` | Alias-ul modelului utilizat | `phi-4-mini` | `qwen2.5-7b-instruct` |
| `BASE_URL` | Endpoint Foundry Local | Detectat automat | `http://localhost:51211` |
| `API_KEY` | Cheie API (opÈ›ional pentru local) | `""` | `your-api-key` |

## Depanare

### Probleme Comune

**AplicaÈ›ia Chainlit:**

1. **Serviciu indisponibil:**
   ```cmd
   # Check Foundry Local status
   foundry service status
   foundry service ps
   
   # Validate API endpoint (note: port 51211)
   curl http://localhost:51211/v1/models
   ```

2. **Conflicte de port:**
   ```cmd
   # Check what's using port 8080
   netstat -ano | findstr :8080
   
   # Use different port if needed
   chainlit run samples\04\app.py -w --port 3000
   ```

3. **Probleme cu mediul Python:**
   ```cmd
   # Verify correct interpreter in VS Code
   # Ctrl+Shift+P â†’ Python: Select Interpreter
   # Choose: Module08/.venv/Scripts/python.exe
   
   # Reinstall dependencies
   pip install -r requirements.txt
   ```

**Demo WebGPU:**

1. **WebGPU nu este suportat:**
   - ActualizaÈ›i la Chrome/Edge 113+
   - ActivaÈ›i WebGPU: `chrome://flags/#enable-unsafe-webgpu`
   - VerificaÈ›i statusul GPU: `chrome://gpu`
   - Demo-ul va reveni automat la CPU

2. **Erori la Ã®ncÄƒrcarea modelului:**
   - AsiguraÈ›i-vÄƒ cÄƒ aveÈ›i conexiune la internet pentru descÄƒrcarea modelului
   - VerificaÈ›i consola browserului pentru erori CORS
   - ConfirmaÈ›i cÄƒ serviÈ›i prin HTTP (nu file://)

**Open WebUI:**

1. **Conexiune refuzatÄƒ:**
   ```cmd
   # Check Docker is running
   docker --version
   
   # Check container status
   docker ps | findstr open-webui
   
   # View container logs
   docker logs open-webui
   ```

2. **Modelele nu apar:**
   ```cmd
   # Verify Foundry Local endpoint
   curl http://localhost:51211/v1/models
   
   # Restart Open WebUI
   docker restart open-webui
   ```

### ListÄƒ de Verificare Validare

```cmd
# âœ… 1. Foundry Local Setup
foundry --version                    # Should show version
foundry service status               # Should show "running"
foundry model list                   # Should show loaded models
curl http://localhost:51211/v1/models  # Should return JSON

# âœ… 2. Python Environment  
python --version                     # Should be 3.10+
pip list | findstr chainlit         # Should show chainlit package
pip list | findstr openai           # Should show openai package

# âœ… 3. Application Testing
chainlit run samples\04\app.py -w --port 8080  # Should open browser
# Test WebGPU demo at localhost:5173
# Test Open WebUI at localhost:3000
```

## Utilizare AvansatÄƒ

### Optimizare PerformanÈ›Äƒ

**Chainlit:**
- UtilizaÈ›i streaming pentru o performanÈ›Äƒ perceputÄƒ mai bunÄƒ
- ImplementaÈ›i pooling de conexiuni pentru concurenÈ›Äƒ ridicatÄƒ
- Cache rÄƒspunsurile modelului pentru interogÄƒri repetate
- MonitorizaÈ›i utilizarea memoriei cu istorii mari de conversaÈ›ii

**WebGPU:**
- UtilizaÈ›i WebGPU pentru confidenÈ›ialitate È™i vitezÄƒ maximÄƒ
- ImplementaÈ›i cuantificarea modelului pentru modele mai mici
- FolosiÈ›i Web Workers pentru procesare Ã®n fundal
- Cache modele compilate Ã®n stocarea browserului

**Open WebUI:**
- UtilizaÈ›i volume persistente pentru istoricul conversaÈ›iilor
- ConfiguraÈ›i limite de resurse pentru containerul Docker
- ImplementaÈ›i strategii de backup pentru datele utilizatorilor
- ConfiguraÈ›i un proxy invers pentru terminarea SSL

### Modele de Integrare

**Hibrid Local/Cloud:**
```python
# Route based on complexity and privacy requirements
async def intelligent_routing(prompt: str, metadata: dict):
    if metadata.get("contains_pii"):
        return await foundry_local_completion(prompt)  # Privacy-sensitive
    elif len(prompt.split()) > 200:
        return await azure_openai_completion(prompt)   # Complex reasoning
    else:
        return await foundry_local_completion(prompt)  # Default local
```

**Pipeline Multi-Modal:**
```python
# Combine different AI capabilities
async def analyze_document(file_path: str):
    # 1. OCR with WebGPU (browser-based)
    text = await webgpu_ocr(file_path)
    
    # 2. Analysis with Foundry Local (private)
    summary = await foundry_local_analyze(text)
    
    # 3. Enhancement with cloud (if needed)
    if summary.confidence < 0.8:
        summary = await azure_openai_enhance(summary)
    
    return summary
```

## Implementare pentru ProducÈ›ie

### ConsideraÈ›ii de Securitate

- **Chei API**: UtilizaÈ›i variabile de mediu, nu le hardcodaÈ›i
- **ReÈ›ea**: UtilizaÈ›i HTTPS Ã®n producÈ›ie, luaÈ›i Ã®n considerare VPN pentru accesul echipei
- **Control Acces**: ImplementaÈ›i autentificare pentru Open WebUI
- **ConfidenÈ›ialitate Date**: AuditaÈ›i ce date rÄƒmÃ¢n locale vs. ce ajung Ã®n cloud
- **ActualizÄƒri**: MenÈ›ineÈ›i Foundry Local È™i containerele actualizate

### Monitorizare È™i MentenanÈ›Äƒ

- **VerificÄƒri de SÄƒnÄƒtate**: ImplementaÈ›i monitorizarea endpoint-urilor
- **Logare**: CentralizaÈ›i logurile din toate componentele
- **Metrice**: MonitorizaÈ›i timpii de rÄƒspuns, ratele de eroare, utilizarea resurselor
- **Backup**: RealizaÈ›i backup regulat pentru datele conversaÈ›iilor È™i configuraÈ›ii

## ReferinÈ›e È™i Resurse

### DocumentaÈ›ie
- [DocumentaÈ›ie Chainlit](https://docs.chainlit.io/) - Ghid complet al framework-ului
- [DocumentaÈ›ie Foundry Local](https://learn.microsoft.com/azure/ai-foundry/foundry-local/) - DocumentaÈ›ie oficialÄƒ Microsoft
- [ONNX Runtime Web](https://onnxruntime.ai/docs/get-started/with-javascript/web.html) - Integrare WebGPU
- [DocumentaÈ›ie Open WebUI](https://docs.openwebui.com/) - Configurare avansatÄƒ

### FiÈ™iere Exemplu
- [`app.py`](../../../../../Module08/samples/04/app.py) - AplicaÈ›ie Chainlit pentru producÈ›ie
- [`chainlit_app.ipynb`](./chainlit_app.ipynb) - Notebook educaÈ›ional
- [`webgpu-demo/`](../../../../../Module08/samples/04/webgpu-demo) - InferenÈ›Äƒ AI bazatÄƒ pe browser
- [`open-webui-guide.md`](./open-webui-guide.md) - Configurare completÄƒ Open WebUI

### Exemple Asociate
- [DocumentaÈ›ie Sesiunea 4](../../04.CuttingEdgeModels.md) - Ghid complet al sesiunii
- [Exemple Foundry Local](https://github.com/microsoft/foundry-local/tree/main/samples) - Exemple oficiale

---

