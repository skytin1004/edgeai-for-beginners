<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6503a980cb3bf2b2de2d2bc4ac6acc4c",
  "translation_date": "2025-09-24T22:30:21+00:00",
  "source_file": "Module08/01.FoundryLocalSetup.md",
  "language_code": "el"
}
-->
# Î£Ï…Î½ÎµÎ´ÏÎ¯Î± 1: ÎÎµÎºÎ¹Î½ÏÎ½Ï„Î±Ï‚ Î¼Îµ Ï„Î¿ Foundry Local

## Î•Ï€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ·

Î¤Î¿ Microsoft Foundry Local Ï†Î­ÏÎ½ÎµÎ¹ Ï„Î¹Ï‚ Î´Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„ÎµÏ‚ Ï„Î¿Ï… Azure AI Foundry Î±Ï€ÎµÏ…Î¸ÎµÎ¯Î±Ï‚ ÏƒÏ„Î¿ Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½ Î±Î½Î¬Ï€Ï„Ï…Î¾Î·Ï‚ Ï„Ï‰Î½ Windows 11, ÎµÏ€Î¹Ï„ÏÎ­Ï€Î¿Î½Ï„Î±Ï‚ Ï„Î·Î½ Î±Î½Î¬Ï€Ï„Ï…Î¾Î· AI Î¼Îµ ÎµÏÎ³Î±Î»ÎµÎ¯Î± ÎµÏ€Î¹Ï€Î­Î´Î¿Ï… ÎµÏ€Î¹Ï‡ÎµÎ¯ÏÎ·ÏƒÎ·Ï‚, Î´Î¹Î±Ï„Î·ÏÏÎ½Ï„Î±Ï‚ Ï„Î·Î½ Î¹Î´Î¹Ï‰Ï„Î¹ÎºÏŒÏ„Î·Ï„Î± ÎºÎ±Î¹ Ï‡Î±Î¼Î·Î»Î® ÎºÎ±Î¸Ï…ÏƒÏ„Î­ÏÎ·ÏƒÎ·. Î‘Ï…Ï„Î® Î· ÏƒÏ…Î½ÎµÎ´ÏÎ¯Î± ÎºÎ±Î»ÏÏ€Ï„ÎµÎ¹ Ï„Î·Î½ Ï€Î»Î®ÏÎ· ÎµÎ³ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ·, ÏÏÎ¸Î¼Î¹ÏƒÎ· ÎºÎ±Î¹ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î±Î½Î¬Ï€Ï„Ï…Î¾Î· Î´Î·Î¼Î¿Ï†Î¹Î»ÏÎ½ Î¼Î¿Î½Ï„Î­Î»Ï‰Î½ ÏŒÏ€Ï‰Ï‚ phi, qwen, deepseek ÎºÎ±Î¹ GPT-OSS-20B.

## Î£Ï„ÏŒÏ‡Î¿Î¹ ÎœÎ¬Î¸Î·ÏƒÎ·Ï‚

ÎœÎ­Ï‡ÏÎ¹ Ï„Î¿ Ï„Î­Î»Î¿Ï‚ Î±Ï…Ï„Î®Ï‚ Ï„Î·Ï‚ ÏƒÏ…Î½ÎµÎ´ÏÎ¯Î±Ï‚, Î¸Î± Î¼Ï€Î¿ÏÎµÎ¯Ï„Îµ:
- ÎÎ± ÎµÎ³ÎºÎ±Ï„Î±ÏƒÏ„Î®ÏƒÎµÏ„Îµ ÎºÎ±Î¹ Î½Î± ÏÏ…Î¸Î¼Î¯ÏƒÎµÏ„Îµ Ï„Î¿ Foundry Local ÏƒÏ„Î± Windows 11
- ÎÎ± ÎµÎ¾Î¿Î¹ÎºÎµÎ¹Ï‰Î¸ÎµÎ¯Ï„Îµ Î¼Îµ Ï„Î¹Ï‚ ÎµÎ½Ï„Î¿Î»Î­Ï‚ CLI ÎºÎ±Î¹ Ï„Î¹Ï‚ ÎµÏ€Î¹Î»Î¿Î³Î­Ï‚ ÏÏÎ¸Î¼Î¹ÏƒÎ·Ï‚
- ÎÎ± ÎºÎ±Ï„Î±Î½Î¿Î®ÏƒÎµÏ„Îµ ÏƒÏ„ÏÎ±Ï„Î·Î³Î¹ÎºÎ­Ï‚ Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½Î®Ï‚ Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ·Ï‚ Î¼Î¿Î½Ï„Î­Î»Ï‰Î½ Î³Î¹Î± Î²Î­Î»Ï„Î¹ÏƒÏ„Î· Î±Ï€ÏŒÎ´Î¿ÏƒÎ·
- ÎÎ± ÎµÎºÏ„ÎµÎ»Î­ÏƒÎµÏ„Îµ ÎµÏ€Î¹Ï„Ï…Ï‡ÏÏ‚ Ï„Î± Î¼Î¿Î½Ï„Î­Î»Î± phi, qwen, deepseek ÎºÎ±Î¹ GPT-OSS-20B
- ÎÎ± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®ÏƒÎµÏ„Îµ Ï„Î·Î½ Ï€ÏÏÏ„Î· ÏƒÎ±Ï‚ ÎµÏ†Î±ÏÎ¼Î¿Î³Î® AI Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ Ï„Î¿ Foundry Local

## Î ÏÎ¿Î±Ï€Î±Î¹Ï„Î¿ÏÎ¼ÎµÎ½Î±

### Î‘Ï€Î±Î¹Ï„Î®ÏƒÎµÎ¹Ï‚ Î£Ï…ÏƒÏ„Î®Î¼Î±Ï„Î¿Ï‚
- **Windows 11**: ÎˆÎºÎ´Î¿ÏƒÎ· 22H2 Î® Î½ÎµÏŒÏ„ÎµÏÎ·
- **RAM**: Î•Î»Î¬Ï‡Î¹ÏƒÏ„Î¿ 16GB, ÏƒÏ…Î½Î¹ÏƒÏ„Î¬Ï„Î±Î¹ 32GB
- **Î‘Ï€Î¿Î¸Î·ÎºÎµÏ…Ï„Î¹ÎºÏŒÏ‚ Î§ÏÏÎ¿Ï‚**: 50GB ÎµÎ»ÎµÏÎ¸ÎµÏÎ¿Ï‚ Ï‡ÏÏÎ¿Ï‚ Î³Î¹Î± Î¼Î¿Î½Ï„Î­Î»Î± ÎºÎ±Î¹ Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½Î® Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ·
- **Î¥Î»Î¹ÎºÏŒ**: Î£Ï…ÏƒÎºÎµÏ…Î® Î¼Îµ NPU Î® GPU (Ï€ÏÎ¿Ï„Î¹Î¼Î¬Ï„Î±Î¹ Copilot+ PC Î® NVIDIA GPU)
- **Î”Î¯ÎºÏ„Ï…Î¿**: Î“ÏÎ®Î³Î¿ÏÎ· ÏƒÏÎ½Î´ÎµÏƒÎ· ÏƒÏ„Î¿ Î´Î¹Î±Î´Î¯ÎºÏ„Ï…Î¿ Î³Î¹Î± Î»Î®ÏˆÎ· Î¼Î¿Î½Ï„Î­Î»Ï‰Î½

### Î ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½ Î‘Î½Î¬Ï€Ï„Ï…Î¾Î·Ï‚
```powershell
# Verify Windows version
winver

# Check available memory
Get-ComputerInfo | Select-Object TotalPhysicalMemory

# Verify PowerShell version (5.1+ required)
$PSVersionTable.PSVersion

# Set up Python environment (recommended)
py -m venv .venv
.venv\Scripts\activate

# Install required dependencies
pip install openai foundry-local-sdk
```

## ÎœÎ­ÏÎ¿Ï‚ 1: Î•Î³ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ· ÎºÎ±Î¹ Î¡ÏÎ¸Î¼Î¹ÏƒÎ·

### Î’Î®Î¼Î± 1: Î•Î³ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ· Ï„Î¿Ï… Foundry Local

Î•Î³ÎºÎ±Ï„Î±ÏƒÏ„Î®ÏƒÏ„Îµ Ï„Î¿ Foundry Local Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ Ï„Î¿ Winget Î® ÎºÎ±Ï„ÎµÎ²Î¬ÏƒÏ„Îµ Ï„Î¿Î½ ÎµÎ³ÎºÎ±Ï„Î±ÏƒÏ„Î¬Ï„Î· Î±Ï€ÏŒ Ï„Î¿ GitHub:

```powershell
# Winget (Windows)
winget install --id Microsoft.FoundryLocal --source winget

# Alternatively: download installer from the official repo
# https://aka.ms/foundry-local-installer
```

### Î’Î®Î¼Î± 2: Î•Ï€Î±Î»Î®Î¸ÎµÏ…ÏƒÎ· Î•Î³ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ·Ï‚

```powershell
# Check Foundry Local version
foundry --version

# Verify CLI accessibility and categories
foundry --help
foundry model --help
foundry cache --help
foundry service --help
```

## ÎœÎ­ÏÎ¿Ï‚ 2: ÎšÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎ· Ï„Î¿Ï… CLI

### Î’Î±ÏƒÎ¹ÎºÎ® Î”Î¿Î¼Î® Î•Î½Ï„Î¿Î»ÏÎ½

```powershell
# General command structure
foundry [category] [command] [options]

# Main categories
foundry model   # manage and run models
foundry service # manage the local service
foundry cache   # manage local model cache

# Common commands
foundry model list              # list available models
foundry model run phi-4-mini  # run a model (downloads as needed)
foundry cache ls                # list cached models
```


## ÎœÎ­ÏÎ¿Ï‚ 3: Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· ÎºÎ±Î¹ Î ÏÎ¿ÏƒÏ‰ÏÎ¹Î½Î® Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÎœÎ¿Î½Ï„Î­Î»Ï‰Î½

Î¤Î¿ Foundry Local ÎµÏ†Î±ÏÎ¼ÏŒÎ¶ÎµÎ¹ Î­Î¾Ï…Ï€Î½Î· Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½Î® Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Ï‰Î½ Î³Î¹Î± Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Ï„Î·Ï‚ Î±Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚ ÎºÎ±Î¹ Ï„Î¿Ï… Ï‡ÏÏÎ¿Ï…:

```powershell
# Show cache contents
foundry cache ls

# Optional: change cache directory (advanced)
foundry cache cd "C:\\FoundryLocal\\Cache"
foundry cache ls
```

## ÎœÎ­ÏÎ¿Ï‚ 4: Î ÏÎ±ÎºÏ„Î¹ÎºÎ® Î‘Î½Î¬Ï€Ï„Ï…Î¾Î· ÎœÎ¿Î½Ï„Î­Î»Ï‰Î½

### Î•ÎºÏ„Î­Î»ÎµÏƒÎ· ÎœÎ¿Î½Ï„Î­Î»Ï‰Î½ Microsoft Phi

```powershell
# List catalog and run Phi (auto-downloads best variant for your hardware)
foundry model list
foundry model run phi-4-mini
```

### Î•ÏÎ³Î±ÏƒÎ¯Î± Î¼Îµ ÎœÎ¿Î½Ï„Î­Î»Î± Qwen

```powershell
# Run Qwen2.5 models (downloads on first run)
foundry model run qwen2.5-7b-instruct
foundry model run qwen2.5-14b-instruct
```

### Î•ÎºÏ„Î­Î»ÎµÏƒÎ· ÎœÎ¿Î½Ï„Î­Î»Ï‰Î½ DeepSeek

```powershell
# Run DeepSeek model
foundry model run deepseek-r1-distill-qwen-7b
```

### Î•ÎºÏ„Î­Î»ÎµÏƒÎ· GPT-OSS-20B

```powershell
# Run the latest OpenAI open-source model (requires recent Foundry Local and sufficient GPU VRAM)
foundry model run gpt-oss-20b

# Check version if you encounter errors (requires 0.6.87+ per docs)
foundry --version
```

## ÎœÎ­ÏÎ¿Ï‚ 5: Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï„Î·Ï‚ Î ÏÏÏ„Î·Ï‚ ÏƒÎ±Ï‚ Î•Ï†Î±ÏÎ¼Î¿Î³Î®Ï‚

### Î£ÏÎ³Ï‡ÏÎ¿Î½Î· Î•Ï†Î±ÏÎ¼Î¿Î³Î® Î£Ï…Î½Î¿Î¼Î¹Î»Î¯Î±Ï‚ (OpenAI SDK + Foundry Local)

Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î®ÏƒÏ„Îµ Î¼Î¹Î± ÎµÏ†Î±ÏÎ¼Î¿Î³Î® ÏƒÏ…Î½Î¿Î¼Î¹Î»Î¯Î±Ï‚ Î­Ï„Î¿Î¹Î¼Î· Î³Î¹Î± Ï€Î±ÏÎ±Î³Ï‰Î³Î® Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ Ï„Î¿ OpenAI SDK Î¼Îµ ÎµÎ½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎ· Ï„Î¿Ï… Foundry Local, Î±ÎºÎ¿Î»Î¿Ï…Î¸ÏÎ½Ï„Î±Ï‚ Ï„Î± Ï€ÏÏŒÏ„Ï…Ï€Î± Î±Ï€ÏŒ Ï„Î¿ Î”ÎµÎ¯Î³Î¼Î± 01.

```python
# chat_quickstart.py (Sample 01 pattern)
import os
import sys
from openai import OpenAI

try:
    from foundry_local import FoundryLocalManager
    FOUNDRY_SDK_AVAILABLE = True
except ImportError:
    FOUNDRY_SDK_AVAILABLE = False
    print("âš ï¸ Install foundry-local-sdk: pip install foundry-local-sdk")

def create_client():
    """Create OpenAI client with Foundry Local or Azure OpenAI."""
    # Check for Azure OpenAI configuration
    azure_endpoint = os.environ.get("AZURE_OPENAI_ENDPOINT")
    azure_api_key = os.environ.get("AZURE_OPENAI_API_KEY")
    
    if azure_endpoint and azure_api_key:
        # Azure OpenAI path
        model = os.environ.get("MODEL", "your-deployment-name")
        client = OpenAI(
            base_url=f"{azure_endpoint}/openai",
            api_key=azure_api_key,
            default_query={"api-version": "2024-08-01-preview"},
        )
        print(f"ğŸŒ Using Azure OpenAI with model: {model}")
        return client, model
    
    # Foundry Local path with SDK management
    alias = os.environ.get("MODEL", "phi-4-mini")
    if FOUNDRY_SDK_AVAILABLE:
        try:
            # Use FoundryLocalManager for proper service management
            manager = FoundryLocalManager(alias)
            model_info = manager.get_model_info(alias)
            
            client = OpenAI(
                base_url=manager.endpoint,
                api_key=manager.api_key
            )
            model = model_info.id
            print(f"ğŸ  Using Foundry Local SDK with model: {model}")
            return client, model
        except Exception as e:
            print(f"âš ï¸ Foundry SDK failed ({e}), using manual configuration")
    
    # Fallback to manual configuration
    base_url = os.environ.get("BASE_URL", "http://localhost:8000")
    api_key = os.environ.get("API_KEY", "")
    model = alias
    
    client = OpenAI(
        base_url=f"{base_url}/v1",
        api_key=api_key
    )
    print(f"ğŸ”§ Manual configuration with model: {model}")
    return client, model

def main():
    """Main chat function."""
    client, model = create_client()
    
    print("Foundry Local Chat Interface (type 'quit' to exit)\n")
    conversation_history = []
    
    while True:
        user_input = input("You: ")
        if user_input.lower() == 'quit':
            break
        
        try:
            # Add user message to history
            conversation_history.append({"role": "user", "content": user_input})
            
            # Create chat completion
            response = client.chat.completions.create(
                model=model,
                messages=conversation_history,
                max_tokens=500,
                temperature=0.7
            )
            
            assistant_message = response.choices[0].message.content
            conversation_history.append({"role": "assistant", "content": assistant_message})
            
            print(f"Assistant: {assistant_message}\n")
            
        except Exception as e:
            print(f"Error: {e}\n")

if __name__ == "__main__":
    main()
```

### Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Ï„Î·Ï‚ Î•Ï†Î±ÏÎ¼Î¿Î³Î®Ï‚ Î£Ï…Î½Î¿Î¼Î¹Î»Î¯Î±Ï‚

```powershell
# Ensure the model is running in another terminal
foundry model run phi-4-mini

# Option 1: Using FoundryLocalManager (recommended)
python chat_quickstart.py "Explain what Foundry Local is"

# Option 2: Manual configuration with environment variables
set BASE_URL=http://localhost:8000
set MODEL=phi-4-mini
set API_KEY=
python chat_quickstart.py "Write a welcome message"

# Option 3: Azure OpenAI configuration
set AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
set AZURE_OPENAI_API_KEY=your-api-key
set AZURE_OPENAI_API_VERSION=2024-08-01-preview
set MODEL=your-deployment-name
python chat_quickstart.py "Hello from Azure OpenAI"
```

## ÎœÎ­ÏÎ¿Ï‚ 6: Î‘Î½Ï„Î¹Î¼ÎµÏ„ÏÏ€Î¹ÏƒÎ· Î ÏÎ¿Î²Î»Î·Î¼Î¬Ï„Ï‰Î½ ÎºÎ±Î¹ Î’Î­Î»Ï„Î¹ÏƒÏ„ÎµÏ‚ Î ÏÎ±ÎºÏ„Î¹ÎºÎ­Ï‚

### Î£Ï…Î½Î·Î¸Î¹ÏƒÎ¼Î­Î½Î± Î ÏÎ¿Î²Î»Î®Î¼Î±Ï„Î± ÎºÎ±Î¹ Î›ÏÏƒÎµÎ¹Ï‚

```powershell
# Issue: "Could not use Foundry SDK" warning
pip install foundry-local-sdk
# Or set environment variables for manual configuration

# Issue: Connection refused
foundry service status
foundry service ps  # Check loaded models

# Issue: Model not found
foundry model list
foundry model run phi-4-mini

# Issue: Cache problems or low disk space
foundry cache ls
foundry cache clean

# Issue: GPT-OSS-20B not supported on your version
foundry --version
winget upgrade --id Microsoft.FoundryLocal

# Test API endpoint
curl http://localhost:8000/v1/models
```

### Î Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ· Î ÏŒÏÏ‰Î½ Î£Ï…ÏƒÏ„Î®Î¼Î±Ï„Î¿Ï‚ (Windows)

```powershell
# Quick CPU and process view
Get-Process | Sort-Object -Property CPU -Descending | Select-Object -First 10
Get-Counter '\\Processor(_Total)\\% Processor Time' -SampleInterval 1 -MaxSamples 10
```

### ÎœÎµÏ„Î±Î²Î»Î·Ï„Î­Ï‚ Î ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½Ï„Î¿Ï‚

| ÎœÎµÏ„Î±Î²Î»Î·Ï„Î® | Î ÎµÏÎ¹Î³ÏÎ±Ï†Î® | Î ÏÎ¿ÎµÏ€Î¹Î»Î¿Î³Î® | Î‘Ï€Î±Î¹Ï„ÎµÎ¯Ï„Î±Î¹ |
|----------|-------------|---------|----------|
| `MODEL` | Î¨ÎµÏ…Î´ÏÎ½Ï…Î¼Î¿ Î® ÏŒÎ½Î¿Î¼Î± Î¼Î¿Î½Ï„Î­Î»Î¿Ï… | `phi-4-mini` | ÎŒÏ‡Î¹ |
| `BASE_URL` | Î’Î±ÏƒÎ¹ÎºÏŒ URL Ï„Î¿Ï… Foundry Local | `http://localhost:8000` | ÎŒÏ‡Î¹ |
| `API_KEY` | ÎšÎ»ÎµÎ¹Î´Î¯ API (ÏƒÏ…Î½Î®Î¸Ï‰Ï‚ Î´ÎµÎ½ Î±Ï€Î±Î¹Ï„ÎµÎ¯Ï„Î±Î¹ Î³Î¹Î± Ï„Î¿Ï€Î¹ÎºÏŒ) | `""` | ÎŒÏ‡Î¹ |
| `AZURE_OPENAI_ENDPOINT` | Endpoint Ï„Î¿Ï… Azure OpenAI | - | Î“Î¹Î± Azure |
| `AZURE_OPENAI_API_KEY` | ÎšÎ»ÎµÎ¹Î´Î¯ API Ï„Î¿Ï… Azure OpenAI | - | Î“Î¹Î± Azure |
| `AZURE_OPENAI_API_VERSION` | ÎˆÎºÎ´Î¿ÏƒÎ· API Ï„Î¿Ï… Azure | `2024-08-01-preview` | ÎŒÏ‡Î¹ |

### Î’Î­Î»Ï„Î¹ÏƒÏ„ÎµÏ‚ Î ÏÎ±ÎºÏ„Î¹ÎºÎ­Ï‚

- **Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Ï„Î¿ OpenAI SDK**: Î ÏÎ¿Ï„Î¹Î¼Î®ÏƒÏ„Îµ Ï„Î¿ OpenAI SDK Î±Î½Ï„Î¯ Î³Î¹Î± Î±Ï€Î»Î¬ Î±Î¹Ï„Î®Î¼Î±Ï„Î± HTTP Î³Î¹Î± ÎºÎ±Î»ÏÏ„ÎµÏÎ· ÏƒÏ…Î½Ï„Î·ÏÎ·ÏƒÎ¹Î¼ÏŒÏ„Î·Ï„Î±
- **FoundryLocalManager**: Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Ï„Î¿ ÎµÏ€Î¯ÏƒÎ·Î¼Î¿ SDK Î³Î¹Î± Ï„Î· Î´Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· Ï…Ï€Î·ÏÎµÏƒÎ¹ÏÎ½ ÏŒÏ„Î±Î½ ÎµÎ¯Î½Î±Î¹ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î¿
- **Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· Î£Ï†Î±Î»Î¼Î¬Ï„Ï‰Î½**: Î•Ï†Î±ÏÎ¼ÏŒÏƒÏ„Îµ ÎºÎ±Ï„Î¬Î»Î»Î·Î»ÎµÏ‚ ÏƒÏ„ÏÎ±Ï„Î·Î³Î¹ÎºÎ­Ï‚ ÎµÎ½Î±Î»Î»Î±ÎºÏ„Î¹ÎºÎ®Ï‚ Î»ÏÏƒÎ·Ï‚ Î³Î¹Î± ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚ Ï€Î±ÏÎ±Î³Ï‰Î³Î®Ï‚
- **Î¤Î±ÎºÏ„Î¹ÎºÎ­Ï‚ Î‘Î½Î±Î²Î±Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚**: Î”Î¹Î±Ï„Î·ÏÎ®ÏƒÏ„Îµ Ï„Î¿ Foundry Local ÎµÎ½Î·Î¼ÎµÏÏ‰Î¼Î­Î½Î¿ Î³Î¹Î± Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ· ÏƒÎµ Î½Î­Î± Î¼Î¿Î½Ï„Î­Î»Î± ÎºÎ±Î¹ Î´Î¹Î¿ÏÎ¸ÏÏƒÎµÎ¹Ï‚
- **ÎÎµÎºÎ¹Î½Î®ÏƒÏ„Îµ ÎœÎ¹ÎºÏÎ¬**: ÎÎµÎºÎ¹Î½Î®ÏƒÏ„Îµ Î¼Îµ Î¼Î¹ÎºÏÏŒÏ„ÎµÏÎ± Î¼Î¿Î½Ï„Î­Î»Î± (Phi mini, Qwen 7B) ÎºÎ±Î¹ ÎµÏ€ÎµÎºÏ„Î±Î¸ÎµÎ¯Ï„Îµ
- **Î Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ· Î ÏŒÏÏ‰Î½**: Î Î±ÏÎ±ÎºÎ¿Î»Î¿Ï…Î¸Î®ÏƒÏ„Îµ CPU/GPU/Î¼Î½Î®Î¼Î· ÎµÎ½Ï ÏÏ…Î¸Î¼Î¯Î¶ÎµÏ„Îµ Ï€ÏÎ¿Ï„ÏÎ¿Ï€Î­Ï‚ ÎºÎ±Î¹ ÏÏ…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚

## ÎœÎ­ÏÎ¿Ï‚ 7: Î ÏÎ±ÎºÏ„Î¹ÎºÎ­Ï‚ Î‘ÏƒÎºÎ®ÏƒÎµÎ¹Ï‚

### Î†ÏƒÎºÎ·ÏƒÎ· 1: Î“ÏÎ®Î³Î¿ÏÎ· Î”Î¿ÎºÎ¹Î¼Î® Î Î¿Î»Î»Î±Ï€Î»ÏÎ½ ÎœÎ¿Î½Ï„Î­Î»Ï‰Î½

```powershell
# deploy-models.ps1
$models = @(
    "phi-4-mini",
    "qwen2.5-7b-instruct"
)
foreach ($model in $models) {
    Write-Host "Running $model..."
    foundry model run $model --verbose
}
```

### Î†ÏƒÎºÎ·ÏƒÎ· 2: Î”Î¿ÎºÎ¹Î¼Î® Î•Î½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎ·Ï‚ OpenAI SDK

```python
# sdk_integration_test.py (matching Sample 01 pattern)
import os
from openai import OpenAI
from foundry_local import FoundryLocalManager

def test_model_integration(model_alias):
    """Test OpenAI SDK integration with different models."""
    try:
        # Use FoundryLocalManager for proper setup
        manager = FoundryLocalManager(model_alias)
        model_info = manager.get_model_info(model_alias)
        
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key
        )
        
        # Test basic completion
        response = client.chat.completions.create(
            model=model_info.id,
            messages=[{"role": "user", "content": "Say hello and state your model name."}],
            max_tokens=50
        )
        
        print(f"âœ… {model_alias}: {response.choices[0].message.content}")
        return True
    except Exception as e:
        print(f"âŒ {model_alias}: {e}")
        return False

# Test multiple models
models_to_test = ["phi-4-mini", "qwen2.5-7b-instruct"]
for model in models_to_test:
    test_model_integration(model)
```

### Î†ÏƒÎºÎ·ÏƒÎ· 3: ÎŸÎ»Î¿ÎºÎ»Î·ÏÏ‰Î¼Î­Î½Î¿Ï‚ ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î¥Î³ÎµÎ¯Î±Ï‚ Î¥Ï€Î·ÏÎµÏƒÎ¯Î±Ï‚

```python
# health_check.py
from openai import OpenAI
from foundry_local import FoundryLocalManager

def comprehensive_health_check():
    """Perform comprehensive health check of Foundry Local service."""
    try:
        # Initialize with a common model
        manager = FoundryLocalManager("phi-4-mini")
        client = OpenAI(
            base_url=manager.endpoint,
            api_key=manager.api_key
        )
        
        # 1. Check service connectivity
        models_response = client.models.list()
        available_models = [model.id for model in models_response.data]
        print(f"âœ… Service healthy - {len(available_models)} models available")
        
        # 2. Test each available model
        for model_id in available_models:
            try:
                response = client.chat.completions.create(
                    model=model_id,
                    messages=[{"role": "user", "content": "Test"}],
                    max_tokens=10
                )
                print(f"âœ… {model_id}: Working")
            except Exception as e:
                print(f"âŒ {model_id}: {e}")
        
        return True
    except Exception as e:
        print(f"âŒ Service check failed: {e}")
        return False

comprehensive_health_check()
```

## Î‘Î½Î±Ï†Î¿ÏÎ­Ï‚

- **ÎÎµÎºÎ¹Î½Î®ÏƒÏ„Îµ Î¼Îµ Ï„Î¿ Foundry Local**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started
- **Î‘Î½Î±Ï†Î¿ÏÎ¬ CLI ÎºÎ±Î¹ ÎµÏ€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ· ÎµÎ½Ï„Î¿Î»ÏÎ½**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli
- **Î•Î½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎ· OpenAI SDK**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks
- **Î£Ï…Î³ÎºÎ­Î½Ï„ÏÏ‰ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Ï‰Î½ Hugging Face**: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-compile-hugging-face-models
- **Microsoft Foundry Local GitHub**: https://github.com/microsoft/Foundry-Local
- **OpenAI Python SDK**: https://github.com/openai/openai-python
- **Î”ÎµÎ¯Î³Î¼Î± 01: Î“ÏÎ®Î³Î¿ÏÎ· Î£Ï…Î½Î¿Î¼Î¹Î»Î¯Î± Î¼Î­ÏƒÏ‰ OpenAI SDK**: samples/01/README.md
- **Î”ÎµÎ¯Î³Î¼Î± 02: Î ÏÎ¿Ï‡Ï‰ÏÎ·Î¼Î­Î½Î· Î•Î½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎ· SDK**: samples/02/README.md

---

