<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "135b2658979f1e494bb0ecc6e26d4752",
  "translation_date": "2025-10-08T21:19:12+00:00",
  "source_file": "AGENTS.md",
  "language_code": "fa"
}
-->
# AGENTS.md

> **راهنمای توسعه‌دهندگان برای مشارکت در EdgeAI برای مبتدیان**
> 
> این سند اطلاعات جامعی برای توسعه‌دهندگان، عوامل هوش مصنوعی و مشارکت‌کنندگان در این مخزن ارائه می‌دهد. شامل تنظیمات، جریان‌های کاری توسعه، تست و بهترین شیوه‌ها است.
> 
> **آخرین به‌روزرسانی**: اکتبر 2025 | **نسخه سند**: 2.0

## فهرست مطالب

- [نمای کلی پروژه](../..)
- [ساختار مخزن](../..)
- [پیش‌نیازها](../..)
- [دستورات تنظیم](../..)
- [جریان کاری توسعه](../..)
- [دستورالعمل‌های تست](../..)
- [راهنمای سبک کدنویسی](../..)
- [دستورالعمل‌های درخواست کشش](../..)
- [سیستم ترجمه](../..)
- [یکپارچه‌سازی Foundry Local](../..)
- [ساخت و استقرار](../..)
- [مشکلات رایج و رفع اشکال](../..)
- [منابع اضافی](../..)
- [یادداشت‌های خاص پروژه](../..)
- [دریافت کمک](../..)

## نمای کلی پروژه

EdgeAI برای مبتدیان یک مخزن آموزشی جامع است که توسعه هوش مصنوعی لبه‌ای با مدل‌های زبان کوچک (SLMs) را آموزش می‌دهد. این دوره شامل اصول EdgeAI، استقرار مدل، تکنیک‌های بهینه‌سازی و پیاده‌سازی‌های آماده تولید با استفاده از Microsoft Foundry Local و چارچوب‌های مختلف هوش مصنوعی است.

**فناوری‌های کلیدی:**
- Python 3.8+ (زبان اصلی برای نمونه‌های AI/ML)
- .NET C# (نمونه‌های AI/ML)
- JavaScript/Node.js با Electron (برای برنامه‌های دسکتاپ)
- Microsoft Foundry Local SDK
- Microsoft Windows ML 
- VSCode AI Toolkit
- OpenAI SDK
- چارچوب‌های هوش مصنوعی: LangChain، Semantic Kernel، Chainlit
- بهینه‌سازی مدل: Llama.cpp، Microsoft Olive، OpenVINO، Apple MLX

**نوع مخزن:** مخزن محتوای آموزشی با 8 ماژول و 10 برنامه نمونه جامع

**معماری:** مسیر یادگیری چندماژوله با نمونه‌های عملی که الگوهای استقرار هوش مصنوعی لبه‌ای را نشان می‌دهند

## ساختار مخزن

```
edgeai-for-beginners/
├── introduction.md          # Course introduction and overview
├── Module01-07/            # Core educational modules (Markdown)
├── Module08/               # Foundry Local toolkit with 10 samples
│   ├── samples/01-06/     # Foundation samples (Python)
│   ├── samples/07/        # API client (Python)
│   ├── samples/08/        # Windows 11 chat app (Electron)
│   └── samples/09-10/     # Advanced multi-agent systems (Python)
├── translations/          # Multi-language translations (50+ languages)
├── translated_images/     # Localized images
└── imgs/                  # Course images and assets
```

## پیش‌نیازها

### ابزارهای مورد نیاز

- **Python 3.8+** - برای نمونه‌های AI/ML و نوت‌بوک‌ها
- **Node.js 16+** - برای برنامه نمونه Electron
- **Git** - برای کنترل نسخه
- **Microsoft Foundry Local** - برای اجرای مدل‌های هوش مصنوعی به صورت محلی

### ابزارهای توصیه‌شده

- **Visual Studio Code** - با افزونه‌های Python، Jupyter و Pylance
- **Windows Terminal** - برای تجربه بهتر خط فرمان (کاربران ویندوز)
- **Docker** - برای توسعه کانتینری (اختیاری)

### الزامات سیستم

- **RAM**: حداقل 8GB، 16GB+ توصیه‌شده برای سناریوهای چندمدلی
- **فضای ذخیره‌سازی**: حداقل 10GB فضای آزاد برای مدل‌ها و وابستگی‌ها
- **سیستم‌عامل**: Windows 10/11، macOS 11+، یا Linux (Ubuntu 20.04+)
- **سخت‌افزار**: CPU با پشتیبانی AVX2؛ GPU (CUDA، Qualcomm NPU) اختیاری اما توصیه‌شده

### پیش‌نیازهای دانش

- درک پایه‌ای از برنامه‌نویسی Python
- آشنایی با رابط‌های خط فرمان
- درک مفاهیم AI/ML (برای توسعه نمونه‌ها)
- جریان‌های کاری Git و فرآیندهای درخواست کشش

## دستورات تنظیم

### تنظیم مخزن

```bash
# Clone the repository
git clone https://github.com/microsoft/edgeai-for-beginners.git
cd edgeai-for-beginners

# No build step required - this is primarily an educational content repository
```

### تنظیم نمونه‌های Python (ماژول08 و نمونه‌های Python)

```bash
# Create and activate virtual environment
python -m venv .venv
# On Windows
.venv\Scripts\activate
# On macOS/Linux
source .venv/bin/activate

# Install Foundry Local SDK and dependencies
pip install foundry-local-sdk openai

# Install additional dependencies for Module08 samples
cd Module08
pip install -r requirements.txt
```

### تنظیم نمونه‌های Node.js (نمونه 08 - برنامه چت ویندوز)

```bash
cd Module08/samples/08
npm install

# Start in development mode
npm run dev

# Build for production
npm run build

# Create installer
npm run dist
```

### تنظیم Foundry Local

Foundry Local برای اجرای نمونه‌ها مورد نیاز است. از مخزن رسمی دانلود و نصب کنید:

**نصب:**
- **ویندوز**: `winget install Microsoft.FoundryLocal`
- **macOS**: `brew tap microsoft/foundrylocal && brew install foundrylocal`
- **دستی**: دانلود از [صفحه انتشار](https://github.com/microsoft/Foundry-Local/releases)

**شروع سریع:**
```bash
# Run your first model (auto-downloads if needed)
foundry model run phi-3.5-mini

# List available models
foundry model ls

# Check service status
foundry service status
```

**توجه**: Foundry Local به طور خودکار بهترین نوع مدل را برای سخت‌افزار شما انتخاب می‌کند (CUDA GPU، Qualcomm NPU، یا CPU).

## جریان کاری توسعه

### توسعه محتوا

این مخزن عمدتاً شامل **محتوای آموزشی Markdown** است. هنگام ایجاد تغییرات:

1. فایل‌های `.md` را در دایرکتوری‌های ماژول مناسب ویرایش کنید
2. الگوهای قالب‌بندی موجود را دنبال کنید
3. اطمینان حاصل کنید که نمونه‌های کد دقیق و تست‌شده هستند
4. در صورت لزوم محتوای ترجمه‌شده مربوطه را به‌روزرسانی کنید (یا اجازه دهید اتوماسیون این کار را انجام دهد)

### توسعه برنامه نمونه

برای نمونه‌های Python (نمونه‌های 01-07، 09-10):
```bash
cd Module08
python samples/01/chat_quickstart.py "Test message"
```

برای نمونه Electron (نمونه 08):
```bash
cd Module08/samples/08
npm run dev  # Development with hot reload
```

### تست برنامه‌های نمونه

نمونه‌های Python تست‌های خودکار ندارند اما می‌توان با اجرای آن‌ها اعتبارسنجی کرد:
```bash
# Test basic chat functionality
python samples/01/chat_quickstart.py "Hello"

# Test with specific model
set MODEL=phi-4-mini
python samples/02/openai_sdk_client.py
```

نمونه Electron دارای زیرساخت تست است:
```bash
cd Module08/samples/08
npm test           # Run unit tests
npm run test:e2e   # Run end-to-end tests
npm run lint       # Check code style
```

## دستورالعمل‌های تست

### اعتبارسنجی محتوا

مخزن از جریان‌های کاری ترجمه خودکار استفاده می‌کند. تست دستی برای ترجمه‌ها لازم نیست.

**اعتبارسنجی دستی برای تغییرات محتوا:**
1. رندر Markdown را با پیش‌نمایش فایل‌های `.md` بررسی کنید
2. اطمینان حاصل کنید که همه لینک‌ها به اهداف معتبر اشاره دارند
3. هر قطعه کد موجود در مستندات را تست کنید
4. بررسی کنید که تصاویر به درستی بارگذاری شوند

### تست برنامه‌های نمونه

**Module08/samples/08 (برنامه Electron) دارای تست جامع است:**
```bash
cd Module08/samples/08

# Run all tests
npm test

# Run unit tests only
npm test -- --testPathPattern=unit

# Run integration tests
npm run test:integration

# Run E2E tests
npm run test:e2e

# Check test coverage
npm test -- --coverage
```

**نمونه‌های Python باید به صورت دستی تست شوند:**
```bash
# Each sample can be run directly
python samples/01/chat_quickstart.py "Test prompt"
python samples/04/chainlit_rag.py
python samples/09/multi_agent_system.py
```

## راهنمای سبک کدنویسی

### محتوای Markdown

- از سلسله‌مراتب عنوان ثابت استفاده کنید (# برای عنوان، ## برای بخش‌های اصلی، ### برای زیر‌بخش‌ها)
- بلوک‌های کد را با مشخص‌کننده زبان شامل کنید: ```python, ```bash, ```javascript
- قالب‌بندی موجود برای جداول، لیست‌ها و تأکید را دنبال کنید
- خطوط را خوانا نگه دارید (هدف ~80-100 کاراکتر، اما سخت‌گیرانه نیست)
- از لینک‌های نسبی برای ارجاعات داخلی استفاده کنید

### سبک کدنویسی Python

- از کنوانسیون‌های PEP 8 پیروی کنید
- در صورت امکان از نوع‌دهی استفاده کنید
- برای توابع و کلاس‌ها توضیحات اضافه کنید
- از نام‌های متغیر معنی‌دار استفاده کنید
- توابع را متمرکز و مختصر نگه دارید

### سبک کدنویسی JavaScript/Node.js

```bash
# Electron sample follows ESLint configuration
cd Module08/samples/08
npm run lint        # Check for style issues
npm run lint:fix    # Auto-fix style issues
npm run format      # Format with Prettier
```

**کنوانسیون‌های کلیدی:**
- پیکربندی ESLint در نمونه 08 ارائه شده است
- Prettier برای قالب‌بندی کد
- از سینتکس مدرن ES6+ استفاده کنید
- الگوهای موجود در کدبیس را دنبال کنید

## دستورالعمل‌های درخواست کشش

### جریان کاری مشارکت

1. **مخزن را فورک کنید** و یک شاخه جدید از `main` ایجاد کنید
2. **تغییرات خود را اعمال کنید** با پیروی از راهنمای سبک کدنویسی
3. **به طور کامل تست کنید** با استفاده از دستورالعمل‌های تست بالا
4. **با پیام‌های واضح کامیت کنید** با فرمت کامیت‌های متعارف
5. **به فورک خود پوش کنید** و یک درخواست کشش ایجاد کنید
6. **به بازخوردها پاسخ دهید** از سوی نگهدارندگان در طول بررسی

### کنوانسیون نام‌گذاری شاخه‌ها

- `feature/<module>-<description>` - برای ویژگی‌ها یا محتوای جدید
- `fix/<module>-<description>` - برای رفع اشکال
- `docs/<description>` - برای بهبود مستندات
- `refactor/<description>` - برای بازسازی کد

### فرمت پیام کامیت

از [کامیت‌های متعارف](https://www.conventionalcommits.org/) پیروی کنید:

```
<type>(<scope>): <description>

[optional body]

[optional footer]
```

**نمونه‌ها:**
```
feat(Module08): add intent-based routing notebook
docs(AGENTS): update Foundry Local setup instructions
fix(samples/08): resolve Electron build issue
```

### فرمت عنوان
```
[ModuleXX] Brief description of change
```
or
```
[Module08/samples/XX] Description for sample changes
```

### کد رفتار

همه مشارکت‌کنندگان باید از [کد رفتار منبع باز مایکروسافت](https://opensource.microsoft.com/codeofconduct/) پیروی کنند. لطفاً قبل از مشارکت [CODE_OF_CONDUCT.md](CODE_OF_CONDUCT.md) را مرور کنید.

### قبل از ارسال

**برای تغییرات محتوا:**
- همه فایل‌های Markdown اصلاح‌شده را پیش‌نمایش کنید
- لینک‌ها و تصاویر را بررسی کنید
- خطاهای تایپی و گرامری را بررسی کنید

**برای تغییرات کد نمونه (Module08/samples/08):**
```bash
npm run lint
npm test
```

**برای تغییرات نمونه‌های Python:**
- تست کنید که نمونه به درستی اجرا شود
- بررسی کنید که مدیریت خطا به درستی کار کند
- سازگاری با Foundry Local را بررسی کنید

### فرآیند بررسی

- تغییرات محتوای آموزشی از نظر دقت و وضوح بررسی می‌شوند
- نمونه‌های کد از نظر عملکرد تست می‌شوند
- به‌روزرسانی‌های ترجمه به صورت خودکار توسط GitHub Actions مدیریت می‌شوند

## سیستم ترجمه

**مهم:** این مخزن از ترجمه خودکار از طریق GitHub Actions استفاده می‌کند.

- ترجمه‌ها در دایرکتوری `/translations/` (50+ زبان) قرار دارند
- به صورت خودکار از طریق جریان کاری `co-op-translator.yml` انجام می‌شود
- **فایل‌های ترجمه را به صورت دستی ویرایش نکنید** - آن‌ها بازنویسی خواهند شد
- فقط فایل‌های منبع انگلیسی را در دایرکتوری‌های ریشه و ماژول ویرایش کنید
- ترجمه‌ها به صورت خودکار در هنگام پوش به شاخه `main` تولید می‌شوند

## یکپارچه‌سازی Foundry Local

بیشتر نمونه‌های ماژول08 نیاز به اجرای Microsoft Foundry Local دارند.

### نصب و تنظیم

**نصب Foundry Local:**
```bash
# Windows
winget install Microsoft.FoundryLocal

# macOS
brew tap microsoft/foundrylocal
brew install foundrylocal
```

**نصب Python SDK:**
```bash
pip install foundry-local-sdk openai
```

### شروع Foundry Local
```bash
# Start service and run a model (auto-downloads if needed)
foundry model run phi-3.5-mini

# Or use model aliases for automatic hardware optimization
foundry model run phi-4-mini
foundry model run qwen2.5-0.5b
foundry model run qwen2.5-coder-0.5b

# Check service status
foundry service status

# List available models
foundry model ls
```

### استفاده از SDK (Python)
```python
from foundry_local import FoundryLocalManager
import openai

# Use model alias for automatic hardware optimization
alias = "phi-3.5-mini"

# Create manager (auto-starts service and loads model)
manager = FoundryLocalManager(alias)

# Configure OpenAI client for local Foundry service
client = openai.OpenAI(
    base_url=manager.endpoint,
    api_key=manager.api_key
)

# Use the model
response = client.chat.completions.create(
    model=manager.get_model_info(alias).id,
    messages=[{"role": "user", "content": "Hello!"}]
)
```

### اعتبارسنجی Foundry Local
```bash
# Service status and endpoint
foundry service status

# List loaded models (REST API)
curl http://localhost:<port>/v1/models

# Note: Port is displayed when running 'foundry service status'
```

### متغیرهای محیطی برای نمونه‌ها

بیشتر نمونه‌ها از این متغیرهای محیطی استفاده می‌کنند:
```bash
# Foundry Local configuration
# Note: The SDK (FoundryLocalManager) automatically detects endpoint
set MODEL=phi-3.5-mini  # or phi-4-mini, qwen2.5-0.5b, qwen2.5-coder-0.5b
set API_KEY=            # Not required for local usage

# Manual endpoint (if not using SDK)
# Port is shown via 'foundry service status'
set BASE_URL=http://localhost:<port>

# For Azure OpenAI fallback (optional)
set AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
set AZURE_OPENAI_API_KEY=your-api-key
set AZURE_OPENAI_API_VERSION=2024-08-01-preview
```

**توجه**: هنگام استفاده از `FoundryLocalManager`، SDK به طور خودکار کشف سرویس و بارگذاری مدل را مدیریت می‌کند. نام مستعار مدل‌ها (مانند `phi-3.5-mini`) بهترین نوع را برای سخت‌افزار شما تضمین می‌کند.

## ساخت و استقرار

### استقرار محتوا

این مخزن عمدتاً مستندات است - فرآیند ساخت برای محتوا لازم نیست.

### ساخت برنامه نمونه

**برنامه Electron (Module08/samples/08):**
```bash
cd Module08/samples/08

# Development build
npm run dev

# Production build
npm run build

# Create Windows installer
npm run dist

# Create portable executable
npm run pack
```

**نمونه‌های Python:**
فرآیند ساخت ندارد - نمونه‌ها مستقیماً با مفسر Python اجرا می‌شوند.

## مشکلات رایج و رفع اشکال

> **نکته**: مشکلات شناخته‌شده و راه‌حل‌ها را در [GitHub Issues](https://github.com/microsoft/edgeai-for-beginners/issues) بررسی کنید.

### مشکلات بحرانی (مسدودکننده)

#### Foundry Local اجرا نمی‌شود
**مشکل:** نمونه‌ها با خطاهای اتصال شکست می‌خورند

**راه‌حل:**
```bash
# Check if service is running
foundry service status

# Start service with a model
foundry model run phi-3.5-mini

# Or explicitly start service
foundry service start

# List loaded models
foundry model ls

# Verify via REST API (port shown in 'foundry service status')
curl http://localhost:<port>/v1/models
```

### مشکلات رایج (متوسط)

#### مشکلات محیط مجازی Python
**مشکل:** خطاهای وارد کردن ماژول

**راه‌حل:**
```bash
# Ensure virtual environment is activated
# Windows
.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate

# Reinstall dependencies
pip install -r requirements.txt
```

#### مشکلات ساخت Electron
**مشکل:** شکست نصب npm یا ساخت

**راه‌حل:**
```bash
cd Module08/samples/08
# Clean install
npm run clean
rm -rf node_modules package-lock.json
npm install
```

### مشکلات جریان کاری (جزئی)

#### تعارض‌های جریان کاری ترجمه
**مشکل:** درخواست کشش ترجمه با تغییرات شما تعارض دارد

**راه‌حل:**
- فقط فایل‌های منبع انگلیسی را ویرایش کنید
- اجازه دهید جریان کاری ترجمه خودکار ترجمه‌ها را مدیریت کند
- اگر تعارض رخ داد، پس از ادغام ترجمه‌ها، `main` را به شاخه خود ادغام کنید

#### شکست دانلود مدل
**مشکل:** Foundry Local در دانلود مدل‌ها شکست می‌خورد

**راه‌حل:**
```bash
# Check internet connectivity
# Clear model cache and retry
foundry model remove <model-alias>
foundry model run <model-alias>

# Check available disk space (models can be 2-16GB)
# Verify firewall settings allow downloads
```

## منابع اضافی

### مسیرهای یادگیری
- **مسیر مبتدی:** ماژول‌های 01-02 (7-9 ساعت)
- **مسیر متوسط:** ماژول‌های 03-04 (9-11 ساعت)
- **مسیر پیشرفته:** ماژول‌های 05-07 (12-15 ساعت)
- **مسیر متخصص:** ماژول 08 (8-10 ساعت)

### محتوای کلیدی ماژول
- **ماژول01:** اصول EdgeAI و مطالعات موردی دنیای واقعی
- **ماژول02:** خانواده‌ها و معماری‌های مدل‌های زبان کوچک (SLM)
- **ماژول03:** استراتژی‌های استقرار محلی و ابری
- **ماژول04:** بهینه‌سازی مدل با چارچوب‌های متعدد
- **ماژول05:** SLMOps - عملیات تولید
- **ماژول06:** عوامل هوش مصنوعی و فراخوانی توابع
- **ماژول07:** پیاده‌سازی‌های خاص پلتفرم
- **ماژول08:** ابزار Foundry Local با 10 نمونه جامع

### وابستگی‌های خارجی
- [Microsoft Foundry Local](https://github.com/microsoft/Foundry-Local) - زمان اجرای مدل هوش مصنوعی محلی با API سازگار با OpenAI
  - [مستندات](https://github.com/microsoft/Foundry-Local/blob/main/docs/README.md)
  - [Python SDK](https://github.com/microsoft/Foundry-Local/tree/main/sdk/python)
  - [JavaScript SDK](https://github.com/microsoft/Foundry-Local/tree/main/sdk/javascript)
- [Llama.cpp](https://github.com/ggml-org/llama.cpp) - چارچوب بهینه‌سازی
- [Microsoft Olive](https://microsoft.github.io/Olive/) - ابزار بهینه‌سازی مدل
- [OpenVINO](https://docs.openvino.ai/) - ابزار بهینه‌سازی اینتل

## یادداشت‌های خاص پروژه

### برنامه‌های نمونه ماژول08

مخزن شامل 10 برنامه نمونه جامع است:

1. **01-REST Chat Quickstart** - یکپارچه‌سازی اولیه OpenAI SDK
2. **02-OpenAI SDK Integration** - ویژگی‌های پیشرفته SDK
3. **03-Model Discovery & Benchmarking** - ابزارهای مقایسه مدل
4. **04-Chainlit RAG Application** - تولید تقویت‌شده با بازیابی
5. **05-Multi-Agent Orchestration** - هماهنگی عوامل پایه
6. **06-Models-as-Tools Router** - مسیریابی هوشمند مدل
7. **07-Direct API Client** - یکپارچه‌سازی سطح پایین API
8. **08-Windows 11 Chat App** - برنامه دسکتاپ Electron بومی
9. **09-Advanced Multi-Agent System** - هماهنگی پیچیده عوامل
10. **10-Foundry Tools Framework** - یکپارچه‌سازی LangChain/Semantic Kernel

هر نمونه جنبه‌های مختلف توسعه هوش مصنوعی لبه‌ای با Foundry Local را نشان می‌دهد.

### ملاحظات عملکردی

- مدل‌های زبان کوچک برای استقرار لبه‌ای بهینه شده‌اند (2-16GB RAM)
- استنتاج محلی زمان پاسخ‌دهی ۵۰ تا ۵۰۰ میلی‌ثانیه ارائه می‌دهد  
- تکنیک‌های کمینه‌سازی (Quantization) به کاهش ۷۵ درصدی اندازه با حفظ ۸۵ درصد عملکرد دست می‌یابند  
- قابلیت‌های مکالمه بلادرنگ با مدل‌های محلی  

### امنیت و حریم خصوصی  

- تمام پردازش‌ها به صورت محلی انجام می‌شود - هیچ داده‌ای به فضای ابری ارسال نمی‌شود  
- مناسب برای برنامه‌های حساس به حریم خصوصی (مانند مراقبت‌های بهداشتی، امور مالی)  
- الزامات حاکمیت داده را برآورده می‌کند  
- Foundry Local به طور کامل بر روی سخت‌افزار محلی اجرا می‌شود  

## دریافت کمک  

### مستندات  

- **README اصلی**: [README.md](README.md) - نمای کلی مخزن و مسیرهای یادگیری  
- **راهنمای مطالعه**: [STUDY_GUIDE.md](STUDY_GUIDE.md) - منابع یادگیری و جدول زمانی  
- **پشتیبانی**: [SUPPORT.md](SUPPORT.md) - نحوه دریافت کمک  
- **امنیت**: [SECURITY.md](SECURITY.md) - گزارش مسائل امنیتی  

### پشتیبانی جامعه  

- **مشکلات GitHub**: [گزارش اشکالات یا درخواست ویژگی‌ها](https://github.com/microsoft/edgeai-for-beginners/issues)  
- **بحث‌های GitHub**: [پرسش سوالات و به اشتراک‌گذاری ایده‌ها](https://github.com/microsoft/edgeai-for-beginners/discussions)  
- **مشکلات Foundry Local**: [مسائل فنی مربوط به Foundry Local](https://github.com/microsoft/Foundry-Local/issues)  

### تماس  

- **نگهدارندگان**: مشاهده [CODEOWNERS](https://github.com/microsoft/edgeai-for-beginners/blob/main/.github/CODEOWNERS)  
- **مسائل امنیتی**: پیروی از افشای مسئولانه در [SECURITY.md](SECURITY.md)  
- **پشتیبانی مایکروسافت**: برای پشتیبانی سازمانی، با خدمات مشتریان مایکروسافت تماس بگیرید  

### منابع اضافی  

- **Microsoft Learn**: [مسیرهای یادگیری هوش مصنوعی و یادگیری ماشین](https://learn.microsoft.com/training/browse/?products=ai-services)  
- **مستندات Foundry Local**: [مستندات رسمی](https://github.com/microsoft/Foundry-Local/blob/main/docs/README.md)  
- **نمونه‌های جامعه**: بررسی [بحث‌های GitHub](https://github.com/microsoft/edgeai-for-beginners/discussions) برای مشارکت‌های جامعه  

---

**این مخزن آموزشی بر آموزش توسعه هوش مصنوعی لبه تمرکز دارد. الگوی اصلی مشارکت شامل بهبود محتوای آموزشی و افزودن/تقویت برنامه‌های نمونه‌ای است که مفاهیم هوش مصنوعی لبه را نشان می‌دهند.**  

---

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطاها یا نادرستی‌ها باشند. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، توصیه می‌شود از ترجمه حرفه‌ای انسانی استفاده کنید. ما مسئولیتی در قبال سوء تفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.