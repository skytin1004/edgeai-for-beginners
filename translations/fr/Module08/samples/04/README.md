<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "562ac0eae12d808c9f45fbb77eb5c84f",
  "translation_date": "2025-09-24T10:21:19+00:00",
  "source_file": "Module08/samples/04/README.md",
  "language_code": "fr"
}
-->
# Exemple 04 : Applications de Chat en Production avec Chainlit

Un exemple complet dÃ©montrant plusieurs approches pour crÃ©er des applications de chat prÃªtes pour la production en utilisant Microsoft Foundry Local, avec des interfaces web modernes, des rÃ©ponses en streaming et des technologies de navigateur de pointe.

## Contenu Inclus

- **ðŸš€ Application de Chat Chainlit** (`app.py`) : Application de chat prÃªte pour la production avec streaming
- **ðŸŒ DÃ©mo WebGPU** (`webgpu-demo/`) : InfÃ©rence IA basÃ©e sur le navigateur avec accÃ©lÃ©ration matÃ©rielle
- **ðŸŽ¨ IntÃ©gration Open WebUI** (`open-webui-guide.md`) : Interface professionnelle similaire Ã  ChatGPT
- **ðŸ“š Notebook Ã‰ducatif** (`chainlit_app.ipynb`) : MatÃ©riel d'apprentissage interactif

## DÃ©marrage Rapide

### 1. Application de Chat Chainlit

```cmd
# Navigate to Module08 directory
cd Module08

# Start your model
foundry model run phi-4-mini

# Run Chainlit app (using port 8080 to avoid conflicts)
chainlit run samples\04\app.py -w --port 8080
```

Accessible Ã  : `http://localhost:8080`

### 2. DÃ©mo WebGPU dans le Navigateur

```cmd
# Navigate to WebGPU demo
cd Module08\samples\04\webgpu-demo

# Serve the demo
python -m http.server 5173
```

Accessible Ã  : `http://localhost:5173`

### 3. Configuration Open WebUI

```cmd
# Run Open WebUI with Docker
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

Accessible Ã  : `http://localhost:3000`

## ModÃ¨les d'Architecture

### Matrice de DÃ©cision Local vs Cloud

| ScÃ©nario | Recommandation | Raison |
|----------|----------------|--------|
| **DonnÃ©es Sensibles** | ðŸ  Local (Foundry) | Les donnÃ©es ne quittent jamais l'appareil |
| **Raisonnement Complexe** | â˜ï¸ Cloud (Azure OpenAI) | AccÃ¨s Ã  des modÃ¨les plus grands |
| **Chat en Temps RÃ©el** | ðŸ  Local (Foundry) | Latence rÃ©duite, rÃ©ponses plus rapides |
| **Analyse de Documents** | ðŸ”„ Hybride | Extraction locale, analyse dans le cloud |
| **GÃ©nÃ©ration de Code** | ðŸ  Local (Foundry) | ConfidentialitÃ© + modÃ¨les spÃ©cialisÃ©s |
| **TÃ¢ches de Recherche** | â˜ï¸ Cloud (Azure OpenAI) | Base de connaissances Ã©tendue nÃ©cessaire |

### Comparaison des Technologies

| Technologie | Cas d'Utilisation | Avantages | InconvÃ©nients |
|-------------|-------------------|-----------|---------------|
| **Chainlit** | DÃ©veloppeurs Python, prototypage rapide | Configuration facile, support du streaming | LimitÃ© Ã  Python |
| **WebGPU** | ConfidentialitÃ© maximale, scÃ©narios hors ligne | Natif au navigateur, pas besoin de serveur | Taille de modÃ¨le limitÃ©e |
| **Open WebUI** | DÃ©ploiement en production, Ã©quipes | Interface professionnelle, gestion des utilisateurs | NÃ©cessite Docker |

## PrÃ©requis

- **Foundry Local** : InstallÃ© et en cours d'exÃ©cution ([TÃ©lÃ©charger](https://aka.ms/foundry-local-installer))
- **Python** : Version 3.10+ avec environnement virtuel
- **ModÃ¨le** : Au moins un modÃ¨le chargÃ© (`foundry model run phi-4-mini`)
- **Navigateur** : Chrome/Edge avec support WebGPU pour les dÃ©mos
- **Docker** : Pour Open WebUI (optionnel)

## Installation & Configuration

### 1. Configuration de l'Environnement Python

```cmd
# Navigate to Module08 directory
cd Module08

# Create and activate virtual environment
py -m venv .venv
.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Configuration de Foundry Local

```cmd
# Verify Foundry Local installation
foundry --version

# Start the service
foundry service start

# Load a model
foundry model run phi-4-mini

# Verify model is running
foundry service ps
```

## Applications Exemple

### Application de Chat Chainlit

**CaractÃ©ristiques :**
- ðŸš€ **Streaming en Temps RÃ©el** : Les tokens apparaissent au fur et Ã  mesure de leur gÃ©nÃ©ration
- ðŸ›¡ï¸ **Gestion des Erreurs Robuste** : DÃ©gradation et rÃ©cupÃ©ration en douceur
- ðŸŽ¨ **Interface Moderne** : Interface de chat professionnelle prÃªte Ã  l'emploi
- ðŸ”§ **Configuration Flexible** : Variables d'environnement et dÃ©tection automatique
- ðŸ“± **Design Adaptatif** : Fonctionne sur ordinateurs et appareils mobiles

**DÃ©marrage Rapide :**
```cmd
# Run with default settings (recommended)
chainlit run samples\04\app.py -w --port 8080

# Use specific model
set MODEL=qwen2.5-7b-instruct
chainlit run samples\04\app.py -w --port 8080

# Manual endpoint configuration
set BASE_URL=http://localhost:51211
set API_KEY=your-api-key
chainlit run samples\04\app.py -w --port 8080
```

### DÃ©mo WebGPU dans le Navigateur

**CaractÃ©ristiques :**
- ðŸŒ **IA Natif au Navigateur** : Pas besoin de serveur, fonctionne entiÃ¨rement dans le navigateur
- âš¡ **AccÃ©lÃ©ration WebGPU** : AccÃ©lÃ©ration matÃ©rielle lorsque disponible
- ðŸ”’ **ConfidentialitÃ© Maximale** : Les donnÃ©es ne quittent jamais votre appareil
- ðŸŽ¯ **Installation ZÃ©ro** : Fonctionne dans tout navigateur compatible
- ðŸ”„ **Fallback en Douceur** : Bascule sur le CPU si WebGPU n'est pas disponible

**ExÃ©cution :**
```cmd
cd samples\04\webgpu-demo
python -m http.server 5173
# Open http://localhost:5173
```

### IntÃ©gration Open WebUI

**CaractÃ©ristiques :**
- ðŸŽ¨ **Interface Similaire Ã  ChatGPT** : UI professionnelle et familiÃ¨re
- ðŸ‘¥ **Support Multi-utilisateurs** : Comptes utilisateurs et historique des conversations
- ðŸ“ **Traitement de Fichiers** : TÃ©lÃ©chargement et analyse de documents
- ðŸ”„ **Changement de ModÃ¨le** : Commutation facile entre diffÃ©rents modÃ¨les
- ðŸ³ **DÃ©ploiement Docker** : Configuration prÃªte pour la production en conteneur

**Configuration Rapide :**
```cmd
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

## RÃ©fÃ©rence de Configuration

### Variables d'Environnement

| Variable | Description | Valeur par DÃ©faut | Exemple |
|----------|-------------|-------------------|---------|
| `MODEL` | Alias du modÃ¨le Ã  utiliser | `phi-4-mini` | `qwen2.5-7b-instruct` |
| `BASE_URL` | Point de terminaison Foundry Local | DÃ©tectÃ© automatiquement | `http://localhost:51211` |
| `API_KEY` | ClÃ© API (optionnelle pour local) | `""` | `your-api-key` |

## RÃ©solution des ProblÃ¨mes

### ProblÃ¨mes Courants

**Application Chainlit :**

1. **Service non disponible :**
   ```cmd
   # Check Foundry Local status
   foundry service status
   foundry service ps
   
   # Validate API endpoint (note: port 51211)
   curl http://localhost:51211/v1/models
   ```

2. **Conflits de port :**
   ```cmd
   # Check what's using port 8080
   netstat -ano | findstr :8080
   
   # Use different port if needed
   chainlit run samples\04\app.py -w --port 3000
   ```

3. **ProblÃ¨mes d'environnement Python :**
   ```cmd
   # Verify correct interpreter in VS Code
   # Ctrl+Shift+P â†’ Python: Select Interpreter
   # Choose: Module08/.venv/Scripts/python.exe
   
   # Reinstall dependencies
   pip install -r requirements.txt
   ```

**DÃ©mo WebGPU :**

1. **WebGPU non supportÃ© :**
   - Mettre Ã  jour vers Chrome/Edge 113+
   - Activer WebGPU : `chrome://flags/#enable-unsafe-webgpu`
   - VÃ©rifier le statut GPU : `chrome://gpu`
   - La dÃ©mo basculera automatiquement sur le CPU

2. **Erreurs de chargement de modÃ¨le :**
   - VÃ©rifier la connexion internet pour le tÃ©lÃ©chargement du modÃ¨le
   - Consulter la console du navigateur pour les erreurs CORS
   - VÃ©rifier que vous servez via HTTP (pas file://)

**Open WebUI :**

1. **Connexion refusÃ©e :**
   ```cmd
   # Check Docker is running
   docker --version
   
   # Check container status
   docker ps | findstr open-webui
   
   # View container logs
   docker logs open-webui
   ```

2. **ModÃ¨les non visibles :**
   ```cmd
   # Verify Foundry Local endpoint
   curl http://localhost:51211/v1/models
   
   # Restart Open WebUI
   docker restart open-webui
   ```

### Liste de Validation

```cmd
# âœ… 1. Foundry Local Setup
foundry --version                    # Should show version
foundry service status               # Should show "running"
foundry model list                   # Should show loaded models
curl http://localhost:51211/v1/models  # Should return JSON

# âœ… 2. Python Environment  
python --version                     # Should be 3.10+
pip list | findstr chainlit         # Should show chainlit package
pip list | findstr openai           # Should show openai package

# âœ… 3. Application Testing
chainlit run samples\04\app.py -w --port 8080  # Should open browser
# Test WebGPU demo at localhost:5173
# Test Open WebUI at localhost:3000
```

## Utilisation AvancÃ©e

### Optimisation des Performances

**Chainlit :**
- Utiliser le streaming pour une meilleure perception des performances
- ImplÃ©menter le pooling de connexions pour une haute concurrence
- Mettre en cache les rÃ©ponses des modÃ¨les pour les requÃªtes rÃ©pÃ©tÃ©es
- Surveiller l'utilisation de la mÃ©moire avec des historiques de conversation volumineux

**WebGPU :**
- Utiliser WebGPU pour une confidentialitÃ© et une vitesse maximales
- ImplÃ©menter la quantification des modÃ¨les pour des modÃ¨les plus petits
- Utiliser les Web Workers pour le traitement en arriÃ¨re-plan
- Mettre en cache les modÃ¨les compilÃ©s dans le stockage du navigateur

**Open WebUI :**
- Utiliser des volumes persistants pour l'historique des conversations
- Configurer des limites de ressources pour le conteneur Docker
- ImplÃ©menter des stratÃ©gies de sauvegarde pour les donnÃ©es utilisateur
- Configurer un proxy inverse pour la terminaison SSL

### ModÃ¨les d'IntÃ©gration

**Hybride Local/Cloud :**
```python
# Route based on complexity and privacy requirements
async def intelligent_routing(prompt: str, metadata: dict):
    if metadata.get("contains_pii"):
        return await foundry_local_completion(prompt)  # Privacy-sensitive
    elif len(prompt.split()) > 200:
        return await azure_openai_completion(prompt)   # Complex reasoning
    else:
        return await foundry_local_completion(prompt)  # Default local
```

**Pipeline Multi-modal :**
```python
# Combine different AI capabilities
async def analyze_document(file_path: str):
    # 1. OCR with WebGPU (browser-based)
    text = await webgpu_ocr(file_path)
    
    # 2. Analysis with Foundry Local (private)
    summary = await foundry_local_analyze(text)
    
    # 3. Enhancement with cloud (if needed)
    if summary.confidence < 0.8:
        summary = await azure_openai_enhance(summary)
    
    return summary
```

## DÃ©ploiement en Production

### ConsidÃ©rations de SÃ©curitÃ©

- **ClÃ©s API** : Utiliser des variables d'environnement, ne jamais les coder en dur
- **RÃ©seau** : Utiliser HTTPS en production, envisager un VPN pour l'accÃ¨s en Ã©quipe
- **ContrÃ´le d'AccÃ¨s** : ImplÃ©menter l'authentification pour Open WebUI
- **ConfidentialitÃ© des DonnÃ©es** : Auditer les donnÃ©es locales vs celles envoyÃ©es au cloud
- **Mises Ã  Jour** : Maintenir Foundry Local et les conteneurs Ã  jour

### Surveillance et Maintenance

- **VÃ©rifications de SantÃ©** : ImplÃ©menter la surveillance des points de terminaison
- **Journalisation** : Centraliser les journaux de tous les composants
- **MÃ©triques** : Suivre les temps de rÃ©ponse, taux d'erreur, utilisation des ressources
- **Sauvegarde** : Sauvegarde rÃ©guliÃ¨re des donnÃ©es de conversation et des configurations

## RÃ©fÃ©rences et Ressources

### Documentation
- [Documentation Chainlit](https://docs.chainlit.io/) - Guide complet du framework
- [Documentation Foundry Local](https://learn.microsoft.com/azure/ai-foundry/foundry-local/) - Documentation officielle de Microsoft
- [ONNX Runtime Web](https://onnxruntime.ai/docs/get-started/with-javascript/web.html) - IntÃ©gration WebGPU
- [Documentation Open WebUI](https://docs.openwebui.com/) - Configuration avancÃ©e

### Fichiers Exemple
- [`app.py`](../../../../../Module08/samples/04/app.py) - Application Chainlit en production
- [`chainlit_app.ipynb`](./chainlit_app.ipynb) - Notebook Ã©ducatif
- [`webgpu-demo/`](../../../../../Module08/samples/04/webgpu-demo) - InfÃ©rence IA basÃ©e sur le navigateur
- [`open-webui-guide.md`](./open-webui-guide.md) - Configuration complÃ¨te Open WebUI

### Exemples Connexes
- [Documentation Session 4](../../04.CuttingEdgeModels.md) - Guide complet de la session
- [Exemples Foundry Local](https://github.com/microsoft/foundry-local/tree/main/samples) - Exemples officiels

---

