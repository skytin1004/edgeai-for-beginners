<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a405c29d4e4241d954e24c47bedd739a",
  "translation_date": "2025-07-22T10:00:27+00:00",
  "source_file": "README.md",
  "language_code": "fr"
}
-->
# EdgeAI pour D√©butants

![Image de couverture du cours](../../translated_images/cover.eb18d1b9605d754b30973f4e17c6e11ea4f8473d9686ee378d6e7b44e3c70ac7.fr.png)

[![Contributeurs GitHub](https://img.shields.io/github/contributors/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/graphs/contributors)  
[![Probl√®mes GitHub](https://img.shields.io/github/issues/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/issues)  
[![Pull-requests GitHub](https://img.shields.io/github/issues-pr/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/pulls)  
[![PRs Bienvenus](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)  

[![Observateurs GitHub](https://img.shields.io/github/watchers/microsoft/edgeai-for-beginners.svg?style=social&label=Watch)](https://GitHub.com/microsoft/edgeai-for-beginners/watchers)  
[![Forks GitHub](https://img.shields.io/github/forks/microsoft/edgeai-for-beginners.svg?style=social&label=Fork)](https://GitHub.com/microsoft/edgeai-for-beginners/fork)  
[![√âtoiles GitHub](https://img.shields.io/github/stars/microsoft/edgeai-for-beginners?style=social&label=Star)](https://GitHub.com/microsoft/edgeai-for-beginners/stargazers)  

[![Discord Microsoft Azure AI Foundry](https://dcbadge.limes.pink/api/server/ByRwuEEgH4)](https://discord.com/invite/ByRwuEEgH4)

Suivez ces √©tapes pour commencer √† utiliser ces ressources :

1. **Forkez le d√©p√¥t** : Cliquez sur [![Forks GitHub](https://img.shields.io/github/forks/microsoft/edgeai-for-beginners.svg?style=social&label=Fork)](https://GitHub.com/microsoft/edgeai-for-beginners/fork)  
2. **Clonez le d√©p√¥t** : `git clone https://github.com/microsoft/edgeai-for-beginners.git`  
3. [**Rejoignez le Discord Azure AI Foundry pour rencontrer des experts et d'autres d√©veloppeurs**](https://discord.com/invite/ByRwuEEgH4)

### üåê Support Multilingue

#### Pris en charge via GitHub Action (Automatis√© & Toujours √† jour)

[Fran√ßais](./README.md) | [Espagnol](../es/README.md) | [Chinois (Simplifi√©)](../zh/README.md) | [Chinois (Traditionnel, Macao)](../mo/README.md) | [Chinois (Traditionnel, Hong Kong)](../hk/README.md) | [Chinois (Traditionnel, Ta√Øwan)](../tw/README.md) | [Japonais](../ja/README.md) | [Cor√©en](../ko/README.md)

Bienvenue dans EdgeAI pour D√©butants, o√π la puissance des mod√®les de langage rencontre l'efficacit√© des appareils locaux. Ce cours introduit comment de petits mod√®les de langage optimis√©s (SLMs) peuvent fonctionner directement sur du mat√©riel edge‚Äîsmartphones, cartes IoT et serveurs compacts‚Äîsans n√©cessiter d'acc√®s au cloud. Vous d√©couvrirez comment l'inf√©rence IA en temps r√©el, respectueuse de la vie priv√©e, r√©volutionne les maisons intelligentes, la surveillance industrielle et les applications hors ligne, gr√¢ce √† des d√©ploiements l√©gers con√ßus pour la rapidit√©, la s√©curit√© et la modularit√©.

**Edge AI**

Edge AI d√©signe l'ex√©cution d'algorithmes d'IA et de mod√®les de langage localement sur du mat√©riel‚Äîproche de l'endroit o√π les donn√©es sont g√©n√©r√©es‚Äîsans d√©pendre des ressources cloud pour l'inf√©rence. Cela r√©duit la latence, am√©liore la confidentialit√© et permet une prise de d√©cision en temps r√©el.

Principes fondamentaux :
- Inf√©rence sur appareil : Les mod√®les d'IA s'ex√©cutent sur des appareils edge (t√©l√©phones, routeurs, microcontr√¥leurs, PC industriels).
- Fonctionnement hors ligne : Op√®re sans connexion internet permanente.
- Faible latence : R√©ponses imm√©diates adapt√©es aux syst√®mes en temps r√©el.
- Souverainet√© des donn√©es : Les donn√©es sensibles restent locales, am√©liorant la s√©curit√© et la conformit√©.

**Petits Mod√®les de Langage (SLMs)**  
Les SLMs comme Phi-4, Mistral-7B ou Gemma sont des versions optimis√©es de grands mod√®les de langage (LLMs)‚Äîentra√Æn√©es ou distill√©es pour :  
- R√©duire l'empreinte m√©moire  
- Diminuer les besoins en calcul  
- Acc√©l√©rer les temps de d√©marrage  

Ils offrent des capacit√©s NLP puissantes tout en respectant les contraintes de :  
- Syst√®mes embarqu√©s  
- Appareils mobiles  
- Dispositifs IoT  
- Serveurs edge avec GPU limit√©  
- Ordinateurs personnels  

## Architecture du Cours

### [Module 01 : Fondamentaux et Transformation de l'EdgeAI](./Module01/README.md)  
**Th√®me** : La transformation apport√©e par le d√©ploiement de l'EdgeAI  

#### Structure des chapitres :  
- [**Section 1 : Fondamentaux de l'EdgeAI**](./Module01/01.EdgeAIFundamentals.md)  
  - Comparaison entre IA cloud traditionnelle et IA edge  
  - D√©fis et contraintes de l'informatique edge  
  - Technologies cl√©s : quantification des mod√®les, optimisation par compression, Petits Mod√®les de Langage (SLMs)  
  - Acc√©l√©ration mat√©rielle : NPUs, optimisation GPU, optimisation CPU  
  - Avantages : s√©curit√© de la vie priv√©e, faible latence, capacit√©s hors ligne, efficacit√© des co√ªts  

- [**Section 2 : √âtudes de Cas R√©els**](./Module01/02.RealWorldCaseStudies.md)  
  - √âcosyst√®me de mod√®les Microsoft Phi & Mu  
  - √âtude de cas : syst√®me de reporting IA de Japan Airlines  
  - Impact sur le march√© et orientations futures  
  - Consid√©rations de d√©ploiement et meilleures pratiques  

- [**Section 3 : Guide Pratique de Mise en ≈íuvre**](./Module01/03.PracticalImplementationGuide.md)  
  - Configuration de l'environnement de d√©veloppement (Python 3.10+, .NET 8+)  
  - Exigences mat√©rielles et configurations recommand√©es  
  - Ressources des familles de mod√®les principaux  
  - Outils de quantification et d'optimisation (Llama.cpp, Microsoft Olive, Apple MLX)  
  - Liste de v√©rification pour l'√©valuation et la validation  

- [**Section 4 : Plateformes Mat√©rielles pour le D√©ploiement Edge AI**](./Module01/04.EdgeDeployment.md)  
  - Consid√©rations et exigences pour le d√©ploiement Edge AI  
  - Mat√©riel Edge AI d'Intel et techniques d'optimisation  
  - Solutions IA de Qualcomm pour syst√®mes mobiles et embarqu√©s  
  - Plateformes de calcul edge NVIDIA Jetson  
  - Plateformes PC Windows AI avec acc√©l√©ration NPU  
  - Strat√©gies d'optimisation sp√©cifiques au mat√©riel  

---

### [Module 02 : Fondations des Petits Mod√®les de Langage](./Module02/README.md)  
**Th√®me** : Principes th√©oriques des SLMs, strat√©gies de mise en ≈ìuvre et d√©ploiement en production  

#### Structure des chapitres :  
- [**Section 1 : Fondamentaux de la Famille de Mod√®les Microsoft Phi**](./Module02/01.PhiFamily.md)  
  - √âvolution de la philosophie de conception (Phi-1 √† Phi-4)  
  - Conception ax√©e sur l'efficacit√©  
  - Capacit√©s sp√©cialis√©es (raisonnement, multimodal, d√©ploiement edge)  

- [**Section 2 : Fondamentaux de la Famille Qwen**](./Module02/02.QwenFamily.md)  
  - Excellence open source (Qwen 1.0 √† Qwen3) - disponible via Hugging Face  
  - Architecture avanc√©e de raisonnement avec capacit√©s de mode r√©flexion  
  - Options de d√©ploiement √©volutives (0.5B-235B param√®tres)  

- [**Section 3 : Fondamentaux de la Famille Gemma**](./Module02/03.GemmaFamily.md)  
  - Innovation ax√©e sur la recherche (Gemma 3 & 3n)  
  - Excellence multimodale  
  - Architecture mobile-first  

- [**Section 4 : Fondamentaux de la Famille BitNET**](./Module02/04.BitNETFamily.md)  
  - Technologie de quantification r√©volutionnaire (1.58-bit)  
  - Cadre d'inf√©rence sp√©cialis√© depuis https://github.com/microsoft/BitNet  
  - Leadership en IA durable gr√¢ce √† une efficacit√© extr√™me  

- [**Section 5 : Fondamentaux du Mod√®le Microsoft Mu**](./Module02/05.mumodel.md)  
  - Architecture orient√©e appareil int√©gr√©e √† Windows 11  
  - Int√©gration syst√®me avec les Param√®tres de Windows 11  
  - Fonctionnement hors ligne respectueux de la vie priv√©e  

- [**Section 6 : Fondamentaux de Phi-Silica**](./Module02/06.phisilica.md)  
  - Architecture optimis√©e pour NPU int√©gr√©e aux PC Windows 11 Copilot+  
  - Efficacit√© exceptionnelle (650 tokens/seconde √† 1.5W)  
  - Int√©gration pour d√©veloppeurs avec le SDK Windows App  

---

### [Module 03 : D√©ploiement des Petits Mod√®les de Langage](./Module03/README.md)  
**Th√®me** : Cycle complet de d√©ploiement des SLMs, de la th√©orie √† l'environnement de production  

#### Structure des chapitres :  
- [**Section 1 : Apprentissage Avanc√© des SLMs**](./Module03/01.SLMAdvancedLearning.md)  
  - Cadre de classification des param√®tres (Micro SLM 100M-1.4B, Medium SLM 14B-30B)  
  - Techniques d'optimisation avanc√©es (m√©thodes de quantification, quantification 1-bit BitNET)  
  - Strat√©gies d'acquisition de mod√®les (Azure AI Foundry pour les mod√®les Phi, Hugging Face pour certains mod√®les)  

- [**Section 2 : D√©ploiement en Environnement Local**](./Module03/02.DeployingSLMinLocalEnv.md)  
  - D√©ploiement universel sur la plateforme Ollama  
  - Solutions locales de niveau entreprise Microsoft Foundry  
  - Analyse comparative des cadres  

- [**Section 3 : D√©ploiement Cloud Conteneuris√©**](./Module03/03.DeployingSLMinCloud.md)  
  - D√©ploiement d'inf√©rence haute performance vLLM  
  - Orchestration de conteneurs Ollama  
  - Impl√©mentation optimis√©e pour edge avec ONNX Runtime  

---  

### [Module 04 : Conversion de Format et Quantification des Mod√®les](./Module04/README.md)  
**Th√®me** : Bo√Æte √† outils compl√®te pour l'optimisation des mod√®les en vue d'un d√©ploiement edge sur diff√©rentes plateformes  

#### Structure des chapitres :  
- [**Section 1 : Fondations de la Conversion de Format et de la Quantification des Mod√®les**](./Module04/01.Introduce.md)  
  - Cadre de classification de pr√©cision (ultra-faible, faible, moyenne pr√©cision)  
  - Avantages et cas d'utilisation des formats GGUF et ONNX  
  - B√©n√©fices de la quantification pour l'efficacit√© op√©rationnelle  
  - Comparaisons de performances et empreintes m√©moire  

- [**Section 2 : Guide d'Impl√©mentation Llama.cpp**](./Module04/02.Llamacpp.md)  
  - Installation multiplateforme (Windows, macOS, Linux)  
  - Conversion au format GGUF et niveaux de quantification (Q2_K √† Q8_0)  
  - Acc√©l√©ration mat√©rielle (CUDA, Metal, OpenCL, Vulkan)  
  - Int√©gration Python et d√©ploiement REST API  

- [**Section 3 : Suite d'Optimisation Microsoft Olive**](./Module04/03.MicrosoftOlive.md)  
  - Optimisation des mod√®les adapt√©e au mat√©riel avec plus de 40 composants int√©gr√©s  
  - Auto-optimisation avec quantification dynamique et statique  
  - Int√©gration en entreprise avec les workflows Azure ML  
  - Support des mod√®les populaires (Llama, Phi, certains mod√®les Qwen, Gemma)  

- [**Section 4 : Exploration Approfondie du Framework Apple MLX**](./Module04/04.AppleMLX.md)  
  - Architecture m√©moire unifi√©e pour Apple Silicon  
  - Support pour LLaMA, Mistral, Phi-3, certains mod√®les Qwen  
  - Fine-tuning LoRA et personnalisation des mod√®les  
  - Int√©gration Hugging Face avec quantification 4-bit/8-bit  

---  

### [Module 05 : SLMOps - Op√©rations sur les Petits Mod√®les de Langage](./Module05/README.md)  
**Th√®me** : Cycle complet des op√©rations SLM, de la distillation au d√©ploiement en production  

#### Structure des chapitres :  
- [**Section 1 : Introduction aux SLMOps**](./Module05/01.IntroduceSLMOps.md)  
  - Changement de paradigme des SLMOps dans les op√©rations IA  
  - Architecture ax√©e sur l'efficacit√© des co√ªts et la confidentialit√©  
  - Impact strat√©gique sur les entreprises et avantages concurrentiels  
  - D√©fis et solutions pour la mise en ≈ìuvre r√©elle  

- [**Section 2 : Distillation des Mod√®les - De la Th√©orie √† la Pratique**](./Module05/02.SLMOps-Distillation.md)  
  - Transfert de connaissances des mod√®les enseignants aux mod√®les √©tudiants  
  - Mise en ≈ìuvre du processus de distillation en deux √©tapes  
  - Workflows de distillation Azure ML avec exemples pratiques  
  - R√©duction de 85 % du temps d'inf√©rence avec une r√©tention de pr√©cision de 92 %  

- [**Section 3 : Fine-Tuning - Personnalisation des Mod√®les pour des T√¢ches Sp√©cifiques**](./Module05/03.SLMOps-Finetuing.md)  
  - Techniques de fine-tuning efficaces en param√®tres (PEFT)  
  - M√©thodes avanc√©es LoRA et QLoRA  
  - Impl√©mentation de fine-tuning avec Microsoft Olive  
  - Entra√Ænement multi-adaptateurs et optimisation des hyperparam√®tres  

- [**Section 4 : D√©ploiement - Mise en ≈íuvre Pr√™te pour la Production**](./Module05/04.SLMOps.Deployment.md)  
  - Conversion et quantification des mod√®les pour la production  
  - Configuration de d√©ploiement Foundry Local  
  - Validation de la qualit√© et benchmarking des performances  
  - R√©duction de 75 % de la taille avec surveillance en production  

---  

### [Module 06 : Syst√®mes Agentiques SLM - Agents IA et Appels de Fonctionnalit√©s](./Module06/README.md)  
**Th√®me** : Mise en ≈ìuvre des syst√®mes agentiques SLM, des bases aux appels de fonctionnalit√©s avanc√©s et √† l'int√©gration du Protocole de Contexte Mod√®le  

#### Structure des chapitres :  
- [**Section 1 : Fondations des Agents IA et des Petits Mod√®les de Langage**](./Module06/01.IntroduceAgent.md)  
  - Cadre de classification des agents (r√©flexes, bas√©s sur des mod√®les, bas√©s sur des objectifs, agents apprenants)  
  - Fondamentaux des SLM et strat√©gies d'optimisation (GGUF, quantification, frameworks edge)  
  - Analyse des compromis SLM vs LLM (r√©duction des co√ªts de 10-30√ó, efficacit√© des t√¢ches de 70-80 %)  
  - D√©ploiement pratique avec Ollama, VLLM et solutions edge Microsoft  

- [**Section 2 : Appels de Fonctionnalit√©s dans les Petits Mod√®les de Langage**](./Module06/02.FunctionCalling.md)  
- Mise en ≈ìuvre syst√©matique du flux de travail (d√©tection d'intention, sortie JSON, ex√©cution externe)
- Impl√©mentations sp√©cifiques √† la plateforme (Phi-4-mini, mod√®les Qwen s√©lectionn√©s, Microsoft Foundry Local)
- Exemples avanc√©s (collaboration multi-agents, s√©lection dynamique d'outils)
- Consid√©rations pour la production (limitation de d√©bit, journalisation d'audit, mesures de s√©curit√©)

- [**Section 3 : Int√©gration du protocole de contexte de mod√®le (MCP)**](./Module06/03.IntroduceMCP.md)
  - Architecture du protocole et conception de syst√®me en couches
  - Support multi-backend (Ollama pour le d√©veloppement, vLLM pour la production)
  - Protocoles de connexion (modes STDIO et SSE)
  - Applications concr√®tes (automatisation web, traitement de donn√©es, int√©gration API)

---

### [Module 07 : √âchantillons d'impl√©mentation EdgeAI](./Module07/README.md)
**Th√®me** : Impl√©mentations compl√®tes d'EdgeAI sur diverses plateformes et frameworks

#### Structure des chapitres :
- [**EdgeAI sur NVIDIA Jetson Orin Nano**](./Module07/README.md#1-edgeai-in-nvidia-jetson-orin-nano)
  - Performance IA de 67 TOPS dans un format de la taille d'une carte de cr√©dit
  - Support des mod√®les d'IA g√©n√©rative (transformateurs de vision, LLMs, mod√®les vision-langage)
  - Applications en robotique, drones, cam√©ras intelligentes, dispositifs autonomes
  - Plateforme abordable √† 249 $ pour un d√©veloppement d'IA d√©mocratis√©

- [**EdgeAI dans les applications mobiles avec .NET MAUI et ONNX Runtime GenAI**](./Module07/README.md#2-edgeai-in-mobile-applications-with-net-maui-and-onnx-runtime-genai)
  - IA mobile multiplateforme avec un code C# unique
  - Support de l'acc√©l√©ration mat√©rielle (CPU, GPU, processeurs IA mobiles)
  - Optimisations sp√©cifiques √† la plateforme (CoreML pour iOS, NNAPI pour Android)
  - Impl√©mentation compl√®te de la boucle d'IA g√©n√©rative

- [**EdgeAI sur Azure avec Small Language Models Engine**](./Module07/README.md#3-edgeai-in-azure-with-small-language-models-engine)
  - Architecture de d√©ploiement hybride cloud-edge
  - Int√©gration des services Azure AI avec ONNX Runtime
  - D√©ploiement √† l'√©chelle de l'entreprise et gestion continue des mod√®les
  - Flux de travail hybrides pour le traitement intelligent de documents

- [**EdgeAI avec Windows ML**](./Module07/README.md#4-edgeai-with-windows-ml)
  - Fondation Windows AI Foundry pour une inf√©rence performante sur appareil
  - Support mat√©riel universel (AMD, Intel, NVIDIA, Qualcomm)
  - Abstraction et optimisation mat√©rielle automatique
  - Framework unifi√© pour un √©cosyst√®me mat√©riel diversifi√© sous Windows

- [**EdgeAI avec les applications Foundry Local**](./Module07/README.md#5-edgeai-with-foundry-local-applications)
  - Impl√©mentation RAG ax√©e sur la confidentialit√© avec des ressources locales
  - Int√©gration du mod√®le linguistique Phi-3 avec recherche s√©mantique (mod√®les Phi uniquement)
  - Support des bases de donn√©es vectorielles locales (SQLite, Qdrant)
  - Capacit√©s de souverainet√© des donn√©es et fonctionnement hors ligne

## Aper√ßu des r√©sultats d'apprentissage

### R√©sultats d'apprentissage du Module 01 :
- Comprendre les diff√©rences fondamentales entre les architectures cloud et edge AI
- Ma√Ætriser les techniques d'optimisation de base pour le d√©ploiement edge
- Reconna√Ætre les applications concr√®tes et les histoires de r√©ussite
- Acqu√©rir des comp√©tences pratiques pour impl√©menter des solutions EdgeAI

### R√©sultats d'apprentissage du Module 02 :
- Compr√©hension approfondie des diff√©rentes philosophies de conception des SLM et de leurs implications de d√©ploiement
- Ma√Ætriser les capacit√©s de prise de d√©cision strat√©gique bas√©es sur les contraintes computationnelles et les exigences de performance
- Comprendre les compromis de flexibilit√© de d√©ploiement
- Poss√©der des perspectives pr√™tes pour l'avenir sur des architectures IA efficaces

### R√©sultats d'apprentissage du Module 03 :
- Capacit√©s strat√©giques de s√©lection de mod√®les
- Ma√Ætrise des techniques d'optimisation
- Ma√Ætrise de la flexibilit√© de d√©ploiement
- Capacit√©s de configuration pr√™tes pour la production

### R√©sultats d'apprentissage du Module 04 :
- Compr√©hension approfondie des limites de quantification et des applications pratiques
- Exp√©rience pratique avec plusieurs frameworks d'optimisation (Llama.cpp, Olive, MLX)
- Capacit√©s de s√©lection d'optimisation adapt√©es au mat√©riel
- Comp√©tences de d√©ploiement en production pour des environnements edge computing multiplateformes

### R√©sultats d'apprentissage du Module 05 :
- Ma√Ætriser le paradigme SLMOps et les principes op√©rationnels
- Impl√©menter la distillation de mod√®les pour le transfert de connaissances et l'optimisation de l'efficacit√©
- Appliquer des techniques de fine-tuning pour la personnalisation de mod√®les sp√©cifiques au domaine
- D√©ployer des solutions SLM pr√™tes pour la production avec des strat√©gies de surveillance et de maintenance

### R√©sultats d'apprentissage du Module 06 :
- Comprendre les concepts fondamentaux des agents IA et de l'architecture des Small Language Models
- Ma√Ætriser l'impl√©mentation d'appels de fonctions sur plusieurs plateformes et frameworks
- Int√©grer le protocole de contexte de mod√®le (MCP) pour une interaction standardis√©e avec des outils externes
- Construire des syst√®mes agentiques sophistiqu√©s n√©cessitant une intervention humaine minimale

### R√©sultats d'apprentissage du Module 07 :
- Acqu√©rir une exp√©rience pratique avec diverses plateformes EdgeAI et strat√©gies d'impl√©mentation
- Ma√Ætriser les techniques d'optimisation sp√©cifiques au mat√©riel sur NVIDIA, mobile, Azure et Windows
- Comprendre les compromis de d√©ploiement entre performance, co√ªt et exigences de confidentialit√©
- D√©velopper des comp√©tences pratiques pour construire des applications EdgeAI concr√®tes dans diff√©rents √©cosyst√®mes

## Diagramme de structure de fichier

```
edgeai-for-beginners/
‚îú‚îÄ‚îÄ imgs/
‚îÇ   ‚îî‚îÄ‚îÄ cover.png
‚îú‚îÄ‚îÄ Module01/ (EdgeAI Fundamentals and Transformation)
‚îÇ   ‚îú‚îÄ‚îÄ 01.EdgeAIFundamentals.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.RealWorldCaseStudies.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.PracticalImplementationGuide.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.EdgeDeployment.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module02/ (Small Language Model Foundations)
‚îÇ   ‚îú‚îÄ‚îÄ 01.PhiFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.QwenFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.GemmaFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.BitNETFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 05.mumodel.md
‚îÇ   ‚îú‚îÄ‚îÄ 06.phisilica.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module03/ (SLM Deployment Practice)
‚îÇ   ‚îú‚îÄ‚îÄ 01.SLMAdvancedLearning.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.DeployingSLMinLocalEnv.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.DeployingSLMinCloud.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module04/ (Model Format Conversion and Quantization)
‚îÇ   ‚îú‚îÄ‚îÄ 01.Introduce.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.Llamacpp.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.MicrosoftOlive.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.AppleMLX.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module05/ (SLMOps - Small Language Model Operations)
‚îÇ   ‚îú‚îÄ‚îÄ 01.IntroduceSLMOps.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.SLMOps-Distillation.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.SLMOps-Finetuing.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.SLMOps.Deployment.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module06/ (SLM Agentic Systems)
‚îÇ   ‚îú‚îÄ‚îÄ 01.IntroduceAgent.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.FunctionCalling.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.IntroduceMCP.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module07/ (EdgeAI Implementation Samples)
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ CODE_OF_CONDUCT.md
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ README.md (This file)
‚îú‚îÄ‚îÄ SECURITY.md
‚îú‚îÄ‚îÄ STUDY_GUIDE.md
‚îî‚îÄ‚îÄ SUPPORT.md
```

## Caract√©ristiques du cours

- **Apprentissage progressif** : Avancez progressivement des concepts de base au d√©ploiement avanc√©
- **Int√©gration th√©orie et pratique** : Chaque module contient des bases th√©oriques et des op√©rations pratiques
- **√âtudes de cas r√©elles** : Bas√©es sur des cas r√©els de Microsoft, Alibaba, Google et autres
- **Pratique concr√®te** : Fichiers de configuration complets, proc√©dures de test API et scripts de d√©ploiement
- **Benchmarks de performance** : Comparaisons d√©taill√©es de vitesse d'inf√©rence, utilisation m√©moire et exigences de ressources
- **Consid√©rations de niveau entreprise** : Pratiques de s√©curit√©, cadres de conformit√© et strat√©gies de protection des donn√©es

## Commencer

Chemin d'apprentissage recommand√© :
1. Commencez par **Module01** pour construire une compr√©hension fondamentale de EdgeAI
2. Passez √† **Module02** pour comprendre en profondeur les diff√©rentes familles de mod√®les SLM
3. Apprenez **Module03** pour ma√Ætriser les comp√©tences pratiques de d√©ploiement
4. Continuez avec **Module04** pour l'optimisation avanc√©e des mod√®les et la conversion de formats
5. Compl√©tez **Module05** pour ma√Ætriser SLMOps pour des impl√©mentations pr√™tes pour la production
6. Explorez **Module06** pour comprendre les syst√®mes agentiques SLM et les capacit√©s d'appel de fonctions
7. Terminez avec **Module07** pour acqu√©rir une exp√©rience pratique avec des √©chantillons d'impl√©mentation EdgeAI diversifi√©s

Chaque module est con√ßu pour √™tre complet ind√©pendamment, mais un apprentissage s√©quentiel offrira les meilleurs r√©sultats.

## Guide d'√©tude

Un [Guide d'√©tude](STUDY_GUIDE.md) complet est disponible pour vous aider √† maximiser votre exp√©rience d'apprentissage. Le guide d'√©tude fournit :

- **Chemins d'apprentissage structur√©s** : Calendriers optimis√©s pour compl√©ter le cours en 20 heures
- **Conseils sur l'allocation du temps** : Recommandations sp√©cifiques pour √©quilibrer lecture, exercices et projets
- **Focus sur les concepts cl√©s** : Objectifs d'apprentissage prioritaires pour chaque module
- **Outils d'auto-√©valuation** : Questions et exercices pour tester votre compr√©hension
- **Id√©es de mini-projets** : Applications pratiques pour renforcer votre apprentissage

Le guide d'√©tude est con√ßu pour s'adapter √† un apprentissage intensif (1 semaine) ou √† un apprentissage √† temps partiel (3 semaines), avec des indications claires sur la fa√ßon de g√©rer votre temps efficacement m√™me si vous ne pouvez consacrer que 10 heures au cours.

---

**L'avenir de EdgeAI repose sur l'am√©lioration continue des architectures de mod√®les, des techniques de quantification et des strat√©gies de d√©ploiement qui privil√©gient l'efficacit√© et la sp√©cialisation plut√¥t que les capacit√©s g√©n√©ralistes. Les organisations qui adoptent ce changement de paradigme seront bien positionn√©es pour exploiter le potentiel transformateur de l'IA tout en gardant le contr√¥le sur leurs donn√©es et leurs op√©rations.**

## Autres cours

Notre √©quipe propose d'autres cours ! D√©couvrez :

- [MCP pour d√©butants](https://github.com/microsoft/mcp-for-beginners)
- [Agents IA pour d√©butants](https://github.com/microsoft/ai-agents-for-beginners?WT.mc_id=academic-105485-koreyst)
- [IA g√©n√©rative pour d√©butants avec .NET](https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst)
- [IA g√©n√©rative pour d√©butants avec JavaScript](https://github.com/microsoft/generative-ai-with-javascript?WT.mc_id=academic-105485-koreyst)
- [IA g√©n√©rative pour d√©butants](https://github.com/microsoft/generative-ai-for-beginners?WT.mc_id=academic-105485-koreyst)
- [ML pour d√©butants](https://aka.ms/ml-beginners?WT.mc_id=academic-105485-koreyst)
- [Data Science pour d√©butants](https://aka.ms/datascience-beginners?WT.mc_id=academic-105485-koreyst)
- [IA pour d√©butants](https://aka.ms/ai-beginners?WT.mc_id=academic-105485-koreyst)
- [Cybers√©curit√© pour d√©butants](https://github.com/microsoft/Security-101??WT.mc_id=academic-96948-sayoung)
- [D√©veloppement web pour d√©butants](https://aka.ms/webdev-beginners?WT.mc_id=academic-105485-koreyst)
- [IoT pour d√©butants](https://aka.ms/iot-beginners?WT.mc_id=academic-105485-koreyst)
- [D√©veloppement XR pour d√©butants](https://github.com/microsoft/xr-development-for-beginners?WT.mc_id=academic-105485-koreyst)
- [Ma√Ætriser GitHub Copilot pour la programmation assist√©e par IA](https://aka.ms/GitHubCopilotAI?WT.mc_id=academic-105485-koreyst)
- [Ma√Ætriser GitHub Copilot pour les d√©veloppeurs C#/.NET](https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers?WT.mc_id=academic-105485-koreyst)
- [Choisissez votre propre aventure Copilot](https://github.com/microsoft/CopilotAdventures?WT.mc_id=academic-105485-koreyst)

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction professionnelle r√©alis√©e par un humain. Nous ne sommes pas responsables des malentendus ou des interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.