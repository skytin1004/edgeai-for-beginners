<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3c232b8e9dac492a43b9c189f4cb04df",
  "translation_date": "2025-09-15T15:33:31+00:00",
  "source_file": "README.md",
  "language_code": "fr"
}
-->
# EdgeAI pour les D√©butants

![Image de couverture du cours](../../translated_images/cover.eb18d1b9605d754b30973f4e17c6e11ea4f8473d9686ee378d6e7b44e3c70ac7.fr.png)

[![Contributeurs GitHub](https://img.shields.io/github/contributors/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/graphs/contributors)  
[![Probl√®mes GitHub](https://img.shields.io/github/issues/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/issues)  
[![Pull-requests GitHub](https://img.shields.io/github/issues-pr/microsoft/edgeai-for-beginners.svg)](https://GitHub.com/microsoft/edgeai-for-beginners/pulls)  
[![PRs Bienvenus](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)  

[![Observateurs GitHub](https://img.shields.io/github/watchers/microsoft/edgeai-for-beginners.svg?style=social&label=Watch)](https://GitHub.com/microsoft/edgeai-for-beginners/watchers)  
[![Forks GitHub](https://img.shields.io/github/forks/microsoft/edgeai-for-beginners.svg?style=social&label=Fork)](https://GitHub.com/microsoft/edgeai-for-beginners/fork)  
[![√âtoiles GitHub](https://img.shields.io/github/stars/microsoft/edgeai-for-beginners?style=social&label=Star)](https://GitHub.com/microsoft/edgeai-for-beginners/stargazers)  

[![Discord Microsoft Azure AI Foundry](https://dcbadge.limes.pink/api/server/ByRwuEEgH4)](https://discord.com/invite/ByRwuEEgH4)

Suivez ces √©tapes pour commencer √† utiliser ces ressources :

1. **Forkez le d√©p√¥t** : Cliquez sur [![Forks GitHub](https://img.shields.io/github/forks/microsoft/edgeai-for-beginners.svg?style=social&label=Fork)](https://GitHub.com/microsoft/edgeai-for-beginners/fork)  
2. **Clonez le d√©p√¥t** : `git clone https://github.com/microsoft/edgeai-for-beginners.git`  
3. [**Rejoignez le Discord Azure AI Foundry pour rencontrer des experts et d'autres d√©veloppeurs**](https://discord.com/invite/ByRwuEEgH4)

### üåê Support Multilingue

#### Support√© via GitHub Action (Automatis√© & Toujours √† jour)

[Fran√ßais](./README.md) | [Espagnol](../es/README.md) | [Chinois (Simplifi√©)](../zh/README.md) | [Chinois (Traditionnel, Macao)](../mo/README.md) | [Chinois (Traditionnel, Hong Kong)](../hk/README.md) | [Chinois (Traditionnel, Ta√Øwan)](../tw/README.md) | [Japonais](../ja/README.md) | [Cor√©en](../ko/README.md)  
**Si vous souhaitez ajouter des langues suppl√©mentaires, les langues support√©es sont list√©es [ici](https://github.com/Azure/co-op-translator/blob/main/getting_started/supported-languages.md)**

## Introduction

Bienvenue dans **EdgeAI pour les D√©butants** ‚Äì votre parcours complet dans le monde transformateur de l'Intelligence Artificielle en p√©riph√©rie. Ce cours relie les capacit√©s puissantes de l'IA √† des d√©ploiements pratiques et r√©els sur des appareils en p√©riph√©rie, vous permettant de tirer parti du potentiel de l'IA directement l√† o√π les donn√©es sont g√©n√©r√©es et o√π les d√©cisions doivent √™tre prises.

### Ce que vous allez ma√Ætriser

Ce cours vous guide des concepts fondamentaux aux impl√©mentations pr√™tes pour la production, couvrant :
- **Mod√®les de Langage R√©duits (SLMs)** optimis√©s pour le d√©ploiement en p√©riph√©rie  
- **Optimisation adapt√©e au mat√©riel** sur diverses plateformes  
- **Inf√©rence en temps r√©el** avec des capacit√©s de pr√©servation de la vie priv√©e  
- **Strat√©gies de d√©ploiement en production** pour des applications d'entreprise  

### Pourquoi l'EdgeAI est important

L'Edge AI repr√©sente un changement de paradigme qui r√©pond √† des d√©fis modernes critiques :  
- **Confidentialit√© & S√©curit√©** : Traitez les donn√©es sensibles localement sans exposition au cloud  
- **Performance en temps r√©el** : √âliminez la latence r√©seau pour les applications critiques  
- **Efficacit√© des co√ªts** : R√©duisez les d√©penses de bande passante et de calcul dans le cloud  
- **Op√©rations r√©silientes** : Maintenez la fonctionnalit√© en cas de panne r√©seau  
- **Conformit√© r√©glementaire** : Respectez les exigences de souverainet√© des donn√©es  

### Edge AI

L'Edge AI consiste √† ex√©cuter des algorithmes d'IA et des mod√®les de langage localement sur du mat√©riel ‚Äì pr√®s de l'endroit o√π les donn√©es sont g√©n√©r√©es ‚Äì sans d√©pendre des ressources cloud pour l'inf√©rence. Cela r√©duit la latence, am√©liore la confidentialit√© et permet une prise de d√©cision en temps r√©el.

### Principes fondamentaux :
- **Inf√©rence sur appareil** : Les mod√®les d'IA s'ex√©cutent sur des appareils en p√©riph√©rie (t√©l√©phones, routeurs, microcontr√¥leurs, PC industriels)  
- **Capacit√© hors ligne** : Fonctionne sans connectivit√© Internet persistante  
- **Faible latence** : R√©ponses imm√©diates adapt√©es aux syst√®mes en temps r√©el  
- **Souverainet√© des donn√©es** : Conserve les donn√©es sensibles localement, am√©liorant la s√©curit√© et la conformit√©  

### Mod√®les de Langage R√©duits (SLMs)

Les SLMs comme Phi-4, Mistral-7B et Gemma sont des versions optimis√©es de grands mod√®les de langage ‚Äì entra√Æn√©s ou distill√©s pour :  
- **Empreinte m√©moire r√©duite** : Utilisation efficace de la m√©moire limit√©e des appareils en p√©riph√©rie  
- **Moins de demande de calcul** : Optimis√©s pour les performances CPU et GPU en p√©riph√©rie  
- **Temps de d√©marrage plus rapides** : Initialisation rapide pour des applications r√©actives  

Ils d√©bloquent des capacit√©s NLP puissantes tout en respectant les contraintes de :  
- **Syst√®mes embarqu√©s** : Appareils IoT et contr√¥leurs industriels  
- **Appareils mobiles** : Smartphones et tablettes avec capacit√©s hors ligne  
- **Appareils IoT** : Capteurs et appareils intelligents avec ressources limit√©es  
- **Serveurs en p√©riph√©rie** : Unit√©s de traitement locales avec ressources GPU limit√©es  
- **Ordinateurs personnels** : Sc√©narios de d√©ploiement sur ordinateurs de bureau et portables  

## Architecture du cours

### [Module 01 : Fondamentaux et Transformation de l'EdgeAI](./Module01/README.md)  
**Th√®me** : Le changement transformateur du d√©ploiement de l'Edge AI  

#### Structure des chapitres :  
- [**Section 1 : Fondamentaux de l'EdgeAI**](./Module01/01.EdgeAIFundamentals.md)  
  - Comparaison entre l'IA cloud traditionnelle et l'IA en p√©riph√©rie  
  - D√©fis et contraintes du calcul en p√©riph√©rie  
  - Technologies cl√©s : quantification des mod√®les, optimisation par compression, Mod√®les de Langage R√©duits (SLMs)  
  - Acc√©l√©ration mat√©rielle : NPUs, optimisation GPU, optimisation CPU  
  - Avantages : s√©curit√© de la confidentialit√©, faible latence, capacit√©s hors ligne, efficacit√© des co√ªts  

- [**Section 2 : √âtudes de cas r√©els**](./Module01/02.RealWorldCaseStudies.md)  
  - √âcosyst√®me de mod√®les Microsoft Phi & Mu  
  - √âtude de cas sur le syst√®me de reporting AI de Japan Airlines  
  - Impact sur le march√© et orientations futures  
  - Consid√©rations de d√©ploiement et meilleures pratiques  

- [**Section 3 : Guide pratique d'impl√©mentation**](./Module01/03.PracticalImplementationGuide.md)  
  - Configuration de l'environnement de d√©veloppement (Python 3.10+, .NET 8+)  
  - Exigences mat√©rielles et configurations recommand√©es  
  - Ressources des familles de mod√®les principaux  
  - Outils de quantification et d'optimisation (Llama.cpp, Microsoft Olive, Apple MLX)  
  - Liste de v√©rification pour l'√©valuation et la v√©rification  

- [**Section 4 : Plateformes mat√©rielles de d√©ploiement Edge AI**](./Module01/04.EdgeDeployment.md)  
  - Consid√©rations et exigences pour le d√©ploiement de l'Edge AI  
  - Mat√©riel Edge AI Intel et techniques d'optimisation  
  - Solutions AI Qualcomm pour syst√®mes mobiles et embarqu√©s  
  - Plateformes de calcul en p√©riph√©rie NVIDIA Jetson  
  - Plateformes PC Windows AI avec acc√©l√©ration NPU  
  - Strat√©gies d'optimisation sp√©cifiques au mat√©riel  

---

### [Module 02 : Fondations des Mod√®les de Langage R√©duits](./Module02/README.md)  
**Th√®me** : Principes th√©oriques des SLMs, strat√©gies d'impl√©mentation et d√©ploiement en production  

#### Structure des chapitres :  
- [**Section 1 : Fondamentaux de la famille de mod√®les Microsoft Phi**](./Module02/01.PhiFamily.md)  
  - √âvolution de la philosophie de conception (Phi-1 √† Phi-4)  
  - Conception ax√©e sur l'efficacit√©  
  - Capacit√©s sp√©cialis√©es (raisonnement, multimodal, d√©ploiement en p√©riph√©rie)  

- [**Section 2 : Fondamentaux de la famille Qwen**](./Module02/02.QwenFamily.md)  
  - Excellence open source (Qwen 1.0 √† Qwen3) - disponible via Hugging Face  
  - Architecture avanc√©e de raisonnement avec capacit√©s de mode r√©flexion  
  - Options de d√©ploiement √©volutives (0.5B-235B param√®tres)  

- [**Section 3 : Fondamentaux de la famille Gemma**](./Module02/03.GemmaFamily.md)  
  - Innovation ax√©e sur la recherche (Gemma 3 & 3n)  
  - Excellence multimodale  
  - Architecture ax√©e sur le mobile  

- [**Section 4 : Fondamentaux de la famille BitNET**](./Module02/04.BitNETFamily.md)  
  - Technologie r√©volutionnaire de quantification (1.58-bit)  
  - Cadre d'inf√©rence sp√©cialis√© depuis https://github.com/microsoft/BitNet  
  - Leadership en IA durable gr√¢ce √† une efficacit√© extr√™me  

- [**Section 5 : Fondamentaux du mod√®le Microsoft Mu**](./Module02/05.mumodel.md)  
  - Architecture ax√©e sur les appareils int√©gr√©e √† Windows 11  
  - Int√©gration syst√®me avec les param√®tres de Windows 11  
  - Fonctionnement hors ligne pr√©servant la confidentialit√©  

- [**Section 6 : Fondamentaux de Phi-Silica**](./Module02/06.phisilica.md)  
  - Architecture optimis√©e pour NPU int√©gr√©e aux PC Windows 11 Copilot+  
  - Efficacit√© exceptionnelle (650 tokens/seconde √† 1.5W)  
  - Int√©gration pour les d√©veloppeurs avec Windows App SDK  

---

### [Module 03 : D√©ploiement des Mod√®les de Langage R√©duits](./Module03/README.md)  
**Th√®me** : Cycle complet de d√©ploiement des SLMs, de la th√©orie √† l'environnement de production  

#### Structure des chapitres :  
- [**Section 1 : Apprentissage avanc√© des SLMs**](./Module03/01.SLMAdvancedLearning.md)  
  - Cadre de classification des param√®tres (Micro SLM 100M-1.4B, Medium SLM 14B-30B)  
  - Techniques avanc√©es d'optimisation (m√©thodes de quantification, quantification BitNET 1-bit)  
  - Strat√©gies d'acquisition de mod√®les (Azure AI Foundry pour les mod√®les Phi, Hugging Face pour les mod√®les s√©lectionn√©s)  

- [**Section 2 : D√©ploiement dans un environnement local**](./Module03/02.DeployingSLMinLocalEnv.md)  
  - D√©ploiement universel sur la plateforme Ollama  
  - Solutions locales de niveau entreprise Microsoft Foundry  
  - Analyse comparative des cadres  

- [**Section 3 : D√©ploiement en cloud conteneuris√©**](./Module03/03.DeployingSLMinCloud.md)  
  - D√©ploiement d'inf√©rence haute performance vLLM  
  - Orchestration de conteneurs Ollama  
  - Impl√©mentation optimis√©e pour la p√©riph√©rie avec ONNX Runtime  

---

### [Module 04 : Conversion de format et quantification des mod√®les](./Module04/README.md)  
**Th√®me** : Bo√Æte √† outils compl√®te d'optimisation des mod√®les pour le d√©ploiement en p√©riph√©rie sur diverses plateformes  

#### Structure des chapitres :  
- [**Section 1 : Fondations de la conversion de format et de la quantification des mod√®les**](./Module04/01.Introduce.md)  
  - Cadre de classification de pr√©cision (ultra-faible, faible, moyenne pr√©cision)  
  - Avantages et cas d'utilisation des formats GGUF et ONNX  
  - B√©n√©fices de la quantification pour l'efficacit√© op√©rationnelle  
  - Comparaisons de performances et empreintes m√©moire  

- [**Section 2 : Guide d'impl√©mentation de Llama.cpp**](./Module04/02.Llamacpp.md)  
  - Installation multiplateforme (Windows, macOS, Linux)  
  - Conversion au format GGUF et niveaux de quantification (Q2_K √† Q8_0)  
  - Acc√©l√©ration mat√©rielle (CUDA, Metal, OpenCL, Vulkan)  
  - Int√©gration Python et d√©ploiement API REST  

- [**Section 3 : Suite d'optimisation Microsoft Olive**](./Module04/03.MicrosoftOlive.md)  
  - Optimisation des mod√®les adapt√©e au mat√©riel avec plus de 40 composants int√©gr√©s  
  - Auto-optimisation avec quantification dynamique et statique  
  - Int√©gration entreprise avec les workflows Azure ML  
  - Support des mod√®les populaires (Llama, Phi, mod√®les Qwen s√©lectionn√©s, Gemma)  

- [**Section 4 : Exploration approfondie du framework Apple MLX**](./Module04/04.AppleMLX.md)  
  - Architecture m√©moire unifi√©e pour Apple Silicon  
  - Support pour LLaMA, Mistral, Phi-3, mod√®les Qwen s√©lectionn√©s  
  - Affinage LoRA et personnalisation des mod√®les  
  - Int√©gration Hugging Face avec quantification 4-bit/8-bit  

---

### [Module 05 : SLMOps - Op√©rations des Mod√®les de Langage R√©duits](./Module05/README.md)  
**Th√®me** : Cycle complet des op√©rations SLM, de la distillation au d√©ploiement en production  

#### Structure des chapitres :  
- [**Section 1 : Introduction aux SLMOps**](./Module05/01.IntroduceSLMOps.md)  
  - Changement de paradigme des SLMOps dans les op√©rations IA  
  - Architecture ax√©e sur l'efficacit√© des co√ªts et la confidentialit√©  
  - Impact strat√©gique sur les entreprises et avantages comp√©titifs  
  - D√©fis r√©els d'impl√©mentation et solutions  

- [**Section 2 : Distillation des mod√®les - De la th√©orie √† la pratique**](./Module05/02.SLMOps-Distillation.md)  
  - Transfert de connaissances des mod√®les enseignants aux mod√®les √©tudiants  
  - Impl√©mentation du processus de distillation en deux √©tapes  
  - Workflows de distillation Azure ML avec exemples pratiques  
  - R√©duction de 85% du temps d'inf√©rence avec une r√©tention de pr√©cision de 92%  

- [**Section 3 : Affinage - Personnalisation des mod√®les pour des t√¢ches sp√©cifiques**](./Module05/03.SLMOps-Finetuing.md)  
  - Techniques d'affinage efficaces en param√®tres (PEFT)  
  - M√©thodes avanc√©es LoRA et QLoRA  
  - Impl√©mentation d'affinage Microsoft Olive  
  - Formation multi-adaptateurs et optimisation des hyperparam√®tres  
- [**Section 4 : D√©ploiement - Mise en ≈ìuvre pr√™te pour la production**](./Module05/04.SLMOps.Deployment.md)
  - Conversion et quantification des mod√®les pour la production
  - Configuration de d√©ploiement Foundry Local
  - Benchmarking des performances et validation de la qualit√©
  - R√©duction de taille de 75 % avec surveillance en production

---

### [Module 06 : Syst√®mes agentiques SLM - Agents IA et appels de fonctions](./Module06/README.md)
**Th√®me** : Mise en ≈ìuvre des syst√®mes agentiques SLM, des bases aux appels de fonctions avanc√©s et int√©gration du protocole de contexte de mod√®le

#### Structure des chapitres :
- [**Section 1 : Fondations des agents IA et des petits mod√®les de langage**](./Module06/01.IntroduceAgent.md)
  - Cadre de classification des agents (r√©flexes, bas√©s sur des mod√®les, orient√©s objectifs, agents apprenants)
  - Fondamentaux des SLM et strat√©gies d'optimisation (GGUF, quantification, frameworks edge)
  - Analyse des compromis entre SLM et LLM (r√©duction des co√ªts de 10 √† 30√ó, efficacit√© des t√¢ches de 70 √† 80 %)
  - D√©ploiement pratique avec Ollama, VLLM et solutions Microsoft edge

- [**Section 2 : Appels de fonctions dans les petits mod√®les de langage**](./Module06/02.FunctionCalling.md)
  - Mise en ≈ìuvre de workflows syst√©matiques (d√©tection d'intention, sortie JSON, ex√©cution externe)
  - Impl√©mentations sp√©cifiques aux plateformes (Phi-4-mini, mod√®les Qwen s√©lectionn√©s, Microsoft Foundry Local)
  - Exemples avanc√©s (collaboration multi-agents, s√©lection dynamique d'outils)
  - Consid√©rations pour la production (limitation de d√©bit, journalisation d'audit, mesures de s√©curit√©)

- [**Section 3 : Int√©gration du protocole de contexte de mod√®le (MCP)**](./Module06/03.IntroduceMCP.md)
  - Architecture du protocole et conception de syst√®mes en couches
  - Support multi-backend (Ollama pour le d√©veloppement, vLLM pour la production)
  - Protocoles de connexion (modes STDIO et SSE)
  - Applications r√©elles (automatisation web, traitement de donn√©es, int√©gration API)

---

### [Module 07 : Exemples d'impl√©mentation EdgeAI](./Module07/README.md)
**Th√®me** : Impl√©mentations EdgeAI compl√®tes sur diverses plateformes et frameworks

#### Structure des chapitres :
- [**EdgeAI sur NVIDIA Jetson Orin Nano**](./Module07/README.md#1-edgeai-in-nvidia-jetson-orin-nano)
  - Performance IA de 67 TOPS dans un format de la taille d'une carte de cr√©dit
  - Support des mod√®les d'IA g√©n√©rative (transformateurs de vision, LLM, mod√®les vision-langage)
  - Applications en robotique, drones, cam√©ras intelligentes, dispositifs autonomes
  - Plateforme abordable √† 249 $ pour un d√©veloppement IA d√©mocratis√©

- [**EdgeAI dans les applications mobiles avec .NET MAUI et ONNX Runtime GenAI**](./Module07/README.md#2-edgeai-in-mobile-applications-with-net-maui-and-onnx-runtime-genai)
  - IA mobile multiplateforme avec un code C# unique
  - Support de l'acc√©l√©ration mat√©rielle (CPU, GPU, processeurs IA mobiles)
  - Optimisations sp√©cifiques aux plateformes (CoreML pour iOS, NNAPI pour Android)
  - Impl√©mentation compl√®te de la boucle d'IA g√©n√©rative

- [**EdgeAI sur Azure avec le moteur des petits mod√®les de langage**](./Module07/README.md#3-edgeai-in-azure-with-small-language-models-engine)
  - Architecture de d√©ploiement hybride cloud-edge
  - Int√©gration des services Azure AI avec ONNX Runtime
  - D√©ploiement √† l'√©chelle de l'entreprise et gestion continue des mod√®les
  - Workflows IA hybrides pour le traitement intelligent de documents

- [**EdgeAI avec Windows ML**](./Module07/README.md#4-edgeai-with-windows-ml)
  - Fondation Windows AI Foundry pour une inf√©rence performante sur appareil
  - Support mat√©riel universel (AMD, Intel, NVIDIA, Qualcomm)
  - Abstraction et optimisation mat√©rielle automatiques
  - Framework unifi√© pour un √©cosyst√®me mat√©riel Windows diversifi√©

- [**EdgeAI avec les applications Foundry Local**](./Module07/README.md#5-edgeai-with-foundry-local-applications)
  - Impl√©mentation RAG ax√©e sur la confidentialit√© avec des ressources locales
  - Int√©gration du mod√®le de langage Phi-3 avec recherche s√©mantique (mod√®les Phi uniquement)
  - Support des bases de donn√©es vectorielles locales (SQLite, Qdrant)
  - Capacit√©s de souverainet√© des donn√©es et fonctionnement hors ligne

## Objectifs d'apprentissage du cours

En compl√©tant ce cours complet sur EdgeAI, vous d√©velopperez l'expertise n√©cessaire pour concevoir, impl√©menter et d√©ployer des solutions EdgeAI pr√™tes pour la production. Notre approche structur√©e garantit que vous ma√Ætriserez √† la fois les bases th√©oriques et les comp√©tences pratiques.

### Comp√©tences techniques

**Connaissances de base**
- Comprendre les diff√©rences fondamentales entre les architectures IA bas√©es sur le cloud et celles bas√©es sur le edge
- Ma√Ætriser les principes de quantification, compression et optimisation des mod√®les pour des environnements contraints en ressources
- Comprendre les options d'acc√©l√©ration mat√©rielle (NPUs, GPUs, CPUs) et leurs implications de d√©ploiement

**Comp√©tences en impl√©mentation**
- D√©ployer des petits mod√®les de langage sur diverses plateformes edge (mobile, embarqu√©, IoT, serveurs edge)
- Appliquer des frameworks d'optimisation tels que Llama.cpp, Microsoft Olive, ONNX Runtime et Apple MLX
- Impl√©menter des syst√®mes d'inf√©rence en temps r√©el avec des exigences de r√©ponse sous la seconde

**Expertise en production**
- Concevoir des architectures EdgeAI √©volutives pour des applications d'entreprise
- Impl√©menter des strat√©gies de surveillance, maintenance et mise √† jour pour les syst√®mes d√©ploy√©s
- Appliquer les meilleures pratiques de s√©curit√© pour des impl√©mentations EdgeAI respectueuses de la vie priv√©e

### Capacit√©s strat√©giques

**Cadre de prise de d√©cision**
- √âvaluer les opportunit√©s EdgeAI et identifier les cas d'utilisation adapt√©s aux applications commerciales
- Analyser les compromis entre pr√©cision du mod√®le, vitesse d'inf√©rence, consommation d'√©nergie et co√ªts mat√©riels
- S√©lectionner les familles SLM et configurations appropri√©es en fonction des contraintes de d√©ploiement sp√©cifiques

**Architecture syst√®me**
- Concevoir des solutions EdgeAI de bout en bout int√©gr√©es √† l'infrastructure existante
- Planifier des architectures hybrides edge-cloud pour une performance et une efficacit√© des co√ªts optimales
- Impl√©menter des flux de donn√©es et des pipelines de traitement pour des applications IA en temps r√©el

### Applications industrielles

**Sc√©narios de d√©ploiement pratiques**
- **Fabrication** : Syst√®mes de contr√¥le qualit√©, maintenance pr√©dictive et optimisation des processus
- **Sant√©** : Outils de diagnostic respectueux de la vie priv√©e et syst√®mes de surveillance des patients
- **Transport** : Prise de d√©cision pour v√©hicules autonomes et gestion du trafic
- **Villes intelligentes** : Infrastructure intelligente et syst√®mes de gestion des ressources
- **√âlectronique grand public** : Applications mobiles aliment√©es par l'IA et dispositifs domestiques intelligents

## Aper√ßu des r√©sultats d'apprentissage

### R√©sultats d'apprentissage du Module 01 :
- Comprendre les diff√©rences fondamentales entre les architectures IA cloud et edge
- Ma√Ætriser les techniques d'optimisation de base pour le d√©ploiement edge
- Reconna√Ætre les applications r√©elles et les succ√®s
- Acqu√©rir des comp√©tences pratiques pour impl√©menter des solutions EdgeAI

### R√©sultats d'apprentissage du Module 02 :
- Compr√©hension approfondie des diff√©rentes philosophies de conception SLM et leurs implications de d√©ploiement
- Ma√Ætriser les capacit√©s de prise de d√©cision strat√©gique bas√©es sur les contraintes computationnelles et les exigences de performance
- Comprendre les compromis de flexibilit√© de d√©ploiement
- Poss√©der des perspectives pr√™tes pour l'avenir sur des architectures IA efficaces

### R√©sultats d'apprentissage du Module 03 :
- Capacit√©s strat√©giques de s√©lection de mod√®les
- Ma√Ætrise des techniques d'optimisation
- Ma√Ætrise de la flexibilit√© de d√©ploiement
- Capacit√©s de configuration pr√™tes pour la production

### R√©sultats d'apprentissage du Module 04 :
- Compr√©hension approfondie des limites de quantification et des applications pratiques
- Exp√©rience pratique avec plusieurs frameworks d'optimisation (Llama.cpp, Olive, MLX)
- Capacit√©s de s√©lection d'optimisation mat√©rielle
- Comp√©tences de d√©ploiement en production pour des environnements edge multiplateformes

### R√©sultats d'apprentissage du Module 05 :
- Ma√Ætriser le paradigme SLMOps et les principes op√©rationnels
- Impl√©menter la distillation de mod√®les pour le transfert de connaissances et l'optimisation de l'efficacit√©
- Appliquer des techniques de fine-tuning pour la personnalisation de mod√®les sp√©cifiques au domaine
- D√©ployer des solutions SLM pr√™tes pour la production avec des strat√©gies de surveillance et de maintenance

### R√©sultats d'apprentissage du Module 06 :
- Comprendre les concepts fondamentaux des agents IA et de l'architecture des petits mod√®les de langage
- Ma√Ætriser l'impl√©mentation des appels de fonctions sur plusieurs plateformes et frameworks
- Int√©grer le protocole de contexte de mod√®le (MCP) pour une interaction standardis√©e avec des outils externes
- Construire des syst√®mes agentiques sophistiqu√©s n√©cessitant une intervention humaine minimale

### R√©sultats d'apprentissage du Module 07 :
- Acqu√©rir une exp√©rience pratique avec diverses plateformes EdgeAI et strat√©gies d'impl√©mentation
- Ma√Ætriser les techniques d'optimisation sp√©cifiques au mat√©riel sur les plateformes NVIDIA, mobiles, Azure et Windows
- Comprendre les compromis de d√©ploiement entre performance, co√ªt et exigences de confidentialit√©
- D√©velopper des comp√©tences pratiques pour construire des applications EdgeAI r√©elles dans diff√©rents √©cosyst√®mes

## R√©sultats attendus du cours

√Ä l'issue de ce cours, vous serez √©quip√© des connaissances, comp√©tences et confiance n√©cessaires pour diriger des initiatives EdgeAI dans des environnements professionnels.

### Pr√©paration professionnelle

**Leadership technique**
- **Architecture de solution** : Concevoir des syst√®mes EdgeAI complets r√©pondant aux exigences d'entreprise
- **Optimisation des performances** : Atteindre un √©quilibre optimal entre pr√©cision, vitesse et consommation de ressources
- **D√©ploiement multiplateforme** : Impl√©menter des solutions sur Windows, Linux, mobile et plateformes embarqu√©es
- **Op√©rations de production** : Maintenir et faire √©voluer des syst√®mes EdgeAI avec une fiabilit√© de niveau entreprise

**Expertise industrielle**
- **√âvaluation technologique** : √âvaluer et recommander des solutions EdgeAI pour des d√©fis commerciaux sp√©cifiques
- **Planification d'impl√©mentation** : D√©velopper des calendriers r√©alistes et des besoins en ressources pour des projets EdgeAI
- **Gestion des risques** : Identifier et att√©nuer les risques techniques et op√©rationnels dans les d√©ploiements EdgeAI
- **Optimisation du ROI** : D√©montrer une valeur commerciale mesurable gr√¢ce aux impl√©mentations EdgeAI

### Opportunit√©s d'avancement professionnel

**R√¥les professionnels**
- Architecte de solutions EdgeAI
- Ing√©nieur en apprentissage automatique (sp√©cialisation Edge)
- D√©veloppeur IA IoT
- D√©veloppeur d'applications mobiles IA
- Consultant IA d'entreprise

**Secteurs industriels**
- Fabrication intelligente et industrie 4.0
- V√©hicules autonomes et transport
- Technologie de sant√© et dispositifs m√©dicaux
- Technologie financi√®re et s√©curit√©
- √âlectronique grand public et applications mobiles

### Certification et validation

**D√©veloppement de portefeuille**
- Compl√©ter des projets EdgeAI de bout en bout d√©montrant une comp√©tence pratique
- D√©ployer des solutions pr√™tes pour la production sur plusieurs plateformes mat√©rielles
- Documenter les strat√©gies d'optimisation et les am√©liorations de performance obtenues

**Chemin d'apprentissage continu**
- Base pour des sp√©cialisations avanc√©es en IA
- Pr√©paration aux architectures hybrides cloud-edge
- Porte d'entr√©e vers les technologies et frameworks IA √©mergents

Ce cours vous positionne √† l'avant-garde du d√©ploiement de la technologie IA, o√π des capacit√©s intelligentes sont int√©gr√©es de mani√®re transparente dans les dispositifs et syst√®mes qui alimentent la vie moderne.

## Diagramme de structure de fichier

```
edgeai-for-beginners/
‚îú‚îÄ‚îÄ imgs/
‚îÇ   ‚îî‚îÄ‚îÄ cover.png
‚îú‚îÄ‚îÄ Module01/ (EdgeAI Fundamentals and Transformation)
‚îÇ   ‚îú‚îÄ‚îÄ 01.EdgeAIFundamentals.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.RealWorldCaseStudies.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.PracticalImplementationGuide.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.EdgeDeployment.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module02/ (Small Language Model Foundations)
‚îÇ   ‚îú‚îÄ‚îÄ 01.PhiFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.QwenFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.GemmaFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.BitNETFamily.md
‚îÇ   ‚îú‚îÄ‚îÄ 05.mumodel.md
‚îÇ   ‚îú‚îÄ‚îÄ 06.phisilica.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module03/ (SLM Deployment Practice)
‚îÇ   ‚îú‚îÄ‚îÄ 01.SLMAdvancedLearning.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.DeployingSLMinLocalEnv.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.DeployingSLMinCloud.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module04/ (Model Format Conversion and Quantization)
‚îÇ   ‚îú‚îÄ‚îÄ 01.Introduce.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.Llamacpp.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.MicrosoftOlive.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.AppleMLX.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module05/ (SLMOps - Small Language Model Operations)
‚îÇ   ‚îú‚îÄ‚îÄ 01.IntroduceSLMOps.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.SLMOps-Distillation.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.SLMOps-Finetuing.md
‚îÇ   ‚îú‚îÄ‚îÄ 04.SLMOps.Deployment.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module06/ (SLM Agentic Systems)
‚îÇ   ‚îú‚îÄ‚îÄ 01.IntroduceAgent.md
‚îÇ   ‚îú‚îÄ‚îÄ 02.FunctionCalling.md
‚îÇ   ‚îú‚îÄ‚îÄ 03.IntroduceMCP.md
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Module07/ (EdgeAI Implementation Samples)
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ CODE_OF_CONDUCT.md
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ README.md (This file)
‚îú‚îÄ‚îÄ SECURITY.md
‚îú‚îÄ‚îÄ STUDY_GUIDE.md
‚îî‚îÄ‚îÄ SUPPORT.md
```

## Caract√©ristiques du cours

- **Apprentissage progressif** : Avancez progressivement des concepts de base au d√©ploiement avanc√©
- **Int√©gration th√©orie et pratique** : Chaque module contient des bases th√©oriques et des op√©rations pratiques
- **√âtudes de cas r√©elles** : Bas√©es sur des cas r√©els de Microsoft, Alibaba, Google et autres
- **Pratique concr√®te** : Fichiers de configuration complets, proc√©dures de test API et scripts de d√©ploiement
- **Benchmarks de performance** : Comparaisons d√©taill√©es de vitesse d'inf√©rence, utilisation m√©moire et exigences en ressources
- **Consid√©rations de niveau entreprise** : Pratiques de s√©curit√©, cadres de conformit√© et strat√©gies de protection des donn√©es

## Premiers pas

Chemin d'apprentissage recommand√© :
1. Commencez par **Module01** pour construire une compr√©hension fondamentale de EdgeAI
2. Passez √† **Module02** pour comprendre en profondeur les diff√©rentes familles de mod√®les SLM
3. Apprenez **Module03** pour ma√Ætriser les comp√©tences pratiques de d√©ploiement
4. Continuez avec **Module04** pour l'optimisation avanc√©e des mod√®les et la conversion de formats
5. Compl√©tez **Module05** pour ma√Ætriser SLMOps pour des impl√©mentations pr√™tes pour la production
6. Explorez **Module06** pour comprendre les syst√®mes agentiques SLM et les capacit√©s d'appel de fonctions
7. Terminez avec **Module07** pour acqu√©rir une exp√©rience pratique avec des exemples d'impl√©mentation EdgeAI diversifi√©s

Chaque module est con√ßu pour √™tre complet ind√©pendamment, mais un apprentissage s√©quentiel fournira les meilleurs r√©sultats.

## Guide d'√©tude

Un [Guide d'√©tude](STUDY_GUIDE.md) complet est disponible pour vous aider √† maximiser votre exp√©rience d'apprentissage. Le guide d'√©tude fournit :

- **Chemins d'apprentissage structur√©s** : Calendriers optimis√©s pour compl√©ter le cours en 20 heures
- **Conseils d'allocation de temps** : Recommandations sp√©cifiques pour √©quilibrer lecture, exercices et projets
- **Focus sur les concepts cl√©s** : Objectifs d'apprentissage prioritaires pour chaque module
- **Outils d'auto-√©valuation** : Questions et exercices pour tester votre compr√©hension
- **Id√©es de mini-projets** : Applications pratiques pour renforcer votre apprentissage

Le guide d'√©tude est con√ßu pour s'adapter √† un apprentissage intensif (1 semaine) ou √† un apprentissage √† temps partiel (3 semaines), avec des indications claires sur la mani√®re de r√©partir votre temps efficacement, m√™me si vous ne pouvez consacrer que 10 heures au cours.

---

**L'avenir de EdgeAI r√©side dans l'am√©lioration continue des architectures de mod√®les, des techniques de quantification et des strat√©gies de d√©ploiement qui privil√©gient l'efficacit√© et la sp√©cialisation plut√¥t que les capacit√©s g√©n√©ralistes. Les organisations qui adoptent ce changement de paradigme seront bien positionn√©es pour exploiter le potentiel transformateur de l'IA tout en gardant le contr√¥le sur leurs donn√©es et leurs op√©rations.**

## Autres cours

Notre √©quipe propose d'autres cours ! D√©couvrez :

- [MCP pour d√©butants](https://github.com/microsoft/mcp-for-beginners)
- [Agents IA pour d√©butants](https://github.com/microsoft/ai-agents-for-beginners?WT.mc_id=academic-105485-koreyst)
- [IA g√©n√©rative pour d√©butants avec .NET](https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst)
- [IA g√©n√©rative pour d√©butants avec JavaScript](https://github.com/microsoft/generative-ai-with-javascript?WT.mc_id=academic-105485-koreyst)
- [IA g√©n√©rative pour d√©butants](https://github.com/microsoft/generative-ai-for-beginners?WT.mc_id=academic-105485-koreyst)
- [ML pour d√©butants](https://aka.ms/ml-beginners?WT.mc_id=academic-105485-koreyst)
- [Data Science pour d√©butants](https://aka.ms/datascience-beginners?WT.mc_id=academic-105485-koreyst)
- [IA pour d√©butants](https://aka.ms/ai-beginners?WT.mc_id=academic-105485-koreyst)
- [Cybers√©curit√© pour d√©butants](https://github.com/microsoft/Security-101??WT.mc_id=academic-96948-sayoung)
- [D√©veloppement web pour d√©butants](https://aka.ms/webdev-beginners?WT.mc_id=academic-105485-koreyst)
- [IoT pour les d√©butants](https://aka.ms/iot-beginners?WT.mc_id=academic-105485-koreyst)  
- [D√©veloppement XR pour les d√©butants](https://github.com/microsoft/xr-development-for-beginners?WT.mc_id=academic-105485-koreyst)  
- [Ma√Ætriser GitHub Copilot pour la programmation assist√©e par IA](https://aka.ms/GitHubCopilotAI?WT.mc_id=academic-105485-koreyst)  
- [Ma√Ætriser GitHub Copilot pour les d√©veloppeurs C#/.NET](https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers?WT.mc_id=academic-105485-koreyst)  
- [Choisissez votre propre aventure avec Copilot](https://github.com/microsoft/CopilotAdventures?WT.mc_id=academic-105485-koreyst)  

---

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de faire appel √† une traduction professionnelle humaine. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.