<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2f1754a482b6a84e07287a5b775e65b6",
  "translation_date": "2025-09-30T23:35:10+00:00",
  "source_file": "Module08/samples/04/README.md",
  "language_code": "ja"
}
-->
# ã‚µãƒ³ãƒ—ãƒ« 04: Chainlit ã‚’ä½¿ã£ãŸãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³

Microsoft Foundry Local ã‚’æ´»ç”¨ã—ã€ãƒ¢ãƒ€ãƒ³ãªã‚¦ã‚§ãƒ–ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”ã€æœ€æ–°ã®ãƒ–ãƒ©ã‚¦ã‚¶æŠ€è¡“ã‚’å‚™ãˆãŸãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³å¯¾å¿œã®ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹è¤‡æ•°ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’åŒ…æ‹¬çš„ã«ç´¹ä»‹ã—ã¾ã™ã€‚

## å«ã¾ã‚Œã‚‹å†…å®¹

- **ğŸš€ Chainlit ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒª** (`app.py`): ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œã®ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
- **ğŸŒ WebGPU ãƒ‡ãƒ¢** (`webgpu-demo/`): ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ´»ç”¨ã—ãŸãƒ–ãƒ©ã‚¦ã‚¶ãƒ™ãƒ¼ã‚¹ã®AIæ¨è«–
- **ğŸ¨ Open WebUI çµ±åˆ** (`open-webui-guide.md`): ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªChatGPTé¢¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
- **ğŸ“š æ•™è‚²ç”¨ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯** (`chainlit_app.ipynb`): ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªå­¦ç¿’æ•™æ

## ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### 1. Chainlit ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³

```cmd
# Navigate to Module08 directory
cd Module08

# Start your model
foundry model run phi-4-mini

# Run Chainlit app (using port 8080 to avoid conflicts)
chainlit run samples\04\app.py -w --port 8080
```

ã‚¢ã‚¯ã‚»ã‚¹å…ˆ: `http://localhost:8080`

### 2. WebGPU ãƒ–ãƒ©ã‚¦ã‚¶ãƒ‡ãƒ¢

```cmd
# Navigate to WebGPU demo
cd Module08\samples\04\webgpu-demo

# Serve the demo
python -m http.server 5173
```

ã‚¢ã‚¯ã‚»ã‚¹å…ˆ: `http://localhost:5173`

### 3. Open WebUI ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```cmd
# Run Open WebUI with Docker
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

ã‚¢ã‚¯ã‚»ã‚¹å…ˆ: `http://localhost:3000`

## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‘ã‚¿ãƒ¼ãƒ³

### ãƒ­ãƒ¼ã‚«ãƒ« vs ã‚¯ãƒ©ã‚¦ãƒ‰ã®æ„æ€æ±ºå®šãƒãƒˆãƒªãƒƒã‚¯ã‚¹

| ã‚·ãƒŠãƒªã‚ª | æ¨å¥¨ | ç†ç”± |
|----------|------|------|
| **ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãŒé‡è¦ãªãƒ‡ãƒ¼ã‚¿** | ğŸ  ãƒ­ãƒ¼ã‚«ãƒ« (Foundry) | ãƒ‡ãƒ¼ã‚¿ãŒãƒ‡ãƒã‚¤ã‚¹ã‚’é›¢ã‚Œãªã„ |
| **è¤‡é›‘ãªæ¨è«–** | â˜ï¸ ã‚¯ãƒ©ã‚¦ãƒ‰ (Azure OpenAI) | å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ |
| **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒ£ãƒƒãƒˆ** | ğŸ  ãƒ­ãƒ¼ã‚«ãƒ« (Foundry) | ä½é…å»¶ã§é«˜é€Ÿå¿œç­” |
| **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåˆ†æ** | ğŸ”„ ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ | æŠ½å‡ºã¯ãƒ­ãƒ¼ã‚«ãƒ«ã€åˆ†æã¯ã‚¯ãƒ©ã‚¦ãƒ‰ |
| **ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ** | ğŸ  ãƒ­ãƒ¼ã‚«ãƒ« (Foundry) | ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ + å°‚ç”¨ãƒ¢ãƒ‡ãƒ« |
| **ç ”ç©¶ã‚¿ã‚¹ã‚¯** | â˜ï¸ ã‚¯ãƒ©ã‚¦ãƒ‰ (Azure OpenAI) | å¹…åºƒã„çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ãŒå¿…è¦ |

### æŠ€è¡“æ¯”è¼ƒ

| æŠ€è¡“ | ä½¿ç”¨ã‚±ãƒ¼ã‚¹ | åˆ©ç‚¹ | æ¬ ç‚¹ |
|------|------------|------|------|
| **Chainlit** | Pythoné–‹ç™ºè€…ã€è¿…é€Ÿãªãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ä½œæˆ | ç°¡å˜ãªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œ | Pythoné™å®š |
| **WebGPU** | æœ€å¤§é™ã®ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã‚·ãƒŠãƒªã‚ª | ãƒ–ãƒ©ã‚¦ã‚¶ãƒã‚¤ãƒ†ã‚£ãƒ–ã€ã‚µãƒ¼ãƒãƒ¼ä¸è¦ | ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒåˆ¶é™ã•ã‚Œã‚‹ |
| **Open WebUI** | ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³å±•é–‹ã€ãƒãƒ¼ãƒ å‘ã‘ | ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªUIã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç† | DockerãŒå¿…è¦ |

## å¿…è¦æ¡ä»¶

- **Foundry Local**: ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ã§ç¨¼åƒä¸­ ([ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰](https://aka.ms/foundry-local-installer))
- **Python**: 3.10ä»¥ä¸Šã€ä»®æƒ³ç’°å¢ƒä»˜ã
- **ãƒ¢ãƒ‡ãƒ«**: å°‘ãªãã¨ã‚‚1ã¤ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ (`foundry model run phi-4-mini`)
- **ãƒ–ãƒ©ã‚¦ã‚¶**: WebGPUå¯¾å¿œã®Chrome/Edge
- **Docker**: Open WebUIç”¨ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)

## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### 1. Pythonç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```cmd
# Navigate to Module08 directory
cd Module08

# Create and activate virtual environment
py -m venv .venv
.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Foundry Local ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```cmd
# Verify Foundry Local installation
foundry --version

# Start the service
foundry service start

# Load a model
foundry model run phi-4-mini

# Verify model is running
foundry service ps
```

## ã‚µãƒ³ãƒ—ãƒ«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³

### Chainlit ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³

**ç‰¹å¾´:**
- ğŸš€ **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°**: ãƒˆãƒ¼ã‚¯ãƒ³ãŒç”Ÿæˆã•ã‚Œã‚‹ã¨ã™ãã«è¡¨ç¤º
- ğŸ›¡ï¸ **å …ç‰¢ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**: å„ªé›…ãªåŠ£åŒ–ã¨å›å¾©
- ğŸ¨ **ãƒ¢ãƒ€ãƒ³ãªUI**: ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
- ğŸ”§ **æŸ”è»Ÿãªè¨­å®š**: ç’°å¢ƒå¤‰æ•°ã¨è‡ªå‹•æ¤œå‡º
- ğŸ“± **ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³**: ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã¨ãƒ¢ãƒã‚¤ãƒ«ã§å‹•ä½œ

**ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ:**
```cmd
# Run with default settings (recommended)
chainlit run samples\04\app.py -w --port 8080

# Use specific model
set MODEL=qwen2.5-7b
chainlit run samples\04\app.py -w --port 8080

# Manual endpoint configuration
set BASE_URL=http://localhost:51211
set API_KEY=your-api-key
chainlit run samples\04\app.py -w --port 8080
```

### WebGPU ãƒ–ãƒ©ã‚¦ã‚¶ãƒ‡ãƒ¢

**ç‰¹å¾´:**
- ğŸŒ **ãƒ–ãƒ©ã‚¦ã‚¶ãƒã‚¤ãƒ†ã‚£ãƒ–AI**: ã‚µãƒ¼ãƒãƒ¼ä¸è¦ã€å®Œå…¨ã«ãƒ–ãƒ©ã‚¦ã‚¶å†…ã§å‹•ä½œ
- âš¡ **WebGPUã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**: åˆ©ç”¨å¯èƒ½ãªå ´åˆã¯ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
- ğŸ”’ **æœ€å¤§é™ã®ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼**: ãƒ‡ãƒ¼ã‚¿ãŒãƒ‡ãƒã‚¤ã‚¹ã‚’é›¢ã‚Œã‚‹ã“ã¨ã¯ãªã„
- ğŸ¯ **ã‚¼ãƒ­ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**: äº’æ›æ€§ã®ã‚ã‚‹ãƒ–ãƒ©ã‚¦ã‚¶ã§å‹•ä½œ
- ğŸ”„ **å„ªé›…ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯**: WebGPUãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯CPUã«åˆ‡ã‚Šæ›¿ãˆ

**å®Ÿè¡Œæ–¹æ³•:**
```cmd
cd samples\04\webgpu-demo
python -m http.server 5173
# Open http://localhost:5173
```

### Open WebUI çµ±åˆ

**ç‰¹å¾´:**
- ğŸ¨ **ChatGPTé¢¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹**: ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§é¦´æŸ“ã¿ã®ã‚ã‚‹UI
- ğŸ‘¥ **ãƒãƒ«ãƒãƒ¦ãƒ¼ã‚¶ãƒ¼å¯¾å¿œ**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã¨ä¼šè©±å±¥æ­´
- ğŸ“ **ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†**: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨åˆ†æ
- ğŸ”„ **ãƒ¢ãƒ‡ãƒ«åˆ‡ã‚Šæ›¿ãˆ**: ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«é–“ã®ç°¡å˜ãªåˆ‡ã‚Šæ›¿ãˆ
- ğŸ³ **Dockerå±•é–‹**: ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³å¯¾å¿œã®ã‚³ãƒ³ãƒ†ãƒŠåŒ–ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

**ã‚¯ã‚¤ãƒƒã‚¯ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—:**
```cmd
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

## è¨­å®šãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

### ç’°å¢ƒå¤‰æ•°

| å¤‰æ•° | èª¬æ˜ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ | ä¾‹ |
|------|------|------------|----|
| `MODEL` | ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ | `phi-4-mini` | `qwen2.5-7b` |
| `BASE_URL` | Foundry Local ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ | è‡ªå‹•æ¤œå‡º | `http://localhost:51211` |
| `API_KEY` | APIã‚­ãƒ¼ (ãƒ­ãƒ¼ã‚«ãƒ«ã§ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³) | `""` | `your-api-key` |

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œ

**Chainlit ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³:**

1. **ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆ©ç”¨ã§ããªã„:**
   ```cmd
   # Check Foundry Local status
   foundry service status
   foundry service ps
   
   # Validate API endpoint (note: port 51211)
   curl http://localhost:51211/v1/models
   ```

2. **ãƒãƒ¼ãƒˆç«¶åˆ:**
   ```cmd
   # Check what's using port 8080
   netstat -ano | findstr :8080
   
   # Use different port if needed
   chainlit run samples\04\app.py -w --port 3000
   ```

3. **Pythonç’°å¢ƒã®å•é¡Œ:**
   ```cmd
   # Verify correct interpreter in VS Code
   # Ctrl+Shift+P â†’ Python: Select Interpreter
   # Choose: Module08/.venv/Scripts/python.exe
   
   # Reinstall dependencies
   pip install -r requirements.txt
   ```

**WebGPU ãƒ‡ãƒ¢:**

1. **WebGPUãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„:**
   - Chrome/Edge 113ä»¥ä¸Šã«æ›´æ–°
   - WebGPUã‚’æœ‰åŠ¹åŒ–: `chrome://flags/#enable-unsafe-webgpu`
   - GPUã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ç¢ºèª: `chrome://gpu`
   - ãƒ‡ãƒ¢ã¯è‡ªå‹•çš„ã«CPUã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™

2. **ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼:**
   - ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã®ãŸã‚ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèª
   - ãƒ–ãƒ©ã‚¦ã‚¶ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§CORSã‚¨ãƒ©ãƒ¼ã‚’ç¢ºèª
   - HTTPçµŒç”±ã§æä¾›ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª (file://ã§ã¯ãªã)

**Open WebUI:**

1. **æ¥ç¶šæ‹’å¦:**
   ```cmd
   # Check Docker is running
   docker --version
   
   # Check container status
   docker ps | findstr open-webui
   
   # View container logs
   docker logs open-webui
   ```

2. **ãƒ¢ãƒ‡ãƒ«ãŒè¡¨ç¤ºã•ã‚Œãªã„:**
   ```cmd
   # Verify Foundry Local endpoint
   curl http://localhost:51211/v1/models
   
   # Restart Open WebUI
   docker restart open-webui
   ```

### æ¤œè¨¼ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

```cmd
# âœ… 1. Foundry Local Setup
foundry --version                    # Should show version
foundry service status               # Should show "running"
foundry model list                   # Should show loaded models
curl http://localhost:51211/v1/models  # Should return JSON

# âœ… 2. Python Environment  
python --version                     # Should be 3.10+
pip list | findstr chainlit         # Should show chainlit package
pip list | findstr openai           # Should show openai package

# âœ… 3. Application Testing
chainlit run samples\04\app.py -w --port 8080  # Should open browser
# Test WebGPU demo at localhost:5173
# Test Open WebUI at localhost:3000
```

## é«˜åº¦ãªä½¿ç”¨æ³•

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

**Chainlit:**
- ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¦çŸ¥è¦šçš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Š
- é«˜ã„åŒæ™‚æ¥ç¶šæ€§ã®ãŸã‚ã«æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚’å®Ÿè£…
- ç¹°ã‚Šè¿”ã—ã‚¯ã‚¨ãƒªã®ãŸã‚ã«ãƒ¢ãƒ‡ãƒ«å¿œç­”ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
- å¤§è¦æ¨¡ãªä¼šè©±å±¥æ­´ã§ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ç›£è¦–

**WebGPU:**
- æœ€å¤§é™ã®ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã¨é€Ÿåº¦ã®ãŸã‚ã«WebGPUã‚’ä½¿ç”¨
- å°å‹ãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã«ãƒ¢ãƒ‡ãƒ«é‡å­åŒ–ã‚’å®Ÿè£…
- ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†ã®ãŸã‚ã«Web Workersã‚’ä½¿ç”¨
- ãƒ–ãƒ©ã‚¦ã‚¶ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥

**Open WebUI:**
- ä¼šè©±å±¥æ­´ã®ãŸã‚ã«æ°¸ç¶šãƒœãƒªãƒ¥ãƒ¼ãƒ ã‚’ä½¿ç”¨
- Dockerã‚³ãƒ³ãƒ†ãƒŠã®ãƒªã‚½ãƒ¼ã‚¹åˆ¶é™ã‚’è¨­å®š
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆ¦ç•¥ã‚’å®Ÿè£…
- SSLçµ‚ç«¯ã®ãŸã‚ã«ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã‚’è¨­å®š

### çµ±åˆãƒ‘ã‚¿ãƒ¼ãƒ³

**ãƒ­ãƒ¼ã‚«ãƒ«/ã‚¯ãƒ©ã‚¦ãƒ‰ã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰:**
```python
# Route based on complexity and privacy requirements
async def intelligent_routing(prompt: str, metadata: dict):
    if metadata.get("contains_pii"):
        return await foundry_local_completion(prompt)  # Privacy-sensitive
    elif len(prompt.split()) > 200:
        return await azure_openai_completion(prompt)   # Complex reasoning
    else:
        return await foundry_local_completion(prompt)  # Default local
```

**ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³:**
```python
# Combine different AI capabilities
async def analyze_document(file_path: str):
    # 1. OCR with WebGPU (browser-based)
    text = await webgpu_ocr(file_path)
    
    # 2. Analysis with Foundry Local (private)
    summary = await foundry_local_analyze(text)
    
    # 3. Enhancement with cloud (if needed)
    if summary.confidence < 0.8:
        summary = await azure_openai_enhance(summary)
    
    return summary
```

## ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³å±•é–‹

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è€ƒæ…®äº‹é …

- **APIã‚­ãƒ¼**: ç’°å¢ƒå¤‰æ•°ã‚’ä½¿ç”¨ã—ã€ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã—ãªã„
- **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯**: ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯HTTPSã‚’ä½¿ç”¨ã—ã€ãƒãƒ¼ãƒ ã‚¢ã‚¯ã‚»ã‚¹ã«ã¯VPNã‚’æ¤œè¨
- **ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡**: Open WebUIã«èªè¨¼ã‚’å®Ÿè£…
- **ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼**: ãƒ­ãƒ¼ã‚«ãƒ«ã«ç•™ã¾ã‚‹ãƒ‡ãƒ¼ã‚¿ã¨ã‚¯ãƒ©ã‚¦ãƒ‰ã«é€ä¿¡ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’ç›£æŸ»
- **æ›´æ–°**: Foundry Localã¨ã‚³ãƒ³ãƒ†ãƒŠã‚’æœ€æ–°çŠ¶æ…‹ã«ä¿ã¤

### ç›£è¦–ã¨ä¿å®ˆ

- **ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯**: ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ç›£è¦–ã‚’å®Ÿè£…
- **ãƒ­ã‚°**: ã™ã¹ã¦ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‹ã‚‰ãƒ­ã‚°ã‚’é›†ä¸­ç®¡ç†
- **ãƒ¡ãƒˆãƒªã‚¯ã‚¹**: å¿œç­”æ™‚é–“ã€ã‚¨ãƒ©ãƒ¼ç‡ã€ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ã‚’è¿½è·¡
- **ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—**: ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã¨è¨­å®šã®å®šæœŸçš„ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—

## å‚è€ƒæ–‡çŒ®ã¨ãƒªã‚½ãƒ¼ã‚¹

### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- [Chainlit Documentation](https://docs.chainlit.io/) - ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®å®Œå…¨ã‚¬ã‚¤ãƒ‰
- [Foundry Local Documentation](https://learn.microsoft.com/azure/ai-foundry/foundry-local/) - Microsoftå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- [ONNX Runtime Web](https://onnxruntime.ai/docs/get-started/with-javascript/web.html) - WebGPUçµ±åˆ
- [Open WebUI Documentation](https://docs.openwebui.com/) - é«˜åº¦ãªè¨­å®š

### ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«
- [`app.py`](../../../../../Module08/samples/04/app.py) - ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³Chainlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
- [`chainlit_app.ipynb`](./chainlit_app.ipynb) - æ•™è‚²ç”¨ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯
- [`webgpu-demo/`](../../../../../Module08/samples/04/webgpu-demo) - ãƒ–ãƒ©ã‚¦ã‚¶ãƒ™ãƒ¼ã‚¹ã®AIæ¨è«–
- [`open-webui-guide.md`](./open-webui-guide.md) - å®Œå…¨ãªOpen WebUIã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### é–¢é€£ã‚µãƒ³ãƒ—ãƒ«
- [Session 4 Documentation](../../04.CuttingEdgeModels.md) - å®Œå…¨ãªã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¬ã‚¤ãƒ‰
- [Foundry Local Samples](https://github.com/microsoft/foundry-local/tree/main/samples) - å…¬å¼ã‚µãƒ³ãƒ—ãƒ«

---

**å…è²¬äº‹é …**:  
ã“ã®æ–‡æ›¸ã¯ã€AIç¿»è¨³ã‚µãƒ¼ãƒ“ã‚¹[Co-op Translator](https://github.com/Azure/co-op-translator)ã‚’ä½¿ç”¨ã—ã¦ç¿»è¨³ã•ã‚Œã¦ã„ã¾ã™ã€‚æ­£ç¢ºæ€§ã‚’è¿½æ±‚ã—ã¦ãŠã‚Šã¾ã™ãŒã€è‡ªå‹•ç¿»è¨³ã«ã¯èª¤ã‚Šã‚„ä¸æ­£ç¢ºãªéƒ¨åˆ†ãŒå«ã¾ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’ã”æ‰¿çŸ¥ãã ã•ã„ã€‚å…ƒã®è¨€èªã§è¨˜è¼‰ã•ã‚ŒãŸæ–‡æ›¸ãŒæ­£å¼ãªæƒ…å ±æºã¨ã¿ãªã•ã‚Œã‚‹ã¹ãã§ã™ã€‚é‡è¦ãªæƒ…å ±ã«ã¤ã„ã¦ã¯ã€å°‚é–€ã®äººé–“ã«ã‚ˆã‚‹ç¿»è¨³ã‚’æ¨å¥¨ã—ã¾ã™ã€‚ã“ã®ç¿»è¨³ã®ä½¿ç”¨ã«èµ·å› ã™ã‚‹èª¤è§£ã‚„èª¤èªã«ã¤ã„ã¦ã€å½“æ–¹ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚