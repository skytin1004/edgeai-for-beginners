<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a35d3b47e6ae98ad9b3e89fb73917e90",
  "translation_date": "2025-07-22T03:00:45+00:00",
  "source_file": "Module01/01.EdgeAIFundamentals.md",
  "language_code": "zh"
}
-->
# ç¬¬1ç« ï¼šEdgeAI åŸºç¡€

EdgeAI ä»£è¡¨äº†ä¸€ç§äººå·¥æ™ºèƒ½éƒ¨ç½²çš„èŒƒå¼è½¬å˜ï¼Œå°† AI èƒ½åŠ›ç›´æ¥å¸¦åˆ°è¾¹ç¼˜è®¾å¤‡ï¼Œè€Œä¸æ˜¯ä»…ä»…ä¾èµ–äº‘ç«¯å¤„ç†ã€‚äº†è§£ EdgeAI å¦‚ä½•åœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šå®ç°æœ¬åœ° AI å¤„ç†ï¼ŒåŒæ—¶ä¿æŒåˆç†çš„æ€§èƒ½å¹¶è§£å†³éšç§ã€å»¶è¿Ÿå’Œç¦»çº¿èƒ½åŠ›ç­‰æŒ‘æˆ˜ï¼Œæ˜¯éå¸¸é‡è¦çš„ã€‚

## ä»‹ç»

åœ¨æœ¬èŠ‚è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨ EdgeAI åŠå…¶åŸºæœ¬æ¦‚å¿µã€‚æˆ‘ä»¬å°†æ¶µç›–ä¼ ç»Ÿçš„ AI è®¡ç®—èŒƒå¼ã€è¾¹ç¼˜è®¡ç®—çš„æŒ‘æˆ˜ã€æ”¯æŒ EdgeAI çš„å…³é”®æŠ€æœ¯ï¼Œä»¥åŠå…¶åœ¨å„è¡Œä¸šä¸­çš„å®é™…åº”ç”¨ã€‚

## å­¦ä¹ ç›®æ ‡

å®Œæˆæœ¬èŠ‚è¯¾ç¨‹åï¼Œæ‚¨å°†èƒ½å¤Ÿï¼š

- ç†è§£ä¼ ç»ŸåŸºäºäº‘çš„ AI æ–¹æ³•ä¸ EdgeAI æ–¹æ³•ä¹‹é—´çš„åŒºåˆ«ã€‚
- è¯†åˆ«æ”¯æŒè¾¹ç¼˜è®¾å¤‡ä¸Š AI å¤„ç†çš„å…³é”®æŠ€æœ¯ã€‚
- è®¤è¯† EdgeAI å®ç°çš„ä¼˜åŠ¿å’Œå±€é™æ€§ã€‚
- å°† EdgeAI çš„çŸ¥è¯†åº”ç”¨äºå®é™…åœºæ™¯å’Œç”¨ä¾‹ã€‚

## ç†è§£ä¼ ç»Ÿ AI è®¡ç®—èŒƒå¼

ä¼ ç»Ÿä¸Šï¼Œç”Ÿæˆå¼ AI åº”ç”¨ä¾èµ–é«˜æ€§èƒ½è®¡ç®—åŸºç¡€è®¾æ–½æ¥æœ‰æ•ˆè¿è¡Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚ç»„ç»‡é€šå¸¸åœ¨äº‘ç¯å¢ƒä¸­çš„ GPU é›†ç¾¤ä¸Šéƒ¨ç½²è¿™äº›æ¨¡å‹ï¼Œé€šè¿‡ API æ¥å£è®¿é—®å…¶åŠŸèƒ½ã€‚

è¿™ç§é›†ä¸­å¼æ¨¡å‹é€‚ç”¨äºè®¸å¤šåº”ç”¨ï¼Œä½†åœ¨è¾¹ç¼˜è®¡ç®—åœºæ™¯ä¸­å­˜åœ¨å›ºæœ‰çš„å±€é™æ€§ã€‚ä¼ ç»Ÿæ–¹æ³•é€šå¸¸éœ€è¦å°†ç”¨æˆ·æŸ¥è¯¢å‘é€åˆ°è¿œç¨‹æœåŠ¡å™¨ï¼Œåˆ©ç”¨å¼ºå¤§çš„ç¡¬ä»¶è¿›è¡Œå¤„ç†ï¼Œç„¶åé€šè¿‡äº’è”ç½‘è¿”å›ç»“æœã€‚å°½ç®¡è¿™ç§æ–¹æ³•æä¾›äº†æœ€å…ˆè¿›æ¨¡å‹çš„è®¿é—®æƒé™ï¼Œä½†å®ƒå¯¹äº’è”ç½‘è¿æ¥çš„ä¾èµ–ä¼šå¼•å‘å»¶è¿Ÿé—®é¢˜ï¼Œå¹¶åœ¨ä¼ è¾“æ•æ„Ÿæ•°æ®åˆ°å¤–éƒ¨æœåŠ¡å™¨æ—¶å¸¦æ¥éšç§é£é™©ã€‚

åœ¨ä½¿ç”¨ä¼ ç»Ÿ AI è®¡ç®—èŒƒå¼æ—¶ï¼Œæˆ‘ä»¬éœ€è¦ç†è§£ä¸€äº›æ ¸å¿ƒæ¦‚å¿µï¼š

- **â˜ï¸ äº‘ç«¯å¤„ç†**ï¼šAI æ¨¡å‹è¿è¡Œåœ¨å…·æœ‰é«˜è®¡ç®—èµ„æºçš„å¼ºå¤§æœåŠ¡å™¨åŸºç¡€è®¾æ–½ä¸Šã€‚
- **ğŸ”Œ åŸºäº API çš„è®¿é—®**ï¼šåº”ç”¨é€šè¿‡è¿œç¨‹ API è°ƒç”¨è®¿é—® AI åŠŸèƒ½ï¼Œè€Œéæœ¬åœ°å¤„ç†ã€‚
- **ğŸ›ï¸ é›†ä¸­å¼æ¨¡å‹ç®¡ç†**ï¼šæ¨¡å‹é›†ä¸­ç»´æŠ¤å’Œæ›´æ–°ï¼Œç¡®ä¿ä¸€è‡´æ€§ï¼Œä½†éœ€è¦ç½‘ç»œè¿æ¥ã€‚
- **ğŸ“ˆ èµ„æºå¯æ‰©å±•æ€§**ï¼šäº‘åŸºç¡€è®¾æ–½å¯ä»¥åŠ¨æ€æ‰©å±•ä»¥åº”å¯¹ä¸åŒçš„è®¡ç®—éœ€æ±‚ã€‚

## è¾¹ç¼˜è®¡ç®—çš„æŒ‘æˆ˜

è¾¹ç¼˜è®¾å¤‡ï¼ˆå¦‚ç¬”è®°æœ¬ç”µè„‘ã€æ‰‹æœºï¼Œä»¥åŠ Raspberry Pi å’Œ NVIDIA Orin Nano ç­‰ç‰©è”ç½‘è®¾å¤‡ï¼‰å…·æœ‰ç‹¬ç‰¹çš„è®¡ç®—é™åˆ¶ã€‚è¿™äº›è®¾å¤‡çš„å¤„ç†èƒ½åŠ›ã€å†…å­˜å’Œèƒ½æºèµ„æºé€šå¸¸è¿œä½äºæ•°æ®ä¸­å¿ƒåŸºç¡€è®¾æ–½ã€‚

ç”±äºè¿™äº›ç¡¬ä»¶é™åˆ¶ï¼Œåœ¨è¿™äº›è®¾å¤‡ä¸Šè¿è¡Œä¼ ç»Ÿçš„ LLM ä¸€ç›´æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚ç„¶è€Œï¼Œåœ¨è®¸å¤šåœºæ™¯ä¸­ï¼Œè¾¹ç¼˜ AI å¤„ç†çš„éœ€æ±‚å˜å¾—è¶Šæ¥è¶Šé‡è¦ã€‚æ¯”å¦‚ï¼Œåœ¨äº’è”ç½‘è¿æ¥ä¸å¯é æˆ–ä¸å¯ç”¨çš„æƒ…å†µä¸‹ï¼ˆå¦‚åè¿œå·¥ä¸šç°åœºã€è¡Œé©¶ä¸­çš„è½¦è¾†æˆ–ç½‘ç»œè¦†ç›–è¾ƒå·®çš„åœ°åŒºï¼‰ã€‚æ­¤å¤–ï¼Œå¯¹äºéœ€è¦é«˜å®‰å…¨æ ‡å‡†çš„åº”ç”¨ï¼ˆå¦‚åŒ»ç–—è®¾å¤‡ã€é‡‘èç³»ç»Ÿæˆ–æ”¿åºœåº”ç”¨ï¼‰ï¼Œå¯èƒ½éœ€è¦åœ¨æœ¬åœ°å¤„ç†æ•æ„Ÿæ•°æ®ä»¥ç»´æŠ¤éšç§å’Œåˆè§„æ€§ã€‚

### è¾¹ç¼˜è®¡ç®—çš„å…³é”®é™åˆ¶

è¾¹ç¼˜è®¡ç®—ç¯å¢ƒé¢ä¸´ä¸€äº›ä¼ ç»ŸåŸºäºäº‘çš„ AI è§£å†³æ–¹æ¡ˆæ‰€æ²¡æœ‰çš„åŸºæœ¬é™åˆ¶ï¼š

- **æœ‰é™çš„å¤„ç†èƒ½åŠ›**ï¼šè¾¹ç¼˜è®¾å¤‡çš„ CPU æ ¸å¿ƒæ•°é‡è¾ƒå°‘ï¼Œæ—¶é’Ÿé€Ÿåº¦è¾ƒä½ã€‚
- **å†…å­˜é™åˆ¶**ï¼šè¾¹ç¼˜è®¾å¤‡çš„å¯ç”¨ RAM å’Œå­˜å‚¨å®¹é‡æ˜¾è‘—å‡å°‘ã€‚
- **åŠŸè€—é™åˆ¶**ï¼šç”µæ± ä¾›ç”µçš„è®¾å¤‡éœ€è¦åœ¨æ€§èƒ½å’Œèƒ½è€—ä¹‹é—´å–å¾—å¹³è¡¡ï¼Œä»¥å»¶é•¿è¿è¡Œæ—¶é—´ã€‚
- **çƒ­ç®¡ç†**ï¼šç´§å‡‘çš„å¤–å½¢é™åˆ¶äº†æ•£çƒ­èƒ½åŠ›ï¼Œä»è€Œå½±å“é«˜è´Ÿè½½ä¸‹çš„æŒç»­æ€§èƒ½ã€‚

## ä»€ä¹ˆæ˜¯ EdgeAIï¼Ÿ

### æ¦‚å¿µï¼šEdgeAI çš„å®šä¹‰

EdgeAI æ˜¯æŒ‡ç›´æ¥åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šéƒ¨ç½²å’Œæ‰§è¡Œäººå·¥æ™ºèƒ½ç®—æ³•â€”â€”è¿™äº›è®¾å¤‡æ˜¯ç½‘ç»œâ€œè¾¹ç¼˜â€çš„ç‰©ç†ç¡¬ä»¶ï¼Œé è¿‘æ•°æ®ç”Ÿæˆå’Œæ”¶é›†çš„ä½ç½®ã€‚è¿™äº›è®¾å¤‡åŒ…æ‹¬æ™ºèƒ½æ‰‹æœºã€ç‰©è”ç½‘ä¼ æ„Ÿå™¨ã€æ™ºèƒ½æ‘„åƒå¤´ã€è‡ªåŠ¨é©¾é©¶æ±½è½¦ã€å¯ç©¿æˆ´è®¾å¤‡å’Œå·¥ä¸šè®¾å¤‡ã€‚ä¸ä¾èµ–äº‘æœåŠ¡å™¨è¿›è¡Œå¤„ç†çš„ä¼ ç»Ÿ AI ç³»ç»Ÿä¸åŒï¼ŒEdgeAI å°†æ™ºèƒ½ç›´æ¥å¸¦åˆ°æ•°æ®æºã€‚

ä»æœ¬è´¨ä¸Šè®²ï¼ŒEdgeAI æ˜¯å…³äºå»ä¸­å¿ƒåŒ– AI å¤„ç†ï¼Œå°†å…¶ä»é›†ä¸­å¼æ•°æ®ä¸­å¿ƒè½¬ç§»åˆ°æ„æˆæˆ‘ä»¬æ•°å­—ç”Ÿæ€ç³»ç»Ÿçš„åºå¤§è®¾å¤‡ç½‘ç»œä¸­ã€‚è¿™ä»£è¡¨äº† AI ç³»ç»Ÿè®¾è®¡å’Œéƒ¨ç½²æ–¹å¼çš„æ ¹æœ¬æ€§æ¶æ„è½¬å˜ã€‚

EdgeAI çš„å…³é”®æ¦‚å¿µæ”¯æŸ±åŒ…æ‹¬ï¼š

- **å°±è¿‘å¤„ç†**ï¼šè®¡ç®—å‘ç”Ÿåœ¨æ•°æ®ç”Ÿæˆçš„ç‰©ç†ä½ç½®é™„è¿‘ã€‚
- **å»ä¸­å¿ƒåŒ–æ™ºèƒ½**ï¼šå†³ç­–èƒ½åŠ›åˆ†å¸ƒåœ¨å¤šä¸ªè®¾å¤‡ä¹‹é—´ã€‚
- **æ•°æ®ä¸»æƒ**ï¼šä¿¡æ¯ä¿æŒåœ¨æœ¬åœ°æ§åˆ¶ä¹‹ä¸‹ï¼Œé€šå¸¸ä¸ä¼šç¦»å¼€è®¾å¤‡ã€‚
- **è‡ªä¸»è¿è¡Œ**ï¼šè®¾å¤‡æ— éœ€æŒç»­è¿æ¥å³å¯æ™ºèƒ½è¿è¡Œã€‚
- **åµŒå…¥å¼ AI**ï¼šæ™ºèƒ½æˆä¸ºæ—¥å¸¸è®¾å¤‡çš„å†…åœ¨èƒ½åŠ›ã€‚

### EdgeAI æ¶æ„å¯è§†åŒ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         TRADITIONAL AI ARCHITECTURE                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   Data Transfer  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   API Response   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Edge Devices â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚ Cloud Servers â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ End Users â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     Data                         Model Inference                     Results
   Collection                     High Latency
                                  High Bandwidth
                                  Privacy Concerns
                               
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            EDGE AI ARCHITECTURE                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   Direct Response   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Edge Devices with Embedded AI        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚ End Users â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â”‚ Sensors â”‚â”€>â”‚ SLM Inference â”‚â”€>â”‚ Local Action â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     Data         Low Latency       Immediate
   Collection     Processing        Response
                  No Data Transfer
                  Enhanced Privacy
```

EdgeAI ä»£è¡¨äº†ä¸€ç§äººå·¥æ™ºèƒ½éƒ¨ç½²çš„èŒƒå¼è½¬å˜ï¼Œå°† AI èƒ½åŠ›ç›´æ¥å¸¦åˆ°è¾¹ç¼˜è®¾å¤‡ï¼Œè€Œä¸æ˜¯ä»…ä»…ä¾èµ–äº‘ç«¯å¤„ç†ã€‚è¿™ç§æ–¹æ³•ä½¿ AI æ¨¡å‹èƒ½å¤Ÿåœ¨è®¡ç®—èµ„æºæœ‰é™çš„è®¾å¤‡ä¸Šæœ¬åœ°è¿è¡Œï¼Œæä¾›å®æ—¶æ¨ç†èƒ½åŠ›ï¼Œè€Œæ— éœ€æŒç»­çš„äº’è”ç½‘è¿æ¥ã€‚

EdgeAI åŒ…æ‹¬å„ç§æŠ€æœ¯å’Œæ–¹æ³•ï¼Œæ—¨åœ¨ä½¿ AI æ¨¡å‹æ›´é«˜æ•ˆï¼Œå¹¶é€‚åˆåœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šéƒ¨ç½²ã€‚ç›®æ ‡æ˜¯åœ¨æ˜¾è‘—å‡å°‘ AI æ¨¡å‹çš„è®¡ç®—å’Œå†…å­˜éœ€æ±‚çš„åŒæ—¶ï¼Œä¿æŒåˆç†çš„æ€§èƒ½ã€‚

è®©æˆ‘ä»¬æ¥çœ‹çœ‹æ”¯æŒ EdgeAI åœ¨ä¸åŒè®¾å¤‡ç±»å‹å’Œç”¨ä¾‹ä¸­å®ç°çš„åŸºæœ¬æ–¹æ³•ã€‚

### EdgeAI çš„æ ¸å¿ƒåŸåˆ™

EdgeAI å»ºç«‹åœ¨å‡ ä¸ªä¸ä¼ ç»ŸåŸºäºäº‘çš„ AI ä¸åŒçš„åŸºç¡€åŸåˆ™ä¹‹ä¸Šï¼š

- **æœ¬åœ°å¤„ç†**ï¼šAI æ¨ç†ç›´æ¥åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šè¿›è¡Œï¼Œæ— éœ€å¤–éƒ¨è¿æ¥ã€‚
- **èµ„æºä¼˜åŒ–**ï¼šæ¨¡å‹ä¸“é—¨é’ˆå¯¹ç›®æ ‡è®¾å¤‡çš„ç¡¬ä»¶é™åˆ¶è¿›è¡Œä¼˜åŒ–ã€‚
- **å®æ—¶æ€§èƒ½**ï¼šå¤„ç†ä»¥æœ€å°çš„å»¶è¿Ÿå®Œæˆï¼Œé€‚ç”¨äºæ—¶é—´æ•æ„Ÿçš„åº”ç”¨ã€‚
- **éšç§è®¾è®¡**ï¼šæ•æ„Ÿæ•°æ®ä¿ç•™åœ¨è®¾å¤‡ä¸Šï¼Œå¢å¼ºå®‰å…¨æ€§å’Œåˆè§„æ€§ã€‚

## æ”¯æŒ EdgeAI çš„å…³é”®æŠ€æœ¯

### æ¨¡å‹é‡åŒ–

æ¨¡å‹é‡åŒ–æ˜¯ EdgeAI ä¸­æœ€é‡è¦çš„æŠ€æœ¯ä¹‹ä¸€ã€‚è¯¥è¿‡ç¨‹æ¶‰åŠé™ä½æ¨¡å‹å‚æ•°çš„ç²¾åº¦ï¼Œé€šå¸¸ä» 32 ä½æµ®ç‚¹æ•°å‡å°‘åˆ° 8 ä½æ•´æ•°ç”šè‡³æ›´ä½çš„ç²¾åº¦æ ¼å¼ã€‚å°½ç®¡è¿™ç§ç²¾åº¦çš„é™ä½å¯èƒ½ä»¤äººæ‹…å¿§ï¼Œä½†ç ”ç©¶è¡¨æ˜ï¼Œè®¸å¤š AI æ¨¡å‹å³ä½¿åœ¨æ˜¾è‘—é™ä½ç²¾åº¦çš„æƒ…å†µä¸‹ä»èƒ½ä¿æŒæ€§èƒ½ã€‚

é‡åŒ–é€šè¿‡å°†æµ®ç‚¹å€¼çš„èŒƒå›´æ˜ å°„åˆ°ä¸€ç»„è¾ƒå°çš„ç¦»æ•£å€¼æ¥å·¥ä½œã€‚ä¾‹å¦‚ï¼Œä¸ä½¿ç”¨ 32 ä½è¡¨ç¤ºæ¯ä¸ªå‚æ•°ç›¸æ¯”ï¼Œé‡åŒ–å¯èƒ½ä»…ä½¿ç”¨ 8 ä½ï¼Œä»è€Œå‡å°‘ 4 å€çš„å†…å­˜éœ€æ±‚ï¼Œå¹¶é€šå¸¸å¯¼è‡´æ›´å¿«çš„æ¨ç†æ—¶é—´ã€‚

```python
# Example: PyTorch model quantization 
import torch

# Load a pre-trained model
model = torch.load('large_model.pth')

# Quantize the model to INT8
quantized_model = torch.quantization.quantize_dynamic(
    model,  # model to quantize
    {torch.nn.Linear, torch.nn.Conv2d},  # layers to quantize
    dtype=torch.qint8  # quantization data type
)

# Save the quantized model
torch.save(quantized_model, 'quantized_model.pth')

# Memory usage comparison
original_size = model.size()
quantized_size = quantized_model.size()
print(f"Memory reduction: {original_size / quantized_size:.2f}x")
```

ä¸åŒçš„é‡åŒ–æŠ€æœ¯åŒ…æ‹¬ï¼š

- **è®­ç»ƒåé‡åŒ–ï¼ˆPTQï¼‰**ï¼šåœ¨æ¨¡å‹è®­ç»ƒååº”ç”¨ï¼Œæ— éœ€é‡æ–°è®­ç»ƒã€‚
- **é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆQATï¼‰**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥é‡åŒ–æ•ˆæœï¼Œä»¥æé«˜ç²¾åº¦ã€‚
- **åŠ¨æ€é‡åŒ–**ï¼šå°†æƒé‡é‡åŒ–ä¸º int8ï¼Œä½†åŠ¨æ€è®¡ç®—æ¿€æ´»å€¼ã€‚
- **é™æ€é‡åŒ–**ï¼šé¢„å…ˆè®¡ç®—æƒé‡å’Œæ¿€æ´»å€¼çš„æ‰€æœ‰é‡åŒ–å‚æ•°ã€‚

å¯¹äº EdgeAI éƒ¨ç½²ï¼Œé€‰æ‹©é€‚å½“çš„é‡åŒ–ç­–ç•¥å–å†³äºå…·ä½“çš„æ¨¡å‹æ¶æ„ã€æ€§èƒ½è¦æ±‚å’Œç›®æ ‡è®¾å¤‡çš„ç¡¬ä»¶èƒ½åŠ›ã€‚

### æ¨¡å‹å‹ç¼©ä¸ä¼˜åŒ–

é™¤äº†é‡åŒ–ä¹‹å¤–ï¼Œå„ç§å‹ç¼©æŠ€æœ¯æœ‰åŠ©äºå‡å°‘æ¨¡å‹å¤§å°å’Œè®¡ç®—éœ€æ±‚ã€‚è¿™äº›åŒ…æ‹¬ï¼š

**å‰ªæ**ï¼šé€šè¿‡ç§»é™¤ç¥ç»ç½‘ç»œä¸­ä¸å¿…è¦çš„è¿æ¥æˆ–ç¥ç»å…ƒæ¥ä¼˜åŒ–æ¨¡å‹ã€‚é€šè¿‡è¯†åˆ«å¹¶åˆ é™¤å¯¹æ¨¡å‹æ€§èƒ½è´¡çŒ®è¾ƒå°çš„å‚æ•°ï¼Œå‰ªæå¯ä»¥æ˜¾è‘—å‡å°‘æ¨¡å‹å¤§å°ï¼ŒåŒæ—¶ä¿æŒç²¾åº¦ã€‚

```python
# Example: Neural network pruning in TensorFlow
import tensorflow as tf
import tensorflow_model_optimization as tfmot

# Define the model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Apply pruning during training
pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(
    initial_sparsity=0.0,
    final_sparsity=0.5,  # 50% of connections will be pruned
    begin_step=0,
    end_step=10000
)

pruned_model = tfmot.sparsity.keras.prune_low_magnitude(
    model, pruning_schedule=pruning_schedule
)

# Compile the pruned model
pruned_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model while pruning
pruned_model.fit(x_train, y_train, epochs=10)

# Convert to a smaller model for deployment
final_model = tfmot.sparsity.keras.strip_pruning(pruned_model)
```

**çŸ¥è¯†è’¸é¦**ï¼šè¯¥æ–¹æ³•é€šè¿‡è®­ç»ƒä¸€ä¸ªè¾ƒå°çš„â€œå­¦ç”Ÿâ€æ¨¡å‹æ¥æ¨¡ä»¿è¾ƒå¤§çš„â€œæ•™å¸ˆâ€æ¨¡å‹çš„è¡Œä¸ºã€‚å­¦ç”Ÿæ¨¡å‹å­¦ä¹ è¿‘ä¼¼æ•™å¸ˆæ¨¡å‹çš„è¾“å‡ºï¼Œé€šå¸¸ä»¥æ˜¾è‘—æ›´å°‘çš„å‚æ•°å®ç°ç±»ä¼¼çš„æ€§èƒ½ã€‚

**æ¨¡å‹æ¶æ„ä¼˜åŒ–**ï¼šç ”ç©¶äººå‘˜å¼€å‘äº†ä¸“é—¨ä¸ºè¾¹ç¼˜éƒ¨ç½²è®¾è®¡çš„æ¶æ„ï¼Œä¾‹å¦‚ MobileNetsã€EfficientNets å’Œå…¶ä»–è½»é‡çº§æ¶æ„ï¼Œè¿™äº›æ¶æ„åœ¨æ€§èƒ½å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´å–å¾—äº†å¹³è¡¡ã€‚

### å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰

EdgeAI çš„ä¸€ä¸ªæ–°å…´è¶‹åŠ¿æ˜¯å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰çš„å¼€å‘ã€‚è¿™äº›æ¨¡å‹ä»ä¸€å¼€å§‹å°±è¢«è®¾è®¡ä¸ºç´§å‡‘ä¸”é«˜æ•ˆï¼ŒåŒæ—¶ä»æä¾›æœ‰æ„ä¹‰çš„è‡ªç„¶è¯­è¨€å¤„ç†èƒ½åŠ›ã€‚SLMs é€šè¿‡ç²¾å¿ƒçš„æ¶æ„é€‰æ‹©ã€é«˜æ•ˆçš„è®­ç»ƒæŠ€æœ¯ä»¥åŠä¸“æ³¨äºç‰¹å®šé¢†åŸŸæˆ–ä»»åŠ¡çš„è®­ç»ƒæ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚

ä¸ä¼ ç»Ÿæ–¹æ³•é€šè¿‡å‹ç¼©å¤§æ¨¡å‹ä¸åŒï¼ŒSLMs é€šå¸¸ä½¿ç”¨è¾ƒå°çš„æ•°æ®é›†å’Œä¸“é—¨ä¼˜åŒ–çš„æ¶æ„è¿›è¡Œè®­ç»ƒï¼Œä¸“ä¸ºè¾¹ç¼˜éƒ¨ç½²è®¾è®¡ã€‚è¿™ç§æ–¹æ³•ä¸ä»…ä½¿æ¨¡å‹æ›´å°ï¼Œè¿˜ä½¿å…¶åœ¨ç‰¹å®šç”¨ä¾‹ä¸­æ›´é«˜æ•ˆã€‚

## EdgeAI çš„ç¡¬ä»¶åŠ é€Ÿ

ç°ä»£è¾¹ç¼˜è®¾å¤‡è¶Šæ¥è¶Šå¤šåœ°åŒ…æ‹¬ä¸“é—¨è®¾è®¡ç”¨äºåŠ é€Ÿ AI å·¥ä½œè´Ÿè½½çš„ç¡¬ä»¶ï¼š

### ç¥ç»å¤„ç†å•å…ƒï¼ˆNPUsï¼‰

NPUs æ˜¯ä¸“é—¨ä¸ºç¥ç»ç½‘ç»œè®¡ç®—è®¾è®¡çš„å¤„ç†å™¨ã€‚è¿™äº›èŠ¯ç‰‡å¯ä»¥æ¯”ä¼ ç»Ÿ CPU æ›´é«˜æ•ˆåœ°æ‰§è¡Œ AI æ¨ç†ä»»åŠ¡ï¼Œé€šå¸¸åŠŸè€—æ›´ä½ã€‚è®¸å¤šç°ä»£æ™ºèƒ½æ‰‹æœºã€ç¬”è®°æœ¬ç”µè„‘å’Œç‰©è”ç½‘è®¾å¤‡ç°åœ¨éƒ½é…å¤‡äº† NPUsï¼Œä»¥å®ç°è®¾å¤‡ä¸Šçš„ AI å¤„ç†ã€‚

```csharp
// Example: Using Windows ML to target NPU acceleration in C#
using Microsoft.ML.OnnxRuntime;

// Create session options with NPU provider
var sessionOptions = new SessionOptions();
sessionOptions.AppendExecutionProvider_DmlExecutionProvider();  // DirectML for NPU

// Load the ONNX model
using var session = new InferenceSession("model.onnx", sessionOptions);

// Create input tensor
var inputTensor = new DenseTensor<float>(new[] { 1, 3, 224, 224 });  // Example input shape
var inputs = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor("input", inputTensor) };

// Run inference with NPU acceleration
using var results = session.Run(inputs);
var output = results.First().AsTensor<float>();

// Process output
Console.WriteLine($"Inference result: {output[0]}");
```

é…å¤‡ NPUs çš„è®¾å¤‡åŒ…æ‹¬ï¼š

- **è‹¹æœ**ï¼šå¸¦æœ‰ Neural Engine çš„ A ç³»åˆ—å’Œ M ç³»åˆ—èŠ¯ç‰‡ã€‚
- **é«˜é€š**ï¼šå¸¦æœ‰ Hexagon DSP/NPU çš„ Snapdragon å¤„ç†å™¨ã€‚
- **ä¸‰æ˜Ÿ**ï¼šå¸¦æœ‰ NPU çš„ Exynos å¤„ç†å™¨ã€‚
- **è‹±ç‰¹å°”**ï¼šMovidius VPU å’Œ Habana Labs åŠ é€Ÿå™¨ã€‚
- **å¾®è½¯**ï¼šå¸¦æœ‰ NPUs çš„ Windows Copilot+ ç”µè„‘ã€‚

### ğŸ® GPU åŠ é€Ÿ

å°½ç®¡è¾¹ç¼˜è®¾å¤‡å¯èƒ½æ²¡æœ‰æ•°æ®ä¸­å¿ƒä¸­å¼ºå¤§çš„ GPUï¼Œä½†è®¸å¤šè®¾å¤‡ä»é…å¤‡äº†é›†æˆæˆ–ç‹¬ç«‹çš„ GPUï¼Œå¯ä»¥åŠ é€Ÿ AI å·¥ä½œè´Ÿè½½ã€‚ç°ä»£ç§»åŠ¨ GPU å’Œé›†æˆå›¾å½¢å¤„ç†å™¨å¯ä»¥ä¸º AI æ¨ç†ä»»åŠ¡æä¾›æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

```python
# Example: Using TensorRT for GPU acceleration on edge devices
import tensorrt as trt
import numpy as np

# Create TensorRT logger and builder
TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
builder = trt.Builder(TRT_LOGGER)
network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
parser = trt.OnnxParser(network, TRT_LOGGER)

# Parse ONNX model
with open('model.onnx', 'rb') as model:
    parser.parse(model.read())

# Configure builder
config = builder.create_builder_config()
config.max_workspace_size = 1 << 28  # 256 MiB
config.set_flag(trt.BuilderFlag.FP16)  # Use FP16 precision for edge GPU

# Build and serialize engine
engine = builder.build_engine(network, config)
with open('model.trt', 'wb') as f:
    f.write(engine.serialize())
```

### CPU ä¼˜åŒ–

å³ä½¿æ˜¯ä»…é…å¤‡ CPU çš„è®¾å¤‡ä¹Ÿå¯ä»¥é€šè¿‡ä¼˜åŒ–å®ç° EdgeAIã€‚ç°ä»£ CPU åŒ…æ‹¬ä¸“é—¨ç”¨äº AI å·¥ä½œè´Ÿè½½çš„æŒ‡ä»¤é›†ï¼Œå¹¶ä¸”å·²ç»å¼€å‘äº†è½¯ä»¶æ¡†æ¶ä»¥æœ€å¤§åŒ– CPU åœ¨ AI æ¨ç†ä¸­çš„æ€§èƒ½ã€‚

```bash
# Example: Using XNNPACK with TFLite for optimized CPU inference
# Compilation command with XNNPACK acceleration enabled

bazel build -c opt --copt=-O3 --copt=-march=native \
  tensorflow/lite/delegates/xnnpack:libxnnpack_delegate.so

# Convert TensorFlow model to TFLite with optimization
tflite_convert \
  --keras_model_file=model.h5 \
  --output_file=model.tflite \
  --inference_type=FLOAT \
  --experimental_new_converter \
  --experimental_new_quantizer
```

å¯¹äºä»äº‹ EdgeAI çš„è½¯ä»¶å·¥ç¨‹å¸ˆæ¥è¯´ï¼Œäº†è§£å¦‚ä½•åˆ©ç”¨è¿™äº›ç¡¬ä»¶åŠ é€Ÿé€‰é¡¹å¯¹äºä¼˜åŒ–ç›®æ ‡è®¾å¤‡ä¸Šçš„æ¨ç†æ€§èƒ½å’Œèƒ½æ•ˆè‡³å…³é‡è¦ã€‚

## EdgeAI çš„ä¼˜åŠ¿

### éšç§å’Œå®‰å…¨

EdgeAI çš„ä¸€ä¸ªæ˜¾è‘—ä¼˜åŠ¿æ˜¯å¢å¼ºçš„éšç§å’Œå®‰å…¨æ€§ã€‚é€šè¿‡åœ¨è®¾å¤‡æœ¬åœ°å¤„ç†æ•°æ®ï¼Œæ•æ„Ÿä¿¡æ¯ä¸ä¼šç¦»å¼€ç”¨æˆ·çš„æ§åˆ¶èŒƒå›´ã€‚è¿™å¯¹äºå¤„ç†ä¸ªäººæ•°æ®ã€åŒ»ç–—ä¿¡æ¯æˆ–æœºå¯†å•†ä¸šæ•°æ®çš„åº”ç”¨å°¤ä¸ºé‡è¦ã€‚

### å‡å°‘å»¶è¿Ÿ

EdgeAI æ¶ˆé™¤äº†å°†æ•°æ®å‘é€åˆ°è¿œç¨‹æœåŠ¡å™¨è¿›è¡Œå¤„ç†çš„éœ€æ±‚ï¼Œä»è€Œæ˜¾è‘—å‡å°‘å»¶è¿Ÿã€‚è¿™å¯¹äºéœ€è¦å³æ—¶å“åº”çš„å®æ—¶åº”ç”¨ï¼ˆå¦‚è‡ªåŠ¨é©¾é©¶æ±½è½¦ã€å·¥ä¸šè‡ªåŠ¨åŒ–æˆ–äº¤äº’å¼åº”ç”¨ï¼‰è‡³å…³é‡è¦ã€‚

### ç¦»çº¿èƒ½åŠ›

EdgeAI å³ä½¿åœ¨æ²¡æœ‰äº’è”ç½‘è¿æ¥çš„æƒ…å†µä¸‹ä¹Ÿèƒ½æä¾› AI åŠŸèƒ½ã€‚è¿™å¯¹äºåè¿œåœ°åŒºã€æ—…è¡Œé€”ä¸­æˆ–ç½‘ç»œå¯é æ€§è¾ƒå·®çš„æƒ…å†µä¸‹çš„åº”ç”¨éå¸¸æœ‰ä»·å€¼ã€‚

### æˆæœ¬æ•ˆç›Š

é€šè¿‡å‡å°‘å¯¹åŸºäºäº‘çš„ AI æœåŠ¡çš„ä¾èµ–ï¼ŒEdgeAI å¯ä»¥å¸®åŠ©é™ä½è¿è¥æˆæœ¬ï¼Œå°¤å…¶æ˜¯å¯¹äºé«˜ä½¿ç”¨é‡çš„åº”ç”¨ã€‚ç»„ç»‡å¯ä»¥é¿å…æŒç»­çš„ API æˆæœ¬å¹¶å‡å°‘å¸¦å®½éœ€æ±‚ã€‚

### å¯æ‰©å±•æ€§

EdgeAI å°†è®¡ç®—è´Ÿè½½åˆ†å¸ƒåˆ°è¾¹ç¼˜è®¾å¤‡ä¸Šï¼Œè€Œä¸æ˜¯é›†ä¸­åœ¨æ•°æ®ä¸­å¿ƒã€‚è¿™æœ‰åŠ©äºé™ä½åŸºç¡€è®¾æ–½æˆæœ¬å¹¶æé«˜æ•´ä½“ç³»ç»Ÿçš„å¯æ‰©å±•æ€§ã€‚

## EdgeAI çš„åº”ç”¨

### æ™ºèƒ½è®¾å¤‡å’Œç‰©è”ç½‘

EdgeAI ä¸ºè®¸å¤šæ™ºèƒ½è®¾å¤‡åŠŸèƒ½æä¾›æ”¯æŒï¼Œä»å¯ä»¥æœ¬åœ°å¤„ç†å‘½ä»¤çš„è¯­éŸ³åŠ©æ‰‹åˆ°æ— éœ€å°†è§†é¢‘å‘é€åˆ°äº‘ç«¯å³å¯è¯†åˆ«å¯¹è±¡å’Œäººçš„æ™ºèƒ½æ‘„åƒå¤´ã€‚ç‰©è”ç½‘è®¾å¤‡åˆ©ç”¨ EdgeAI è¿›è¡Œé¢„æµ‹æ€§ç»´æŠ¤ã€ç¯å¢ƒç›‘æµ‹å’Œè‡ªåŠ¨åŒ–å†³ç­–ã€‚

### ç§»åŠ¨åº”ç”¨

æ™ºèƒ½æ‰‹æœºå’Œå¹³æ¿ç”µè„‘ä½¿ç”¨ EdgeAI æä¾›å„ç§åŠŸèƒ½ï¼ŒåŒ…æ‹¬ç…§ç‰‡å¢å¼ºã€å®æ—¶ç¿»è¯‘ã€å¢å¼ºç°å®å’Œä¸ªæ€§åŒ–æ¨èã€‚è¿™äº›åº”ç”¨å—ç›Šäºæœ¬åœ°å¤„ç†çš„ä½å»¶è¿Ÿå’Œéšç§ä¼˜åŠ¿ã€‚

### å·¥ä¸šåº”ç”¨

åˆ¶é€ ä¸šå’Œå·¥ä¸šç¯å¢ƒåˆ©ç”¨ EdgeAI è¿›è¡Œè´¨é‡æ§åˆ¶ã€é¢„æµ‹æ€§ç»´æŠ¤å’Œæµç¨‹ä¼˜åŒ–ã€‚è¿™äº›åº”ç”¨é€šå¸¸éœ€è¦å®æ—¶å¤„ç†ï¼Œå¹¶å¯èƒ½åœ¨è¿æ¥æœ‰é™çš„ç¯å¢ƒä¸­è¿è¡Œã€‚

### åŒ»ç–—ä¿å¥

åŒ»ç–—è®¾å¤‡å’ŒåŒ»ç–—åº”ç”¨åˆ©ç”¨ EdgeAI è¿›è¡Œæ‚£è€…ç›‘æµ‹ã€è¯Šæ–­è¾…åŠ©å’Œæ²»ç–—å»ºè®®ã€‚æœ¬åœ°å¤„ç†çš„éšç§å’Œå®‰å…¨ä¼˜åŠ¿åœ¨åŒ»ç–—åº”ç”¨ä¸­å°¤ä¸ºé‡è¦ã€‚

## æŒ‘æˆ˜å’Œå±€é™æ€§

### æ€§èƒ½æƒè¡¡

EdgeAI é€šå¸¸æ¶‰åŠæ¨¡å‹å¤§å°ã€è®¡ç®—æ•ˆç‡å’Œæ€§èƒ½ä¹‹é—´çš„æƒè¡¡ã€‚å°½ç®¡é‡åŒ–å’Œå‰ªæç­‰æŠ€æœ¯å¯ä»¥æ˜¾è‘—å‡å°‘èµ„æºéœ€æ±‚ï¼Œä½†å®ƒä»¬ä¹Ÿå¯èƒ½å½±å“æ¨¡å‹çš„ç²¾åº¦æˆ–èƒ½åŠ›ã€‚

### å¼€å‘å¤æ‚æ€§

å¼€å‘ EdgeAI åº”ç”¨éœ€è¦ä¸“ä¸šçŸ¥è¯†å’Œå·¥å…·ã€‚å¼€å‘äººå‘˜å¿…é¡»äº†è§£ä¼˜åŒ–æŠ€æœ¯ã€ç¡¬ä»¶èƒ½åŠ›å’Œéƒ¨ç½²é™åˆ¶ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ å¼€å‘çš„å¤æ‚æ€§ã€‚

### ç¡¬ä»¶é™åˆ¶

å°½ç®¡è¾¹ç¼˜ç¡¬ä»¶å–å¾—äº†è¿›æ­¥ï¼Œä½†è¿™äº›è®¾å¤‡ä¸æ•°æ®ä¸­å¿ƒåŸºç¡€è®¾æ–½ç›¸æ¯”ä»æœ‰æ˜¾è‘—é™åˆ¶ã€‚å¹¶éæ‰€æœ‰ AI åº”ç”¨éƒ½èƒ½æœ‰æ•ˆéƒ¨ç½²åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šï¼Œæœ‰äº›å¯èƒ½éœ€è¦æ··åˆæ–¹æ³•ã€‚

### æ¨¡å‹æ›´æ–°å’Œç»´æŠ¤

æ›´æ–°éƒ¨ç½²åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„ AI æ¨¡å‹å¯èƒ½å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå°¤å…¶æ˜¯å¯¹äºè¿æ¥æˆ–å­˜å‚¨å®¹é‡æœ‰é™çš„è®¾å¤‡ã€‚ç»„ç»‡å¿…é¡»åˆ¶å®šæ¨¡å‹ç‰ˆæœ¬ç®¡ç†ã€æ›´æ–°å’Œç»´æŠ¤çš„ç­–ç•¥ã€‚

## EdgeAI çš„æœªæ¥

EdgeAI çš„å‘å±•æ­£åœ¨è¿…é€Ÿæ¨è¿›ï¼Œç¡¬ä»¶ã€è½¯ä»¶å’ŒæŠ€æœ¯æ–¹é¢çš„æŒç»­è¿›æ­¥ä¸æ–­æ¶Œç°ã€‚æœªæ¥è¶‹åŠ¿åŒ…æ‹¬æ›´å¤šä¸“ç”¨çš„è¾¹ç¼˜ AI èŠ¯ç‰‡ã€æ”¹è¿›çš„ä¼˜åŒ–æŠ€æœ¯ä»¥åŠæ›´å¥½çš„ EdgeAI å¼€å‘å’Œéƒ¨ç½²å·¥å…·ã€‚

éšç€ 5G ç½‘ç»œçš„æ™®åŠï¼Œæˆ‘ä»¬å¯èƒ½ä¼šçœ‹åˆ°ç»“åˆè¾¹ç¼˜å¤„ç†å’Œäº‘èƒ½åŠ›çš„æ··åˆæ–¹æ³•ï¼Œä»è€Œåœ¨ä¿æŒæœ¬åœ°å¤„ç†ä¼˜åŠ¿çš„åŒæ—¶å®ç°æ›´å¤æ‚çš„ AI åº”ç”¨ã€‚

EdgeAI ä»£è¡¨äº†ä¸€ç§æ›´åŠ åˆ†å¸ƒå¼ã€é«˜æ•ˆä¸”æ³¨é‡éšç§çš„ AI ç³»ç»Ÿçš„æ ¹æœ¬è½¬å˜ã€‚éšç€æŠ€æœ¯çš„ä¸æ–­æˆç†Ÿï¼Œæˆ‘ä»¬å¯ä»¥é¢„è§ EdgeAI åœ¨æ”¯æŒå„ç§åº”ç”¨å’Œè®¾å¤‡çš„ AI åŠŸèƒ½æ–¹é¢å°†å˜å¾—è¶Šæ¥è¶Šé‡è¦ã€‚

é€šè¿‡ EdgeAI å®ç° AI çš„æ°‘ä¸»åŒ–ä¸ºåˆ›æ–°å¼€è¾Ÿäº†æ–°çš„å¯èƒ½æ€§ï¼Œä½¿å¼€å‘äººå‘˜èƒ½å¤Ÿåˆ›å»ºåœ¨å¤šæ ·åŒ–ç¯å¢ƒä¸­å¯é è¿è¡Œçš„ AI é©±åŠ¨åº”ç”¨ï¼ŒåŒæ—¶å°Šé‡ç”¨æˆ·éšç§å¹¶æä¾›å“åº”è¿…é€Ÿçš„å®æ—¶ä½“éªŒã€‚ç†è§£ EdgeAI æ­£å˜å¾—è¶Šæ¥è¶Šé‡è¦ï¼Œå› ä¸ºå®ƒä»£è¡¨äº† AI åœ¨æˆ‘ä»¬æ—¥å¸¸ç”Ÿæ´»ä¸­éƒ¨ç½²å’Œä½“éªŒçš„æœªæ¥ã€‚
## â¡ï¸ æ¥ä¸‹æ¥æ˜¯ä»€ä¹ˆ

- [02: EdgeAI åº”ç”¨](02.RealWorldCaseStudies.md)

**å…è´£å£°æ˜**ï¼š  
æœ¬æ–‡æ¡£ä½¿ç”¨AIç¿»è¯‘æœåŠ¡[Co-op Translator](https://github.com/Azure/co-op-translator)è¿›è¡Œç¿»è¯‘ã€‚å°½ç®¡æˆ‘ä»¬åŠªåŠ›ç¡®ä¿å‡†ç¡®æ€§ï¼Œä½†è¯·æ³¨æ„ï¼Œè‡ªåŠ¨ç¿»è¯‘å¯èƒ½åŒ…å«é”™è¯¯æˆ–ä¸å‡†ç¡®ä¹‹å¤„ã€‚åº”ä»¥åŸå§‹è¯­è¨€çš„æ–‡æ¡£ä½œä¸ºæƒå¨æ¥æºã€‚å¯¹äºå…³é”®ä¿¡æ¯ï¼Œå»ºè®®ä½¿ç”¨ä¸“ä¸šäººå·¥ç¿»è¯‘ã€‚å› ä½¿ç”¨æœ¬ç¿»è¯‘è€Œå¯¼è‡´çš„ä»»ä½•è¯¯è§£æˆ–è¯¯è¯»ï¼Œæˆ‘ä»¬æ¦‚ä¸è´Ÿè´£ã€‚