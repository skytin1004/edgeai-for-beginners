<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "76b134be93f45283a2df8f8a93717d06",
  "translation_date": "2025-10-17T09:14:07+00:00",
  "source_file": "Module01/01.EdgeAIFundamentals.md",
  "language_code": "zh"
}
-->
# ç¬¬1ç« ï¼šEdgeAIåŸºç¡€çŸ¥è¯†

EdgeAIä»£è¡¨äº†äººå·¥æ™ºèƒ½éƒ¨ç½²çš„ä¸€ç§èŒƒå¼è½¬å˜ï¼Œå°†AIèƒ½åŠ›ç›´æ¥å¸¦åˆ°è¾¹ç¼˜è®¾å¤‡ï¼Œè€Œä¸æ˜¯ä»…ä¾èµ–äºåŸºäºäº‘çš„å¤„ç†ã€‚äº†è§£EdgeAIå¦‚ä½•åœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šå®ç°æœ¬åœ°AIå¤„ç†ï¼ŒåŒæ—¶ä¿æŒåˆç†æ€§èƒ½å¹¶è§£å†³éšç§ã€å»¶è¿Ÿå’Œç¦»çº¿èƒ½åŠ›ç­‰æŒ‘æˆ˜éå¸¸é‡è¦ã€‚

## ç®€ä»‹

åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨EdgeAIåŠå…¶åŸºæœ¬æ¦‚å¿µã€‚æˆ‘ä»¬å°†æ¶µç›–ä¼ ç»ŸAIè®¡ç®—èŒƒå¼ã€è¾¹ç¼˜è®¡ç®—çš„æŒ‘æˆ˜ã€æ”¯æŒEdgeAIçš„å…³é”®æŠ€æœ¯ï¼Œä»¥åŠåœ¨å„è¡Œä¸šä¸­çš„å®é™…åº”ç”¨ã€‚

## å­¦ä¹ ç›®æ ‡

å®Œæˆæœ¬è¯¾ç¨‹åï¼Œæ‚¨å°†èƒ½å¤Ÿï¼š

- ç†è§£ä¼ ç»ŸåŸºäºäº‘çš„AIä¸EdgeAIæ–¹æ³•çš„åŒºåˆ«ã€‚
- è¯†åˆ«æ”¯æŒè¾¹ç¼˜è®¾å¤‡ä¸ŠAIå¤„ç†çš„å…³é”®æŠ€æœ¯ã€‚
- è®¤è¯†EdgeAIå®æ–½çš„ä¼˜åŠ¿å’Œå±€é™æ€§ã€‚
- å°†EdgeAIçŸ¥è¯†åº”ç”¨äºç°å®åœºæ™¯å’Œä½¿ç”¨æ¡ˆä¾‹ã€‚

## ç†è§£ä¼ ç»ŸAIè®¡ç®—èŒƒå¼

ä¼ ç»Ÿä¸Šï¼Œç”Ÿæˆå¼AIåº”ç”¨ä¾èµ–äºé«˜æ€§èƒ½è®¡ç®—åŸºç¡€è®¾æ–½æ¥æœ‰æ•ˆè¿è¡Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚ç»„ç»‡é€šå¸¸å°†è¿™äº›æ¨¡å‹éƒ¨ç½²åœ¨äº‘ç¯å¢ƒä¸­çš„GPUé›†ç¾¤ä¸Šï¼Œé€šè¿‡APIæ¥å£è®¿é—®å…¶åŠŸèƒ½ã€‚

è¿™ç§é›†ä¸­å¼æ¨¡å‹é€‚ç”¨äºè®¸å¤šåº”ç”¨ï¼Œä½†åœ¨è¾¹ç¼˜è®¡ç®—åœºæ™¯ä¸­å­˜åœ¨å›ºæœ‰çš„å±€é™æ€§ã€‚ä¼ ç»Ÿæ–¹æ³•éœ€è¦å°†ç”¨æˆ·æŸ¥è¯¢å‘é€åˆ°è¿œç¨‹æœåŠ¡å™¨ï¼Œä½¿ç”¨å¼ºå¤§çš„ç¡¬ä»¶è¿›è¡Œå¤„ç†ï¼Œå¹¶é€šè¿‡äº’è”ç½‘è¿”å›ç»“æœã€‚è™½ç„¶è¿™ç§æ–¹æ³•æä¾›äº†æœ€å…ˆè¿›çš„æ¨¡å‹è®¿é—®ï¼Œä½†å®ƒå¯¹äº’è”ç½‘è¿æ¥äº§ç”Ÿä¾èµ–ï¼Œå¼•å…¥äº†å»¶è¿Ÿé—®é¢˜ï¼Œå¹¶åœ¨ä¼ è¾“æ•æ„Ÿæ•°æ®åˆ°å¤–éƒ¨æœåŠ¡å™¨æ—¶å¼•å‘éšç§é—®é¢˜ã€‚

åœ¨ä½¿ç”¨ä¼ ç»ŸAIè®¡ç®—èŒƒå¼æ—¶ï¼Œæˆ‘ä»¬éœ€è¦ç†è§£ä¸€äº›æ ¸å¿ƒæ¦‚å¿µï¼š

- **â˜ï¸ åŸºäºäº‘çš„å¤„ç†**ï¼šAIæ¨¡å‹è¿è¡Œåœ¨å…·æœ‰é«˜è®¡ç®—èµ„æºçš„å¼ºå¤§æœåŠ¡å™¨åŸºç¡€è®¾æ–½ä¸Šã€‚
- **ğŸ”Œ åŸºäºAPIçš„è®¿é—®**ï¼šåº”ç”¨é€šè¿‡è¿œç¨‹APIè°ƒç”¨è®¿é—®AIåŠŸèƒ½ï¼Œè€Œä¸æ˜¯æœ¬åœ°å¤„ç†ã€‚
- **ğŸ›ï¸ é›†ä¸­å¼æ¨¡å‹ç®¡ç†**ï¼šæ¨¡å‹é›†ä¸­ç»´æŠ¤å’Œæ›´æ–°ï¼Œç¡®ä¿ä¸€è‡´æ€§ä½†éœ€è¦ç½‘ç»œè¿æ¥ã€‚
- **ğŸ“ˆ èµ„æºå¯æ‰©å±•æ€§**ï¼šäº‘åŸºç¡€è®¾æ–½å¯ä»¥åŠ¨æ€æ‰©å±•ä»¥åº”å¯¹ä¸åŒçš„è®¡ç®—éœ€æ±‚ã€‚

## è¾¹ç¼˜è®¡ç®—çš„æŒ‘æˆ˜

è¾¹ç¼˜è®¾å¤‡å¦‚ç¬”è®°æœ¬ç”µè„‘ã€æ‰‹æœºä»¥åŠç‰©è”ç½‘ï¼ˆIoTï¼‰è®¾å¤‡ï¼ˆå¦‚Raspberry Piå’ŒNVIDIA Orin Nanoï¼‰å…·æœ‰ç‹¬ç‰¹çš„è®¡ç®—çº¦æŸã€‚è¿™äº›è®¾å¤‡é€šå¸¸ä¸æ•°æ®ä¸­å¿ƒåŸºç¡€è®¾æ–½ç›¸æ¯”ï¼Œå¤„ç†èƒ½åŠ›ã€å†…å­˜å’Œèƒ½æºèµ„æºæœ‰é™ã€‚

ç”±äºç¡¬ä»¶é™åˆ¶ï¼Œåœ¨è¿™äº›è®¾å¤‡ä¸Šè¿è¡Œä¼ ç»ŸLLMsä¸€ç›´æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚ç„¶è€Œï¼Œåœ¨è®¸å¤šåœºæ™¯ä¸­ï¼Œè¾¹ç¼˜AIå¤„ç†çš„éœ€æ±‚å˜å¾—è¶Šæ¥è¶Šé‡è¦ã€‚è€ƒè™‘ä»¥ä¸‹æƒ…å†µï¼šäº’è”ç½‘è¿æ¥ä¸å¯é æˆ–ä¸å¯ç”¨ï¼Œä¾‹å¦‚è¿œç¨‹å·¥ä¸šåœºæ‰€ã€è¿è¾“ä¸­çš„è½¦è¾†æˆ–ç½‘ç»œè¦†ç›–è¾ƒå·®çš„åœ°åŒºã€‚æ­¤å¤–ï¼Œè¦æ±‚é«˜å®‰å…¨æ ‡å‡†çš„åº”ç”¨ï¼ˆå¦‚åŒ»ç–—è®¾å¤‡ã€é‡‘èç³»ç»Ÿæˆ–æ”¿åºœåº”ç”¨ï¼‰å¯èƒ½éœ€è¦æœ¬åœ°å¤„ç†æ•æ„Ÿæ•°æ®ä»¥ç»´æŠ¤éšç§å’Œåˆè§„æ€§ã€‚

### è¾¹ç¼˜è®¡ç®—çš„å…³é”®çº¦æŸ

è¾¹ç¼˜è®¡ç®—ç¯å¢ƒé¢ä¸´ä¸€äº›ä¼ ç»ŸåŸºäºäº‘çš„AIè§£å†³æ–¹æ¡ˆæ‰€æ²¡æœ‰çš„åŸºæœ¬çº¦æŸï¼š

- **æœ‰é™çš„å¤„ç†èƒ½åŠ›**ï¼šè¾¹ç¼˜è®¾å¤‡é€šå¸¸å…·æœ‰è¾ƒå°‘çš„CPUæ ¸å¿ƒå’Œè¾ƒä½çš„æ—¶é’Ÿé€Ÿåº¦ï¼Œä¸æœåŠ¡å™¨çº§ç¡¬ä»¶ç›¸æ¯”ã€‚
- **å†…å­˜é™åˆ¶**ï¼šè¾¹ç¼˜è®¾å¤‡ä¸Šçš„å¯ç”¨RAMå’Œå­˜å‚¨å®¹é‡æ˜¾è‘—å‡å°‘ã€‚
- **ç”µåŠ›é™åˆ¶**ï¼šç”µæ± ä¾›ç”µè®¾å¤‡å¿…é¡»åœ¨æ€§èƒ½ä¸èƒ½è€—ä¹‹é—´å¹³è¡¡ï¼Œä»¥å®ç°é•¿æ—¶é—´è¿è¡Œã€‚
- **çƒ­ç®¡ç†**ï¼šç´§å‡‘çš„å¤–å½¢é™åˆ¶äº†å†·å´èƒ½åŠ›ï¼Œå½±å“äº†è´Ÿè½½ä¸‹çš„æŒç»­æ€§èƒ½ã€‚

## ä»€ä¹ˆæ˜¯EdgeAIï¼Ÿ

### æ¦‚å¿µï¼šEdgeAIå®šä¹‰

EdgeAIæ˜¯æŒ‡äººå·¥æ™ºèƒ½ç®—æ³•ç›´æ¥éƒ¨ç½²å’Œæ‰§è¡Œåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šâ€”â€”è¿™äº›è®¾å¤‡æ˜¯ç½‘ç»œâ€œè¾¹ç¼˜â€çš„ç‰©ç†ç¡¬ä»¶ï¼Œé è¿‘æ•°æ®ç”Ÿæˆå’Œæ”¶é›†çš„åœ°æ–¹ã€‚è¿™äº›è®¾å¤‡åŒ…æ‹¬æ™ºèƒ½æ‰‹æœºã€ç‰©è”ç½‘ä¼ æ„Ÿå™¨ã€æ™ºèƒ½æ‘„åƒå¤´ã€è‡ªåŠ¨é©¾é©¶è½¦è¾†ã€å¯ç©¿æˆ´è®¾å¤‡å’Œå·¥ä¸šè®¾å¤‡ã€‚ä¸ä¾èµ–äº‘æœåŠ¡å™¨è¿›è¡Œå¤„ç†çš„ä¼ ç»ŸAIç³»ç»Ÿä¸åŒï¼ŒEdgeAIå°†æ™ºèƒ½ç›´æ¥å¸¦åˆ°æ•°æ®æºã€‚

ä»æœ¬è´¨ä¸Šè®²ï¼ŒEdgeAIæ˜¯å…³äºå»ä¸­å¿ƒåŒ–AIå¤„ç†ï¼Œå°†å…¶ä»é›†ä¸­å¼æ•°æ®ä¸­å¿ƒè½¬ç§»åˆ°æ„æˆæˆ‘ä»¬æ•°å­—ç”Ÿæ€ç³»ç»Ÿçš„åºå¤§è®¾å¤‡ç½‘ç»œä¸­ã€‚è¿™ä»£è¡¨äº†AIç³»ç»Ÿè®¾è®¡å’Œéƒ¨ç½²æ–¹å¼çš„æ ¹æœ¬æ€§æ¶æ„è½¬å˜ã€‚

EdgeAIçš„å…³é”®æ¦‚å¿µæ”¯æŸ±åŒ…æ‹¬ï¼š

- **å°±è¿‘å¤„ç†**ï¼šè®¡ç®—åœ¨æ•°æ®æºé™„è¿‘ç‰©ç†å‘ç”Ÿã€‚
- **åˆ†æ•£å¼æ™ºèƒ½**ï¼šå†³ç­–èƒ½åŠ›åˆ†å¸ƒåœ¨å¤šä¸ªè®¾å¤‡ä¹‹é—´ã€‚
- **æ•°æ®ä¸»æƒ**ï¼šä¿¡æ¯ä¿æŒæœ¬åœ°æ§åˆ¶ï¼Œé€šå¸¸ä¸ä¼šç¦»å¼€è®¾å¤‡ã€‚
- **è‡ªä¸»æ“ä½œ**ï¼šè®¾å¤‡å¯ä»¥åœ¨ä¸éœ€è¦æŒç»­è¿æ¥çš„æƒ…å†µä¸‹æ™ºèƒ½è¿è¡Œã€‚
- **åµŒå…¥å¼AI**ï¼šæ™ºèƒ½æˆä¸ºæ—¥å¸¸è®¾å¤‡çš„å†…åœ¨èƒ½åŠ›ã€‚

### EdgeAIæ¶æ„å¯è§†åŒ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         TRADITIONAL AI ARCHITECTURE                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   Data Transfer  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   API Response   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Edge Devices â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚ Cloud Servers â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ End Users â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     Data                         Model Inference                     Results
   Collection                     High Latency
                                  High Bandwidth
                                  Privacy Concerns
                               
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            EDGE AI ARCHITECTURE                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   Direct Response  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Edge Devices with Embedded AI         â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚ End Users â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â”‚ Sensors â”‚â”€>â”‚ SLM Inference â”‚â”€>â”‚ Local Action â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     Data         Low Latency       Immediate
   Collection     Processing        Response
                  No Data Transfer
                  Enhanced Privacy
```

EdgeAIä»£è¡¨äº†äººå·¥æ™ºèƒ½éƒ¨ç½²çš„ä¸€ç§èŒƒå¼è½¬å˜ï¼Œå°†AIèƒ½åŠ›ç›´æ¥å¸¦åˆ°è¾¹ç¼˜è®¾å¤‡ï¼Œè€Œä¸æ˜¯ä»…ä¾èµ–äºåŸºäºäº‘çš„å¤„ç†ã€‚è¿™ç§æ–¹æ³•ä½¿AIæ¨¡å‹èƒ½å¤Ÿåœ¨è®¡ç®—èµ„æºæœ‰é™çš„è®¾å¤‡ä¸Šæœ¬åœ°è¿è¡Œï¼Œæä¾›å®æ—¶æ¨ç†èƒ½åŠ›ï¼Œè€Œæ— éœ€æŒç»­çš„äº’è”ç½‘è¿æ¥ã€‚

EdgeAIæ¶µç›–äº†å„ç§æŠ€æœ¯å’Œæ–¹æ³•ï¼Œæ—¨åœ¨ä½¿AIæ¨¡å‹æ›´é«˜æ•ˆå¹¶é€‚åˆåœ¨èµ„æºå—é™è®¾å¤‡ä¸Šéƒ¨ç½²ã€‚ç›®æ ‡æ˜¯åœ¨æ˜¾è‘—å‡å°‘AIæ¨¡å‹çš„è®¡ç®—å’Œå†…å­˜éœ€æ±‚çš„åŒæ—¶ä¿æŒåˆç†æ€§èƒ½ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹æ”¯æŒä¸åŒè®¾å¤‡ç±»å‹å’Œä½¿ç”¨æ¡ˆä¾‹çš„EdgeAIå®æ–½çš„åŸºæœ¬æ–¹æ³•ã€‚

### EdgeAIæ ¸å¿ƒåŸåˆ™

EdgeAIåŸºäºå‡ ä¸ªåŒºåˆ†äºä¼ ç»ŸåŸºäºäº‘çš„AIçš„åŸºç¡€åŸåˆ™ï¼š

- **æœ¬åœ°å¤„ç†**ï¼šAIæ¨ç†ç›´æ¥åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šè¿›è¡Œï¼Œæ— éœ€å¤–éƒ¨è¿æ¥ã€‚
- **èµ„æºä¼˜åŒ–**ï¼šæ¨¡å‹ä¸“é—¨é’ˆå¯¹ç›®æ ‡è®¾å¤‡çš„ç¡¬ä»¶çº¦æŸè¿›è¡Œä¼˜åŒ–ã€‚
- **å®æ—¶æ€§èƒ½**ï¼šå¤„ç†ä»¥æœ€å°å»¶è¿Ÿè¿›è¡Œï¼Œé€‚ç”¨äºæ—¶é—´æ•æ„Ÿçš„åº”ç”¨ã€‚
- **éšç§è®¾è®¡**ï¼šæ•æ„Ÿæ•°æ®ä¿ç•™åœ¨è®¾å¤‡ä¸Šï¼Œå¢å¼ºå®‰å…¨æ€§å’Œåˆè§„æ€§ã€‚

## æ”¯æŒEdgeAIçš„å…³é”®æŠ€æœ¯

### æ¨¡å‹é‡åŒ–

æ¨¡å‹é‡åŒ–æ˜¯EdgeAIä¸­æœ€é‡è¦çš„æŠ€æœ¯ä¹‹ä¸€ã€‚æ­¤è¿‡ç¨‹æ¶‰åŠå°†æ¨¡å‹å‚æ•°çš„ç²¾åº¦ä»32ä½æµ®ç‚¹æ•°å‡å°‘åˆ°8ä½æ•´æ•°ç”šè‡³æ›´ä½çš„ç²¾åº¦æ ¼å¼ã€‚è™½ç„¶ç²¾åº¦çš„é™ä½å¯èƒ½çœ‹èµ·æ¥ä»¤äººæ‹…å¿§ï¼Œä½†ç ”ç©¶è¡¨æ˜ï¼Œè®¸å¤šAIæ¨¡å‹å³ä½¿åœ¨æ˜¾è‘—é™ä½ç²¾åº¦çš„æƒ…å†µä¸‹ä»èƒ½ä¿æŒæ€§èƒ½ã€‚

é‡åŒ–é€šè¿‡å°†æµ®ç‚¹å€¼èŒƒå›´æ˜ å°„åˆ°è¾ƒå°çš„ç¦»æ•£å€¼é›†æ¥å®ç°ã€‚ä¾‹å¦‚ï¼Œä¸ä½¿ç”¨32ä½è¡¨ç¤ºæ¯ä¸ªå‚æ•°ç›¸æ¯”ï¼Œé‡åŒ–å¯èƒ½ä»…ä½¿ç”¨8ä½ï¼Œä»è€Œå‡å°‘4å€çš„å†…å­˜éœ€æ±‚ï¼Œå¹¶é€šå¸¸å¯¼è‡´æ›´å¿«çš„æ¨ç†æ—¶é—´ã€‚

```python
# Example: PyTorch model quantization 
import torch

# Load a pre-trained model
model = torch.load('large_model.pth')

# Quantize the model to INT8
quantized_model = torch.quantization.quantize_dynamic(
    model,  # model to quantize
    {torch.nn.Linear, torch.nn.Conv2d},  # layers to quantize
    dtype=torch.qint8  # quantization data type
)

# Save the quantized model
torch.save(quantized_model, 'quantized_model.pth')

# Memory usage comparison
original_size = model.size()
quantized_size = quantized_model.size()
print(f"Memory reduction: {original_size / quantized_size:.2f}x")
```

ä¸åŒçš„é‡åŒ–æŠ€æœ¯åŒ…æ‹¬ï¼š

- **åè®­ç»ƒé‡åŒ–ï¼ˆPTQï¼‰**ï¼šåœ¨æ¨¡å‹è®­ç»ƒååº”ç”¨ï¼Œæ— éœ€é‡æ–°è®­ç»ƒã€‚
- **é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆQATï¼‰**ï¼šåœ¨è®­ç»ƒæœŸé—´ç»“åˆé‡åŒ–æ•ˆæœä»¥æé«˜å‡†ç¡®æ€§ã€‚
- **åŠ¨æ€é‡åŒ–**ï¼šå°†æƒé‡é‡åŒ–ä¸ºint8ï¼Œä½†åŠ¨æ€è®¡ç®—æ¿€æ´»å€¼ã€‚
- **é™æ€é‡åŒ–**ï¼šé¢„å…ˆè®¡ç®—æƒé‡å’Œæ¿€æ´»çš„æ‰€æœ‰é‡åŒ–å‚æ•°ã€‚

å¯¹äºEdgeAIéƒ¨ç½²ï¼Œé€‰æ‹©é€‚å½“çš„é‡åŒ–ç­–ç•¥å–å†³äºç›®æ ‡è®¾å¤‡çš„å…·ä½“æ¨¡å‹æ¶æ„ã€æ€§èƒ½è¦æ±‚å’Œç¡¬ä»¶èƒ½åŠ›ã€‚

### æ¨¡å‹å‹ç¼©ä¸ä¼˜åŒ–

é™¤äº†é‡åŒ–ä¹‹å¤–ï¼Œå„ç§å‹ç¼©æŠ€æœ¯æœ‰åŠ©äºå‡å°‘æ¨¡å‹å¤§å°å’Œè®¡ç®—éœ€æ±‚ã€‚è¿™äº›åŒ…æ‹¬ï¼š

**å‰ªæ**ï¼šæ­¤æŠ€æœ¯ä»ç¥ç»ç½‘ç»œä¸­ç§»é™¤ä¸å¿…è¦çš„è¿æ¥æˆ–ç¥ç»å…ƒã€‚é€šè¿‡è¯†åˆ«å¹¶æ¶ˆé™¤å¯¹æ¨¡å‹æ€§èƒ½è´¡çŒ®è¾ƒå°çš„å‚æ•°ï¼Œå‰ªæå¯ä»¥æ˜¾è‘—å‡å°‘æ¨¡å‹å¤§å°ï¼ŒåŒæ—¶ä¿æŒå‡†ç¡®æ€§ã€‚

```python
# Example: Neural network pruning in TensorFlow
import tensorflow as tf
import tensorflow_model_optimization as tfmot

# Define the model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Apply pruning during training
pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(
    initial_sparsity=0.0,
    final_sparsity=0.5,  # 50% of connections will be pruned
    begin_step=0,
    end_step=10000
)

pruned_model = tfmot.sparsity.keras.prune_low_magnitude(
    model, pruning_schedule=pruning_schedule
)

# Compile the pruned model
pruned_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model while pruning
pruned_model.fit(x_train, y_train, epochs=10)

# Convert to a smaller model for deployment
final_model = tfmot.sparsity.keras.strip_pruning(pruned_model)
```

**çŸ¥è¯†è’¸é¦**ï¼šæ­¤æ–¹æ³•æ¶‰åŠè®­ç»ƒä¸€ä¸ªè¾ƒå°çš„â€œå­¦ç”Ÿâ€æ¨¡å‹ä»¥æ¨¡ä»¿è¾ƒå¤§çš„â€œæ•™å¸ˆâ€æ¨¡å‹çš„è¡Œä¸ºã€‚å­¦ç”Ÿæ¨¡å‹å­¦ä¹ è¿‘ä¼¼æ•™å¸ˆçš„è¾“å‡ºï¼Œé€šå¸¸ä»¥æ˜¾è‘—è¾ƒå°‘çš„å‚æ•°å®ç°ç±»ä¼¼æ€§èƒ½ã€‚

**æ¨¡å‹æ¶æ„ä¼˜åŒ–**ï¼šç ”ç©¶äººå‘˜å¼€å‘äº†ä¸“é—¨ä¸ºè¾¹ç¼˜éƒ¨ç½²è®¾è®¡çš„æ¶æ„ï¼Œä¾‹å¦‚MobileNetsã€EfficientNetsä»¥åŠå…¶ä»–è½»é‡çº§æ¶æ„ï¼Œå¹³è¡¡æ€§èƒ½ä¸è®¡ç®—æ•ˆç‡ã€‚

### å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰

EdgeAIçš„ä¸€ä¸ªæ–°å…´è¶‹åŠ¿æ˜¯å¼€å‘å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰ã€‚è¿™äº›æ¨¡å‹ä»å¤´å¼€å§‹è®¾è®¡ï¼Œæ—¢ç´§å‡‘åˆé«˜æ•ˆï¼ŒåŒæ—¶ä»æä¾›æœ‰æ„ä¹‰çš„è‡ªç„¶è¯­è¨€èƒ½åŠ›ã€‚SLMsé€šè¿‡ç²¾å¿ƒçš„æ¶æ„é€‰æ‹©ã€é«˜æ•ˆçš„è®­ç»ƒæŠ€æœ¯ä»¥åŠé’ˆå¯¹ç‰¹å®šé¢†åŸŸæˆ–ä»»åŠ¡çš„ä¸“æ³¨è®­ç»ƒå®ç°è¿™ä¸€ç›®æ ‡ã€‚

ä¸ä¼ ç»Ÿæ–¹æ³•å‹ç¼©å¤§å‹æ¨¡å‹ä¸åŒï¼ŒSLMsé€šå¸¸ä½¿ç”¨è¾ƒå°çš„æ•°æ®é›†å’Œä¸“é—¨è®¾è®¡çš„æ¶æ„è¿›è¡Œè®­ç»ƒï¼Œä¸“é—¨é’ˆå¯¹è¾¹ç¼˜éƒ¨ç½²ä¼˜åŒ–ã€‚è¿™ç§æ–¹æ³•ä¸ä»…ä½¿æ¨¡å‹æ›´å°ï¼Œè¿˜ä½¿å…¶åœ¨ç‰¹å®šä½¿ç”¨åœºæ™¯ä¸­æ›´é«˜æ•ˆã€‚

## EdgeAIçš„ç¡¬ä»¶åŠ é€Ÿ

ç°ä»£è¾¹ç¼˜è®¾å¤‡è¶Šæ¥è¶Šå¤šåœ°åŒ…æ‹¬ä¸“é—¨è®¾è®¡ç”¨äºåŠ é€ŸAIå·¥ä½œè´Ÿè½½çš„ç¡¬ä»¶ï¼š

### ç¥ç»å¤„ç†å•å…ƒï¼ˆNPUsï¼‰

NPUsæ˜¯ä¸“é—¨ä¸ºç¥ç»ç½‘ç»œè®¡ç®—è®¾è®¡çš„å¤„ç†å™¨ã€‚è¿™äº›èŠ¯ç‰‡å¯ä»¥æ¯”ä¼ ç»ŸCPUæ›´é«˜æ•ˆåœ°æ‰§è¡ŒAIæ¨ç†ä»»åŠ¡ï¼Œé€šå¸¸åŠŸè€—æ›´ä½ã€‚è®¸å¤šç°ä»£æ™ºèƒ½æ‰‹æœºã€ç¬”è®°æœ¬ç”µè„‘å’Œç‰©è”ç½‘è®¾å¤‡ç°åœ¨éƒ½é…å¤‡äº†NPUsï¼Œä»¥å®ç°è®¾å¤‡ä¸Šçš„AIå¤„ç†ã€‚

```csharp
// Example: Using Windows ML to target NPU acceleration in C#
using Microsoft.ML.OnnxRuntime;

// Create session options with NPU provider
var sessionOptions = new SessionOptions();
sessionOptions.AppendExecutionProvider_DmlExecutionProvider();  // DirectML for NPU

// Load the ONNX model
using var session = new InferenceSession("model.onnx", sessionOptions);

// Create input tensor
var inputTensor = new DenseTensor<float>(new[] { 1, 3, 224, 224 });  // Example input shape
var inputs = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor("input", inputTensor) };

// Run inference with NPU acceleration
using var results = session.Run(inputs);
var output = results.First().AsTensor<float>();

// Process output
Console.WriteLine($"Inference result: {output[0]}");
```

é…å¤‡NPUsçš„è®¾å¤‡åŒ…æ‹¬ï¼š

- **Apple**ï¼šå¸¦æœ‰ç¥ç»å¼•æ“çš„Aç³»åˆ—å’ŒMç³»åˆ—èŠ¯ç‰‡
- **Qualcomm**ï¼šå¸¦æœ‰Hexagon DSP/NPUçš„Snapdragonå¤„ç†å™¨
- **Samsung**ï¼šå¸¦æœ‰NPUçš„Exynoså¤„ç†å™¨
- **Intel**ï¼šMovidius VPUså’ŒHabana LabsåŠ é€Ÿå™¨
- **Microsoft**ï¼šå¸¦æœ‰NPUsçš„Windows Copilot+ PC

### ğŸ® GPUåŠ é€Ÿ

è™½ç„¶è¾¹ç¼˜è®¾å¤‡å¯èƒ½æ²¡æœ‰æ•°æ®ä¸­å¿ƒä¸­çš„å¼ºå¤§GPUï¼Œä½†è®¸å¤šè®¾å¤‡ä»åŒ…æ‹¬é›†æˆæˆ–ç‹¬ç«‹GPUï¼Œå¯ä»¥åŠ é€ŸAIå·¥ä½œè´Ÿè½½ã€‚ç°ä»£ç§»åŠ¨GPUå’Œé›†æˆå›¾å½¢å¤„ç†å™¨å¯ä»¥ä¸ºAIæ¨ç†ä»»åŠ¡æä¾›æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

```python
# Example: Using TensorRT for GPU acceleration on edge devices
import tensorrt as trt
import numpy as np

# Create TensorRT logger and builder
TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
builder = trt.Builder(TRT_LOGGER)
network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
parser = trt.OnnxParser(network, TRT_LOGGER)

# Parse ONNX model
with open('model.onnx', 'rb') as model:
    parser.parse(model.read())

# Configure builder
config = builder.create_builder_config()
config.max_workspace_size = 1 << 28  # 256 MiB
config.set_flag(trt.BuilderFlag.FP16)  # Use FP16 precision for edge GPU

# Build and serialize engine
engine = builder.build_engine(network, config)
with open('model.trt', 'wb') as f:
    f.write(engine.serialize())
```

### CPUä¼˜åŒ–

å³ä½¿æ˜¯ä»…é…å¤‡CPUçš„è®¾å¤‡ä¹Ÿå¯ä»¥é€šè¿‡ä¼˜åŒ–å®ç°EdgeAIã€‚ç°ä»£CPUåŒ…æ‹¬ä¸“é—¨é’ˆå¯¹AIå·¥ä½œè´Ÿè½½çš„æŒ‡ä»¤ï¼Œå¹¶å¼€å‘äº†è½¯ä»¶æ¡†æ¶ä»¥æœ€å¤§åŒ–CPUåœ¨AIæ¨ç†ä¸­çš„æ€§èƒ½ã€‚

```bash
# Example: Using XNNPACK with TFLite for optimized CPU inference
# Compilation command with XNNPACK acceleration enabled

bazel build -c opt --copt=-O3 --copt=-march=native \
  tensorflow/lite/delegates/xnnpack:libxnnpack_delegate.so

# Convert TensorFlow model to TFLite with optimization
tflite_convert \
  --keras_model_file=model.h5 \
  --output_file=model.tflite \
  --inference_type=FLOAT \
  --experimental_new_converter \
  --experimental_new_quantizer
```

å¯¹äºä»äº‹EdgeAIçš„å¼€å‘äººå‘˜æ¥è¯´ï¼Œäº†è§£å¦‚ä½•åˆ©ç”¨è¿™äº›ç¡¬ä»¶åŠ é€Ÿé€‰é¡¹å¯¹äºä¼˜åŒ–ç›®æ ‡è®¾å¤‡ä¸Šçš„æ¨ç†æ€§èƒ½å’Œèƒ½æ•ˆè‡³å…³é‡è¦ã€‚

## EdgeAIçš„ä¼˜åŠ¿

### éšç§å’Œå®‰å…¨

EdgeAIæœ€æ˜¾è‘—çš„ä¼˜åŠ¿ä¹‹ä¸€æ˜¯å¢å¼ºçš„éšç§å’Œå®‰å…¨æ€§ã€‚é€šè¿‡åœ¨è®¾å¤‡æœ¬åœ°å¤„ç†æ•°æ®ï¼Œæ•æ„Ÿä¿¡æ¯ä¸ä¼šç¦»å¼€ç”¨æˆ·çš„æ§åˆ¶ã€‚è¿™å¯¹äºå¤„ç†ä¸ªäººæ•°æ®ã€åŒ»ç–—ä¿¡æ¯æˆ–æœºå¯†ä¸šåŠ¡æ•°æ®çš„åº”ç”¨å°¤ä¸ºé‡è¦ã€‚

### å‡å°‘å»¶è¿Ÿ

EdgeAIæ¶ˆé™¤äº†å°†æ•°æ®å‘é€åˆ°è¿œç¨‹æœåŠ¡å™¨è¿›è¡Œå¤„ç†çš„éœ€æ±‚ï¼Œæ˜¾è‘—å‡å°‘äº†å»¶è¿Ÿã€‚è¿™å¯¹äºå®æ—¶åº”ç”¨ï¼ˆå¦‚è‡ªåŠ¨é©¾é©¶è½¦è¾†ã€å·¥ä¸šè‡ªåŠ¨åŒ–æˆ–éœ€è¦å³æ—¶å“åº”çš„äº¤äº’å¼åº”ç”¨ï¼‰è‡³å…³é‡è¦ã€‚

### ç¦»çº¿èƒ½åŠ›

EdgeAIå³ä½¿åœ¨æ²¡æœ‰äº’è”ç½‘è¿æ¥çš„æƒ…å†µä¸‹ä¹Ÿèƒ½å®ç°AIåŠŸèƒ½ã€‚è¿™å¯¹äºè¿œç¨‹ä½ç½®ã€æ—…è¡ŒæœŸé—´æˆ–ç½‘ç»œå¯é æ€§å—åˆ°å½±å“çš„æƒ…å†µéå¸¸æœ‰ä»·å€¼ã€‚

### æˆæœ¬æ•ˆç›Š

é€šè¿‡å‡å°‘å¯¹åŸºäºäº‘çš„AIæœåŠ¡çš„ä¾èµ–ï¼ŒEdgeAIå¯ä»¥å¸®åŠ©é™ä½è¿è¥æˆæœ¬ï¼Œç‰¹åˆ«æ˜¯å¯¹äºé«˜ä½¿ç”¨é‡çš„åº”ç”¨ã€‚ç»„ç»‡å¯ä»¥é¿å…æŒç»­çš„APIæˆæœ¬å¹¶å‡å°‘å¸¦å®½éœ€æ±‚ã€‚

### å¯æ‰©å±•æ€§

EdgeAIå°†è®¡ç®—è´Ÿè½½åˆ†å¸ƒåˆ°è¾¹ç¼˜è®¾å¤‡ä¸Šï¼Œè€Œä¸æ˜¯é›†ä¸­åœ¨æ•°æ®ä¸­å¿ƒã€‚è¿™å¯ä»¥å¸®åŠ©é™ä½åŸºç¡€è®¾æ–½æˆæœ¬å¹¶æé«˜æ•´ä½“ç³»ç»Ÿçš„å¯æ‰©å±•æ€§ã€‚

## EdgeAIçš„åº”ç”¨

### æ™ºèƒ½è®¾å¤‡å’Œç‰©è”ç½‘

EdgeAIä¸ºè®¸å¤šæ™ºèƒ½è®¾å¤‡åŠŸèƒ½æä¾›æ”¯æŒï¼Œä»å¯ä»¥æœ¬åœ°å¤„ç†å‘½ä»¤çš„è¯­éŸ³åŠ©æ‰‹åˆ°æ— éœ€å°†è§†é¢‘å‘é€åˆ°äº‘ç«¯å³å¯è¯†åˆ«ç‰©ä½“å’Œäººçš„æ™ºèƒ½æ‘„åƒå¤´ã€‚ç‰©è”ç½‘è®¾å¤‡ä½¿ç”¨EdgeAIè¿›è¡Œé¢„æµ‹æ€§ç»´æŠ¤ã€ç¯å¢ƒç›‘æµ‹å’Œè‡ªåŠ¨å†³ç­–ã€‚

### ç§»åŠ¨åº”ç”¨

æ™ºèƒ½æ‰‹æœºå’Œå¹³æ¿ç”µè„‘ä½¿ç”¨EdgeAIå®ç°å„ç§åŠŸèƒ½ï¼ŒåŒ…æ‹¬ç…§ç‰‡å¢å¼ºã€å®æ—¶ç¿»è¯‘ã€å¢å¼ºç°å®å’Œä¸ªæ€§åŒ–æ¨èã€‚è¿™äº›åº”ç”¨å—ç›Šäºæœ¬åœ°å¤„ç†çš„ä½å»¶è¿Ÿå’Œéšç§ä¼˜åŠ¿ã€‚

### å·¥ä¸šåº”ç”¨

åˆ¶é€ å’Œå·¥ä¸šç¯å¢ƒä½¿ç”¨EdgeAIè¿›è¡Œè´¨é‡æ§åˆ¶ã€é¢„æµ‹æ€§ç»´æŠ¤å’Œæµç¨‹ä¼˜åŒ–ã€‚è¿™äº›åº”ç”¨é€šå¸¸éœ€è¦å®æ—¶å¤„ç†ï¼Œå¹¶å¯èƒ½åœ¨è¿æ¥æœ‰é™çš„ç¯å¢ƒä¸­è¿è¡Œã€‚

### åŒ»ç–—ä¿å¥

åŒ»ç–—è®¾å¤‡å’ŒåŒ»ç–—åº”ç”¨ä½¿ç”¨EdgeAIè¿›è¡Œæ‚£è€…ç›‘æµ‹ã€è¯Šæ–­è¾…åŠ©å’Œæ²»ç–—å»ºè®®ã€‚æœ¬åœ°å¤„ç†çš„éšç§å’Œå®‰å…¨ä¼˜åŠ¿åœ¨åŒ»ç–—åº”ç”¨ä¸­å°¤ä¸ºé‡è¦ã€‚

## æŒ‘æˆ˜å’Œå±€é™æ€§

### æ€§èƒ½æƒè¡¡

EdgeAIé€šå¸¸æ¶‰åŠæ¨¡å‹å¤§å°ã€è®¡ç®—æ•ˆç‡å’Œæ€§èƒ½ä¹‹é—´çš„æƒè¡¡ã€‚è™½ç„¶é‡åŒ–å’Œå‰ªæç­‰æŠ€æœ¯å¯ä»¥æ˜¾è‘—å‡å°‘èµ„æºéœ€æ±‚ï¼Œä½†å®ƒä»¬ä¹Ÿå¯èƒ½å½±å“æ¨¡å‹çš„å‡†ç¡®æ€§æˆ–èƒ½åŠ›ã€‚

### å¼€å‘å¤æ‚æ€§

å¼€å‘EdgeAIåº”ç”¨éœ€è¦ä¸“ä¸šçŸ¥è¯†å’Œå·¥å…·ã€‚å¼€å‘äººå‘˜å¿…é¡»äº†è§£ä¼˜åŒ–æŠ€æœ¯ã€ç¡¬ä»¶èƒ½åŠ›å’Œéƒ¨ç½²çº¦æŸï¼Œè¿™å¯èƒ½å¢åŠ å¼€å‘å¤æ‚æ€§ã€‚

### ç¡¬ä»¶é™åˆ¶

å°½ç®¡è¾¹ç¼˜ç¡¬ä»¶å–å¾—äº†è¿›æ­¥ï¼Œè¿™äº›è®¾å¤‡ä¸æ•°æ®ä¸­å¿ƒåŸºç¡€è®¾æ–½ç›¸æ¯”ä»æœ‰æ˜¾è‘—é™åˆ¶ã€‚å¹¶éæ‰€æœ‰AIåº”ç”¨éƒ½èƒ½æœ‰æ•ˆéƒ¨ç½²åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šï¼Œæœ‰äº›å¯èƒ½éœ€è¦æ··åˆæ–¹æ³•ã€‚

### æ¨¡å‹æ›´æ–°å’Œç»´æŠ¤

æ›´æ–°éƒ¨ç½²åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„AIæ¨¡å‹å¯èƒ½å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå°¤å…¶æ˜¯å¯¹äºè¿æ¥æˆ–å­˜å‚¨å®¹é‡æœ‰é™çš„è®¾å¤‡ã€‚ç»„ç»‡å¿…é¡»åˆ¶å®šæ¨¡å‹ç‰ˆæœ¬ç®¡ç†ã€æ›´æ–°å’Œç»´æŠ¤çš„ç­–ç•¥ã€‚

## EdgeAIçš„æœªæ¥

EdgeAIé¢†åŸŸæ­£åœ¨å¿«é€Ÿå‘å±•ï¼Œç¡¬ä»¶ã€è½¯ä»¶å’ŒæŠ€æœ¯æ–¹é¢ä¸æ–­å–å¾—è¿›å±•ã€‚æœªæ¥è¶‹åŠ¿åŒ…æ‹¬æ›´å¤šä¸“é—¨çš„è¾¹ç¼˜AIèŠ¯ç‰‡ã€æ”¹è¿›çš„ä¼˜åŒ–æŠ€æœ¯ä»¥åŠæ›´å¥½çš„EdgeAIå¼€å‘å’Œéƒ¨ç½²å·¥å…·ã€‚

éšç€5Gç½‘ç»œçš„æ™®åŠï¼Œæˆ‘ä»¬å¯èƒ½ä¼šçœ‹åˆ°ç»“åˆè¾¹ç¼˜å¤„ç†å’Œäº‘èƒ½åŠ›çš„æ··åˆæ–¹æ³•ï¼Œä»è€Œå®ç°æ›´å¤æ‚çš„AIåº”ç”¨ï¼ŒåŒæ—¶ä¿æŒæœ¬åœ°å¤„ç†çš„ä¼˜åŠ¿ã€‚

EdgeAIä»£è¡¨äº†ä¸€ç§æ›´åˆ†æ•£ã€æ›´é«˜æ•ˆã€æ›´æ³¨é‡éšç§ä¿æŠ¤çš„AIç³»ç»Ÿçš„æ ¹æœ¬è½¬å˜ã€‚éšç€æŠ€æœ¯çš„ä¸æ–­æˆç†Ÿï¼Œæˆ‘ä»¬å¯ä»¥é¢„æœŸEdgeAIå°†åœ¨å¹¿æ³›çš„åº”ç”¨å’Œè®¾å¤‡ä¸­å˜å¾—è¶Šæ¥è¶Šé‡è¦ã€‚

é€šè¿‡EdgeAIå®ç°AIçš„æ°‘ä¸»åŒ–ä¸ºåˆ›æ–°å¼€è¾Ÿäº†æ–°çš„å¯èƒ½æ€§ï¼Œä½¿å¼€å‘äººå‘˜èƒ½å¤Ÿåˆ›å»ºåœ¨å¤šæ ·åŒ–ç¯å¢ƒä¸­å¯é è¿è¡Œçš„AIé©±åŠ¨åº”ç”¨ï¼ŒåŒæ—¶å°Šé‡ç”¨æˆ·éšç§å¹¶æä¾›å“åº”è¿…é€Ÿçš„å®æ—¶ä½“éªŒã€‚ç†è§£EdgeAIå¯¹äºä»»ä½•ä»äº‹AIæŠ€æœ¯çš„äººæ¥è¯´éƒ½å˜å¾—è¶Šæ¥è¶Šé‡è¦ï¼Œå› ä¸ºå®ƒä»£è¡¨äº†AIå¦‚ä½•è¢«éƒ¨ç½²å’Œä½“éªŒçš„æœªæ¥ã€‚

## â¡ï¸ ä¸‹ä¸€æ­¥
- [02: EdgeAI åº”ç”¨](02.RealWorldCaseStudies.md)

---

**å…è´£å£°æ˜**ï¼š  
æœ¬æ–‡æ¡£ä½¿ç”¨AIç¿»è¯‘æœåŠ¡[Co-op Translator](https://github.com/Azure/co-op-translator)è¿›è¡Œç¿»è¯‘ã€‚å°½ç®¡æˆ‘ä»¬åŠªåŠ›ç¡®ä¿ç¿»è¯‘çš„å‡†ç¡®æ€§ï¼Œä½†è¯·æ³¨æ„ï¼Œè‡ªåŠ¨ç¿»è¯‘å¯èƒ½åŒ…å«é”™è¯¯æˆ–ä¸å‡†ç¡®ä¹‹å¤„ã€‚åŸå§‹è¯­è¨€çš„æ–‡æ¡£åº”è¢«è§†ä¸ºæƒå¨æ¥æºã€‚å¯¹äºé‡è¦ä¿¡æ¯ï¼Œå»ºè®®ä½¿ç”¨ä¸“ä¸šäººå·¥ç¿»è¯‘ã€‚æˆ‘ä»¬ä¸å¯¹å› ä½¿ç”¨æ­¤ç¿»è¯‘è€Œäº§ç”Ÿçš„ä»»ä½•è¯¯è§£æˆ–è¯¯è¯»æ‰¿æ‹…è´£ä»»ã€‚