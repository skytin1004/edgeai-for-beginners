<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2f1754a482b6a84e07287a5b775e65b6",
  "translation_date": "2025-09-30T23:20:36+00:00",
  "source_file": "Module08/samples/04/README.md",
  "language_code": "zh"
}
-->
# ç¤ºä¾‹ 04ï¼šä½¿ç”¨ Chainlit æ„å»ºç”Ÿäº§çº§èŠå¤©åº”ç”¨

ä¸€ä¸ªå…¨é¢çš„ç¤ºä¾‹ï¼Œå±•ç¤ºäº†ä½¿ç”¨ Microsoft Foundry Local æ„å»ºç”Ÿäº§çº§èŠå¤©åº”ç”¨çš„å¤šç§æ–¹æ³•ï¼ŒåŒ…å«ç°ä»£åŒ–çš„ç½‘é¡µç•Œé¢ã€æµå¼å“åº”ä»¥åŠå…ˆè¿›çš„æµè§ˆå™¨æŠ€æœ¯ã€‚

## åŒ…å«å†…å®¹

- **ğŸš€ Chainlit èŠå¤©åº”ç”¨** (`app.py`)ï¼šæ”¯æŒæµå¼å“åº”çš„ç”Ÿäº§çº§èŠå¤©åº”ç”¨
- **ğŸŒ WebGPU æ¼”ç¤º** (`webgpu-demo/`)ï¼šåŸºäºæµè§ˆå™¨çš„ AI æ¨ç†ï¼Œæ”¯æŒç¡¬ä»¶åŠ é€Ÿ
- **ğŸ¨ Open WebUI é›†æˆ** (`open-webui-guide.md`)ï¼šä¸“ä¸šçš„ ChatGPT é£æ ¼ç•Œé¢
- **ğŸ“š æ•™å­¦ç¬”è®°æœ¬** (`chainlit_app.ipynb`)ï¼šäº¤äº’å¼å­¦ä¹ ææ–™

## å¿«é€Ÿå¼€å§‹

### 1. Chainlit èŠå¤©åº”ç”¨

```cmd
# Navigate to Module08 directory
cd Module08

# Start your model
foundry model run phi-4-mini

# Run Chainlit app (using port 8080 to avoid conflicts)
chainlit run samples\04\app.py -w --port 8080
```

è®¿é—®åœ°å€ï¼š`http://localhost:8080`

### 2. WebGPU æµè§ˆå™¨æ¼”ç¤º

```cmd
# Navigate to WebGPU demo
cd Module08\samples\04\webgpu-demo

# Serve the demo
python -m http.server 5173
```

è®¿é—®åœ°å€ï¼š`http://localhost:5173`

### 3. Open WebUI è®¾ç½®

```cmd
# Run Open WebUI with Docker
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

è®¿é—®åœ°å€ï¼š`http://localhost:3000`

## æ¶æ„æ¨¡å¼

### æœ¬åœ°ä¸äº‘ç«¯å†³ç­–çŸ©é˜µ

| åœºæ™¯ | æ¨è | åŸå›  |
|------|------|------|
| **éšç§æ•æ„Ÿæ•°æ®** | ğŸ  æœ¬åœ° (Foundry) | æ•°æ®ä¸ä¼šç¦»å¼€è®¾å¤‡ |
| **å¤æ‚æ¨ç†** | â˜ï¸ äº‘ç«¯ (Azure OpenAI) | å¯è®¿é—®æ›´å¤§çš„æ¨¡å‹ |
| **å®æ—¶èŠå¤©** | ğŸ  æœ¬åœ° (Foundry) | æ›´ä½å»¶è¿Ÿï¼Œæ›´å¿«å“åº” |
| **æ–‡æ¡£åˆ†æ** | ğŸ”„ æ··åˆ | æœ¬åœ°æå–ï¼Œäº‘ç«¯åˆ†æ |
| **ä»£ç ç”Ÿæˆ** | ğŸ  æœ¬åœ° (Foundry) | éšç§ä¿æŠ¤ + ä¸“ç”¨æ¨¡å‹ |
| **ç ”ç©¶ä»»åŠ¡** | â˜ï¸ äº‘ç«¯ (Azure OpenAI) | éœ€è¦å¹¿æ³›çš„çŸ¥è¯†åº“ |

### æŠ€æœ¯å¯¹æ¯”

| æŠ€æœ¯ | ä½¿ç”¨åœºæ™¯ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|----------|------|------|
| **Chainlit** | Python å¼€å‘è€…ï¼Œå¿«é€ŸåŸå‹è®¾è®¡ | è®¾ç½®ç®€å•ï¼Œæ”¯æŒæµå¼å“åº” | ä»…æ”¯æŒ Python |
| **WebGPU** | æœ€å¤§éšç§ï¼Œç¦»çº¿åœºæ™¯ | åŸç”Ÿæµè§ˆå™¨ï¼Œæ— éœ€æœåŠ¡å™¨ | æ¨¡å‹å¤§å°æœ‰é™ |
| **Open WebUI** | ç”Ÿäº§éƒ¨ç½²ï¼Œå›¢é˜Ÿåä½œ | ä¸“ä¸šç•Œé¢ï¼Œç”¨æˆ·ç®¡ç† | éœ€è¦ Docker |

## å‰ç½®æ¡ä»¶

- **Foundry Local**ï¼šå·²å®‰è£…å¹¶è¿è¡Œ ([ä¸‹è½½](https://aka.ms/foundry-local-installer))
- **Python**ï¼š3.10+ï¼Œæ”¯æŒè™šæ‹Ÿç¯å¢ƒ
- **æ¨¡å‹**ï¼šè‡³å°‘åŠ è½½ä¸€ä¸ªæ¨¡å‹ (`foundry model run phi-4-mini`)
- **æµè§ˆå™¨**ï¼šæ”¯æŒ WebGPU çš„ Chrome/Edgeï¼Œç”¨äºæ¼”ç¤º
- **Docker**ï¼šç”¨äº Open WebUIï¼ˆå¯é€‰ï¼‰

## å®‰è£…ä¸è®¾ç½®

### 1. Python ç¯å¢ƒè®¾ç½®

```cmd
# Navigate to Module08 directory
cd Module08

# Create and activate virtual environment
py -m venv .venv
.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Foundry Local è®¾ç½®

```cmd
# Verify Foundry Local installation
foundry --version

# Start the service
foundry service start

# Load a model
foundry model run phi-4-mini

# Verify model is running
foundry service ps
```

## ç¤ºä¾‹åº”ç”¨

### Chainlit èŠå¤©åº”ç”¨

**åŠŸèƒ½ç‰¹ç‚¹ï¼š**
- ğŸš€ **å®æ—¶æµå¼å“åº”**ï¼šç”Ÿæˆçš„ token å³æ—¶æ˜¾ç¤º
- ğŸ›¡ï¸ **å¼ºå¤§çš„é”™è¯¯å¤„ç†**ï¼šä¼˜é›…é™çº§ä¸æ¢å¤
- ğŸ¨ **ç°ä»£åŒ–ç•Œé¢**ï¼šå¼€ç®±å³ç”¨çš„ä¸“ä¸šèŠå¤©ç•Œé¢
- ğŸ”§ **çµæ´»é…ç½®**ï¼šæ”¯æŒç¯å¢ƒå˜é‡ä¸è‡ªåŠ¨æ£€æµ‹
- ğŸ“± **å“åº”å¼è®¾è®¡**ï¼šé€‚é…æ¡Œé¢ä¸ç§»åŠ¨è®¾å¤‡

**å¿«é€Ÿå¼€å§‹ï¼š**
```cmd
# Run with default settings (recommended)
chainlit run samples\04\app.py -w --port 8080

# Use specific model
set MODEL=qwen2.5-7b
chainlit run samples\04\app.py -w --port 8080

# Manual endpoint configuration
set BASE_URL=http://localhost:51211
set API_KEY=your-api-key
chainlit run samples\04\app.py -w --port 8080
```

### WebGPU æµè§ˆå™¨æ¼”ç¤º

**åŠŸèƒ½ç‰¹ç‚¹ï¼š**
- ğŸŒ **åŸç”Ÿæµè§ˆå™¨ AI**ï¼šæ— éœ€æœåŠ¡å™¨ï¼Œå®Œå…¨åœ¨æµè§ˆå™¨ä¸­è¿è¡Œ
- âš¡ **WebGPU åŠ é€Ÿ**ï¼šæ”¯æŒç¡¬ä»¶åŠ é€Ÿ
- ğŸ”’ **æœ€å¤§éšç§ä¿æŠ¤**ï¼šæ•°æ®ç»ä¸ä¼šç¦»å¼€è®¾å¤‡
- ğŸ¯ **é›¶å®‰è£…**ï¼šå…¼å®¹çš„æµè§ˆå™¨å³å¯è¿è¡Œ
- ğŸ”„ **ä¼˜é›…å›é€€**ï¼šWebGPU ä¸å¯ç”¨æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ° CPU

**è¿è¡Œæ–¹å¼ï¼š**
```cmd
cd samples\04\webgpu-demo
python -m http.server 5173
# Open http://localhost:5173
```

### Open WebUI é›†æˆ

**åŠŸèƒ½ç‰¹ç‚¹ï¼š**
- ğŸ¨ **ChatGPT é£æ ¼ç•Œé¢**ï¼šä¸“ä¸šä¸”ç†Ÿæ‚‰çš„ç”¨æˆ·ç•Œé¢
- ğŸ‘¥ **å¤šç”¨æˆ·æ”¯æŒ**ï¼šç”¨æˆ·è´¦æˆ·ä¸ä¼šè¯å†å²è®°å½•
- ğŸ“ **æ–‡ä»¶å¤„ç†**ï¼šä¸Šä¼ å¹¶åˆ†ææ–‡æ¡£
- ğŸ”„ **æ¨¡å‹åˆ‡æ¢**ï¼šè½»æ¾åˆ‡æ¢ä¸åŒæ¨¡å‹
- ğŸ³ **Docker éƒ¨ç½²**ï¼šç”Ÿäº§çº§å®¹å™¨åŒ–è®¾ç½®

**å¿«é€Ÿè®¾ç½®ï¼š**
```cmd
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

## é…ç½®å‚è€ƒ

### ç¯å¢ƒå˜é‡

| å˜é‡ | æè¿° | é»˜è®¤å€¼ | ç¤ºä¾‹ |
|------|------|--------|------|
| `MODEL` | ä½¿ç”¨çš„æ¨¡å‹åˆ«å | `phi-4-mini` | `qwen2.5-7b` |
| `BASE_URL` | Foundry Local ç«¯ç‚¹ | è‡ªåŠ¨æ£€æµ‹ | `http://localhost:51211` |
| `API_KEY` | API å¯†é’¥ï¼ˆæœ¬åœ°å¯é€‰ï¼‰ | `""` | `your-api-key` |

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**Chainlit åº”ç”¨ï¼š**

1. **æœåŠ¡ä¸å¯ç”¨ï¼š**
   ```cmd
   # Check Foundry Local status
   foundry service status
   foundry service ps
   
   # Validate API endpoint (note: port 51211)
   curl http://localhost:51211/v1/models
   ```

2. **ç«¯å£å†²çªï¼š**
   ```cmd
   # Check what's using port 8080
   netstat -ano | findstr :8080
   
   # Use different port if needed
   chainlit run samples\04\app.py -w --port 3000
   ```

3. **Python ç¯å¢ƒé—®é¢˜ï¼š**
   ```cmd
   # Verify correct interpreter in VS Code
   # Ctrl+Shift+P â†’ Python: Select Interpreter
   # Choose: Module08/.venv/Scripts/python.exe
   
   # Reinstall dependencies
   pip install -r requirements.txt
   ```

**WebGPU æ¼”ç¤ºï¼š**

1. **WebGPU ä¸æ”¯æŒï¼š**
   - æ›´æ–°åˆ° Chrome/Edge 113+
   - å¯ç”¨ WebGPUï¼š`chrome://flags/#enable-unsafe-webgpu`
   - æ£€æŸ¥ GPU çŠ¶æ€ï¼š`chrome://gpu`
   - æ¼”ç¤ºä¼šè‡ªåŠ¨å›é€€åˆ° CPU

2. **æ¨¡å‹åŠ è½½é”™è¯¯ï¼š**
   - ç¡®ä¿ç½‘ç»œè¿æ¥ä»¥ä¸‹è½½æ¨¡å‹
   - æ£€æŸ¥æµè§ˆå™¨æ§åˆ¶å°ä¸­çš„ CORS é”™è¯¯
   - ç¡®ä¿é€šè¿‡ HTTP æœåŠ¡ï¼ˆè€Œé file://ï¼‰

**Open WebUIï¼š**

1. **è¿æ¥è¢«æ‹’ç»ï¼š**
   ```cmd
   # Check Docker is running
   docker --version
   
   # Check container status
   docker ps | findstr open-webui
   
   # View container logs
   docker logs open-webui
   ```

2. **æ¨¡å‹æœªæ˜¾ç¤ºï¼š**
   ```cmd
   # Verify Foundry Local endpoint
   curl http://localhost:51211/v1/models
   
   # Restart Open WebUI
   docker restart open-webui
   ```

### éªŒè¯æ¸…å•

```cmd
# âœ… 1. Foundry Local Setup
foundry --version                    # Should show version
foundry service status               # Should show "running"
foundry model list                   # Should show loaded models
curl http://localhost:51211/v1/models  # Should return JSON

# âœ… 2. Python Environment  
python --version                     # Should be 3.10+
pip list | findstr chainlit         # Should show chainlit package
pip list | findstr openai           # Should show openai package

# âœ… 3. Application Testing
chainlit run samples\04\app.py -w --port 8080  # Should open browser
# Test WebGPU demo at localhost:5173
# Test Open WebUI at localhost:3000
```

## é«˜çº§ç”¨æ³•

### æ€§èƒ½ä¼˜åŒ–

**Chainlitï¼š**
- ä½¿ç”¨æµå¼å“åº”æå‡ç”¨æˆ·ä½“éªŒ
- å®ç°è¿æ¥æ± ä»¥æ”¯æŒé«˜å¹¶å‘
- ç¼“å­˜æ¨¡å‹å“åº”ä»¥å¤„ç†é‡å¤æŸ¥è¯¢
- ç›‘æ§å¤§è§„æ¨¡ä¼šè¯å†å²çš„å†…å­˜ä½¿ç”¨

**WebGPUï¼š**
- ä½¿ç”¨ WebGPU å®ç°æœ€å¤§éšç§ä¸é€Ÿåº¦
- å®ç°æ¨¡å‹é‡åŒ–ä»¥å‡å°æ¨¡å‹å¤§å°
- ä½¿ç”¨ Web Workers è¿›è¡Œåå°å¤„ç†
- åœ¨æµè§ˆå™¨å­˜å‚¨ä¸­ç¼“å­˜ç¼–è¯‘åçš„æ¨¡å‹

**Open WebUIï¼š**
- ä½¿ç”¨æŒä¹…å·ä¿å­˜ä¼šè¯å†å²
- ä¸º Docker å®¹å™¨é…ç½®èµ„æºé™åˆ¶
- å®ç°ç”¨æˆ·æ•°æ®çš„å¤‡ä»½ç­–ç•¥
- è®¾ç½®åå‘ä»£ç†ä»¥æ”¯æŒ SSL ç»ˆæ­¢

### é›†æˆæ¨¡å¼

**æœ¬åœ°/äº‘ç«¯æ··åˆï¼š**
```python
# Route based on complexity and privacy requirements
async def intelligent_routing(prompt: str, metadata: dict):
    if metadata.get("contains_pii"):
        return await foundry_local_completion(prompt)  # Privacy-sensitive
    elif len(prompt.split()) > 200:
        return await azure_openai_completion(prompt)   # Complex reasoning
    else:
        return await foundry_local_completion(prompt)  # Default local
```

**å¤šæ¨¡æ€ç®¡é“ï¼š**
```python
# Combine different AI capabilities
async def analyze_document(file_path: str):
    # 1. OCR with WebGPU (browser-based)
    text = await webgpu_ocr(file_path)
    
    # 2. Analysis with Foundry Local (private)
    summary = await foundry_local_analyze(text)
    
    # 3. Enhancement with cloud (if needed)
    if summary.confidence < 0.8:
        summary = await azure_openai_enhance(summary)
    
    return summary
```

## ç”Ÿäº§éƒ¨ç½²

### å®‰å…¨æ³¨æ„äº‹é¡¹

- **API å¯†é’¥**ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Œåˆ‡å‹¿ç¡¬ç¼–ç 
- **ç½‘ç»œ**ï¼šç”Ÿäº§ç¯å¢ƒä½¿ç”¨ HTTPSï¼Œå›¢é˜Ÿè®¿é—®å¯è€ƒè™‘ VPN
- **è®¿é—®æ§åˆ¶**ï¼šä¸º Open WebUI å®ç°èº«ä»½éªŒè¯
- **æ•°æ®éšç§**ï¼šå®¡æŸ¥å“ªäº›æ•°æ®ç•™åœ¨æœ¬åœ°ï¼Œå“ªäº›å‘é€åˆ°äº‘ç«¯
- **æ›´æ–°**ï¼šä¿æŒ Foundry Local å’Œå®¹å™¨çš„æœ€æ–°ç‰ˆæœ¬

### ç›‘æ§ä¸ç»´æŠ¤

- **å¥åº·æ£€æŸ¥**ï¼šå®ç°ç«¯ç‚¹ç›‘æ§
- **æ—¥å¿—è®°å½•**ï¼šé›†ä¸­ç®¡ç†æ‰€æœ‰ç»„ä»¶çš„æ—¥å¿—
- **æŒ‡æ ‡ç›‘æ§**ï¼šè·Ÿè¸ªå“åº”æ—¶é—´ã€é”™è¯¯ç‡ã€èµ„æºä½¿ç”¨æƒ…å†µ
- **å¤‡ä»½**ï¼šå®šæœŸå¤‡ä»½ä¼šè¯æ•°æ®å’Œé…ç½®

## å‚è€ƒä¸èµ„æº

### æ–‡æ¡£
- [Chainlit æ–‡æ¡£](https://docs.chainlit.io/) - å®Œæ•´æ¡†æ¶æŒ‡å—
- [Foundry Local æ–‡æ¡£](https://learn.microsoft.com/azure/ai-foundry/foundry-local/) - å®˜æ–¹ Microsoft æ–‡æ¡£
- [ONNX Runtime Web](https://onnxruntime.ai/docs/get-started/with-javascript/web.html) - WebGPU é›†æˆ
- [Open WebUI æ–‡æ¡£](https://docs.openwebui.com/) - é«˜çº§é…ç½®æŒ‡å—

### ç¤ºä¾‹æ–‡ä»¶
- [`app.py`](../../../../../Module08/samples/04/app.py) - ç”Ÿäº§çº§ Chainlit åº”ç”¨
- [`chainlit_app.ipynb`](./chainlit_app.ipynb) - æ•™å­¦ç¬”è®°æœ¬
- [`webgpu-demo/`](../../../../../Module08/samples/04/webgpu-demo) - åŸºäºæµè§ˆå™¨çš„ AI æ¨ç†
- [`open-webui-guide.md`](./open-webui-guide.md) - å®Œæ•´çš„ Open WebUI è®¾ç½®æŒ‡å—

### ç›¸å…³ç¤ºä¾‹
- [ç¬¬ 4 èŠ‚æ–‡æ¡£](../../04.CuttingEdgeModels.md) - å®Œæ•´è¯¾ç¨‹æŒ‡å—
- [Foundry Local ç¤ºä¾‹](https://github.com/microsoft/foundry-local/tree/main/samples) - å®˜æ–¹ç¤ºä¾‹

---

**å…è´£å£°æ˜**ï¼š  
æœ¬æ–‡æ¡£ä½¿ç”¨AIç¿»è¯‘æœåŠ¡ [Co-op Translator](https://github.com/Azure/co-op-translator) è¿›è¡Œç¿»è¯‘ã€‚å°½ç®¡æˆ‘ä»¬åŠªåŠ›ç¡®ä¿ç¿»è¯‘çš„å‡†ç¡®æ€§ï¼Œä½†è¯·æ³¨æ„ï¼Œè‡ªåŠ¨ç¿»è¯‘å¯èƒ½åŒ…å«é”™è¯¯æˆ–ä¸å‡†ç¡®ä¹‹å¤„ã€‚åŸå§‹è¯­è¨€çš„æ–‡æ¡£åº”è¢«è§†ä¸ºæƒå¨æ¥æºã€‚å¯¹äºå…³é”®ä¿¡æ¯ï¼Œå»ºè®®ä½¿ç”¨ä¸“ä¸šäººå·¥ç¿»è¯‘ã€‚æˆ‘ä»¬å¯¹å› ä½¿ç”¨æ­¤ç¿»è¯‘è€Œäº§ç”Ÿçš„ä»»ä½•è¯¯è§£æˆ–è¯¯è¯»ä¸æ‰¿æ‹…è´£ä»»ã€‚