<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ddaad917d0c16fc3d498a6b4eabc8088",
  "translation_date": "2025-10-09T17:06:45+00:00",
  "source_file": "Workshop/notebooks/quickstart.md",
  "language_code": "he"
}
-->
# ××“×¨×™×š ××”×™×¨ ×œ××—×‘×¨×•×ª ×¡×“× ×”

## ×ª×•×›×Ÿ ×¢× ×™×™× ×™×

- [×“×¨×™×©×•×ª ××§×“×™××•×ª](../../../../Workshop/notebooks)
- [×”×’×“×¨×” ×¨××©×•× ×™×ª](../../../../Workshop/notebooks)
- [××¤×’×© 04: ×”×©×•×•××ª ××•×“×œ×™×](../../../../Workshop/notebooks)
- [××¤×’×© 05: ××ª×–××¨ ×¨×‘-×¡×•×›× ×™×](../../../../Workshop/notebooks)
- [××¤×’×© 06: × ×™×ª×•×‘ ××•×“×œ×™× ××‘×•×¡×¡ ×›×•×•× ×”](../../../../Workshop/notebooks)
- [××©×ª× ×™ ×¡×‘×™×‘×”](../../../../Workshop/notebooks)
- [×¤×§×•×“×•×ª × ×¤×•×¦×•×ª](../../../../Workshop/notebooks)

---

## ×“×¨×™×©×•×ª ××§×“×™××•×ª

### 1. ×”×ª×§× ×ª Foundry Local

**Windows:**
```bash
winget install Microsoft.FoundryLocal
```

**macOS:**
```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

**××™××•×ª ×”×ª×§× ×”:**
```bash
foundry --version
```

### 2. ×”×ª×§× ×ª ×ª×œ×•×ª×™× ×‘-Python

```bash
cd Workshop
pip install -r requirements.txt
```

××• ×”×ª×§× ×” ×¤×¨×˜× ×™×ª:
```bash
pip install foundry-local-sdk openai numpy requests
```

---

## ×”×’×“×¨×” ×¨××©×•× ×™×ª

### ×”×¤×¢×œ×ª ×©×™×¨×•×ª Foundry Local

**× ×“×¨×© ×œ×¤× ×™ ×”×¤×¢×œ×ª ×›×œ ××—×‘×¨×ª:**

```bash
# Start the service
foundry service start

# Verify it's running
foundry service status
```

×¤×œ×˜ ×¦×¤×•×™:
```
âœ… Service started successfully
Endpoint: http://localhost:59959
```

### ×”×•×¨×“×” ×•×˜×¢×™× ×ª ××•×“×œ×™×

×”××—×‘×¨×•×ª ××©×ª××©×•×ª ×‘××•×“×œ×™× ×”×‘××™× ×›×‘×¨×™×¨×ª ××—×“×œ:

```bash
# Download models (first time only - may take several minutes)
foundry model download phi-4-mini
foundry model download qwen2.5-3b
foundry model download phi-3.5-mini
foundry model download qwen2.5-0.5b

# Load models into memory
foundry model run phi-4-mini
foundry model run qwen2.5-3b
foundry model run phi-3.5-mini
```

### ××™××•×ª ×”×’×“×¨×”

```bash
# List loaded models
foundry model ls

# Check service health
curl http://localhost:59959/v1/models
```

---

## ××¤×’×© 04: ×”×©×•×•××ª ××•×“×œ×™×

### ××˜×¨×”
×”×©×•×•××ª ×‘×™×¦×•×¢×™× ×‘×™×Ÿ ××•×“×œ×™× ×§×˜× ×™× (SLM) ×œ××•×“×œ×™× ×’×“×•×œ×™× (LLM).

### ×”×’×“×¨×” ××”×™×¨×”

```bash
# Start service (if not already running)
foundry service start

# Load required models
foundry model run phi-4-mini
foundry model run qwen2.5-3b
```

### ×”×¤×¢×œ×ª ×”××—×‘×¨×ª

1. **×¤×ª×—×•** `session04_model_compare.ipynb` ×‘-VS Code ××• Jupyter
2. **××ª×—×œ×• ××ª ×”×œ×™×‘×”** (Kernel â†’ Restart Kernel)
3. **×”×¨×™×¦×• ××ª ×›×œ ×”×ª××™×** ×œ×¤×™ ×”×¡×“×¨

### ×”×’×“×¨×•×ª ×¢×™×§×¨×™×•×ª

**××•×“×œ×™× ×‘×¨×™×¨×ª ××—×“×œ:**
- **SLM:** `phi-4-mini` (~4GB RAM, ××”×™×¨ ×™×•×ª×¨)
- **LLM:** `qwen2.5-3b` (~3GB RAM, ××•×ª×× ×œ×–×™×›×¨×•×Ÿ)

**××©×ª× ×™ ×¡×‘×™×‘×” (××•×¤×¦×™×•× ×œ×™):**
```python
import os
os.environ['SLM_ALIAS'] = 'phi-4-mini'
os.environ['LLM_ALIAS'] = 'qwen2.5-3b'
os.environ['FOUNDRY_LOCAL_ENDPOINT'] = 'http://localhost:59959/v1'
```

### ×¤×œ×˜ ×¦×¤×•×™

```
================================================================================
COMPARISON SUMMARY
================================================================================
Alias                Latency(s)      Tokens     Route               
--------------------------------------------------------------------------------
phi-4-mini           1.234           150        chat.completions    
qwen2.5-3b           2.456           180        chat.completions    
================================================================================

ğŸ’¡ SLM is 1.99x faster than LLM for this prompt
```

### ×”×ª×××” ××™×©×™×ª

**×©×™××•×© ×‘××•×“×œ×™× ×©×•× ×™×:**
```python
os.environ['SLM_ALIAS'] = 'phi-3.5-mini'
os.environ['LLM_ALIAS'] = 'qwen2.5-1.5b'
```

**×”× ×—×™×” ××•×ª×××ª ××™×©×™×ª:**
```python
os.environ['COMPARE_PROMPT'] = 'Explain quantum computing in simple terms'
```

### ×¨×©×™××ª ×‘×“×™×§×•×ª ××™××•×ª

- [ ] ×ª× 12 ××¦×™×’ ××•×“×œ×™× × ×›×•× ×™× (phi-4-mini, qwen2.5-3b)
- [ ] ×ª× 12 ××¦×™×’ × ×§×•×“×ª ×§×¦×” × ×›×•× ×” (×¤×•×¨×˜ 59959)
- [ ] ×ª× 16 ×‘×“×™×§×ª ××‘×—×•×Ÿ ×¢×‘×¨×” (âœ… ×”×©×™×¨×•×ª ×¤×•×¢×œ)
- [ ] ×ª× 20 ×‘×“×™×§×ª ×˜×¨×•× ×˜×™×¡×” ×¢×‘×¨×” (×©× ×™ ×”××•×“×œ×™× ×ª×§×™× ×™×)
- [ ] ×ª× 22 ×”×©×•×•××” ×”×•×©×œ××” ×¢× ×¢×¨×›×™ ×–××Ÿ ×ª×’×•×‘×”
- [ ] ×ª× 24 ××™××•×ª ××¦×™×’ ğŸ‰ ×›×œ ×”×‘×“×™×§×•×ª ×¢×‘×¨×•!

### ×”×¢×¨×›×ª ×–××Ÿ
- **×”×¨×¦×” ×¨××©×•× ×”:** 5-10 ×“×§×•×ª (×›×•×œ×œ ×”×•×¨×“×ª ××•×“×œ×™×)
- **×”×¨×¦×•×ª × ×•×¡×¤×•×ª:** 1-2 ×“×§×•×ª

---

## ××¤×’×© 05: ××ª×–××¨ ×¨×‘-×¡×•×›× ×™×

### ××˜×¨×”
×”×“×’××ª ×©×™×ª×•×£ ×¤×¢×•×œ×” ×‘×™×Ÿ ×¡×•×›× ×™× ×‘×××¦×¢×•×ª Foundry Local SDK - ×”×¡×•×›× ×™× ×¢×•×‘×“×™× ×™×—×“ ×œ×™×¦×™×¨×ª ×ª×•×¦×¨×™× ××©×•×¤×¨×™×.

### ×”×’×“×¨×” ××”×™×¨×”

```bash
# Start service
foundry service start

# Load models
foundry model run phi-4-mini  # Primary model
foundry model run qwen2.5-7b  # Optional: higher quality editor
```

### ×”×¤×¢×œ×ª ×”××—×‘×¨×ª

1. **×¤×ª×—×•** `session05_agents_orchestrator.ipynb`
2. **××ª×—×œ×• ××ª ×”×œ×™×‘×”**
3. **×”×¨×™×¦×• ××ª ×›×œ ×”×ª××™×** ×œ×¤×™ ×”×¡×“×¨

### ×”×’×“×¨×•×ª ×¢×™×§×¨×™×•×ª

**×”×’×“×¨×” ×‘×¨×™×¨×ª ××—×“×œ (××•×ª×• ××•×“×œ ×œ×©× ×™ ×”×¡×•×›× ×™×):**
```python
PRIMARY_ALIAS = 'phi-4-mini'
EDITOR_ALIAS = 'phi-4-mini'  # Uses same model
```

**×”×’×“×¨×” ××ª×§×“××ª (××•×“×œ×™× ×©×•× ×™×):**
```python
import os
os.environ['AGENT_MODEL_PRIMARY'] = 'phi-4-mini'     # Fast for research
os.environ['AGENT_MODEL_EDITOR'] = 'qwen2.5-7b'      # High quality for editing
```

### ××¨×›×™×˜×§×˜×•×¨×”

```
User Question
    â†“
Researcher Agent (phi-4-mini)
  â†’ Gathers bullet points
    â†“
Editor Agent (phi-4-mini or qwen2.5-7b)
  â†’ Refines into executive summary
    â†“
Final Output
```

### ×¤×œ×˜ ×¦×¤×•×™

```
================================================================================
[Pipeline] Question: Explain why edge AI matters for compliance.
================================================================================

[Stage 1: Research]
Output: â€¢ Edge AI processes data locally, reducing transmission...

[Stage 2: Editorial Refinement]
Output: Executive Summary: Edge AI enhances compliance by keeping data...

[FINAL OUTPUT]
Executive Summary: Edge AI enhances compliance by keeping sensitive data 
on-premises and reduces latency through local processing.

[METADATA]
Models used: {'researcher': 'phi-4-mini', 'editor': 'phi-4-mini'}
```

### ×”×¨×—×‘×•×ª

**×”×•×¡×¤×ª ×¡×•×›× ×™× × ×•×¡×¤×™×:**
```python
critic = Agent(
    name='Critic',
    system='Review content for accuracy',
    client=client,
    model_id=model_id
)
```

**×‘×“×™×§×•×ª ×‘×§×‘×•×¦×•×ª:**
```python
test_questions = [
    "What are benefits of local AI?",
    "How does RAG improve accuracy?",
]

for q in test_questions:
    result = pipeline(q, verbose=False)
    print(result['final'])
```

### ×”×¢×¨×›×ª ×–××Ÿ
- **×”×¨×¦×” ×¨××©×•× ×”:** 3-5 ×“×§×•×ª
- **×”×¨×¦×•×ª × ×•×¡×¤×•×ª:** 1-2 ×“×§×•×ª ×œ×©××œ×”

---

## ××¤×’×© 06: × ×™×ª×•×‘ ××•×“×œ×™× ××‘×•×¡×¡ ×›×•×•× ×”

### ××˜×¨×”
× ×™×ª×•×‘ ×—×›× ×©×œ ×”× ×—×™×•×ª ×œ××•×“×œ×™× ××ª××—×™× ×‘×”×ª×× ×œ×›×•×•× ×” ×©×–×•×”×ª×”.

### ×”×’×“×¨×” ××”×™×¨×”

```bash
# Start service
foundry service start

# Load all routing models (CPU variants recommended)
foundry model run phi-4-mini-cpu
foundry model run qwen2.5-0.5b-cpu
foundry model run phi-3.5-mini-cpu
```

**×”×¢×¨×”:** ××¤×’×© 06 ××©×ª××© ×‘××•×“×œ×™× ××‘×•×¡×¡×™ CPU ×›×‘×¨×™×¨×ª ××—×“×œ ×œ×¦×•×¨×š ×ª××™××•×ª ××¨×‘×™×ª.

### ×”×¤×¢×œ×ª ×”××—×‘×¨×ª

1. **×¤×ª×—×•** `session06_models_router.ipynb`
2. **××ª×—×œ×• ××ª ×”×œ×™×‘×”**
3. **×”×¨×™×¦×• ××ª ×›×œ ×”×ª××™×** ×œ×¤×™ ×”×¡×“×¨

### ×”×’×“×¨×•×ª ×¢×™×§×¨×™×•×ª

**×§×˜×œ×•×’ ×‘×¨×™×¨×ª ××—×“×œ (××•×“×œ×™× CPU):**
```python
CATALOG = {
    'phi-4-mini-cpu': {'capabilities':['general','summarize'],'priority':2},
    'qwen2.5-0.5b-cpu': {'capabilities':['classification','fast'],'priority':1},
    'phi-3.5-mini-cpu': {'capabilities':['code','refactor'],'priority':3},
}
```

**×—×œ×•×¤×” (××•×“×œ×™× GPU):**
```python
# Uncomment GPU catalog in Cell #6 if you have sufficient VRAM (8GB+)
CATALOG = {
    'phi-4-mini': {'capabilities':['general','summarize'],'priority':2},
    'qwen2.5-0.5b': {'capabilities':['classification','fast'],'priority':1},
    'phi-3.5-mini': {'capabilities':['code','refactor'],'priority':3},
}
```

### ×–×™×”×•×™ ×›×•×•× ×”

×”× ×ª×‘ ××©×ª××© ×‘×ª×‘× ×™×•×ª regex ×œ×–×™×”×•×™ ×›×•×•× ×”:

| ×›×•×•× ×” | ×“×•×’×××•×ª ×œ×ª×‘× ×™×•×ª | ×× ×•×ª×‘ ×œ- |
|-------|-----------------|-----------|
| `code` | "refactor", "implement function" | phi-3.5-mini-cpu |
| `classification` | "categorize", "classify this" | qwen2.5-0.5b-cpu |
| `summarize` | "summarize", "tl;dr" | phi-4-mini-cpu |
| `general` | ×›×œ ×”×©××¨ | phi-4-mini-cpu |

### ×¤×œ×˜ ×¦×¤×•×™

```
âœ“ Using CPU-optimized models (default configuration)
  Models: phi-4-mini-cpu, qwen2.5-0.5b-cpu, phi-3.5-mini-cpu

Routing prompts to specialized models...
============================================================

Prompt: Refactor this Python function for readability
  Intent: code           | Model: phi-3.5-mini-cpu
  Output: Here's a refactored version...
  Tokens: 156

Prompt: Categorize this email as urgent or normal
  Intent: classification | Model: qwen2.5-0.5b-cpu
  Output: Category: Normal
  Tokens: 45

âœ“ Success! All prompts routed correctly.
```

### ×”×ª×××” ××™×©×™×ª

**×”×•×¡×¤×ª ×›×•×•× ×” ××•×ª×××ª ××™×©×™×ª:**
```python
import re

# Add to RULES
RULES.append((re.compile('translate|ç¿»è¯‘', re.I), 'translation'))

# Add capability to catalog
CATALOG['phi-4-mini-cpu']['capabilities'].append('translation')
```

**×”×¤×¢×œ×ª ××¢×§×‘ ××—×¨ ×˜×•×§× ×™×:**
```python
import os
os.environ['SHOW_USAGE'] = '1'
```

### ××¢×‘×¨ ×œ××•×“×œ×™× GPU

×× ×™×© ×œ×›× 8GB+ VRAM:

1. ×‘×ª× **#6**, ×”×’×™×‘×• ××ª ×§×˜×œ×•×’ ×”-CPU
2. ×‘×˜×œ×• ××ª ×”×”×¢×¨×” ××§×˜×œ×•×’ ×”-GPU
3. ×˜×¢× ×• ××•×“×œ×™× GPU:
   ```bash
   foundry model run phi-4-mini
   foundry model run qwen2.5-0.5b
   foundry model run phi-3.5-mini
   ```
4. ××ª×—×œ×• ××ª ×”×œ×™×‘×” ×•×”×¨×™×¦×• ××ª ×”××—×‘×¨×ª ××—×“×©

### ×”×¢×¨×›×ª ×–××Ÿ
- **×”×¨×¦×” ×¨××©×•× ×”:** 5-10 ×“×§×•×ª (×˜×¢×™× ×ª ××•×“×œ×™×)
- **×”×¨×¦×•×ª × ×•×¡×¤×•×ª:** 30-60 ×©× ×™×•×ª ×œ×‘×“×™×§×”

---

## ××©×ª× ×™ ×¡×‘×™×‘×”

### ×”×’×“×¨×” ×’×œ×•×‘×œ×™×ª

×™×© ×œ×”×’×“×™×¨ ×œ×¤× ×™ ×”×¤×¢×œ×ª Jupyter/VS Code:

**Windows (Command Prompt):**
```cmd
set FOUNDRY_LOCAL_ENDPOINT=http://localhost:59959/v1
set SHOW_USAGE=1
set RETRY_ON_FAIL=1
```

**Windows (PowerShell):**
```powershell
$env:FOUNDRY_LOCAL_ENDPOINT="http://localhost:59959/v1"
$env:SHOW_USAGE="1"
$env:RETRY_ON_FAIL="1"
```

**macOS/Linux:**
```bash
export FOUNDRY_LOCAL_ENDPOINT=http://localhost:59959/v1
export SHOW_USAGE=1
export RETRY_ON_FAIL=1
```

### ×”×’×“×¨×” ×‘×ª×•×š ×”××—×‘×¨×ª

×™×© ×œ×”×’×“×™×¨ ×‘×ª×—×™×œ×ª ×›×œ ××—×‘×¨×ª:

```python
import os

# Foundry Local configuration
os.environ['FOUNDRY_LOCAL_ENDPOINT'] = 'http://localhost:59959/v1'

# Model selection
os.environ['SLM_ALIAS'] = 'phi-4-mini'
os.environ['LLM_ALIAS'] = 'qwen2.5-3b'

# Agent models
os.environ['AGENT_MODEL_PRIMARY'] = 'phi-4-mini'
os.environ['AGENT_MODEL_EDITOR'] = 'qwen2.5-7b'

# Debugging
os.environ['SHOW_USAGE'] = '1'       # Show token usage
os.environ['RETRY_ON_FAIL'] = '1'    # Enable retries
os.environ['RETRY_BACKOFF'] = '2.0'  # Retry delay
```

---

## ×¤×§×•×“×•×ª × ×¤×•×¦×•×ª

### × ×™×”×•×œ ×©×™×¨×•×ª

```bash
# Start service
foundry service start

# Check status
foundry service status

# Stop service
foundry service stop

# View logs
foundry service logs
```

### × ×™×”×•×œ ××•×“×œ×™×

```bash
# List all available models in catalog
foundry model catalog

# List loaded models
foundry model ls

# Download a model
foundry model download phi-4-mini

# Load a model
foundry model run phi-4-mini

# Unload a model
foundry model unload phi-4-mini

# Remove a model
foundry model remove phi-4-mini

# Get model info
foundry model info phi-4-mini
```

### ×‘×“×™×§×ª × ×§×•×“×•×ª ×§×¦×”

```bash
# Check service health
curl http://localhost:59959/health

# List available models via API
curl http://localhost:59959/v1/models

# Test model completion
curl http://localhost:59959/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "phi-4-mini",
    "messages": [{"role":"user","content":"Hello"}],
    "max_tokens": 50
  }'
```

### ×¤×§×•×“×•×ª ××‘×—×•×Ÿ

```bash
# Check everything
foundry --version
foundry service status
foundry model ls
foundry device info

# GPU status (NVIDIA)
nvidia-smi

# NPU status (Qualcomm)
foundry device info
```

---

## ×©×™×˜×•×ª ×¢×‘×•×“×” ××•××œ×¦×•×ª

### ×œ×¤× ×™ ×”×¤×¢×œ×ª ×›×œ ××—×‘×¨×ª

1. **×‘×“×§×• ×©×”×©×™×¨×•×ª ×¤×•×¢×œ:**
   ```bash
   foundry service status
   ```

2. **×•×•×“××• ×©×”××•×“×œ×™× × ×˜×¢× ×•:**
   ```bash
   foundry model ls
   ```

3. **××ª×—×œ×• ××ª ×œ×™×‘×ª ×”××—×‘×¨×ª** ×× ××¨×™×¦×™× ××—×“×©

4. **× ×§×• ××ª ×›×œ ×”×¤×œ×˜×™×** ×œ×”×¨×¦×” × ×§×™×™×”

### × ×™×”×•×œ ××©××‘×™×

1. **×”×©×ª××©×• ×‘××•×“×œ×™× CPU ×›×‘×¨×™×¨×ª ××—×“×œ** ×œ×¦×•×¨×š ×ª××™××•×ª
2. **×¢×‘×¨×• ×œ××•×“×œ×™× GPU** ×¨×§ ×× ×™×© ×œ×›× 8GB+ VRAM
3. **×¡×’×¨×• ×™×™×©×•××™ GPU ××—×¨×™×** ×œ×¤× ×™ ×”×”×¨×¦×”
4. **×”×©××™×¨×• ××ª ×”×©×™×¨×•×ª ×¤×•×¢×œ** ×‘×™×Ÿ ××¤×’×©×™ ××—×‘×¨×•×ª
5. **×¢×§×‘×• ××—×¨ ×©×™××•×© ×‘××©××‘×™×** ×‘×××¦×¢×•×ª Task Manager / nvidia-smi

### ×¤×ª×¨×•×Ÿ ×‘×¢×™×•×ª

1. **×ª××™×“ ×‘×“×§×• ××ª ×”×©×™×¨×•×ª ×ª×—×™×œ×”** ×œ×¤× ×™ × ×™×¤×•×™ ×©×’×™××•×ª ×‘×§×•×“
2. **××ª×—×œ×• ××ª ×”×œ×™×‘×”** ×× ××ª× ×¨×•××™× ×”×’×“×¨×•×ª ×™×©× ×•×ª
3. **×”×¨×™×¦×• ××—×“×© ×ª××™ ××‘×—×•×Ÿ** ×œ××—×¨ ×›×œ ×©×™× ×•×™
4. **×•×•×“××• ×©×©××•×ª ×”××•×“×œ×™×** ×ª×•×××™× ×œ××” ×©× ×˜×¢×Ÿ
5. **×××ª×• ××ª ×¤×•×¨×˜ × ×§×•×“×ª ×”×§×¦×”** ×ª×•×× ×œ××¦×‘ ×”×©×™×¨×•×ª

---

## ×”×¤× ×™×” ××”×™×¨×”: ×›×™× ×•×™×™× ×œ××•×“×œ×™×

### ××•×“×œ×™× × ×¤×•×¦×™×

| ×›×™× ×•×™ | ×’×•×“×œ | ×©×™××•×© ××™×˜×‘×™ | RAM/VRAM | ×•×¨×™×× ×˜×™× |
|-------|------|-------------|----------|----------|
| `phi-4-mini` | ~4B | ×¦'××˜ ×›×œ×œ×™, ×¡×™×›×•× | 4-6GB | `-cpu`, `-cuda-gpu`, `-npu` |
| `phi-3.5-mini` | ~3.5B | ×™×¦×™×¨×ª ×§×•×“, ×©×›×ª×•×‘ | 3-5GB | `-cpu`, `-cuda-gpu`, `-npu` |
| `qwen2.5-3b` | ~3B | ××©×™××•×ª ×›×œ×œ×™×•×ª, ×™×¢×™×œ | 3-4GB | `-cpu`, `-cuda-gpu` |
| `qwen2.5-1.5b` | ~1.5B | ××”×™×¨, ××©××‘×™× × ××•×›×™× | 2-3GB | `-cpu`, `-cuda-gpu` |
| `qwen2.5-0.5b` | ~0.5B | ×¡×™×•×•×’, ××©××‘×™× ××™× ×™××œ×™×™× | 1-2GB | `-cpu`, `-cuda-gpu` |

### ×©××•×ª ×•×¨×™×× ×˜×™×

- **×©× ×‘×¡×™×¡** (×œ×“×•×’××”, `phi-4-mini`): ×‘×•×—×¨ ××•×˜×•××˜×™×ª ××ª ×”×•×•×¨×™×× ×˜ ×”×˜×•×‘ ×‘×™×•×ª×¨ ×¢×‘×•×¨ ×”×—×•××¨×” ×©×œ×›×
- **`-cpu`**: ××•×ª×× ×œ-CPU, ×¢×•×‘×“ ×‘×›×œ ××§×•×
- **`-cuda-gpu`**: ××•×ª×× ×œ-GPU ×©×œ NVIDIA, ×“×•×¨×© 8GB+ VRAM
- **`-npu`**: ××•×ª×× ×œ-NPU ×©×œ Qualcomm, ×“×•×¨×© ×“×¨×™×™×‘×¨×™× ×œ-NPU

**×”××œ×¦×”:** ×”×©×ª××©×• ×‘×©××•×ª ×‘×¡×™×¡ (×œ×œ× ×¡×™×•××ª) ×•×ª× ×• ×œ-Foundry Local ×œ×‘×—×•×¨ ××•×˜×•××˜×™×ª ××ª ×”×•×•×¨×™×× ×˜ ×”×˜×•×‘ ×‘×™×•×ª×¨.

---

## ××“×“×™ ×”×¦×œ×—×”

××ª× ××•×›× ×™× ×›××©×¨:

âœ… `foundry service status` ××¦×™×’ "×¤×•×¢×œ"
âœ… `foundry model ls` ××¦×™×’ ××ª ×”××•×“×œ×™× ×”× ×“×¨×©×™×
âœ… ×”×©×™×¨×•×ª × ×’×™×© ×‘× ×§×•×“×ª ×”×§×¦×” ×”× ×›×•× ×”
âœ… ×‘×“×™×§×ª ×‘×¨×™××•×ª ××—×–×™×¨×” 200 OK
âœ… ×ª××™ ××‘×—×•×Ÿ ×‘××—×‘×¨×ª ×¢×•×‘×¨×™×
âœ… ××™×Ÿ ×©×’×™××•×ª ×—×™×‘×•×¨ ×‘×¤×œ×˜

---

## ×§×‘×œ×ª ×¢×–×¨×”

### ×ª×™×¢×•×“
- **×××’×¨ ×¨××©×™**: https://github.com/microsoft/Foundry-Local
- **Python SDK**: https://github.com/microsoft/Foundry-Local/tree/main/sdk/python
- **CLI Reference**: https://github.com/microsoft/Foundry-Local/blob/main/docs/reference/reference-cli.md
- **×¤×ª×¨×•×Ÿ ×‘×¢×™×•×ª**: ×¨××• `troubleshooting.md` ×‘×ª×™×§×™×™×” ×–×•

### ×‘×¢×™×•×ª ×‘-GitHub
- https://github.com/microsoft/Foundry-Local/issues
- https://github.com/microsoft/edgeai-for-beginners/issues

---

**×¢×•×“×›×Ÿ ×œ××—×¨×•× ×”:** 8 ×‘××•×§×˜×•×‘×¨ 2025  
**×’×¨×¡×”:** ××—×‘×¨×•×ª ×¡×“× ×” 2.0

---

**×›×ª×‘ ×•×™×ª×•×¨**:  
××¡××š ×–×” ×ª×•×¨×’× ×‘×××¦×¢×•×ª ×©×™×¨×•×ª ×ª×¨×’×•× ××‘×•×¡×¡ ×‘×™× ×” ××œ××›×•×ª×™×ª [Co-op Translator](https://github.com/Azure/co-op-translator). ×œ××¨×•×ª ×©×× ×• ×©×•××¤×™× ×œ×“×™×•×§, ×™×© ×œ×§×—×ª ×‘×—×©×‘×•×Ÿ ×©×ª×¨×’×•××™× ××•×˜×•××˜×™×™× ×¢×©×•×™×™× ×œ×”×›×™×œ ×©×’×™××•×ª ××• ××™ ×“×™×•×§×™×. ×”××¡××š ×”××§×•×¨×™ ×‘×©×¤×ª×• ×”××§×•×¨×™×ª ×¦×¨×™×š ×œ×”×™×—×©×‘ ×›××§×•×¨ ×¡××›×•×ª×™. ×¢×‘×•×¨ ××™×“×¢ ×§×¨×™×˜×™, ××•××œ×¥ ×œ×”×©×ª××© ×‘×ª×¨×’×•× ××§×¦×•×¢×™ ×¢×œ ×™×“×™ ××“×. ××™× × ×• × ×•×©××™× ×‘××—×¨×™×•×ª ×œ××™ ×”×‘× ×•×ª ××• ×œ×¤×¨×©× ×•×™×•×ª ×©×’×•×™×•×ª ×”× ×•×‘×¢×•×ª ××©×™××•×© ×‘×ª×¨×’×•× ×–×”.