<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ddaad917d0c16fc3d498a6b4eabc8088",
  "translation_date": "2025-10-09T07:09:56+00:00",
  "source_file": "Workshop/notebooks/quickstart.md",
  "language_code": "ur"
}
-->
# ÙˆØ±Ú©Ø´Ø§Ù¾ Ù†ÙˆÙ¹ Ø¨Ú©Ø³ - ÙÙˆØ±ÛŒ Ø¢ØºØ§Ø² Ú¯Ø§Ø¦ÛŒÚˆ

## Ù…ÙˆØ§Ø¯ Ú©ÛŒ ÙÛØ±Ø³Øª

- [Ø¶Ø±ÙˆØ±ÛŒØ§Øª](../../../../Workshop/notebooks)
- [Ø§Ø¨ØªØ¯Ø§Ø¦ÛŒ Ø³ÛŒÙ¹ Ø§Ù¾](../../../../Workshop/notebooks)
- [Ø³ÛŒØ´Ù† 04: Ù…Ø§ÚˆÙ„ Ù…ÙˆØ§Ø²Ù†Û](../../../../Workshop/notebooks)
- [Ø³ÛŒØ´Ù† 05: Ù…Ù„Ù¹ÛŒ Ø§ÛŒØ¬Ù†Ù¹ Ø¢Ø±Ú©ÛŒØ³Ù¹Ø±ÛŒÙ¹Ø±](../../../../Workshop/notebooks)
- [Ø³ÛŒØ´Ù† 06: Ø§Ø±Ø§Ø¯Û’ Ù¾Ø± Ù…Ø¨Ù†ÛŒ Ù…Ø§ÚˆÙ„ Ø±ÙˆÙ¹Ù†Ú¯](../../../../Workshop/notebooks)
- [Ù…Ø§Ø­ÙˆÙ„ÛŒØ§ØªÛŒ Ù…ØªØºÛŒØ±Ø§Øª](../../../../Workshop/notebooks)
- [Ø¹Ø§Ù… Ú©Ù…Ø§Ù†ÚˆØ²](../../../../Workshop/notebooks)

---

## Ø¶Ø±ÙˆØ±ÛŒØ§Øª

### 1. ÙØ§Ø¤Ù†ÚˆØ±ÛŒ Ù„ÙˆÚ©Ù„ Ø§Ù†Ø³Ù¹Ø§Ù„ Ú©Ø±ÛŒÚº

**ÙˆÙ†ÚˆÙˆØ²:**
```bash
winget install Microsoft.FoundryLocal
```

**macOS:**
```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

**Ø§Ù†Ø³Ù¹Ø§Ù„ÛŒØ´Ù† Ú©ÛŒ ØªØµØ¯ÛŒÙ‚ Ú©Ø±ÛŒÚº:**
```bash
foundry --version
```

### 2. Ù¾Ø§Ø¦ØªÚ¾ÙˆÙ† ÚˆÛŒÙ¾ÛŒÙ†ÚˆÙ†Ø³ÛŒØ² Ø§Ù†Ø³Ù¹Ø§Ù„ Ú©Ø±ÛŒÚº

```bash
cd Workshop
pip install -r requirements.txt
```

ÛŒØ§ Ø§Ù†ÙØ±Ø§Ø¯ÛŒ Ø·ÙˆØ± Ù¾Ø± Ø§Ù†Ø³Ù¹Ø§Ù„ Ú©Ø±ÛŒÚº:
```bash
pip install foundry-local-sdk openai numpy requests
```

---

## Ø§Ø¨ØªØ¯Ø§Ø¦ÛŒ Ø³ÛŒÙ¹ Ø§Ù¾

### ÙØ§Ø¤Ù†ÚˆØ±ÛŒ Ù„ÙˆÚ©Ù„ Ø³Ø±ÙˆØ³ Ø´Ø±ÙˆØ¹ Ú©Ø±ÛŒÚº

**Ú©Ø³ÛŒ Ø¨Ú¾ÛŒ Ù†ÙˆÙ¹ Ø¨Ú© Ú†Ù„Ø§Ù†Û’ Ø³Û’ Ù¾ÛÙ„Û’ Ø¶Ø±ÙˆØ±ÛŒ ÛÛ’:**

```bash
# Start the service
foundry service start

# Verify it's running
foundry service status
```

Ù…ØªÙˆÙ‚Ø¹ Ø¢Ø¤Ù¹ Ù¾Ù¹:
```
âœ… Service started successfully
Endpoint: http://localhost:59959
```

### Ù…Ø§ÚˆÙ„Ø² ÚˆØ§Ø¤Ù† Ù„ÙˆÚˆ Ø§ÙˆØ± Ù„ÙˆÚˆ Ú©Ø±ÛŒÚº

Ù†ÙˆÙ¹ Ø¨Ú©Ø³ Ø§Ù† Ù…Ø§ÚˆÙ„Ø² Ú©Ùˆ ÚˆÛŒÙØ§Ù„Ù¹ Ú©Û’ Ø·ÙˆØ± Ù¾Ø± Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ØªÛŒ ÛÛŒÚº:

```bash
# Download models (first time only - may take several minutes)
foundry model download phi-4-mini
foundry model download qwen2.5-3b
foundry model download phi-3.5-mini
foundry model download qwen2.5-0.5b

# Load models into memory
foundry model run phi-4-mini
foundry model run qwen2.5-3b
foundry model run phi-3.5-mini
```

### Ø³ÛŒÙ¹ Ø§Ù¾ Ú©ÛŒ ØªØµØ¯ÛŒÙ‚ Ú©Ø±ÛŒÚº

```bash
# List loaded models
foundry model ls

# Check service health
curl http://localhost:59959/v1/models
```

---

## Ø³ÛŒØ´Ù† 04: Ù…Ø§ÚˆÙ„ Ù…ÙˆØ§Ø²Ù†Û

### Ù…Ù‚ØµØ¯
Ú†Ú¾ÙˆÙ¹Û’ Ø²Ø¨Ø§Ù† Ù…Ø§ÚˆÙ„Ø² (SLM) Ø§ÙˆØ± Ø¨Ú‘Û’ Ø²Ø¨Ø§Ù† Ù…Ø§ÚˆÙ„Ø² (LLM) Ú©Û’ Ø¯Ø±Ù…ÛŒØ§Ù† Ú©Ø§Ø±Ú©Ø±Ø¯Ú¯ÛŒ Ú©Ø§ Ù…ÙˆØ§Ø²Ù†Û Ú©Ø±ÛŒÚºÛ”

### ÙÙˆØ±ÛŒ Ø³ÛŒÙ¹ Ø§Ù¾

```bash
# Start service (if not already running)
foundry service start

# Load required models
foundry model run phi-4-mini
foundry model run qwen2.5-3b
```

### Ù†ÙˆÙ¹ Ø¨Ú© Ú†Ù„Ø§Ù†Ø§

1. **Ú©Ú¾ÙˆÙ„ÛŒÚº** `session04_model_compare.ipynb` VS Ú©ÙˆÚˆ ÛŒØ§ Jupyter Ù…ÛŒÚº
2. **Ú©Ø±Ù†Ù„ Ø±ÛŒ Ø§Ø³Ù¹Ø§Ø±Ù¹ Ú©Ø±ÛŒÚº** (Kernel â†’ Restart Kernel)
3. **ØªÙ…Ø§Ù… Ø³ÛŒÙ„Ø² Ú©Ùˆ ØªØ±ØªÛŒØ¨ ÙˆØ§Ø± Ú†Ù„Ø§Ø¦ÛŒÚº**

### Ú©Ù„ÛŒØ¯ÛŒ Ú©Ù†ÙÛŒÚ¯Ø±ÛŒØ´Ù†

**ÚˆÛŒÙØ§Ù„Ù¹ Ù…Ø§ÚˆÙ„Ø²:**
- **SLM:** `phi-4-mini` (~4GB RAMØŒ ØªÛŒØ²)
- **LLM:** `qwen2.5-3b` (~3GB RAMØŒ Ù…ÛŒÙ…ÙˆØ±ÛŒ Ú©Û’ Ù„ÛŒÛ’ Ø¨ÛØªØ±)

**Ù…Ø§Ø­ÙˆÙ„ÛŒØ§ØªÛŒ Ù…ØªØºÛŒØ±Ø§Øª (Ø§Ø®ØªÛŒØ§Ø±ÛŒ):**
```python
import os
os.environ['SLM_ALIAS'] = 'phi-4-mini'
os.environ['LLM_ALIAS'] = 'qwen2.5-3b'
os.environ['FOUNDRY_LOCAL_ENDPOINT'] = 'http://localhost:59959/v1'
```

### Ù…ØªÙˆÙ‚Ø¹ Ø¢Ø¤Ù¹ Ù¾Ù¹

```
================================================================================
COMPARISON SUMMARY
================================================================================
Alias                Latency(s)      Tokens     Route               
--------------------------------------------------------------------------------
phi-4-mini           1.234           150        chat.completions    
qwen2.5-3b           2.456           180        chat.completions    
================================================================================

ğŸ’¡ SLM is 1.99x faster than LLM for this prompt
```

### Ø­Ø³Ø¨ Ø¶Ø±ÙˆØ±Øª

**Ù…Ø®ØªÙ„Ù Ù…Ø§ÚˆÙ„Ø² Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ÛŒÚº:**
```python
os.environ['SLM_ALIAS'] = 'phi-3.5-mini'
os.environ['LLM_ALIAS'] = 'qwen2.5-1.5b'
```

**Ø­Ø³Ø¨ Ø¶Ø±ÙˆØ±Øª Ù¾Ø±Ø§Ù…Ù¾Ù¹:**
```python
os.environ['COMPARE_PROMPT'] = 'Explain quantum computing in simple terms'
```

### ØªÙˆØ«ÛŒÙ‚ Ú†ÛŒÚ© Ù„Ø³Ù¹

- [ ] Ø³ÛŒÙ„ 12 Ø¯Ø±Ø³Øª Ù…Ø§ÚˆÙ„Ø² Ø¯Ú©Ú¾Ø§ØªØ§ ÛÛ’ (phi-4-miniØŒ qwen2.5-3b)
- [ ] Ø³ÛŒÙ„ 12 Ø¯Ø±Ø³Øª Ø§ÛŒÙ†Úˆ Ù¾ÙˆØ§Ø¦Ù†Ù¹ Ø¯Ú©Ú¾Ø§ØªØ§ ÛÛ’ (Ù¾ÙˆØ±Ù¹ 59959)
- [ ] Ø³ÛŒÙ„ 16 ØªØ´Ø®ÛŒØµÛŒ Ù¾Ø§Ø³ Ú©Ø±ØªØ§ ÛÛ’ (âœ… Ø³Ø±ÙˆØ³ Ú†Ù„ Ø±ÛÛŒ ÛÛ’)
- [ ] Ø³ÛŒÙ„ 20 Ù¾Ø±ÛŒ ÙÙ„Ø§Ø¦Ù¹ Ú†ÛŒÚ© Ù¾Ø§Ø³ Ú©Ø±ØªØ§ ÛÛ’ (Ø¯ÙˆÙ†ÙˆÚº Ù…Ø§ÚˆÙ„Ø² Ù¹Ú¾ÛŒÚ© ÛÛŒÚº)
- [ ] Ø³ÛŒÙ„ 22 Ù…ÙˆØ§Ø²Ù†Û Ù…Ú©Ù…Ù„ Ú©Ø±ØªØ§ ÛÛ’ Ù„ÛŒÙ¹Ù†Ø³ÛŒ ÙˆÛŒÙ„ÛŒÙˆØ² Ú©Û’ Ø³Ø§ØªÚ¾
- [ ] Ø³ÛŒÙ„ 24 ØªÙˆØ«ÛŒÙ‚ Ø¯Ú©Ú¾Ø§ØªØ§ ÛÛ’ ğŸ‰ ØªÙ…Ø§Ù… Ú†ÛŒÚ©Ø³ Ù¾Ø§Ø³ ÛÙˆ Ú¯Ø¦Û’!

### ÙˆÙ‚Øª Ú©Ø§ ØªØ®Ù…ÛŒÙ†Û
- **Ù¾ÛÙ„ÛŒ Ø¨Ø§Ø± Ú†Ù„Ø§Ù†Ø§:** 5-10 Ù…Ù†Ù¹ (Ù…Ø§ÚˆÙ„Ø² ÚˆØ§Ø¤Ù† Ù„ÙˆÚˆ Ø³Ù…ÛŒØª)
- **Ø¨Ø¹Ø¯ Ú©Û’ Ø±Ù†Ø²:** 1-2 Ù…Ù†Ù¹

---

## Ø³ÛŒØ´Ù† 05: Ù…Ù„Ù¹ÛŒ Ø§ÛŒØ¬Ù†Ù¹ Ø¢Ø±Ú©ÛŒØ³Ù¹Ø±ÛŒÙ¹Ø±

### Ù…Ù‚ØµØ¯
ÙØ§Ø¤Ù†ÚˆØ±ÛŒ Ù„ÙˆÚ©Ù„ SDK Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ØªÛ’ ÛÙˆØ¦Û’ Ù…Ù„Ù¹ÛŒ Ø§ÛŒØ¬Ù†Ù¹ ØªØ¹Ø§ÙˆÙ† Ú©Ø§ Ù…Ø¸Ø§ÛØ±Û Ú©Ø±ÛŒÚº - Ø§ÛŒØ¬Ù†Ù¹Ø³ Ù…Ù„ Ú©Ø± Ø¨ÛØªØ± Ù†ØªØ§Ø¦Ø¬ Ù¾ÛŒØ¯Ø§ Ú©Ø±ØªÛ’ ÛÛŒÚºÛ”

### ÙÙˆØ±ÛŒ Ø³ÛŒÙ¹ Ø§Ù¾

```bash
# Start service
foundry service start

# Load models
foundry model run phi-4-mini  # Primary model
foundry model run qwen2.5-7b  # Optional: higher quality editor
```

### Ù†ÙˆÙ¹ Ø¨Ú© Ú†Ù„Ø§Ù†Ø§

1. **Ú©Ú¾ÙˆÙ„ÛŒÚº** `session05_agents_orchestrator.ipynb`
2. **Ú©Ø±Ù†Ù„ Ø±ÛŒ Ø§Ø³Ù¹Ø§Ø±Ù¹ Ú©Ø±ÛŒÚº**
3. **ØªÙ…Ø§Ù… Ø³ÛŒÙ„Ø² Ú©Ùˆ ØªØ±ØªÛŒØ¨ ÙˆØ§Ø± Ú†Ù„Ø§Ø¦ÛŒÚº**

### Ú©Ù„ÛŒØ¯ÛŒ Ú©Ù†ÙÛŒÚ¯Ø±ÛŒØ´Ù†

**ÚˆÛŒÙØ§Ù„Ù¹ Ø³ÛŒÙ¹ Ø§Ù¾ (Ø¯ÙˆÙ†ÙˆÚº Ø§ÛŒØ¬Ù†Ù¹Ø³ Ú©Û’ Ù„ÛŒÛ’ Ø§ÛŒÚ© ÛÛŒ Ù…Ø§ÚˆÙ„):**
```python
PRIMARY_ALIAS = 'phi-4-mini'
EDITOR_ALIAS = 'phi-4-mini'  # Uses same model
```

**Ø§ÛŒÚˆÙˆØ§Ù†Ø³ Ø³ÛŒÙ¹ Ø§Ù¾ (Ù…Ø®ØªÙ„Ù Ù…Ø§ÚˆÙ„Ø²):**
```python
import os
os.environ['AGENT_MODEL_PRIMARY'] = 'phi-4-mini'     # Fast for research
os.environ['AGENT_MODEL_EDITOR'] = 'qwen2.5-7b'      # High quality for editing
```

### Ø¢Ø±Ú©ÛŒÙ¹ÛŒÚ©Ú†Ø±

```
User Question
    â†“
Researcher Agent (phi-4-mini)
  â†’ Gathers bullet points
    â†“
Editor Agent (phi-4-mini or qwen2.5-7b)
  â†’ Refines into executive summary
    â†“
Final Output
```

### Ù…ØªÙˆÙ‚Ø¹ Ø¢Ø¤Ù¹ Ù¾Ù¹

```
================================================================================
[Pipeline] Question: Explain why edge AI matters for compliance.
================================================================================

[Stage 1: Research]
Output: â€¢ Edge AI processes data locally, reducing transmission...

[Stage 2: Editorial Refinement]
Output: Executive Summary: Edge AI enhances compliance by keeping data...

[FINAL OUTPUT]
Executive Summary: Edge AI enhances compliance by keeping sensitive data 
on-premises and reduces latency through local processing.

[METADATA]
Models used: {'researcher': 'phi-4-mini', 'editor': 'phi-4-mini'}
```

### ØªÙˆØ³ÛŒØ¹Ø§Øª

**Ù…Ø²ÛŒØ¯ Ø§ÛŒØ¬Ù†Ù¹Ø³ Ø´Ø§Ù…Ù„ Ú©Ø±ÛŒÚº:**
```python
critic = Agent(
    name='Critic',
    system='Review content for accuracy',
    client=client,
    model_id=model_id
)
```

**Ø¨ÛŒÚ† Ù¹ÛŒØ³Ù¹Ù†Ú¯:**
```python
test_questions = [
    "What are benefits of local AI?",
    "How does RAG improve accuracy?",
]

for q in test_questions:
    result = pipeline(q, verbose=False)
    print(result['final'])
```

### ÙˆÙ‚Øª Ú©Ø§ ØªØ®Ù…ÛŒÙ†Û
- **Ù¾ÛÙ„ÛŒ Ø¨Ø§Ø± Ú†Ù„Ø§Ù†Ø§:** 3-5 Ù…Ù†Ù¹
- **Ø¨Ø¹Ø¯ Ú©Û’ Ø±Ù†Ø²:** ÛØ± Ø³ÙˆØ§Ù„ Ú©Û’ Ù„ÛŒÛ’ 1-2 Ù…Ù†Ù¹

---

## Ø³ÛŒØ´Ù† 06: Ø§Ø±Ø§Ø¯Û’ Ù¾Ø± Ù…Ø¨Ù†ÛŒ Ù…Ø§ÚˆÙ„ Ø±ÙˆÙ¹Ù†Ú¯

### Ù…Ù‚ØµØ¯
Ø§Ø±Ø§Ø¯Û’ Ú©Ø§ Ù¾ØªÛ Ù„Ú¯Ø§ Ú©Ø± Ù¾Ø±Ø§Ù…Ù¾Ù¹Ø³ Ú©Ùˆ Ø®ØµÙˆØµÛŒ Ù…Ø§ÚˆÙ„Ø² Ú©ÛŒ Ø·Ø±Ù Ø°ÛØ§Ù†Øª Ø³Û’ Ø±ÙˆÙ¹ Ú©Ø±ÛŒÚºÛ”

### ÙÙˆØ±ÛŒ Ø³ÛŒÙ¹ Ø§Ù¾

```bash
# Start service
foundry service start

# Load all routing models (CPU variants recommended)
foundry model run phi-4-mini-cpu
foundry model run qwen2.5-0.5b-cpu
foundry model run phi-3.5-mini-cpu
```

**Ù†ÙˆÙ¹:** Ø³ÛŒØ´Ù† 06 Ø²ÛŒØ§Ø¯Û Ø³Û’ Ø²ÛŒØ§Ø¯Û Ù…Ø·Ø§Ø¨Ù‚Øª Ú©Û’ Ù„ÛŒÛ’ CPU Ù…Ø§ÚˆÙ„Ø² Ú©Ùˆ ÚˆÛŒÙØ§Ù„Ù¹ Ú©Ø±ØªØ§ ÛÛ’Û”

### Ù†ÙˆÙ¹ Ø¨Ú© Ú†Ù„Ø§Ù†Ø§

1. **Ú©Ú¾ÙˆÙ„ÛŒÚº** `session06_models_router.ipynb`
2. **Ú©Ø±Ù†Ù„ Ø±ÛŒ Ø§Ø³Ù¹Ø§Ø±Ù¹ Ú©Ø±ÛŒÚº**
3. **ØªÙ…Ø§Ù… Ø³ÛŒÙ„Ø² Ú©Ùˆ ØªØ±ØªÛŒØ¨ ÙˆØ§Ø± Ú†Ù„Ø§Ø¦ÛŒÚº**

### Ú©Ù„ÛŒØ¯ÛŒ Ú©Ù†ÙÛŒÚ¯Ø±ÛŒØ´Ù†

**ÚˆÛŒÙØ§Ù„Ù¹ Ú©ÛŒÙ¹Ù„Ø§Ú¯ (CPU Ù…Ø§ÚˆÙ„Ø²):**
```python
CATALOG = {
    'phi-4-mini-cpu': {'capabilities':['general','summarize'],'priority':2},
    'qwen2.5-0.5b-cpu': {'capabilities':['classification','fast'],'priority':1},
    'phi-3.5-mini-cpu': {'capabilities':['code','refactor'],'priority':3},
}
```

**Ù…ØªØ¨Ø§Ø¯Ù„ (GPU Ù…Ø§ÚˆÙ„Ø²):**
```python
# Uncomment GPU catalog in Cell #6 if you have sufficient VRAM (8GB+)
CATALOG = {
    'phi-4-mini': {'capabilities':['general','summarize'],'priority':2},
    'qwen2.5-0.5b': {'capabilities':['classification','fast'],'priority':1},
    'phi-3.5-mini': {'capabilities':['code','refactor'],'priority':3},
}
```

### Ø§Ø±Ø§Ø¯Û’ Ú©Ø§ Ù¾ØªÛ Ù„Ú¯Ø§Ù†Ø§

Ø±ÙˆÙ¹Ø± Ø§Ø±Ø§Ø¯Û’ Ú©Ø§ Ù¾ØªÛ Ù„Ú¯Ø§Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ regex Ù¾ÛŒÙ¹Ø±Ù†Ø² Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ØªØ§ ÛÛ’:

| Ø§Ø±Ø§Ø¯Û | Ù¾ÛŒÙ¹Ø±Ù† Ú©ÛŒ Ù…Ø«Ø§Ù„ÛŒÚº | Ø±ÙˆÙ¹ Ú©ÛŒØ§ Ú¯ÛŒØ§ |
|-------|-----------------|-----------|
| `code` | "refactor"ØŒ "implement function" | phi-3.5-mini-cpu |
| `classification` | "categorize"ØŒ "classify this" | qwen2.5-0.5b-cpu |
| `summarize` | "summarize"ØŒ "tl;dr" | phi-4-mini-cpu |
| `general` | Ø¨Ø§Ù‚ÛŒ Ø³Ø¨ | phi-4-mini-cpu |

### Ù…ØªÙˆÙ‚Ø¹ Ø¢Ø¤Ù¹ Ù¾Ù¹

```
âœ“ Using CPU-optimized models (default configuration)
  Models: phi-4-mini-cpu, qwen2.5-0.5b-cpu, phi-3.5-mini-cpu

Routing prompts to specialized models...
============================================================

Prompt: Refactor this Python function for readability
  Intent: code           | Model: phi-3.5-mini-cpu
  Output: Here's a refactored version...
  Tokens: 156

Prompt: Categorize this email as urgent or normal
  Intent: classification | Model: qwen2.5-0.5b-cpu
  Output: Category: Normal
  Tokens: 45

âœ“ Success! All prompts routed correctly.
```

### Ø­Ø³Ø¨ Ø¶Ø±ÙˆØ±Øª

**Ø­Ø³Ø¨ Ø¶Ø±ÙˆØ±Øª Ø§Ø±Ø§Ø¯Û Ø´Ø§Ù…Ù„ Ú©Ø±ÛŒÚº:**
```python
import re

# Add to RULES
RULES.append((re.compile('translate|ç¿»è¯‘', re.I), 'translation'))

# Add capability to catalog
CATALOG['phi-4-mini-cpu']['capabilities'].append('translation')
```

**Ù¹ÙˆÚ©ÛŒÙ† Ù¹Ø±ÛŒÚ©Ù†Ú¯ ÙØ¹Ø§Ù„ Ú©Ø±ÛŒÚº:**
```python
import os
os.environ['SHOW_USAGE'] = '1'
```

### GPU Ù…Ø§ÚˆÙ„Ø² Ù¾Ø± Ø³ÙˆØ¦Ú† Ú©Ø±Ù†Ø§

Ø§Ú¯Ø± Ø¢Ù¾ Ú©Û’ Ù¾Ø§Ø³ 8GB+ VRAM ÛÛ’:

1. **Ø³ÛŒÙ„ #6** Ù…ÛŒÚºØŒ CPU Ú©ÛŒÙ¹Ù„Ø§Ú¯ Ú©Ùˆ Ú©Ù…Ù†Ù¹ Ú©Ø±ÛŒÚº
2. GPU Ú©ÛŒÙ¹Ù„Ø§Ú¯ Ú©Ùˆ Ø§Ù† Ú©Ù…Ù†Ù¹ Ú©Ø±ÛŒÚº
3. GPU Ù…Ø§ÚˆÙ„Ø² Ù„ÙˆÚˆ Ú©Ø±ÛŒÚº:
   ```bash
   foundry model run phi-4-mini
   foundry model run qwen2.5-0.5b
   foundry model run phi-3.5-mini
   ```
4. Ú©Ø±Ù†Ù„ Ø±ÛŒ Ø§Ø³Ù¹Ø§Ø±Ù¹ Ú©Ø±ÛŒÚº Ø§ÙˆØ± Ù†ÙˆÙ¹ Ø¨Ú© Ø¯ÙˆØ¨Ø§Ø±Û Ú†Ù„Ø§Ø¦ÛŒÚº

### ÙˆÙ‚Øª Ú©Ø§ ØªØ®Ù…ÛŒÙ†Û
- **Ù¾ÛÙ„ÛŒ Ø¨Ø§Ø± Ú†Ù„Ø§Ù†Ø§:** 5-10 Ù…Ù†Ù¹ (Ù…Ø§ÚˆÙ„ Ù„ÙˆÚˆÙ†Ú¯)
- **Ø¨Ø¹Ø¯ Ú©Û’ Ø±Ù†Ø²:** ÛØ± Ù¹ÛŒØ³Ù¹ Ú©Û’ Ù„ÛŒÛ’ 30-60 Ø³ÛŒÚ©Ù†Úˆ

---

## Ù…Ø§Ø­ÙˆÙ„ÛŒØ§ØªÛŒ Ù…ØªØºÛŒØ±Ø§Øª

### Ø¹Ø§Ù„Ù…ÛŒ Ú©Ù†ÙÛŒÚ¯Ø±ÛŒØ´Ù†

Jupyter/VS Ú©ÙˆÚˆ Ø´Ø±ÙˆØ¹ Ú©Ø±Ù†Û’ Ø³Û’ Ù¾ÛÙ„Û’ Ø³ÛŒÙ¹ Ú©Ø±ÛŒÚº:

**ÙˆÙ†ÚˆÙˆØ² (Ú©Ù…Ø§Ù†Úˆ Ù¾Ø±Ø§Ù…Ù¾Ù¹):**
```cmd
set FOUNDRY_LOCAL_ENDPOINT=http://localhost:59959/v1
set SHOW_USAGE=1
set RETRY_ON_FAIL=1
```

**ÙˆÙ†ÚˆÙˆØ² (Ù¾Ø§ÙˆØ± Ø´ÛŒÙ„):**
```powershell
$env:FOUNDRY_LOCAL_ENDPOINT="http://localhost:59959/v1"
$env:SHOW_USAGE="1"
$env:RETRY_ON_FAIL="1"
```

**macOS/Linux:**
```bash
export FOUNDRY_LOCAL_ENDPOINT=http://localhost:59959/v1
export SHOW_USAGE=1
export RETRY_ON_FAIL=1
```

### Ù†ÙˆÙ¹ Ø¨Ú© Ù…ÛŒÚº Ú©Ù†ÙÛŒÚ¯Ø±ÛŒØ´Ù†

Ú©Ø³ÛŒ Ø¨Ú¾ÛŒ Ù†ÙˆÙ¹ Ø¨Ú© Ú©Û’ Ø¢ØºØ§Ø² Ù…ÛŒÚº Ø³ÛŒÙ¹ Ú©Ø±ÛŒÚº:

```python
import os

# Foundry Local configuration
os.environ['FOUNDRY_LOCAL_ENDPOINT'] = 'http://localhost:59959/v1'

# Model selection
os.environ['SLM_ALIAS'] = 'phi-4-mini'
os.environ['LLM_ALIAS'] = 'qwen2.5-3b'

# Agent models
os.environ['AGENT_MODEL_PRIMARY'] = 'phi-4-mini'
os.environ['AGENT_MODEL_EDITOR'] = 'qwen2.5-7b'

# Debugging
os.environ['SHOW_USAGE'] = '1'       # Show token usage
os.environ['RETRY_ON_FAIL'] = '1'    # Enable retries
os.environ['RETRY_BACKOFF'] = '2.0'  # Retry delay
```

---

## Ø¹Ø§Ù… Ú©Ù…Ø§Ù†ÚˆØ²

### Ø³Ø±ÙˆØ³ Ù…ÛŒÙ†Ø¬Ù…Ù†Ù¹

```bash
# Start service
foundry service start

# Check status
foundry service status

# Stop service
foundry service stop

# View logs
foundry service logs
```

### Ù…Ø§ÚˆÙ„ Ù…ÛŒÙ†Ø¬Ù…Ù†Ù¹

```bash
# List all available models in catalog
foundry model catalog

# List loaded models
foundry model ls

# Download a model
foundry model download phi-4-mini

# Load a model
foundry model run phi-4-mini

# Unload a model
foundry model unload phi-4-mini

# Remove a model
foundry model remove phi-4-mini

# Get model info
foundry model info phi-4-mini
```

### Ø§ÛŒÙ†Úˆ Ù¾ÙˆØ§Ø¦Ù†Ù¹Ø³ Ú©ÛŒ Ø¬Ø§Ù†Ú†

```bash
# Check service health
curl http://localhost:59959/health

# List available models via API
curl http://localhost:59959/v1/models

# Test model completion
curl http://localhost:59959/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "phi-4-mini",
    "messages": [{"role":"user","content":"Hello"}],
    "max_tokens": 50
  }'
```

### ØªØ´Ø®ÛŒØµÛŒ Ú©Ù…Ø§Ù†ÚˆØ²

```bash
# Check everything
foundry --version
foundry service status
foundry model ls
foundry device info

# GPU status (NVIDIA)
nvidia-smi

# NPU status (Qualcomm)
foundry device info
```

---

## Ø¨ÛØªØ±ÛŒÙ† Ø·Ø±ÛŒÙ‚Û’

### Ú©Ø³ÛŒ Ø¨Ú¾ÛŒ Ù†ÙˆÙ¹ Ø¨Ú© Ø´Ø±ÙˆØ¹ Ú©Ø±Ù†Û’ Ø³Û’ Ù¾ÛÙ„Û’

1. **Ú†ÛŒÚ© Ú©Ø±ÛŒÚº Ú©Û Ø³Ø±ÙˆØ³ Ú†Ù„ Ø±ÛÛŒ ÛÛ’:**
   ```bash
   foundry service status
   ```

2. **ØªØµØ¯ÛŒÙ‚ Ú©Ø±ÛŒÚº Ú©Û Ù…Ø§ÚˆÙ„Ø² Ù„ÙˆÚˆ ÛÛŒÚº:**
   ```bash
   foundry model ls
   ```

3. **Ù†ÙˆÙ¹ Ø¨Ú© Ú©Ø±Ù†Ù„ Ø±ÛŒ Ø§Ø³Ù¹Ø§Ø±Ù¹ Ú©Ø±ÛŒÚº** Ø§Ú¯Ø± Ø¯ÙˆØ¨Ø§Ø±Û Ú†Ù„Ø§Ù†Ø§ ÛÙˆ

4. **ØªÙ…Ø§Ù… Ø¢Ø¤Ù¹ Ù¾Ù¹Ø³ ØµØ§Ù Ú©Ø±ÛŒÚº** Ø§ÛŒÚ© ØµØ§Ù Ø±Ù† Ú©Û’ Ù„ÛŒÛ’

### ÙˆØ³Ø§Ø¦Ù„ Ú©Ø§ Ø§Ù†ØªØ¸Ø§Ù…

1. **ÚˆÛŒÙØ§Ù„Ù¹ Ú©Û’ Ø·ÙˆØ± Ù¾Ø± CPU Ù…Ø§ÚˆÙ„Ø² Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ÛŒÚº** Ù…Ø·Ø§Ø¨Ù‚Øª Ú©Û’ Ù„ÛŒÛ’
2. **GPU Ù…Ø§ÚˆÙ„Ø² Ù¾Ø± Ø³ÙˆØ¦Ú† Ú©Ø±ÛŒÚº** ØµØ±Ù Ø§Ú¯Ø± Ø¢Ù¾ Ú©Û’ Ù¾Ø§Ø³ 8GB+ VRAM ÛÙˆ
3. **Ø¯ÛŒÚ¯Ø± GPU Ø§ÛŒÙ¾Ù„ÛŒÚ©ÛŒØ´Ù†Ø² Ø¨Ù†Ø¯ Ú©Ø±ÛŒÚº** Ú†Ù„Ø§Ù†Û’ Ø³Û’ Ù¾ÛÙ„Û’
4. **Ø³Ø±ÙˆØ³ Ú©Ùˆ Ú†Ù„ØªØ§ Ø±Ú©Ú¾ÛŒÚº** Ù†ÙˆÙ¹ Ø¨Ú© Ø³ÛŒØ´Ù†Ø² Ú©Û’ Ø¯Ø±Ù…ÛŒØ§Ù†
5. **ÙˆØ³Ø§Ø¦Ù„ Ú©Û’ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©ÛŒ Ù†Ú¯Ø±Ø§Ù†ÛŒ Ú©Ø±ÛŒÚº** Ù¹Ø§Ø³Ú© Ù…ÛŒÙ†ÛŒØ¬Ø± / nvidia-smi Ú©Û’ Ø³Ø§ØªÚ¾

### Ø®Ø±Ø§Ø¨ÛŒÙˆÚº Ú©Ø§ Ø³Ø±Ø§Øº Ù„Ú¯Ø§Ù†Ø§

1. **ÛÙ…ÛŒØ´Û Ù¾ÛÙ„Û’ Ø³Ø±ÙˆØ³ Ú†ÛŒÚ© Ú©Ø±ÛŒÚº** Ú©ÙˆÚˆ ÚˆÛŒØ¨Ú¯ Ú©Ø±Ù†Û’ Ø³Û’ Ù¾ÛÙ„Û’
2. **Ú©Ø±Ù†Ù„ Ø±ÛŒ Ø§Ø³Ù¹Ø§Ø±Ù¹ Ú©Ø±ÛŒÚº** Ø§Ú¯Ø± Ø¢Ù¾ Ú©Ùˆ Ù¾Ø±Ø§Ù†ÛŒ Ú©Ù†ÙÛŒÚ¯Ø±ÛŒØ´Ù† Ù†Ø¸Ø± Ø¢Ø¦Û’
3. **ØªØ´Ø®ÛŒØµÛŒ Ø³ÛŒÙ„Ø² Ø¯ÙˆØ¨Ø§Ø±Û Ú†Ù„Ø§Ø¦ÛŒÚº** Ú©Ø³ÛŒ Ø¨Ú¾ÛŒ ØªØ¨Ø¯ÛŒÙ„ÛŒ Ú©Û’ Ø¨Ø¹Ø¯
4. **Ù…Ø§ÚˆÙ„ Ú©Û’ Ù†Ø§Ù… Ú†ÛŒÚ© Ú©Ø±ÛŒÚº** Ø¬Ùˆ Ù„ÙˆÚˆ Ú©ÛŒÛ’ Ú¯Ø¦Û’ ÛÛŒÚº
5. **Ø§ÛŒÙ†Úˆ Ù¾ÙˆØ§Ø¦Ù†Ù¹ Ù¾ÙˆØ±Ù¹ Ú©ÛŒ ØªØµØ¯ÛŒÙ‚ Ú©Ø±ÛŒÚº** Ú©Û Ø³Ø±ÙˆØ³ Ø§Ø³Ù¹ÛŒÙ¹Ø³ Ø³Û’ Ù…ÛŒÙ„ Ú©Ú¾Ø§ØªØ§ ÛÛ’

---

## ÙÙˆØ±ÛŒ Ø­ÙˆØ§Ù„Û: Ù…Ø§ÚˆÙ„ Ú©Û’ Ø¹Ø±ÙÛŒ Ù†Ø§Ù…

### Ø¹Ø§Ù… Ù…Ø§ÚˆÙ„Ø²

| Ø¹Ø±ÙÛŒ Ù†Ø§Ù… | Ø³Ø§Ø¦Ø² | Ø¨ÛØªØ±ÛŒÙ† Ø§Ø³ØªØ¹Ù…Ø§Ù„ | RAM/VRAM | ÙˆÛŒØ±ÛŒØ¦Ù†Ù¹Ø³ |
|---------|------|----------------|----------|----------|
| `phi-4-mini` | ~4B | Ø¹Ù…ÙˆÙ…ÛŒ Ú†ÛŒÙ¹ØŒ Ø®Ù„Ø§ØµÛ | 4-6GB | `-cpu`, `-cuda-gpu`, `-npu` |
| `phi-3.5-mini` | ~3.5B | Ú©ÙˆÚˆ Ø¬Ù†Ø±ÛŒØ´Ù†ØŒ Ø±ÛŒÙÛŒÚ©Ù¹Ø±Ù†Ú¯ | 3-5GB | `-cpu`, `-cuda-gpu`, `-npu` |
| `qwen2.5-3b` | ~3B | Ø¹Ù…ÙˆÙ…ÛŒ Ú©Ø§Ù…ØŒ Ù…ÙˆØ«Ø± | 3-4GB | `-cpu`, `-cuda-gpu` |
| `qwen2.5-1.5b` | ~1.5B | ØªÛŒØ²ØŒ Ú©Ù… ÙˆØ³Ø§Ø¦Ù„ | 2-3GB | `-cpu`, `-cuda-gpu` |
| `qwen2.5-0.5b` | ~0.5B | Ø¯Ø±Ø¬Û Ø¨Ù†Ø¯ÛŒØŒ Ú©Ù… Ø³Û’ Ú©Ù… ÙˆØ³Ø§Ø¦Ù„ | 1-2GB | `-cpu`, `-cuda-gpu` |

### ÙˆÛŒØ±ÛŒØ¦Ù†Ù¹ Ù†Ø§Ù…

- **Ø¨Ù†ÛŒØ§Ø¯ÛŒ Ù†Ø§Ù…** (Ø¬ÛŒØ³Û’ØŒ `phi-4-mini`): Ø¢Ù¾ Ú©Û’ ÛØ§Ø±ÚˆÙˆÛŒØ¦Ø± Ú©Û’ Ù„ÛŒÛ’ Ø¨ÛØªØ±ÛŒÙ† ÙˆÛŒØ±ÛŒØ¦Ù†Ù¹ Ø®ÙˆØ¯ Ø¨Ø®ÙˆØ¯ Ù…Ù†ØªØ®Ø¨ Ú©Ø±ØªØ§ ÛÛ’
- **`-cpu`**: CPU Ú©Û’ Ù„ÛŒÛ’ Ø¨ÛØªØ±ØŒ ÛØ± Ø¬Ú¯Û Ú©Ø§Ù… Ú©Ø±ØªØ§ ÛÛ’
- **`-cuda-gpu`**: NVIDIA GPU Ú©Û’ Ù„ÛŒÛ’ Ø¨ÛØªØ±ØŒ 8GB+ VRAM Ú©ÛŒ Ø¶Ø±ÙˆØ±Øª ÛÛ’
- **`-npu`**: Qualcomm NPU Ú©Û’ Ù„ÛŒÛ’ Ø¨ÛØªØ±ØŒ NPU ÚˆØ±Ø§Ø¦ÛŒÙˆØ±Ø² Ú©ÛŒ Ø¶Ø±ÙˆØ±Øª ÛÛ’

**ØªØ¬ÙˆÛŒØ²:** Ø¨Ù†ÛŒØ§Ø¯ÛŒ Ù†Ø§Ù… Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ÛŒÚº (Ø¨ØºÛŒØ± Ù„Ø§Ø­Ù‚Û Ú©Û’) Ø§ÙˆØ± ÙØ§Ø¤Ù†ÚˆØ±ÛŒ Ù„ÙˆÚ©Ù„ Ú©Ùˆ Ø¨ÛØªØ±ÛŒÙ† ÙˆÛŒØ±ÛŒØ¦Ù†Ù¹ Ø®ÙˆØ¯ Ø¨Ø®ÙˆØ¯ Ù…Ù†ØªØ®Ø¨ Ú©Ø±Ù†Û’ Ø¯ÛŒÚºÛ”

---

## Ú©Ø§Ù…ÛŒØ§Ø¨ÛŒ Ú©Û’ Ø§Ø´Ø§Ø±Û’

Ø¢Ù¾ ØªÛŒØ§Ø± ÛÛŒÚº Ø¬Ø¨ Ø¢Ù¾ Ø¯ÛŒÚ©Ú¾ÛŒÚº:

âœ… `foundry service status` "running" Ø¯Ú©Ú¾Ø§ØªØ§ ÛÛ’  
âœ… `foundry model ls` Ø¢Ù¾ Ú©Û’ Ù…Ø·Ù„ÙˆØ¨Û Ù…Ø§ÚˆÙ„Ø² Ø¯Ú©Ú¾Ø§ØªØ§ ÛÛ’  
âœ… Ø³Ø±ÙˆØ³ Ø¯Ø±Ø³Øª Ø§ÛŒÙ†Úˆ Ù¾ÙˆØ§Ø¦Ù†Ù¹ Ù¾Ø± Ù‚Ø§Ø¨Ù„ Ø±Ø³Ø§Ø¦ÛŒ ÛÛ’  
âœ… ÛÛŒÙ„ØªÚ¾ Ú†ÛŒÚ© 200 OK ÙˆØ§Ù¾Ø³ Ú©Ø±ØªØ§ ÛÛ’  
âœ… Ù†ÙˆÙ¹ Ø¨Ú© ØªØ´Ø®ÛŒØµÛŒ Ø³ÛŒÙ„Ø² Ù¾Ø§Ø³ Ú©Ø±ØªÛ’ ÛÛŒÚº  
âœ… Ø¢Ø¤Ù¹ Ù¾Ù¹ Ù…ÛŒÚº Ú©ÙˆØ¦ÛŒ Ú©Ù†Ú©Ø´Ù† Ø§ÛŒØ±Ø± Ù†ÛÛŒÚº ÛÛ’  

---

## Ù…Ø¯Ø¯ Ø­Ø§ØµÙ„ Ú©Ø±Ù†Ø§

### Ø¯Ø³ØªØ§ÙˆÛŒØ²Ø§Øª
- **Ù…ÛŒÙ† Ø±ÛŒÙ¾ÙˆØ²Ù¹Ø±ÛŒ**: https://github.com/microsoft/Foundry-Local
- **Ù¾Ø§Ø¦ØªÚ¾ÙˆÙ† SDK**: https://github.com/microsoft/Foundry-Local/tree/main/sdk/python
- **CLI Ø­ÙˆØ§Ù„Û**: https://github.com/microsoft/Foundry-Local/blob/main/docs/reference/reference-cli.md
- **Ø®Ø±Ø§Ø¨ÛŒÙˆÚº Ú©Ø§ Ø³Ø±Ø§Øº Ù„Ú¯Ø§Ù†Ø§**: Ø§Ø³ ÚˆØ§Ø¦Ø±ÛŒÚ©Ù¹Ø±ÛŒ Ù…ÛŒÚº `troubleshooting.md` Ø¯ÛŒÚ©Ú¾ÛŒÚº

### GitHub Ù…Ø³Ø§Ø¦Ù„
- https://github.com/microsoft/Foundry-Local/issues
- https://github.com/microsoft/edgeai-for-beginners/issues

---

**Ø¢Ø®Ø±ÛŒ Ø§Ù¾ ÚˆÛŒÙ¹:** 8 Ø§Ú©ØªÙˆØ¨Ø±ØŒ 2025  
**ÙˆØ±Ú˜Ù†:** ÙˆØ±Ú©Ø´Ø§Ù¾ Ù†ÙˆÙ¹ Ø¨Ú©Ø³ 2.0  

---

**ÚˆØ³Ú©Ù„ÛŒÙ…Ø±**:  
ÛŒÛ Ø¯Ø³ØªØ§ÙˆÛŒØ² AI ØªØ±Ø¬Ù…Û Ø³Ø±ÙˆØ³ [Co-op Translator](https://github.com/Azure/co-op-translator) Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ØªÛ’ ÛÙˆØ¦Û’ ØªØ±Ø¬Ù…Û Ú©ÛŒ Ú¯Ø¦ÛŒ ÛÛ’Û” ÛÙ… Ø¯Ø±Ø³ØªÚ¯ÛŒ Ú©Û’ Ù„ÛŒÛ’ Ú©ÙˆØ´Ø´ Ú©Ø±ØªÛ’ ÛÛŒÚºØŒ Ù„ÛŒÚ©Ù† Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø¢Ú¯Ø§Û Ø±ÛÛŒÚº Ú©Û Ø®ÙˆØ¯Ú©Ø§Ø± ØªØ±Ø¬Ù…Û’ Ù…ÛŒÚº ØºÙ„Ø·ÛŒØ§Úº ÛŒØ§ ØºÛŒØ± Ø¯Ø±Ø³ØªÛŒØ§Úº ÛÙˆ Ø³Ú©ØªÛŒ ÛÛŒÚºÛ” Ø§ØµÙ„ Ø¯Ø³ØªØ§ÙˆÛŒØ² Ú©Ùˆ Ø§Ø³ Ú©ÛŒ Ø§ØµÙ„ Ø²Ø¨Ø§Ù† Ù…ÛŒÚº Ù…Ø³ØªÙ†Ø¯ Ø°Ø±ÛŒØ¹Û Ø³Ù…Ø¬Ú¾Ø§ Ø¬Ø§Ù†Ø§ Ú†Ø§ÛÛŒÛ’Û” Ø§ÛÙ… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ú©Û’ Ù„ÛŒÛ’ØŒ Ù¾ÛŒØ´Û ÙˆØ± Ø§Ù†Ø³Ø§Ù†ÛŒ ØªØ±Ø¬Ù…Û Ú©ÛŒ Ø³ÙØ§Ø±Ø´ Ú©ÛŒ Ø¬Ø§ØªÛŒ ÛÛ’Û” ÛÙ… Ø§Ø³ ØªØ±Ø¬Ù…Û’ Ú©Û’ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ø³Û’ Ù¾ÛŒØ¯Ø§ ÛÙˆÙ†Û’ ÙˆØ§Ù„ÛŒ Ú©Ø³ÛŒ Ø¨Ú¾ÛŒ ØºÙ„Ø· ÙÛÙ…ÛŒ ÛŒØ§ ØºÙ„Ø· ØªØ´Ø±ÛŒØ­ Ú©Û’ Ø°Ù…Û Ø¯Ø§Ø± Ù†ÛÛŒÚº ÛÛŒÚºÛ”