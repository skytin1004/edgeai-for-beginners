<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "27be883865b4bad1e3c7e02c696da642",
  "translation_date": "2025-09-17T18:13:10+00:00",
  "source_file": "Module03/01.SLMAdvancedLearning.md",
  "language_code": "ur"
}
-->
# ุณฺฉุดู 1: SLM ุงฺูุงูุณฺ ูุฑููฺฏ - ุจูุงุฏฺบ ุงูุฑ ุงุตูุงุญ

ฺฺพููน ููฺฏูุฌ ูุงฺูุฒ (SLMs) EdgeAI ูฺบ ุงฺฉ ุงู ูพุด ุฑูุช ฺฉ ููุงุฆูุฏฺฏ ฺฉุฑุช ฺบุ ุฌู ูุญุฏูุฏ ูุณุงุฆู ูุงู ุขูุงุช ูพุฑ ูพฺุฏ ูุฏุฑุช ุฒุจุงู ฺฉ ูพุฑูุณุณูฺฏ ฺฉ ุตูุงุญุชูฺบ ฺฉู ููฺฉู ุจูุงุช ฺบ SLMs ฺฉู ูุคุซุฑ ุทุฑู ุณ ุชุนูุงุชุ ุจุชุฑ ุงูุฑ ุงุณุชุนูุงู ฺฉุฑู ฺฉุง ุทุฑู ุณูุฌฺพูุง ุนูู ุงุฌ ูพุฑ ูุจู AI ุญู ุจูุงู ฺฉ ู ุถุฑูุฑ 

## ุชุนุงุฑู

ุงุณ ุณุจู ูฺบุ ู ฺฺพููน ููฺฏูุฌ ูุงฺูุฒ (SLMs) ุงูุฑ ุงู ฺฉ ุงฺูุงูุณฺ ููุงุฐ ฺฉ ุญฺฉูุช ุนูููฺบ ฺฉุง ุฌุงุฆุฒ ูฺบ ฺฏ ู SLMs ฺฉ ุจูุงุฏ ุชุตูุฑุงุชุ ุงู ฺฉ ูพุฑุงููนุฑ ฺฉ ุญุฏูุฏ ุงูุฑ ุฏุฑุฌ ุจูุฏุ ุงุตูุงุญ ฺฉ ุชฺฉูฺฉุ ุงูุฑ ุงุฌ ฺฉููพููนูฺฏ ูุงุญูู ฺฉ ู ุนูู ุชุนูุงุช ฺฉ ุญฺฉูุช ุนูููฺบ ฺฉุง ุงุญุงุท ฺฉุฑฺบ ฺฏ

## ุณฺฉฺพู ฺฉ ููุงุตุฏ

ุงุณ ุณุจู ฺฉ ุงุฎุชุชุงู ุชฺฉุ ุขูพ:

- ๐ข ฺฺพููน ููฺฏูุฌ ูุงฺูุฒ ฺฉ ูพุฑุงููนุฑ ฺฉ ุญุฏูุฏ ุงูุฑ ุฏุฑุฌ ุจูุฏ ฺฉู ุณูุฌฺพ ุณฺฉฺบ ฺฏ
- ๐๏ธ ุงุฌ ฺูุงุฆุณุฒ ูพุฑ SLM ฺฉ ุชุนูุงุช ฺฉ ู ฺฉูุฏ ุงุตูุงุญ ุชฺฉูฺฉูฺบ ฺฉ ุดูุงุฎุช ฺฉุฑ ุณฺฉฺบ ฺฏ
- ๐ SLMs ฺฉ ู ุงฺูุงูุณฺ ฺฉูุงููนุงุฆุฒุดู ุงูุฑ ฺฉููพุฑุดู ฺฉ ุญฺฉูุช ุนูููฺบ ฺฉู ูุงูุฐ ฺฉุฑูุง ุณฺฉฺพ ุณฺฉฺบ ฺฏ

## SLM ูพุฑุงููนุฑ ฺฉ ุญุฏูุฏ ุงูุฑ ุฏุฑุฌ ุจูุฏ ฺฉู ุณูุฌฺพูุง

ฺฺพููน ููฺฏูุฌ ูุงฺูุฒ (SLMs) AI ูุงฺูุฒ ฺบ ุฌู ูุฏุฑุช ุฒุจุงู ฺฉ ููุงุฏ ฺฉู ูพุฑูุณุณุ ุณูุฌฺพู ุงูุฑ ูพุฏุง ฺฉุฑู ฺฉ ู ฺุฒุงุฆู ฺฉ ฺฏุฆ ฺบุ ุงูุฑ ุงู ฺฉ ุจฺ ู ููุตุจูฺบ ฺฉ ููุงุจู ูฺบ ููุงุงฺบ ุทูุฑ ูพุฑ ฺฉู ูพุฑุงููนุฑุฒ ุฑฺฉฺพุช ฺบ ุฌุงฺบ ุจฺ ููฺฏูุฌ ูุงฺูุฒ (LLMs) ูฺบ ุณูฺฉฺูฺบ ุงุฑุจ ุณ ฺฉฺพุฑุจูฺบ ูพุฑุงููนุฑุฒ ูุช ฺบุ SLMs ุฎุงุต ุทูุฑ ูพุฑ ฺฉุงุฑฺฉุฑุฏฺฏ ุงูุฑ ุงุฌ ุชุนูุงุช ฺฉ ู ฺุฒุงุฆู ฺฉ ฺฏุฆ ฺบ

ูพุฑุงููนุฑ ฺฉ ุฏุฑุฌ ุจูุฏ ฺฉุง ูุฑู ูุฑฺฉ ูฺบ SLMs ฺฉ ูุฎุชูู ุฒูุฑูฺบ ุงูุฑ ุงู ฺฉ ููุงุณุจ ุงุณุชุนูุงู ฺฉ ูุนุงููุงุช ฺฉู ุณูุฌฺพู ูฺบ ูุฏุฏ ุฏุชุง   ุฏุฑุฌ ุจูุฏ ุงุฌ ฺฉููพููนูฺฏ ฺฉ ูุฎุตูุต ููุธุฑูุงููฺบ ฺฉ ู ุตุญุญ ูุงฺู ฺฉุง ุงูุชุฎุงุจ ฺฉุฑู ฺฉ ู ุงู 

### ูพุฑุงููนุฑ ฺฉ ุฏุฑุฌ ุจูุฏ ฺฉุง ูุฑู ูุฑฺฉ

ูพุฑุงููนุฑ ฺฉ ุญุฏูุฏ ฺฉู ุณูุฌฺพูุง ูุฎุชูู ุงุฌ ฺฉููพููนูฺฏ ููุธุฑูุงููฺบ ฺฉ ู ููุงุณุจ ูุงฺูุฒ ฺฉ ุงูุชุฎุงุจ ูฺบ ูุฏุฏ ฺฉุฑุชุง :

- **๐ฌ ูุงุฆฺฉุฑู SLMs**: 100M - 1.4B ูพุฑุงููนุฑุฒ (ููุจุงุฆู ฺูุงุฆุณุฒ ฺฉ ู ุงูุชุงุฆ ูฺฉ ูุฒู ูุงู)
- **๐ฑ ฺฺพููน SLMs**: 1.5B - 13.9B ูพุฑุงููนุฑุฒ (ฺฉุงุฑฺฉุฑุฏฺฏ ุงูุฑ ฺฉุงุฑฺฉุฑุฏฺฏ ูฺบ ุชูุงุฒู)
- **โ๏ธ ุฏุฑูุงู SLMs**: 14B - 30B ูพุฑุงููนุฑุฒ (LLM ฺฉ ุตูุงุญุชูฺบ ฺฉ ูุฑุจ ูพูฺุช ูุฆ ฺฉุงุฑฺฉุฑุฏฺฏ ุจุฑูุฑุงุฑ ุฑฺฉฺพุช ฺบ)

ุชุญููุงุช ฺฉููููน ูฺบ ุจุงูฺฉู ุญุฏ ูุชุบุฑ ุฑุช ุ ูฺฉู ุฒุงุฏ ุชุฑ ูุงุฑู 30 ุงุฑุจ ูพุฑุงููนุฑุฒ ุณ ฺฉู ูุงฺูุฒ ฺฉู "ฺฺพููนุง" ุณูุฌฺพุช ฺบุ ุฌุจฺฉ ฺฉฺฺพ ุฐุฑุงุฆุน ุงุณ ุญุฏ ฺฉู 10 ุงุฑุจ ูพุฑุงููนุฑุฒ ุชฺฉ ุจฺพ ฺฉู ฺฉุฑุช ฺบ

### SLMs ฺฉ ฺฉูุฏ ููุงุฆุฏ

SLMs ฺฉุฆ ุจูุงุฏ ููุงุฆุฏ ูพุด ฺฉุฑุช ฺบ ุฌู ุงูฺบ ุงุฌ ฺฉููพููนูฺฏ ุงูพูฺฉุดูุฒ ฺฉ ู ูุซุงู ุจูุงุช ฺบ:

**ุขูพุฑุดูู ฺฉุงุฑฺฉุฑุฏฺฏ**: SLMs ฺฉู ูพุฑุงููนุฑุฒ ฺฉ ูพุฑูุณุณูฺฏ ฺฉ ูุฌ ุณ ุชุฒ ุชุฑ ุงููุฑูุณ ฺฉ ุงููุงุช ูุฑุงู ฺฉุฑุช ฺบุ ุฌู ุงูฺบ ุญูู ููุช ฺฉ ุงูพูฺฉุดูุฒ ฺฉ ู ูุซุงู ุจูุงุช ฺบ  ฺฉู ฺฉููพููนุดูู ูุณุงุฆู ฺฉ ุถุฑูุฑุช ุฑฺฉฺพุช ฺบุ ูุญุฏูุฏ ูุณุงุฆู ูุงู ุขูุงุช ูพุฑ ุชุนูุงุช ฺฉู ููฺฉู ุจูุงุช ฺบุ ฺฉู ุชูุงูุงุฆ ุงุณุชุนูุงู ฺฉุฑุช ฺบุ ุงูุฑ ฺฉุงุฑุจู ฺฉ ุงุซุฑุงุช ฺฉู ฺฉู ุฑฺฉฺพุช ฺบ

**ุชุนูุงุช ฺฉ ูฺฺฉ**:  ูุงฺูุฒ ุงููนุฑููน ฺฉูฺฉูนููน ฺฉ ุถุฑูุฑุช ฺฉ ุจุบุฑ ุขู ฺูุงุฆุณ AI ุตูุงุญุชูฺบ ฺฉู ูุนุงู ฺฉุฑุช ฺบุ ููุงู ูพุฑูุณุณูฺฏ ฺฉ ุฐุฑุน ูพุฑุงุฆูุณ ุงูุฑ ุณฺฉูุฑูน ฺฉู ุจฺฺพุงุช ฺบุ ฺููู ูุฎุตูุต ุงูพูฺฉุดูุฒ ฺฉ ู ุญุณุจ ุถุฑูุฑุช ุจูุงุฆ ุฌุง ุณฺฉุช ฺบุ ุงูุฑ ูุฎุชูู ุงุฌ ฺฉููพููนูฺฏ ูุงุญูู ฺฉ ู ููุฒูฺบ ฺบ

**ูุงฺฏุช ฺฉ ุชุงุซุฑ**: SLMs ุชุฑุจุช ุงูุฑ ุชุนูุงุช ฺฉ ู ูุงฺฏุช ฺฉ ูุญุงุธ ุณ ูุคุซุฑ ฺบุ ุขูพุฑุดูู ุงุฎุฑุงุฌุงุช ฺฉู ฺฉู ฺฉุฑุช ฺบุ ุงูุฑ ุงุฌ ุงูพูฺฉุดูุฒ ฺฉ ู ฺฉู ุจูฺูฺุชฺพ ฺฉ ุถุฑูุฑุงุช ุฑฺฉฺพุช ฺบ

## ุงฺูุงูุณฺ ูุงฺู ุญุงุตู ฺฉุฑู ฺฉ ุญฺฉูุช ุนูู

### ฺฏูฺฏ ูุณ ุงฺฉู ุณุณูนู

ฺฏูฺฏ ูุณ ุฌุฏุฏ ุชุฑู SLMs ฺฉู ุฏุฑุงูุช ฺฉุฑู ุงูุฑ ุงู ุชฺฉ ุฑุณุงุฆ ุญุงุตู ฺฉุฑู ฺฉ ู ุจูุงุฏ ูุฑฺฉุฒ ฺฉ ุทูุฑ ูพุฑ ฺฉุงู ฺฉุฑุชุง   ูพููน ูุงุฑู ูุงฺู ุฏุฑุงูุช ุงูุฑ ุชุนูุงุช ฺฉ ู ุฌุงูุน ูุณุงุฆู ูุฑุงู ฺฉุฑุชุง :

**ูุงฺู ุฏุฑุงูุช ฺฉ ุฎุตูุตุงุช**: ูพููน ูุงุฑู ูพุฑุงููนุฑ ฺฉ ุชุนุฏุงุฏุ ูุงุฆุณูุณ ฺฉ ูุณูุ ุงูุฑ ฺฉุงุฑฺฉุฑุฏฺฏ ฺฉ ููนุฑฺฉุณ ฺฉ ุฐุฑุน ุงฺูุงูุณฺ ูููนุฑูฺฏ ูพุด ฺฉุฑุชุง  ุตุงุฑูู ุณุงุฆฺ ุจุงุฆ ุณุงุฆฺ ูุงฺู ููุงุฒู ฺฉ ูนููุฒุ ุญูู ููุช ฺฉ ฺฉุงุฑฺฉุฑุฏฺฏ ฺฉ ุจูฺ ูุงุฑฺฉุณ ุงูุฑ ุชุดุฎุต ูุชุงุฆุฌุ ุงูุฑ ููุฑ ุฌุงูฺ ฺฉ ู WebGPU ฺูู ุชฺฉ ุฑุณุงุฆ ุญุงุตู ฺฉุฑ ุณฺฉุช ฺบ

**ููุชุฎุจ SLM ูุฌููุน**: ูุดูุฑ ูุงฺูุฒ ูฺบ ุดุงูู ฺบ Phi-4-mini-3.8B ุงฺูุงูุณฺ ุฑุฒููฺฏ ูนุงุณฺฉุณ ฺฉ ูุ Qwen3 ุณุฑุฒ (0.6B/1.7B/4B) ฺฉุซุฑ ูุณุงู ุงูพูฺฉุดูุฒ ฺฉ ูุ Google Gemma3 ููุซุฑ ุนููู ููุตุฏ ฺฉ ฺฉุงููฺบ ฺฉ ูุ ุงูุฑ ุชุฌุฑุจุงุช ูุงฺูุฒ ุฌุณ BitNET ุงูุชุงุฆ ฺฉู ูพุฑุณุฌู ุชุนูุงุช ฺฉ ู ูพููน ูุงุฑู ฺฉููููน ุณ ฺูู ูุงู ูุฌููุน ุจฺพ ูพุด ฺฉุฑุชุง  ุฌู ูฺบ ูุฎุตูุต ฺูููุฒ ฺฉ ู ุฎุตูุต ูุงฺูุฒ ุงูุฑ ูุฎุชูู ุงุณุชุนูุงู ฺฉ ูุนุงููุงุช ฺฉ ู ุจุชุฑ ูพุฑ ูนุฑูฺ ุงูุฑ ุงูุณูนุฑฺฉุดู ูนููฺ ูุฑุฆููนุณ ุดุงูู ฺบ

### Azure AI Foundry ูุงฺู ฺฉูนูุงฺฏ

Azure AI Foundry ูุงฺู ฺฉูนูุงฺฏ ุงููนุฑูพุฑุงุฆุฒ ฺฏุฑฺ SLMs ุชฺฉ ุฑุณุงุฆ ูุฑุงู ฺฉุฑุชุง  ุฌุณ ูฺบ ุจุชุฑ ุงูุถูุงู ฺฉ ุตูุงุญุชฺบ ุดุงูู ฺบ:

**ุงููนุฑูพุฑุงุฆุฒ ุงูุถูุงู**: ฺฉูนูุงฺฏ ูฺบ Azure ฺฉ ุฐุฑุน ุจุฑุง ุฑุงุณุช ูุฑูุฎุช ฺฉ ุฌุงู ูุงู ูุงฺูุฒ ุดุงูู ฺบ ุฌู ูฺบ ุงููนุฑูพุฑุงุฆุฒ ฺฏุฑฺ ุณูพูุฑูน ุงูุฑ SLAs ุดุงูู ฺบุ ุฌุณ Phi-4-mini-3.8B ุงฺูุงูุณฺ ุฑุฒููฺฏ ุตูุงุญุชูฺบ ฺฉ ู ุงูุฑ Llama 3-8B ูพุฑูฺฺฉุดู ุชุนูุงุช ฺฉ ู ุงุณ ูฺบ Qwen3 8B ุฌุณ ูุงฺูุฒ ุจฺพ ุดุงูู ฺบ ุฌู ูุงุจู ุงุนุชูุงุฏ ุชฺพุฑฺ ูพุงุฑูน ุงููพู ุณูุฑุณ ูุงฺู ุณ ฺบ

**ุงููนุฑูพุฑุงุฆุฒ ููุงุฆุฏ**: ูุงุฆู ูนูููฺฏุ ูุดุงุฏุ ุงูุฑ ุฐู ุฏุงุฑ AI ฺฉ ู ุจููน ุงู ูนููุฒ ูุงฺู ูููุฒ ฺฉ ุฏุฑูุงู ูุงุจู ุชุจุงุฏู Provisioned Throughput ฺฉ ุณุงุชฺพ ูุฑุจูุท ฺบ ุงููนุฑูพุฑุงุฆุฒ SLAs ฺฉ ุณุงุชฺพ ุจุฑุง ุฑุงุณุช Microsoft ุณูพูุฑูนุ ูุฑุจูุท ุณฺฉูุฑูน ุงูุฑ ุชุนูู ฺฉ ุฎุตูุตุงุชุ ุงูุฑ ุฌุงูุน ุชุนูุงุช ูุฑฺฉ ููู ุงููนุฑูพุฑุงุฆุฒ ุชุฌุฑุจ ฺฉู ุจฺฺพุงุช ฺบ

## ุงฺูุงูุณฺ ฺฉูุงููนุงุฆุฒุดู ุงูุฑ ุงุตูุงุญ ุชฺฉูฺฉฺบ

### Llama.cpp ุงุตูุงุญ ูุฑู ูุฑฺฉ

Llama.cpp ุงุฌ ุชุนูุงุช ูฺบ ุฒุงุฏ ุณ ุฒุงุฏ ฺฉุงุฑฺฉุฑุฏฺฏ ฺฉ ู ุฌุฏุฏ ฺฉูุงููนุงุฆุฒุดู ุชฺฉูฺฉฺบ ูุฑุงู ฺฉุฑุชุง :

**ฺฉูุงููนุงุฆุฒุดู ฺฉ ุทุฑู**: ูุฑู ูุฑฺฉ ูุฎุชูู ฺฉูุงููนุงุฆุฒุดู ูููุฒ ฺฉ ุญูุงุช ฺฉุฑุชุง ุ ุฌู ูฺบ ุดุงูู ฺบ Q4_0 (4-ุจูน ฺฉูุงููนุงุฆุฒุดู ุจุชุฑู ุณุงุฆุฒ ูฺบ ฺฉู ฺฉ ุณุงุชฺพ - Qwen3-0.6B ููุจุงุฆู ุชุนูุงุช ฺฉ ู ูุซุงู)ุ Q5_1 (5-ุจูน ฺฉูุงููนุงุฆุฒุดู ูุนุงุฑ ุงูุฑ ฺฉููพุฑุดู ูฺบ ุชูุงุฒู - Phi-4-mini-3.8B ุงุฌ ุงููุฑูุณ ฺฉ ู ููุฒูฺบ)ุ ุงูุฑ Q8_0 (ุงุตู ูุนุงุฑ ฺฉ ูุฑุจ - Google Gemma3 ูพุฑูฺฺฉุดู ุงุณุชุนูุงู ฺฉ ู ุชุฌูุฒ ฺฉุฑุฏ) BitNET ุงูุชุงุฆ ฺฉููพุฑุดู ฺฉ ููุธุฑูุงููฺบ ฺฉ ู 1-ุจูน ฺฉูุงููนุงุฆุฒุดู ฺฉ ุณุงุชฺพ ุฌุฏุฏ ุชุฑู 

**ููุงุฐ ฺฉ ููุงุฆุฏ**: SIMD ุงฺฉุณูุฑุดู ฺฉ ุณุงุชฺพ CPU-ุขูพูนูุงุฆุฒฺ ุงููุฑูุณ ูููุฑ ฺฉ ููุซุฑ ูุงฺู ููฺูฺฏ ุงูุฑ ุนููุฏุฑุขูุฏ ูุฑุงู ฺฉุฑุชุง  x86ุ ARMุ ุงูุฑ Apple Silicon ุขุฑฺฉูนฺฉฺุฑุฒ ฺฉ ุฏุฑูุงู ฺฉุฑุงุณ ูพููน ูุงุฑู ูุทุงุจูุช ุงุฑฺูุฆุฑ-ุงฺฏูุงุณูนฺฉ ุชุนูุงุช ฺฉ ุตูุงุญุชูฺบ ฺฉู ูุนุงู ฺฉุฑุช 

**ุนูู ููุงุฐ ฺฉ ูุซุงู**:

```bash
# Clone and build llama.cpp
git clone https://github.com/ggerganov/llama.cpp.git
cd llama.cpp
mkdir build && cd build
cmake .. -DCMAKE_BUILD_TYPE=Release
cmake --build . --config Release

# Convert Phi-4-mini model from Hugging Face to GGUF format
# First, download the model from Hugging Face
cd ..
python convert.py --outtype f16 --outfile phi-4-mini.gguf /path/to/downloaded/phi-4-mini/model

# Quantize the model to 4-bit precision (Q4_0)
./build/bin/quantize phi-4-mini.gguf phi-4-mini-q4_0.gguf q4_0

# Benchmark the model to check performance
./build/bin/llama-bench -m phi-4-mini-q4_0.gguf -p "Write a function to calculate the Fibonacci sequence"

# Run inference with the quantized model
./build/bin/main -m phi-4-mini-q4_0.gguf -n 512 -p "Explain quantum computing in simple terms"
```

**ูููุฑ ููน ูพุฑููน ฺฉุง ููุงุฒู**:

```python
# Python script to analyze model size differences
import os
import matplotlib.pyplot as plt
import numpy as np

# Model sizes (in GB)
models = ['Phi-4-mini', 'Qwen3-0.6B', 'Gemma3']
original_sizes = [7.6, 1.2, 4.8]  # F16 format
q4_0_sizes = [2.0, 0.35, 1.3]     # Q4_0 format
q8_0_sizes = [3.9, 0.68, 2.5]     # Q8_0 format

# Calculate reduction percentages
q4_reduction = [(orig - q4) / orig * 100 for orig, q4 in zip(original_sizes, q4_0_sizes)]
q8_reduction = [(orig - q8) / orig * 100 for orig, q8 in zip(original_sizes, q8_0_sizes)]

print("Model Size Reduction:")
for i, model in enumerate(models):
    print(f"{model}: Q4_0 reduces size by {q4_reduction[i]:.1f}%, Q8_0 reduces size by {q8_reduction[i]:.1f}%")

# Memory usage during inference will be approximately:
# - Original F16: ~2x model size
# - Q4_0: ~1.2x model size
# - Q8_0: ~1.5x model size
```

### Microsoft Olive ุงุตูุงุญ ุณููน

Microsoft Olive ูพุฑูฺฺฉุดู ูุงุญูู ฺฉ ู ุฌุงูุน ูุงฺู ุงุตูุงุญ ูุฑฺฉ ููู ูุฑุงู ฺฉุฑุชุง :

**ุงุตูุงุญ ุชฺฉูฺฉฺบ**: ุณููน ูฺบ ุดุงูู ฺบ ฺุงุฆูุงูฺฉ ฺฉูุงููนุงุฆุฒุดู ุฎูุฏฺฉุงุฑ ูพุฑุณุฌู ุณูฺฉุดู ฺฉ ู (ุฎุงุต ุทูุฑ ูพุฑ Qwen3 ุณุฑุฒ ูุงฺูุฒ ฺฉ ุณุงุชฺพ ูุคุซุฑ)ุ ฺฏุฑุงู ุงุตูุงุญ ุงูุฑ ุขูพุฑูนุฑ ููฺู (Google Gemma3 ุขุฑฺฉูนฺฉฺุฑ ฺฉ ู ุจุชุฑ)ุ CPUุ GPUุ ุงูุฑ NPU ฺฉ ู ุงุฑฺูุฆุฑ ูุฎุตูุต ุงุตูุงุญุงุช (ARM ฺูุงุฆุณุฒ ูพุฑ Phi-4-mini-3.8B ฺฉ ู ุฎุตูุต ุณูพูุฑูน ฺฉ ุณุงุชฺพ)ุ ุงูุฑ ูููน ุงุณูนุฌ ุงุตูุงุญ ูพุงุฆูพ ูุงุฆูุฒ BitNET ูุงฺูุฒ ฺฉู Olive ูุฑู ูุฑฺฉ ฺฉ ุงูุฏุฑ ุฎุตูุต 1-ุจูน ฺฉูุงููนุงุฆุฒุดู ูุฑฺฉ ููู ฺฉ ุถุฑูุฑุช ูุช 

**ูุฑฺฉ ููู ุขูนููุดู**: ุงุตูุงุญ ูุฑุฆููนุณ ฺฉ ุฏุฑูุงู ุฎูุฏฺฉุงุฑ ุจูฺ ูุงุฑฺฉูฺฏ ูุนุงุฑ ฺฉ ููนุฑฺฉุณ ฺฉู ูุญููุธ ุฑฺฉฺพุช ูุฆ ุงุตูุงุญ ฺฉู ูู ุจูุงุช  PyTorch ุงูุฑ ONNX ุฌุณ ูุดูุฑ ML ูุฑู ูุฑฺฉ ฺฉ ุณุงุชฺพ ุงูุถูุงู ฺฉูุงุคฺ ุงูุฑ ุงุฌ ุชุนูุงุช ฺฉ ุงุตูุงุญ ุตูุงุญุชฺบ ูุฑุงู ฺฉุฑุชุง 

**ุนูู ููุงุฐ ฺฉ ูุซุงู**:

```python
# Microsoft Olive optimization workflow for SLM
from olive.model import PyTorchModel, ONNXModel
from olive.workflows import run_workflow
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Define the workflow configuration
def create_olive_config(model_id="microsoft/phi-4-mini-instruct"):
    # Load model and create sample inputs
    tokenizer = AutoTokenizer.from_pretrained(model_id)
    model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16)
    
    # Create sample inputs for tracing
    sample_text = "Explain the concept of edge computing"
    inputs = tokenizer(sample_text, return_tensors="pt")
    
    # Export to ONNX first
    model_path = f"{model_id.split('/')[-1]}.onnx"
    torch.onnx.export(
        model,
        (inputs["input_ids"],),
        model_path,
        input_names=["input_ids"],
        output_names=["logits"],
        dynamic_axes={
            "input_ids": {0: "batch", 1: "sequence"},
            "logits": {0: "batch", 1: "sequence"}
        },
        opset_version=15
    )
    
    # Create Olive optimization config
    config = {
        "input_model": ONNXModel(model_path),
        "systems": {
            "local_system": {
                "type": "LocalSystem"
            }
        },
        "passes": {
            # Graph optimization pass
            "graph_optimization": {
                "type": "OrtTransformersOptimization",
                "config": {
                    "optimization_options": {
                        "enable_gelu": True,
                        "enable_layer_norm": True,
                        "enable_attention": True,
                        "use_multi_head_attention": True
                    }
                }
            },
            # Quantization pass for INT8
            "quantization": {
                "type": "OrtQuantization",
                "config": {
                    "quant_mode": "static",
                    "activation_type": "int8",
                    "weight_type": "int8",
                    "op_types_to_quantize": ["MatMul", "Add", "Conv"]
                },
                "disable_search": True
            }
        },
        "engine": {
            "log_severity_level": 0,
            "cache_dir": "./cache"
        }
    }
    
    return config

# Run the optimization workflow
config = create_olive_config()
result = run_workflow(config)

# Save the optimized model
optimized_model = result.optimized_model
optimized_model.save("./optimized_phi4_mini")

# Benchmark performance comparison
print(f"Original model size: {os.path.getsize(model_path) / (1024 * 1024):.2f} MB")
print(f"Optimized model size: {os.path.getsize('./optimized_phi4_mini/model.onnx') / (1024 * 1024):.2f} MB")
```

### Apple MLX ูุฑู ูุฑฺฉ

Apple MLX ุฎุงุต ุทูุฑ ูพุฑ Apple Silicon ฺูุงุฆุณุฒ ฺฉ ู ฺุฒุงุฆู ฺฉุฑุฏ ููุงู ุงุตูุงุญ ุตูุงุญุชฺบ ูุฑุงู ฺฉุฑุชุง :

**Apple Silicon ุงุตูุงุญ**: ูุฑู ูุฑฺฉ ูุชุญุฏ ูููุฑ ุขุฑฺฉูนฺฉฺุฑ ฺฉ ุณุงุชฺพ Metal Performance Shaders ุงูุถูุงูุ ุฎูุฏฺฉุงุฑ ูฺฉุณฺ ูพุฑุณุฌู ุงููุฑูุณ (ุฎุงุต ุทูุฑ ูพุฑ Google Gemma3 ฺฉ ุณุงุชฺพ ูุคุซุฑ)ุ ุงูุฑ ุจุชุฑ ูููุฑ ุจูฺูฺุชฺพ ุงุณุชุนูุงู ูุฑุงู ฺฉุฑุชุง  Phi-4-mini-3.8B M-ุณุฑุฒ ฺูพุณ ูพุฑ ุบุฑ ูุนููู ฺฉุงุฑฺฉุฑุฏฺฏ ุฏฺฉฺพุงุชุง ุ ุฌุจฺฉ Qwen3-1.7B MacBook Air ุชุนูุงุช ฺฉ ู ุจุชุฑู ุชูุงุฒู ูุฑุงู ฺฉุฑุชุง 

**ุชุฑูุงุช ุฎุตูุตุงุช**: Python ุงูุฑ Swift API ุณูพูุฑูน ฺฉ ุณุงุชฺพ NumPy-ูุทุงุจูุช ูพุฐุฑ ุงุฑ ุขูพุฑุดูุฒุ ุฎูุฏฺฉุงุฑ ุชูุฑู ฺฉ ุตูุงุญุชฺบุ ุงูุฑ Apple ุชุฑูุงุช ูนููุฒ ฺฉ ุณุงุชฺพ ููุงุฑ ุงูุถูุงู ุฌุงูุน ุชุฑูุงุช ูุงุญูู ูุฑุงู ฺฉุฑุชุง 

**ุนูู ููุงุฐ ฺฉ ูุซุงู**:

```python
# Apple MLX optimization for Phi-4-mini model
import mlx.core as mx
import mlx.nn as nn
from transformers import AutoTokenizer, AutoModelForCausalLM
from mlx_lm import load, generate

# Install the required packages
# pip install mlx transformers mlx-lm

# Load the Phi-4-mini model with MLX optimization
model_path = "microsoft/phi-4-mini-instruct"
model, tokenizer = load(model_path)

# Convert to float16 for better performance on Apple Silicon
model.convert_to_float16()

# Sample inference
prompt = "Write a function to find prime numbers in Python"
results = generate(
    model, 
    tokenizer,
    prompt=prompt,
    max_tokens=512,
    temperature=0.7,
    top_p=0.9,
)

print(results[0]["generation"])

# Benchmark the model
import time

def benchmark_inference(model, tokenizer, prompt, runs=10):
    # Warmup
    generate(model, tokenizer, prompt=prompt, max_tokens=128)
    
    # Benchmark
    start_time = time.time()
    for _ in range(runs):
        generate(model, tokenizer, prompt=prompt, max_tokens=128)
    end_time = time.time()
    
    avg_time = (end_time - start_time) / runs
    return avg_time

avg_inference_time = benchmark_inference(model, tokenizer, "Explain quantum computing")
print(f"Average inference time: {avg_inference_time:.4f} seconds")

# Save the optimized model for later use
model.save_weights("phi4_mini_optimized_mlx.npz")
```

## ูพุฑูฺฺฉุดู ุชุนูุงุช ุงูุฑ ุงููุฑูุณ ฺฉ ุญฺฉูุช ุนูู

### Ollama: ุณุงุฏ ููุงู ุชุนูุงุช

Ollama ุงุฌ ุงูุฑ ููุงู ูุงุญูู ฺฉ ู ุงููนุฑูพุฑุงุฆุฒ ุฑฺ ุฎุตูุตุงุช ฺฉ ุณุงุชฺพ SLM ุชุนูุงุช ฺฉู ุขุณุงู ุจูุงุชุง :

**ุชุนูุงุช ฺฉ ุตูุงุญุชฺบ**: ุงฺฉ ฺฉูุงูฺ ูุงฺู ุงูุณูนุงูุดู ุงูุฑ ุนููุฏุฑุขูุฏ ฺฉ ุณุงุชฺพ ุฎูุฏฺฉุงุฑ ูุงฺู ูพููฺฏ ุงูุฑ ฺฉุดูฺฏ Phi-4-mini-3.8Bุ ูฺฉูู Qwen3 ุณุฑุฒ (0.6B/1.7B/4B)ุ ุงูุฑ Google Gemma3 ฺฉ ู ุณูพูุฑูน ฺฉ ุณุงุชฺพ REST API ุงูพูฺฉุดู ุงูุถูุงู ุงูุฑ ูููน ูุงฺู ููุฌูููน ุงูุฑ ุณูุฆฺูฺฏ ฺฉ ุตูุงุญุชฺบ BitNET ูุงฺูุฒ ฺฉู 1-ุจูน ฺฉูุงููนุงุฆุฒุดู ุณูพูุฑูน ฺฉ ู ุชุฌุฑุจุงุช ุจูฺ ฺฉููฺฏุฑุดูุฒ ฺฉ ุถุฑูุฑุช ูุช 

**ุงฺูุงูุณฺ ุฎุตูุตุงุช**: ฺฉุณูนู ูุงฺู ูุงุฆู ูนูููฺฏ ุณูพูุฑูนุ ฺฉููนูุฑุงุฆุฒฺ ุชุนูุงุช ฺฉ ู Dockerfile ุฌูุฑุดูุ GPU ุงฺฉุณูุฑุดู ฺฉ ุณุงุชฺพ ุฎูุฏฺฉุงุฑ ฺูนฺฉุดูุ ุงูุฑ ูุงฺู ฺฉูุงููนุงุฆุฒุดู ุงูุฑ ุงุตูุงุญ ุงุฎุชุงุฑุงุช ุฌุงูุน ุชุนูุงุช ฺฉ ูฺฺฉ ูุฑุงู ฺฉุฑุช ฺบ

### VLLM: ุงุนู ฺฉุงุฑฺฉุฑุฏฺฏ ุงููุฑูุณ

VLLM ุงุนู throughput ููุธุฑูุงููฺบ ฺฉ ู ูพุฑูฺฺฉุดู ฺฏุฑฺ ุงููุฑูุณ ุงุตูุงุญ ูุฑุงู ฺฉุฑุชุง :

**ฺฉุงุฑฺฉุฑุฏฺฏ ฺฉ ุงุตูุงุญุงุช**: PagedAttention ูููุฑ ฺฉ ููุซุฑ ุชูุฌ ฺฉ ฺฏูุช ฺฉ ู (ุฎุงุต ุทูุฑ ูพุฑ Phi-4-mini-3.8B ฺฉ ูนุฑุงูุณูุงุฑูุฑ ุขุฑฺฉูนฺฉฺุฑ ฺฉ ู ูุงุฆุฏ ููุฏ)ุ throughput ฺฉ ุงุตูุงุญ ฺฉ ู ฺุงุฆูุงูฺฉ ุจฺูฺฏ (Qwen3 ุณุฑุฒ ฺฉ ูุชูุงุฒ ูพุฑูุณุณูฺฏ ฺฉ ู ุจุชุฑ)ุ ูููน-GPU ุงุณฺฉููฺฏ ฺฉ ู ูนูุณุฑ ูพุฑุงููุฒู (Google Gemma3 ุณูพูุฑูน)ุ ุงูุฑ ููนูุณ ฺฉู ฺฉู ฺฉุฑู ฺฉ ู speculative decoding BitNET ูุงฺูุฒ ฺฉู 1-ุจูน ุขูพุฑุดูุฒ ฺฉ ู ุฎุตูุต ุงููุฑูุณ ฺฉุฑููุฒ ฺฉ ุถุฑูุฑุช ูุช 

**ุงููนุฑูพุฑุงุฆุฒ ุงูุถูุงู**: OpenAI-ูุทุงุจูุช ูพุฐุฑ API ุงูฺูพูุงุฆููนุณุ Kubernetes ุชุนูุงุช ุณูพูุฑูนุ ูุงููนุฑูฺฏ ุงูุฑ ูุดุงุฏ ุงูุถูุงูุ ุงูุฑ ุฎูุฏฺฉุงุฑ ุงุณฺฉููฺฏ ฺฉ ุตูุงุญุชฺบ ุงููนุฑูพุฑุงุฆุฒ ฺฏุฑฺ ุชุนูุงุช ฺฉ ุญู ูุฑุงู ฺฉุฑุช ฺบ

### Foundry Local: Microsoft ฺฉุง ุงุฌ ุญู

Foundry Local ุงููนุฑูพุฑุงุฆุฒ ูุงุญูู ฺฉ ู ุฌุงูุน ุงุฌ ุชุนูุงุช ฺฉ ุตูุงุญุชฺบ ูุฑุงู ฺฉุฑุชุง :

**ุงุฌ ฺฉููพููนูฺฏ ุฎุตูุตุงุช**: ุขู ูุงุฆู-ูุฑุณูน ุขุฑฺฉูนฺฉฺุฑ ฺุฒุงุฆู ฺฉ ุณุงุชฺพ ูุณุงุฆู ฺฉ ูพุงุจูุฏ ฺฉ ุงุตูุงุญุ ููุงู ูุงฺู ุฑุฌุณูนุฑ ููุฌูููนุ ุงูุฑ ุงุฌ-ูนู-ฺฉูุงุคฺ ู ุขูฺฏ ฺฉ ุตูุงุญุชฺบ ูุงุจู ุงุนุชูุงุฏ ุงุฌ ุชุนูุงุช ฺฉู ูู ุจูุงุช ฺบ

**ุณฺฉูุฑูน ุงูุฑ ุชุนูู**: ูพุฑุงุฆูุณ ฺฉ ุชุญูุธ ฺฉ ู ููุงู ฺูนุง ูพุฑูุณุณูฺฏุ ุงููนุฑูพุฑุงุฆุฒ ุณฺฉูุฑูน ฺฉููนุฑููุฒุ ุขฺูน ูุงฺฏูฺฏ ุงูุฑ ุชุนูู ฺฉ ุฑูพูุฑูนูฺฏุ ุงูุฑ ุฑูู-ุจุณฺ ุงฺฉุณุณ ููุฌูููน ุงุฌ ุชุนูุงุชูฺบ ฺฉ ู ุฌุงูุน ุณฺฉูุฑูน ูุฑุงู ฺฉุฑุช ฺบ

## SLM ููุงุฐ ฺฉ ุจุชุฑู ุทุฑู

### ูุงฺู ุงูุชุฎุงุจ ฺฉ ุฑููุง ุงุตูู

ุงุฌ ุชุนูุงุช ฺฉ ู SLMs ฺฉุง ุงูุชุฎุงุจ ฺฉุฑุช ููุช ุฏุฑุฌ ุฐู ุนูุงูู ูพุฑ ุบูุฑ ฺฉุฑฺบ:

**ูพุฑุงููนุฑ ฺฉ ุชุนุฏุงุฏ ฺฉ ุชุญูุธุงุช**: ูุงุฆฺฉุฑู SLMs ุฌุณ Qwen3-0.6B ุงูุชุงุฆ ูฺฉ ูุฒู ูุงู ููุจุงุฆู ุงูพูฺฉุดูุฒ ฺฉ ู ููุชุฎุจ ฺฉุฑฺบุ ฺฺพููน SLMs ุฌุณ Qwen3-1.7B ุง Google Gemma3 ูุชูุงุฒู ฺฉุงุฑฺฉุฑุฏฺฏ ฺฉ ููุธุฑูุงููฺบ ฺฉ ูุ ุงูุฑ ุฏุฑูุงู SLMs ุฌุณ Phi-4-mini-3.8B ุง Qwen3-4B LLM ฺฉ ุตูุงุญุชูฺบ ฺฉ ูุฑุจ ูพูฺุช ูุฆ ฺฉุงุฑฺฉุฑุฏฺฏ ุจุฑูุฑุงุฑ ุฑฺฉฺพู ฺฉ ู BitNET ูุงฺูุฒ ูุฎุตูุต ุชุญูู ุงูพูฺฉุดูุฒ ฺฉ ู ุชุฌุฑุจุงุช ุงูุชุงุฆ ฺฉููพุฑุดู ูพุด ฺฉุฑุช ฺบ

**ุงุณุชุนูุงู ฺฉ ูุนุงูู ฺฉ ูุทุงุจูุช**: ูุงฺู ฺฉ ุตูุงุญุชูฺบ ฺฉู ูุฎุตูุต ุงูพูฺฉุดู ฺฉ ุถุฑูุฑุงุช ฺฉ ูุทุงุจู ุจูุงุฆฺบุ ุฌุณ ุฌูุงุจ ฺฉ ูุนุงุฑุ ุงููุฑูุณ ฺฉ ุฑูุชุงุฑุ ูููุฑ ฺฉ ูพุงุจูุฏุงฺบุ ุงูุฑ ุขู ูุงุฆู ุขูพุฑุดู ฺฉ ุถุฑูุฑุงุช

### ุงุตูุงุญ ุญฺฉูุช ุนูู ฺฉุง ุงูุชุฎุงุจ

**ฺฉูุงููนุงุฆุฒุดู ฺฉุง ุทุฑู**: ูุนุงุฑ ฺฉ ุถุฑูุฑุงุช ุงูุฑ ุงุฑฺูุฆุฑ ฺฉ ูพุงุจูุฏูฺบ ฺฉ ุจูุงุฏ ูพุฑ ููุงุณุจ ฺฉูุงููนุงุฆุฒุดู ูููุฒ ฺฉุง ุงูุชุฎุงุจ ฺฉุฑฺบ ุฒุงุฏ ุณ ุฒุงุฏ ฺฉููพุฑุดู ฺฉ ู Q4_0 ููุชุฎุจ ฺฉุฑฺบ (Qwen3-0.6B ููุจุงุฆู ุชุนูุงุช ฺฉ ู ูุซุงู)ุ Q5_1 ูุนุงุฑ-ฺฉููพุฑุดู ฺฉ ุชูุงุฒู ฺฉ ู (Phi-4-mini-3.8B ุงูุฑ Google Gemma3 ฺฉ ู ููุฒูฺบ)ุ ุงูุฑ Q8_0 ุงุตู ูุนุงุฑ ฺฉ ุชุญูุธ ฺฉ ู (Qwen3-4B ูพุฑูฺฺฉุดู ูุงุญูู ฺฉ ู ุชุฌูุฒ ฺฉุฑุฏ) BitNET ฺฉุง 1-ุจูน ฺฉูุงููนุงุฆุฒุดู ูุฎุตูุต ุงูพูฺฉุดูุฒ ฺฉ ู ุงูุชุงุฆ ฺฉููพุฑุดู ฺฉ ุญุฏ ฺฉ ููุงุฆูุฏฺฏ ฺฉุฑุชุง 

**ูุฑู ูุฑฺฉ ฺฉุง ุงูุชุฎุงุจ**: ุฏู ุงุฑฺูุฆุฑ ุงูุฑ ุชุนูุงุช ฺฉ ุถุฑูุฑุงุช ฺฉ ุจูุงุฏ ูพุฑ ุงุตูุงุญ ูุฑู ูุฑฺฉ ฺฉุง ุงูุชุฎุงุจ ฺฉุฑฺบ CPU-ุขูพูนูุงุฆุฒฺ ุชุนูุงุช ฺฉ ู Llama.cpp ุงุณุชุนูุงู ฺฉุฑฺบุ ุฌุงูุน ุงุตูุงุญ ูุฑฺฉ ููู ฺฉ ู Microsoft Oliveุ ุงูุฑ Apple Silicon ฺูุงุฆุณุฒ ฺฉ ู Apple MLX

## ุนูู ูุงฺู ฺฉ ูุซุงูฺบ ุงูุฑ ุงุณุชุนูุงู ฺฉ ูุนุงููุงุช

### ุญูู ุฏูุง ฺฉ ุชุนูุงุช ฺฉ ููุธุฑูุงู

**ููุจุงุฆู ุงูพูฺฉุดูุฒ**: Qwen3-0.6B ุงุณูุงุฑูน ููู ฺูน ุจููน ุงูพูฺฉุดูุฒ ูฺบ ฺฉู ุณ ฺฉู ูููุฑ ููน ูพุฑููน ฺฉ ุณุงุชฺพ ุจุชุฑู ฺฉุงุฑฺฉุฑุฏฺฏ ุฏฺฉฺพุงุชุง ุ ุฌุจฺฉ Google Gemma3 ูนุจููน ูพุฑ ูุจู ุชุนูู ูนููุฒ ฺฉ ู ูุชูุงุฒู ฺฉุงุฑฺฉุฑุฏฺฏ ูุฑุงู ฺฉุฑุชุง  Phi-4-mini-3.8B ููุจุงุฆู ูพุฑูฺฺฉูนููน ุงูพูฺฉุดูุฒ ฺฉ ู ุงุนููฐ ุฑุฒููฺฏ ุตูุงุญุชฺบ ูพุด ฺฉุฑุชุง 

**ฺุณฺฉ ูนุงูพ ุงูุฑ ุงุฌ ฺฉููพููนูฺฏ**: Qwen3-1.7B ฺุณฺฉ ูนุงูพ ุงุณุณูนููน ุงูพูฺฉุดูุฒ ฺฉ ู ุจุชุฑู ฺฉุงุฑฺฉุฑุฏฺฏ ูุฑุงู ฺฉุฑุชุง ุ Phi-4-mini-3.8B ฺูููพุฑ ูนููุฒ ฺฉ ู ุงฺูุงูุณฺ ฺฉูฺ ุฌูุฑุดู ฺฉ ุตูุงุญุชฺบ ูุฑุงู ฺฉุฑุชุง ุ ุงูุฑ Qwen3-4B ูุฑฺฉ ุณูนุดู ูุงุญูู ูฺบ ูพฺุฏ ุฏุณุชุงูุฒ ุชุฌุฒ ฺฉู ูุนุงู ฺฉุฑุชุง 

**ุชุญูู ุงูุฑ ุชุฌุฑุจุงุช**: BitNET ูุงฺูุฒ ุงูุชุงุฆ ฺฉู ูพุฑุณุฌู ุงููุฑูุณ ฺฉ ุชูุงุด ฺฉ ู ุชุนูู ุชุญูู ุงูุฑ ูพุฑูู ุขู ฺฉุงูุณูพูน ุงูพูฺฉุดูุฒ ฺฉ ู ุงูุชุงุฆ ูุณุงุฆู ฺฉ ูพุงุจูุฏูฺบ ฺฉ ุณุงุชฺพ ูุงุจู ุจูุงุช ฺบ

### ฺฉุงุฑฺฉุฑุฏฺฏ ฺฉ ุจูฺ ูุงุฑฺฉุณ ุงูุฑ ููุงุฒู

**ุงููุฑูุณ ฺฉ ุฑูุชุงุฑ**: Qwen3-0.6B

---

**ฺุณฺฉููุฑ**:  
 ุฏุณุชุงูุฒ AI ุชุฑุฌู ุณุฑูุณ [Co-op Translator](https://github.com/Azure/co-op-translator) ฺฉุง ุงุณุชุนูุงู ฺฉุฑุช ูุฆ ุชุฑุฌู ฺฉ ฺฏุฆ  ู ุฏุฑุณุชฺฏ ฺฉ ู ฺฉูุดุด ฺฉุฑุช ฺบุ ูฺฉู ุจุฑุง ฺฉุฑู ุขฺฏุง ุฑฺบ ฺฉ ุฎูุฏฺฉุงุฑ ุชุฑุฌู ูฺบ ุบูุทุงฺบ ุง ุบุฑ ุฏุฑุณุชุงฺบ ู ุณฺฉุช ฺบ ุงุตู ุฏุณุชุงูุฒ ฺฉู ุงุณ ฺฉ ุงุตู ุฒุจุงู ูฺบ ูุณุชูุฏ ุฐุฑุน ุณูุฌฺพุง ุฌุงูุง ฺุง ุงู ูุนูููุงุช ฺฉ ูุ ูพุด ูุฑ ุงูุณุงู ุชุฑุฌู ฺฉ ุณูุงุฑุด ฺฉ ุฌุงุช  ู ุงุณ ุชุฑุฌู ฺฉ ุงุณุชุนูุงู ุณ ูพุฏุง ูู ูุงู ฺฉุณ ุจฺพ ุบูุท ูู ุง ุบูุท ุชุดุฑุญ ฺฉ ุฐู ุฏุงุฑ ูฺบ ฺบ