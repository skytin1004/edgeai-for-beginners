<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "38b68a204a9621126d056b0e5b51ab7c",
  "translation_date": "2025-10-09T06:31:09+00:00",
  "source_file": "Module03/01.SLMAdvancedLearning.md",
  "language_code": "ar"
}
-->
# ุงููุณู 1: ุงูุชุนูู ุงููุชูุฏู ูููุงุฐุฌ ุงููุบุฉ ุงูุตุบูุฑุฉ - ุงูุฃุณุณ ูุงูุชุญุณูู

ููุงุฐุฌ ุงููุบุฉ ุงูุตุบูุฑุฉ (SLMs) ุชูุซู ุชูุฏููุง ููููุง ูู EdgeAIุ ุญูุซ ุชุชูุญ ูุฏุฑุงุช ูุนุงูุฌุฉ ุงููุบุฉ ุงูุทุจูุนูุฉ ุงููุชูุฏูุฉ ุนูู ุงูุฃุฌูุฒุฉ ุฐุงุช ุงูููุงุฑุฏ ุงููุญุฏูุฏุฉ. ููู ููููุฉ ูุดุฑ ูุชุญุณูู ูุงุณุชุฎุฏุงู SLMs ุจุดูู ูุนุงู ุถุฑูุฑู ูุจูุงุก ุญููู ุฐูุงุก ุงุตุทูุงุนู ุนูููุฉ ุชุนุชูุฏ ุนูู ุงูุญุงูุฉ.

## ุงูููุฏูุฉ

ูู ูุฐู ุงูุฏุฑุณุ ุณูุณุชูุดู ููุงุฐุฌ ุงููุบุฉ ุงูุตุบูุฑุฉ (SLMs) ูุงุณุชุฑุงุชูุฌูุงุช ุชูููุฐูุง ุงููุชูุฏูุฉ. ุณูุบุทู ุงูููุงููู ุงูุฃุณุงุณูุฉ ูู SLMsุ ุญุฏูุฏ ุงููุนููุงุช ูุชุตูููุงุชูุงุ ุชูููุงุช ุงูุชุญุณููุ ูุงุณุชุฑุงุชูุฌูุงุช ุงููุดุฑ ุงูุนูููุฉ ูุจูุฆุงุช ุงูุญูุณุจุฉ ุงูุทุฑููุฉ.

## ุฃูุฏุงู ุงูุชุนูู

ุจููุงูุฉ ูุฐุง ุงูุฏุฑุณุ ุณุชููู ูุงุฏุฑูุง ุนูู:

- ๐ข ููู ุญุฏูุฏ ุงููุนููุงุช ูุชุตูููุงุช ููุงุฐุฌ ุงููุบุฉ ุงูุตุบูุฑุฉ.
- ๐๏ธ ุชุญุฏูุฏ ุชูููุงุช ุงูุชุญุณูู ุงูุฑุฆูุณูุฉ ููุดุฑ SLMs ุนูู ุงูุฃุฌูุฒุฉ ุงูุทุฑููุฉ.
- ๐ ุชุนูู ุชูููุฐ ุงุณุชุฑุงุชูุฌูุงุช ุงูุชูููู ูุงูุถุบุท ุงููุชูุฏูุฉ ูู SLMs.

## ููู ุญุฏูุฏ ุงููุนููุงุช ูุชุตูููุงุช SLM

ููุงุฐุฌ ุงููุบุฉ ุงูุตุบูุฑุฉ (SLMs) ูู ููุงุฐุฌ ุฐูุงุก ุงุตุทูุงุนู ูุตููุฉ ููุนุงูุฌุฉ ูููู ูุฅูุดุงุก ูุญุชูู ุงููุบุฉ ุงูุทุจูุนูุฉ ุจุนุฏุฏ ุฃูู ุจูุซูุฑ ูู ุงููุนููุงุช ููุงุฑูุฉ ุจูุธูุฑุงุชูุง ุงููุจูุฑุฉ. ุจูููุง ุชุญุชูู ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ (LLMs) ุนูู ูุฆุงุช ุงููููุงุฑุงุช ุฅูู ุชุฑูููููุงุช ูู ุงููุนููุงุชุ ุชู ุชุตููู SLMs ุฎุตูุตูุง ูุชุญููู ุงูููุงุกุฉ ูุงููุดุฑ ุนูู ุงูุญุงูุฉ.

ูุณุงุนุฏ ุฅุทุงุฑ ุชุตููู ุงููุนููุงุช ูู ููู ุงููุฆุงุช ุงููุฎุชููุฉ ูู SLMs ูุงุณุชุฎุฏุงูุงุชูุง ุงูููุงุณุจุฉ. ูุฐุง ุงูุชุตููู ุถุฑูุฑู ูุงุฎุชูุงุฑ ุงููููุฐุฌ ุงูููุงุณุจ ูุณููุงุฑูููุงุช ุงูุญูุณุจุฉ ุงูุทุฑููุฉ ุงููุญุฏุฏุฉ.

### ุฅุทุงุฑ ุชุตููู ุงููุนููุงุช

ููู ุญุฏูุฏ ุงููุนููุงุช ูุณุงุนุฏ ูู ุงุฎุชูุงุฑ ุงูููุงุฐุฌ ุงูููุงุณุจุฉ ูุณููุงุฑูููุงุช ุงูุญูุณุจุฉ ุงูุทุฑููุฉ ุงููุฎุชููุฉ:

- **๐ฌ ููุงุฐุฌ ุตุบูุฑุฉ ุฌุฏูุง (Micro SLMs)**: 100 ููููู - 1.4 ูููุงุฑ ูุนููุฉ (ุฎูููุฉ ููุบุงูุฉ ููุฃุฌูุฒุฉ ุงููุญูููุฉ)
- **๐ฑ ููุงุฐุฌ ุตุบูุฑุฉ (Small SLMs)**: 1.5 ูููุงุฑ - 13.9 ูููุงุฑ ูุนููุฉ (ุฃุฏุงุก ูุชูุงุฒู ูููุงุกุฉ)
- **โ๏ธ ููุงุฐุฌ ูุชูุณุทุฉ (Medium SLMs)**: 14 ูููุงุฑ - 30 ูููุงุฑ ูุนููุฉ (ุชูุชุฑุจ ูู ูุฏุฑุงุช LLM ูุน ุงูุญูุงุธ ุนูู ุงูููุงุกุฉ)

ูุจูู ุงูุญุฏ ุงูุฏููู ูุฑููุง ูู ูุฌุชูุน ุงูุจุญุซุ ููู ูุนุธู ุงูููุงุฑุณูู ูุนุชุจุฑูู ุงูููุงุฐุฌ ุงูุชู ุชุญุชูู ุนูู ุฃูู ูู 30 ูููุงุฑ ูุนููุฉ "ุตุบูุฑุฉ"ุ ูุน ุชุญุฏูุฏ ุจุนุถ ุงููุตุงุฏุฑ ุงูุญุฏ ุงูุฃุฏูู ุญุชู 10 ูููุงุฑุงุช ูุนููุฉ.

### ุงููุฒุงูุง ุงูุฑุฆูุณูุฉ ูู SLMs

ุชูุฏู SLMs ุงูุนุฏูุฏ ูู ุงููุฒุงูุง ุงูุฃุณุงุณูุฉ ุงูุชู ุชุฌุนููุง ูุซุงููุฉ ูุชุทุจููุงุช ุงูุญูุณุจุฉ ุงูุทุฑููุฉ:

**ุงูููุงุกุฉ ุงูุชุดุบูููุฉ**: ุชููุฑ SLMs ุฃููุงุช ุงุณุชูุชุงุฌ ุฃุณุฑุน ุจุณุจุจ ุนุฏุฏ ุฃูู ูู ุงููุนููุงุช ูููุนุงูุฌุฉุ ููุง ูุฌุนููุง ูุซุงููุฉ ููุชุทุจููุงุช ูู ุงูููุช ุงููุนูู. ุชุชุทูุจ ููุงุฑุฏ ุญุณุงุจูุฉ ุฃููุ ููุง ูุชูุญ ุงููุดุฑ ุนูู ุงูุฃุฌูุฒุฉ ุฐุงุช ุงูููุงุฑุฏ ุงููุญุฏูุฏุฉ ูุน ุงุณุชููุงู ุฃูู ููุทุงูุฉ ูุชูููู ุงูุจุตูุฉ ุงููุฑุจูููุฉ.

**ูุฑููุฉ ุงููุดุฑ**: ุชุชูุญ ูุฐู ุงูููุงุฐุฌ ูุฏุฑุงุช ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุนูู ุงูุฃุฌูุฒุฉ ุฏูู ุงูุญุงุฌุฉ ุฅูู ุงูุงุชุตุงู ุจุงูุฅูุชุฑูุชุ ูุชุนุฒุฒ ุงูุฎุตูุตูุฉ ูุงูุฃูุงู ูู ุฎูุงู ุงููุนุงูุฌุฉ ุงููุญููุฉุ ููููู ุชุฎุตูุตูุง ููุชุทุจููุงุช ุงูุฎุงุตุฉ ุจุงููุฌุงูุ ููู ููุงุณุจุฉ ูุจูุฆุงุช ุงูุญูุณุจุฉ ุงูุทุฑููุฉ ุงููุฎุชููุฉ.

**ูุนุงููุฉ ุงูุชูููุฉ**: ุชูุฏู SLMs ุชุฏุฑูุจูุง ููุดุฑูุง ุจุชูููุฉ ุฃูู ููุงุฑูุฉ ุจู LLMsุ ูุน ุชูููู ุชูุงููู ุงูุชุดุบูู ููุชุทูุจุงุช ุงููุทุงู ุงูุชุฑุฏุฏู ูุชุทุจููุงุช ุงูุญุงูุฉ.

## ุงุณุชุฑุงุชูุฌูุงุช ุงูุญุตูู ุนูู ุงูููุงุฐุฌ ุงููุชูุฏูุฉ

### ูุธุงู Hugging Face

ูุนุฏ Hugging Face ุงููุฑูุฒ ุงูุฃุณุงุณู ูุงูุชุดุงู ูุงููุตูู ุฅูู ููุงุฐุฌ SLMs ุงููุชูุฏูุฉ. ูููุฑ ุงููุธุงู ุงูุฃุณุงุณู ููุงุฑุฏ ุดุงููุฉ ูุงูุชุดุงู ุงูููุงุฐุฌ ููุดุฑูุง:

**ููุฒุงุช ุงูุชุดุงู ุงูููุงุฐุฌ**: ููุฏู ุงููุธุงู ุงูุฃุณุงุณู ุชุตููุฉ ูุชูุฏูุฉ ุญุณุจ ุนุฏุฏ ุงููุนููุงุชุ ููุน ุงูุชุฑุฎูุตุ ูููุงููุณ ุงูุฃุฏุงุก. ูููู ูููุณุชุฎุฏููู ุงููุตูู ุฅูู ุฃุฏูุงุช ููุงุฑูุฉ ุงูููุงุฐุฌ ุฌูุจูุง ุฅูู ุฌูุจุ ูุนุงููุฑ ุงูุฃุฏุงุก ูุงูุชูููู ูู ุงูููุช ุงููุนููุ ูุนุฑูุถ WebGPU ููุชุฌุฑุจุฉ ุงูููุฑูุฉ.

**ูุฌููุนุงุช SLMs ุงููุฎุชุงุฑุฉ**: ุชุดูู ุงูููุงุฐุฌ ุงูุดููุฑุฉ Phi-4-mini-3.8B ููููุงู ุงูุงุณุชุฏูุงููุฉ ุงููุชูุฏูุฉุ ุณูุณูุฉ Qwen3 (0.6B/1.7B/4B) ููุชุทุจููุงุช ูุชุนุฏุฏุฉ ุงููุบุงุชุ Google Gemma3 ููููุงู ุงูุนุงูุฉ ุจููุงุกุฉุ ูุงูููุงุฐุฌ ุงูุชุฌุฑูุจูุฉ ูุซู BitNET ูููุดุฑ ุจุฏูุฉ ููุฎูุถุฉ ููุบุงูุฉ. ููุง ูุถู ุงููุธุงู ุงูุฃุณุงุณู ูุฌููุนุงุช ูุฏููุนุฉ ูู ุงููุฌุชูุน ูุน ููุงุฐุฌ ูุชุฎุตุตุฉ ููุฌุงูุงุช ูุญุฏุฏุฉ ููุชุบูุฑุงุช ูุฏุฑุจุฉ ูุณุจููุง ููุถุจูุทุฉ ุนูู ุงูุชุนูููุงุช ูุชุญุณูู ุงูุงุณุชุฎุฏุงูุงุช ุงููุฎุชููุฉ.

### ูุชุงููุฌ ููุงุฐุฌ Azure AI Foundry

ูููุฑ ูุชุงููุฌ ููุงุฐุฌ Azure AI Foundry ูุตูููุง ุนูู ูุณุชูู ุงููุคุณุณุงุช ุฅูู SLMs ูุน ูุฏุฑุงุช ุชูุงูู ูุญุณูุฉ:

**ุชูุงูู ุงููุคุณุณุงุช**: ูุชุถูู ุงููุชุงููุฌ ููุงุฐุฌ ุชูุจุงุน ูุจุงุดุฑุฉ ูู Azure ูุน ุฏุนู ุนูู ูุณุชูู ุงููุคุณุณุงุช ูุงุชูุงููุงุช ูุณุชูู ุงูุฎุฏูุฉ (SLAs)ุ ูุซู Phi-4-mini-3.8B ูููุฏุฑุงุช ุงูุงุณุชุฏูุงููุฉ ุงููุชูุฏูุฉ ูLlama 3-8B ูููุดุฑ ุงูุฅูุชุงุฌู. ููุง ูุถู ููุงุฐุฌ ูุซู Qwen3 8B ูู ููุงุฐุฌ ููุชูุญุฉ ุงููุตุฏุฑ ููุซููุฉ ูู ุทุฑู ุซุงูุซ.

**ููุงุฆุฏ ุงููุคุณุณุงุช**: ุฃุฏูุงุช ูุฏูุฌุฉ ููุชุฎุตูุตุ ุงููุฑุงูุจุฉุ ูุงูุฐูุงุก ุงูุงุตุทูุงุนู ุงููุณุคูู ูุน ุชูููุฑ ูุงุจู ููุชุฎุตูุต ุนุจุฑ ุนุงุฆูุงุช ุงูููุงุฐุฌ. ุฏุนู ูุจุงุดุฑ ูู Microsoft ูุน ุงุชูุงููุงุช ูุณุชูู ุงูุฎุฏูุฉ ุนูู ูุณุชูู ุงููุคุณุณุงุชุ ููุฒุงุช ุงูุฃูุงู ูุงูุงูุชุซุงู ุงููุฏูุฌุฉุ ูุนูููุงุช ูุดุฑ ุดุงููุฉ ุชุนุฒุฒ ุชุฌุฑุจุฉ ุงููุคุณุณุงุช.

## ุชูููุงุช ุงูุชูููู ูุงูุชุญุณูู ุงููุชูุฏูุฉ

### ุฅุทุงุฑ ุชุญุณูู Llama.cpp

ูููุฑ Llama.cpp ุชูููุงุช ุชูููู ูุชูุฏูุฉ ูุชุญููู ุฃูุตู ููุงุกุฉ ูู ุงููุดุฑ ุงูุทุฑูู:

**ุทุฑู ุงูุชูููู**: ูุฏุนู ุงูุฅุทุงุฑ ูุณุชููุงุช ุชูููู ูุฎุชููุฉ ุจูุง ูู ุฐูู Q4_0 (ุชูููู 4 ุจุช ูุน ุชูููู ุงูุญุฌู ุจุดูู ููุชุงุฒ - ูุซุงูู ููุดุฑ Qwen3-0.6B ุนูู ุงูุฃุฌูุฒุฉ ุงููุญูููุฉ)ุ Q5_1 (ุชูููู 5 ุจุช ููุงุฒู ุจูู ุงูุฌูุฏุฉ ูุงูุถุบุท - ููุงุณุจ ููุงุณุชูุชุงุฌ ุงูุทุฑูู ูู Phi-4-mini-3.8B)ุ ูQ8_0 (ุชูููู 8 ุจุช ููุญูุงุธ ุนูู ุงูุฌูุฏุฉ ุงูุฃุตููุฉ ุชูุฑูุจูุง - ููุตู ุจู ููุงุณุชุฎุฏุงู ุงูุฅูุชุงุฌู ูู Google Gemma3). ููุซู BitNET ุงูุญุฏ ุงูุฃูุตู ูุน ุชูููู 1 ุจุช ููุณููุงุฑูููุงุช ุฐุงุช ุงูุถุบุท ุงูุดุฏูุฏ.

**ููุงุฆุฏ ุงูุชูููุฐ**: ุงุณุชูุชุงุฌ ูุญุณู ููุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ ูุน ุชุณุฑูุน SIMD ูููุฑ ุชุญููู ูุชูููุฐ ุงูููุงุฐุฌ ุจููุงุกุฉ ูู ุงูุฐุงูุฑุฉ. ุงูุชูุงูู ุนุจุฑ ุงูุฃูุธูุฉ ุงูุฃุณุงุณูุฉ ุจูู ูุนูุงุฑูุงุช x86ุ ARMุ ูApple Silicon ูุชูุญ ูุฏุฑุงุช ูุดุฑ ุบูุฑ ูุนุชูุฏุฉ ุนูู ุงูุฃุฌูุฒุฉ.

**ูุซุงู ุนููู ููุชูููุฐ**:

```bash
# Clone and build llama.cpp
git clone https://github.com/ggerganov/llama.cpp.git
cd llama.cpp
mkdir build && cd build
cmake .. -DCMAKE_BUILD_TYPE=Release
cmake --build . --config Release

# Convert Phi-4-mini model from Hugging Face to GGUF format
# First, download the model from Hugging Face
cd ..
python convert.py --outtype f16 --outfile phi-4-mini.gguf /path/to/downloaded/phi-4-mini/model

# Quantize the model to 4-bit precision (Q4_0)
./build/bin/quantize phi-4-mini.gguf phi-4-mini-q4_0.gguf q4_0

# Benchmark the model to check performance
./build/bin/llama-bench -m phi-4-mini-q4_0.gguf -p "Write a function to calculate the Fibonacci sequence"

# Run inference with the quantized model
./build/bin/main -m phi-4-mini-q4_0.gguf -n 512 -p "Explain quantum computing in simple terms"
```

**ููุงุฑูุฉ ุจุตูุฉ ุงูุฐุงูุฑุฉ**:

```python
# Python script to analyze model size differences
import os
import matplotlib.pyplot as plt
import numpy as np

# Model sizes (in GB)
models = ['Phi-4-mini', 'Qwen3-0.6B', 'Gemma3']
original_sizes = [7.6, 1.2, 4.8]  # F16 format
q4_0_sizes = [2.0, 0.35, 1.3]     # Q4_0 format
q8_0_sizes = [3.9, 0.68, 2.5]     # Q8_0 format

# Calculate reduction percentages
q4_reduction = [(orig - q4) / orig * 100 for orig, q4 in zip(original_sizes, q4_0_sizes)]
q8_reduction = [(orig - q8) / orig * 100 for orig, q8 in zip(original_sizes, q8_0_sizes)]

print("Model Size Reduction:")
for i, model in enumerate(models):
    print(f"{model}: Q4_0 reduces size by {q4_reduction[i]:.1f}%, Q8_0 reduces size by {q8_reduction[i]:.1f}%")

# Memory usage during inference will be approximately:
# - Original F16: ~2x model size
# - Q4_0: ~1.2x model size
# - Q8_0: ~1.5x model size
```

### ูุฌููุนุฉ ุชุญุณูู Microsoft Olive

ุชูุฏู Microsoft Olive ุณูุฑ ุนูู ุดุงูู ูุชุญุณูู ุงูููุงุฐุฌ ุงููุตููุฉ ูุจูุฆุงุช ุงูุฅูุชุงุฌ:

**ุชูููุงุช ุงูุชุญุณูู**: ุชุชุถูู ุงููุฌููุนุฉ ุงูุชูููู ุงูุฏููุงูููู ูุงุฎุชูุงุฑ ุงูุฏูุฉ ุชููุงุฆููุง (ูุนุงู ุจุดูู ุฎุงุต ูุน ููุงุฐุฌ ุณูุณูุฉ Qwen3)ุ ุชุญุณูู ุงูุฑุณูู ุงูุจูุงููุฉ ูุฏูุฌ ุงููุดุบููู (ูุญุณู ูููุฏุณุฉ Google Gemma3)ุ ุชุญุณููุงุช ุฎุงุตุฉ ุจุงูุฃุฌูุฒุฉ ููุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉุ ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุชุ ููุญุฏุฉ ุงููุนุงูุฌุฉ ุงูุนุตุจูุฉ (ูุน ุฏุนู ุฎุงุต ูู Phi-4-mini-3.8B ุนูู ุฃุฌูุฒุฉ ARM)ุ ูุฎุทูุท ุชุญุณูู ูุชุนุฏุฏุฉ ุงููุฑุงุญู. ุชุชุทูุจ ููุงุฐุฌ BitNET ุณูุฑ ุนูู ุชูููู 1 ุจุช ูุชุฎุตุต ุฏุงุฎู ุฅุทุงุฑ Olive.

**ุฃุชูุชุฉ ุณูุฑ ุงูุนูู**: ูุถูู ุงูููุงุณ ุงูุชููุงุฆู ุนุจุฑ ูุชุบูุฑุงุช ุงูุชุญุณูู ุงูุญูุงุธ ุนูู ููุงููุณ ุงูุฌูุฏุฉ ุฃุซูุงุก ุงูุชุญุณูู. ูููุฑ ุงูุชูุงูู ูุน ุฃุทุฑ ุงูุชุนูู ุงูุขูู ุงูุดููุฑุฉ ูุซู PyTorch ูONNX ูุฏุฑุงุช ุชุญุณูู ูููุดุฑ ุงูุณุญุงุจู ูุงูุทุฑูู.

**ูุซุงู ุนููู ููุชูููุฐ**:

```python
# Microsoft Olive optimization workflow for SLM
from olive.model import PyTorchModel, ONNXModel
from olive.workflows import run_workflow
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Define the workflow configuration
def create_olive_config(model_id="microsoft/phi-4-mini-instruct"):
    # Load model and create sample inputs
    tokenizer = AutoTokenizer.from_pretrained(model_id)
    model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16)
    
    # Create sample inputs for tracing
    sample_text = "Explain the concept of edge computing"
    inputs = tokenizer(sample_text, return_tensors="pt")
    
    # Export to ONNX first
    model_path = f"{model_id.split('/')[-1]}.onnx"
    torch.onnx.export(
        model,
        (inputs["input_ids"],),
        model_path,
        input_names=["input_ids"],
        output_names=["logits"],
        dynamic_axes={
            "input_ids": {0: "batch", 1: "sequence"},
            "logits": {0: "batch", 1: "sequence"}
        },
        opset_version=15
    )
    
    # Create Olive optimization config
    config = {
        "input_model": ONNXModel(model_path),
        "systems": {
            "local_system": {
                "type": "LocalSystem"
            }
        },
        "passes": {
            # Graph optimization pass
            "graph_optimization": {
                "type": "OrtTransformersOptimization",
                "config": {
                    "optimization_options": {
                        "enable_gelu": True,
                        "enable_layer_norm": True,
                        "enable_attention": True,
                        "use_multi_head_attention": True
                    }
                }
            },
            # Quantization pass for INT8
            "quantization": {
                "type": "OrtQuantization",
                "config": {
                    "quant_mode": "static",
                    "activation_type": "int8",
                    "weight_type": "int8",
                    "op_types_to_quantize": ["MatMul", "Add", "Conv"]
                },
                "disable_search": True
            }
        },
        "engine": {
            "log_severity_level": 0,
            "cache_dir": "./cache"
        }
    }
    
    return config

# Run the optimization workflow
config = create_olive_config()
result = run_workflow(config)

# Save the optimized model
optimized_model = result.optimized_model
optimized_model.save("./optimized_phi4_mini")

# Benchmark performance comparison
print(f"Original model size: {os.path.getsize(model_path) / (1024 * 1024):.2f} MB")
print(f"Optimized model size: {os.path.getsize('./optimized_phi4_mini/model.onnx') / (1024 * 1024):.2f} MB")
```

### ุฅุทุงุฑ Apple MLX

ูููุฑ Apple MLX ุชุญุณูููุง ุฃุตูููุง ูุตูููุง ุฎุตูุตูุง ูุฃุฌูุฒุฉ Apple Silicon:

**ุชุญุณูู Apple Silicon**: ูุณุชุฎุฏู ุงูุฅุทุงุฑ ุจููุฉ ุฐุงูุฑุฉ ููุญุฏุฉ ูุน ุชูุงูู Metal Performance Shadersุ ุงุณุชูุชุงุฌ ุฏูุฉ ูุฎุชูุทุฉ ุชููุงุฆููุง (ูุนุงู ุจุดูู ุฎุงุต ูุน Google Gemma3)ุ ูุชุญุณูู ุงุณุชุฎุฏุงู ุนุฑุถ ุงููุทุงู ุงูุชุฑุฏุฏู ููุฐุงูุฑุฉ. ูุธูุฑ Phi-4-mini-3.8B ุฃุฏุงุกู ุงุณุชุซูุงุฆููุง ุนูู ุฑูุงุฆู ุณูุณูุฉ Mุ ุจูููุง ูููุฑ Qwen3-1.7B ุชูุงุฒููุง ูุซุงูููุง ููุดุฑ MacBook Air.

**ููุฒุงุช ุงูุชุทููุฑ**: ุฏุนู ูุงุฌูุงุช ุจุฑูุฌุฉ ุงูุชุทุจููุงุช Python ูSwift ูุน ุนูููุงุช ุตููู ูุชูุงููุฉ ูุน NumPyุ ูุฏุฑุงุช ุงูุชูุงูุฒ ุงูุชููุงุฆูุ ูุชูุงูู ุณูุณ ูุน ุฃุฏูุงุช ุชุทููุฑ Apple ูููุฑ ุจูุฆุฉ ุชุทููุฑ ุดุงููุฉ.

**ูุซุงู ุนููู ููุชูููุฐ**:

```python
# Apple MLX optimization for Phi-4-mini model
import mlx.core as mx
import mlx.nn as nn
from transformers import AutoTokenizer, AutoModelForCausalLM
from mlx_lm import load, generate

# Install the required packages
# pip install mlx transformers mlx-lm

# Load the Phi-4-mini model with MLX optimization
model_path = "microsoft/phi-4-mini-instruct"
model, tokenizer = load(model_path)

# Convert to float16 for better performance on Apple Silicon
model.convert_to_float16()

# Sample inference
prompt = "Write a function to find prime numbers in Python"
results = generate(
    model, 
    tokenizer,
    prompt=prompt,
    max_tokens=512,
    temperature=0.7,
    top_p=0.9,
)

print(results[0]["generation"])

# Benchmark the model
import time

def benchmark_inference(model, tokenizer, prompt, runs=10):
    # Warmup
    generate(model, tokenizer, prompt=prompt, max_tokens=128)
    
    # Benchmark
    start_time = time.time()
    for _ in range(runs):
        generate(model, tokenizer, prompt=prompt, max_tokens=128)
    end_time = time.time()
    
    avg_time = (end_time - start_time) / runs
    return avg_time

avg_inference_time = benchmark_inference(model, tokenizer, "Explain quantum computing")
print(f"Average inference time: {avg_inference_time:.4f} seconds")

# Save the optimized model for later use
model.save_weights("phi4_mini_optimized_mlx.npz")
```

## ุงุณุชุฑุงุชูุฌูุงุช ุงููุดุฑ ูุงูุฅุณุชูุชุงุฌ ุงูุฅูุชุงุฌู

### Ollama: ูุดุฑ ูุญูู ูุจุณุท

ููุจุณุท Ollama ูุดุฑ SLMs ูุน ููุฒุงุช ุฌุงูุฒุฉ ูููุคุณุณุงุช ูุจูุฆุงุช ุงููุญููุฉ ูุงูุทุฑููุฉ:

**ูุฏุฑุงุช ุงููุดุฑ**: ุชุซุจูุช ูุชุดุบูู ุงูููุงุฐุฌ ุจุฃูุฑ ูุงุญุฏ ูุน ุณุญุจ ุงูููุงุฐุฌ ูุชุฎุฒูููุง ุชููุงุฆููุง. ุฏุนู Phi-4-mini-3.8Bุ ุณูุณูุฉ Qwen3 ุจุงููุงูู (0.6B/1.7B/4B)ุ ูGoogle Gemma3 ูุน ูุงุฌูุฉ REST API ูุชูุงูู ุงูุชุทุจููุงุช ูุฅุฏุงุฑุฉ ุงูููุงุฐุฌ ุงููุชุนุฏุฏุฉ ููุฏุฑุงุช ุงูุชุจุฏูู. ุชุชุทูุจ ููุงุฐุฌ BitNET ุชููููุงุช ุจูุงุก ุชุฌุฑูุจูุฉ ูุฏุนู ุงูุชูููู 1 ุจุช.

**ููุฒุงุช ูุชูุฏูุฉ**: ุฏุนู ุงูุชุฎุตูุต ุงูุฏููู ููููุงุฐุฌุ ุฅูุดุงุก ูููุงุช Docker ูููุดุฑ ูู ุงูุญุงููุงุชุ ุชุณุฑูุน ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช ูุน ุงููุดู ุงูุชููุงุฆูุ ูุฎูุงุฑุงุช ุชูููู ูุชุญุณูู ุงูููุงุฐุฌ ุชููุฑ ูุฑููุฉ ุดุงููุฉ ูููุดุฑ.

### VLLM: ุงุณุชูุชุงุฌ ุนุงูู ุงูุฃุฏุงุก

ูููุฑ VLLM ุชุญุณููุงุช ุงุณุชูุชุงุฌ ุฅูุชุงุฌูุฉ ูุณููุงุฑูููุงุช ุนุงููุฉ ุงูุฅูุชุงุฌูุฉ:

**ุชุญุณููุงุช ุงูุฃุฏุงุก**: PagedAttention ูุญุณุงุจ ุงูุงูุชุจุงู ุจููุงุกุฉ ูู ุงูุฐุงูุฑุฉ (ูููุฏ ุจุดูู ุฎุงุต ูููุฏุณุฉ Phi-4-mini-3.8B)ุ ุงูุชุฌููุน ุงูุฏููุงูููู ูุชุญุณูู ุงูุฅูุชุงุฌูุฉ (ูุญุณู ููุนุงูุฌุฉ ุณูุณูุฉ Qwen3 ุจุงูุชูุงุฒู)ุ ุงูุชูุงุฒู ุงูุชูุณูุฑู ูุชูุณูุน ุงููุทุงู ูุชุนุฏุฏ ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณููุงุช (ุฏุนู Google Gemma3)ุ ูุงูุชุดููุฑ ุงูุชุฎูููู ูุชูููู ุฒูู ุงูุงุณุชุฌุงุจุฉ. ุชุชุทูุจ ููุงุฐุฌ BitNET ููู ุงุณุชูุชุงุฌ ูุชุฎุตุตุฉ ูุนูููุงุช 1 ุจุช.

**ุชูุงูู ุงููุคุณุณุงุช**: ููุงุท ููุงูุฉ API ูุชูุงููุฉ ูุน OpenAIุ ุฏุนู ูุดุฑ Kubernetesุ ุชูุงูู ุงููุฑุงูุจุฉ ูุงูููุงุญุธุฉุ ููุฏุฑุงุช ุงูุชูุณุน ุงูุชููุงุฆู ุชููุฑ ุญููู ูุดุฑ ุนูู ูุณุชูู ุงููุคุณุณุงุช.

### Foundry Local: ุญู ุงูุญุงูุฉ ูู Microsoft

ูููุฑ Foundry Local ูุฏุฑุงุช ูุดุฑ ุทุฑููุฉ ุดุงููุฉ ูุจูุฆุงุช ุงููุคุณุณุงุช:

**ููุฒุงุช ุงูุญูุณุจุฉ ุงูุทุฑููุฉ**: ุชุตููู ูุนูุงุฑู ูุนุชูุฏ ุนูู ุงูุนูู ุฏูู ุงุชุตุงู ูุน ุชุญุณูู ูููุฏ ุงูููุงุฑุฏุ ุฅุฏุงุฑุฉ ุณุฌู ุงูููุงุฐุฌ ุงููุญููุฉุ ููุฏุฑุงุช ุงููุฒุงููุฉ ุจูู ุงูุญุงูุฉ ูุงูุณุญุงุจุฉ ุชุถูู ูุดุฑูุง ููุซูููุง ุนูู ุงูุญุงูุฉ.

**ุงูุฃูุงู ูุงูุงูุชุซุงู**: ูุนุงูุฌุฉ ุงูุจูุงูุงุช ุงููุญููุฉ ููุญูุงุธ ุนูู ุงูุฎุตูุตูุฉุ ุถูุงุจุท ุฃูุงู ุงููุคุณุณุงุชุ ุชุณุฌูู ุงูุชุฏููู ูุฅุนุฏุงุฏ ุชูุงุฑูุฑ ุงูุงูุชุซุงูุ ูุฅุฏุงุฑุฉ ุงููุตูู ุจูุงุกู ุนูู ุงูุฃุฏูุงุฑ ุชููุฑ ุฃูุงููุง ุดุงููุงู ูููุดุฑ ุงูุทุฑูู.

## ุฃูุถู ุงูููุงุฑุณุงุช ูุชูููุฐ SLM

### ุฅุฑุดุงุฏุงุช ุงุฎุชูุงุฑ ุงูููุงุฐุฌ

ุนูุฏ ุงุฎุชูุงุฑ SLMs ูููุดุฑ ุงูุทุฑููุ ุถุน ูู ุงุนุชุจุงุฑู ุงูุนูุงูู ุงูุชุงููุฉ:

**ุงุนุชุจุงุฑุงุช ุนุฏุฏ ุงููุนููุงุช**: ุงุฎุชุฑ ููุงุฐุฌ ุตุบูุฑุฉ ุฌุฏูุง ูุซู Qwen3-0.6B ููุชุทุจููุงุช ุงููุญูููุฉ ุฎูููุฉ ุงููุฒู ููุบุงูุฉุ ููุงุฐุฌ ุตุบูุฑุฉ ูุซู Qwen3-1.7B ุฃู Google Gemma3 ูุณููุงุฑูููุงุช ุงูุฃุฏุงุก ุงููุชูุงุฒูุ ูููุงุฐุฌ ูุชูุณุทุฉ ูุซู Phi-4-mini-3.8B ุฃู Qwen3-4B ุนูุฏ ุงูุงูุชุฑุงุจ ูู ูุฏุฑุงุช LLM ูุน ุงูุญูุงุธ ุนูู ุงูููุงุกุฉ. ุชููุฑ ููุงุฐุฌ BitNET ุถุบุทูุง ูุงุฆููุง ุชุฌุฑูุจููุง ูุชุทุจููุงุช ุงูุจุญุซ ุงููุญุฏุฏุฉ.

**ุชูุงูู ุงูุงุณุชุฎุฏุงู**: ุทุงุจู ูุฏุฑุงุช ุงููููุฐุฌ ูุน ูุชุทูุจุงุช ุงูุชุทุจูู ุงููุญุฏุฏุฉุ ูุน ูุฑุงุนุงุฉ ุนูุงูู ูุซู ุฌูุฏุฉ ุงูุงุณุชุฌุงุจุฉุ ุณุฑุนุฉ ุงูุงุณุชูุชุงุฌุ ูููุฏ ุงูุฐุงูุฑุฉุ ููุชุทูุจุงุช ุงูุชุดุบูู ุฏูู ุงุชุตุงู.

### ุงุฎุชูุงุฑ ุงุณุชุฑุงุชูุฌูุฉ ุงูุชุญุณูู

**ููุฌ ุงูุชูููู**: ุงุฎุชุฑ ูุณุชููุงุช ุงูุชูููู ุงูููุงุณุจุฉ ุจูุงุกู ุนูู ูุชุทูุจุงุช ุงูุฌูุฏุฉ ููููุฏ ุงูุฃุฌูุฒุฉ. ุถุน ูู ุงุนุชุจุงุฑู Q4_0 ูุชุญููู ุฃูุตู ุถุบุท (ูุซุงูู ููุดุฑ Qwen3-0.6B ุนูู ุงูุฃุฌูุฒุฉ ุงููุญูููุฉ)ุ Q5_1 ูุชุญููู ุชูุงุฒู ุจูู ุงูุฌูุฏุฉ ูุงูุถุบุท (ููุงุณุจ ูู Phi-4-mini-3.8B ูGoogle Gemma3)ุ ูQ8_0 ููุญูุงุธ ุนูู ุงูุฌูุฏุฉ ุงูุฃุตููุฉ ุชูุฑูุจูุง (ููุตู ุจู ูุจูุฆุงุช ุงูุฅูุชุงุฌ ูู Qwen3-4B). ููุซู ุชูููู 1 ุจุช ูู BitNET ุงูุญุฏ ุงูุฃูุตู ููุถุบุท ููุชุทุจููุงุช ุงููุชุฎุตุตุฉ.

**ุงุฎุชูุงุฑ ุงูุฅุทุงุฑ**: ุงุฎุชุฑ ุฃุทุฑ ุงูุชุญุณูู ุจูุงุกู ุนูู ุงูุฃุฌูุฒุฉ ุงููุณุชูุฏูุฉ ููุชุทูุจุงุช ุงููุดุฑ. ุงุณุชุฎุฏู Llama.cpp ูููุดุฑ ุงููุญุณู ููุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉุ Microsoft Olive ูุณูุฑ ุนูู ุงูุชุญุณูู ุงูุดุงููุ ูApple MLX ูุฃุฌูุฒุฉ Apple Silicon.

## ุฃูุซูุฉ ุนูููุฉ ููููุงุฐุฌ ูุญุงูุงุช ุงูุงุณุชุฎุฏุงู

### ุณููุงุฑูููุงุช ุงููุดุฑ ุงููุงูุนูุฉ

**ุงูุชุทุจููุงุช ุงููุญูููุฉ**: ูุชููู Qwen3-0.6B ูู ุชุทุจููุงุช ุงูุฏุฑุฏุดุฉ ุนูู ุงูููุงุชู ุงูุฐููุฉ ูุน ุจุตูุฉ ุฐุงูุฑุฉ ุตุบูุฑุฉุ ุจูููุง ูููุฑ Google Gemma3 ุฃุฏุงุกู ูุชูุงุฒููุง ูุฃุฏูุงุช ุงูุชุนููู ุนูู ุงูุฃุฌูุฒุฉ ุงูููุญูุฉ. ููุฏู Phi-4-mini-3.8B ูุฏุฑุงุช ุงุณุชุฏูุงู ูุงุฆูุฉ ูุชุทุจููุงุช ุงูุฅูุชุงุฌูุฉ ุงููุญูููุฉ.

**ุงูุญูุณุจุฉ ุงูููุชุจูุฉ ูุงูุทุฑููุฉ**: ูููุฑ Qwen3-1.7B ุฃุฏุงุกู ูุซุงูููุง ูุชุทุจููุงุช ุงููุณุงุนุฏ ุงูููุชุจูุ ููุฏู Phi-4-mini-3.8B ูุฏุฑุงุช ุฅูุดุงุก ุฃููุงุฏ ูุชูุฏูุฉ ูุฃุฏูุงุช ุงููุทูุฑููุ ููุชูุญ Qwen3-4B ุชุญููููุง ูุชูุฏููุง ูููุซุงุฆู ูู ุจูุฆุงุช ูุญุทุงุช ุงูุนูู.

**ุงูุจุญุซ ูุงูุชุฌุฑูุจ**: ุชุชูุญ ููุงุฐุฌ BitNET ุงุณุชูุดุงู ุงูุงุณุชูุชุงุฌ ุจุฏูุฉ ููุฎูุถุฉ ููุบุงูุฉ ููุจุญุซ ุงูุฃูุงุฏููู ูุชุทุจููุงุช ุฅุซุจุงุช ุงูููููู ุงูุชู ุชุชุทูุจ ูููุฏ ููุงุฑุฏ ุดุฏูุฏุฉ.

### ูุนุงููุฑ ุงูุฃุฏุงุก ูุงูููุงุฑูุงุช

**ุณุฑุนุฉ ุงูุงุณุชูุชุงุฌ**: ูุญูู Qwen3-0.6B ุฃุณุฑุน ุฃููุงุช ุงูุงุณุชูุชุงุฌ ุนูู ูุญุฏุงุช ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ ุงููุญูููุฉุ ูููุฑ Google Gemma3 ูุณุจุฉ ุณุฑุนุฉ-ุฌูุฏุฉ ูุชูุงุฒูุฉ ููุชุทุจููุงุช ุงูุนุงูุฉุ ููุฏู Phi-4-mini-3.8B ุณุฑุนุฉ ุงุณุชุฏูุงู ูุงุฆูุฉ ููููุงู ุงููุนูุฏุฉุ ููุญูู BitNET ุฃูุตู ุฅูุชุงุฌูุฉ ูุธุฑูุฉ ูุน ุงูุฃุฌูุฒุฉ ุงููุชุฎุตุตุฉ.

**ูุชุทูุจุงุช ุงูุฐุงูุฑุฉ**: ุชุชุฑุงูุญ ุจุตูุงุช ุฐุงูุฑุฉ ุงูููุงุฐุฌ ูู Qwen3-0.6B (ุฃูู ูู 1 ุฌูุฌุงุจุงูุช ุจุนุฏ ุงูุชูููู) ุฅูู Phi-4-mini-3.8B (ุญูุงูู 3-4 ุฌูุฌุงุจุงูุช ุจุนุฏ ุงูุชูููู)ุ ูุน ุชุญููู BitNET ุจุตูุงุช ุฃูู ูู 500 ููุฌุงุจุงูุช ูู ุงูุชููููุงุช ุงูุชุฌุฑูุจูุฉ.

## ุงูุชุญุฏูุงุช ูุงูุงุนุชุจุงุฑุงุช

### ุงูุชูุงุฒู ุจูู ุงูุฃุฏุงุก

ูุชุทูุจ ูุดุฑ SLMs ุงููุธุฑ ุจุนูุงูุฉ ูู ุงูุชูุงุฒู ุจูู ุญุฌู ุงููููุฐุฌุ ุณุฑุนุฉ ุงูุงุณุชูุชุงุฌุ ูุฌูุฏุฉ ุงููุฎุฑุฌุงุช. ุนูู ุณุจูู ุงููุซุงูุ ุจูููุง ููุฏู Qwen3-0.6B ุณุฑุนุฉ ูููุงุกุฉ ุงุณุชุซูุงุฆูุฉุ ูููุฑ Phi-4-mini-3.8B ูุฏุฑุงุช ุงุณุชุฏูุงู ูุงุฆูุฉ ุนูู ุญุณุงุจ ุฒูุงุฏุฉ ูุชุทูุจุงุช ุงูููุงุฑุฏ. ููุซู Google Gemma3 ุฎูุงุฑูุง ูุณุทูุง ููุงุณุจูุง ููุนุธู ุงูุชุทุจููุงุช ุงูุนุงูุฉ.

### ุชูุงูู ุงูุฃุฌูุฒุฉ

ุชุชูุชุน ุงูุฃุฌูุฒุฉ ุงูุทุฑููุฉ ุงููุฎุชููุฉ ุจูุฏุฑุงุช ููููุฏ ูุชููุนุฉ. ูุนูู Qwen3-0.6B ุจููุงุกุฉ ุนูู ูุนุงูุฌุงุช ARM ุงูุฃุณุงุณูุฉุ ูุชุทูุจ Google Gemma3 ููุงุฑุฏ ุญุณุงุจูุฉ ูุนุชุฏูุฉุ ููุณุชููุฏ Phi-4-mini-3.8B ูู ุงูุฃุฌูุฒุฉ ุงูุทุฑููุฉ ุนุงููุฉ ุงูุฃุฏุงุก. ุชุชุทูุจ ููุงุฐุฌ BitNET ุฃุฌูุฒุฉ ุฃู ุชุทุจููุงุช ุจุฑูุฌูุฉ ูุชุฎุตุตุฉ ูุชุญููู ุนูููุงุช 1 ุจุช ุงููุซูู.

### ุงูุฃูุงู ูุงูุฎุตูุตูุฉ

ุจูููุง ุชุชูุญ SLMs ุงููุนุงูุฌุฉ ุงููุญููุฉ ูุชุนุฒูุฒ ุงูุฎุตูุตูุฉุ ูุฌุจ ุชูููุฐ ุชุฏุงุจูุฑ ุฃูุงู ููุงุณุจุฉ ูุญูุงูุฉ ุงูููุงุฐุฌ ูุงูุจูุงูุงุช ูู ุงูุจูุฆุงุช ุงูุทุฑููุฉ. ูุฐุง ููู ุจุดูู ุฎุงุต ุนูุฏ ูุดุฑ ููุงุฐุฌ ูุซู Phi-4-mini-3.8B ูู ุจูุฆุงุช ุงููุคุณุณุงุช ุฃู ุณูุณูุฉ Qwen3 ูู ุงูุชุทุจููุงุช ูุชุนุฏุฏุฉ ุงููุบุงุช ุงูุชู ุชุชุนุงูู ูุน ุจูุงูุงุช ุญุณุงุณุฉ.

## ุงูุงุชุฌุงูุงุช ุงููุณุชูุจููุฉ ูู ุชุทููุฑ SLM

ูุณุชูุฑ ูุดูุฏ SLM ูู ุงูุชุทูุฑ ูุน ุงูุชูุฏู ูู ุจูู ุงูููุงุฐุฌุ ุชูููุงุช ุงูุชุญุณููุ ูุงุณุชุฑุงุชูุฌูุงุช ุงููุดุฑ. ุชุดูู ุงูุชุทูุฑุงุช ุงููุณุชูุจููุฉ ุจูู ุฃูุซุฑ ููุงุกุฉุ ุทุฑู ุชูููู ูุญุณูุฉุ ูุชูุงูู ุฃูุถู ูุน ูุณุฑุนุงุช ุงูุฃุฌูุฒุฉ ุงูุทุฑููุฉ.

ููู ูุฐู ุงูุงุชุฌุงูุงุช ูุงูุญูุงุธ ุนูู ุงููุนู ุจุงูุชูููุงุช ุงููุงุดุฆุฉ ุณูููู ุฃูุฑูุง ุญุงุณููุง ููุจูุงุก ุนูู ุงุทูุงุน ุจุฃูุถู ุงูููุงุฑุณุงุช ูุชุทููุฑ ููุดุฑ SLM.

## โก๏ธ ูุง ุงูุชุงูู

- [02: ูุดุฑ SLM ูู ุงูุจูุฆุฉ ุงููุญููุฉ](02.DeployingSLMinLocalEnv.md)

---

**ุฅุฎูุงุก ุงููุณุคูููุฉ**:  
ุชู ุชุฑุฌูุฉ ูุฐุง ุงููุณุชูุฏ ุจุงุณุชุฎุฏุงู ุฎุฏูุฉ ุงูุชุฑุฌูุฉ ุจุงูุฐูุงุก ุงูุงุตุทูุงุนู [Co-op Translator](https://github.com/Azure/co-op-translator). ุจูููุง ูุณุนู ูุชุญููู ุงูุฏูุฉุ ูุฑุฌู ุงูุนูู ุฃู ุงูุชุฑุฌูุงุช ุงูุขููุฉ ูุฏ ุชุญุชูู ุนูู ุฃุฎุทุงุก ุฃู ุนุฏู ุฏูุฉ. ูุฌุจ ุงุนุชุจุงุฑ ุงููุณุชูุฏ ุงูุฃุตูู ุจูุบุชู ุงูุฃุตููุฉ ุงููุตุฏุฑ ุงูุฑุณูู. ููุญุตูู ุนูู ูุนูููุงุช ุญุงุณูุฉุ ูููุตู ุจุงูุชุฑุฌูุฉ ุงูุจุดุฑูุฉ ุงูุงุญุชุฑุงููุฉ. ูุญู ุบูุฑ ูุณุคูููู ุนู ุฃู ุณูุก ููู ุฃู ุชูุณูุฑุงุช ุฎุงุทุฆุฉ ุชูุดุฃ ุนู ุงุณุชุฎุฏุงู ูุฐู ุงูุชุฑุฌูุฉ.