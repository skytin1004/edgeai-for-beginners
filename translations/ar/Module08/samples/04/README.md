<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "562ac0eae12d808c9f45fbb77eb5c84f",
  "translation_date": "2025-09-24T13:27:25+00:00",
  "source_file": "Module08/samples/04/README.md",
  "language_code": "ar"
}
-->
# Ø§Ù„Ø¹ÙŠÙ†Ø© 04: ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Chainlit

Ø¹ÙŠÙ†Ø© Ø´Ø§Ù…Ù„Ø© ØªÙˆØ¶Ø­ Ø·Ø±Ù‚ Ù…ØªØ¹Ø¯Ø¯Ø© Ù„Ø¨Ù†Ø§Ø¡ ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø¯Ø±Ø¯Ø´Ø© Ø¬Ø§Ù‡Ø²Ø© Ù„Ù„Ø¥Ù†ØªØ§Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Microsoft Foundry LocalØŒ Ù…Ø¹ ÙˆØ§Ø¬Ù‡Ø§Øª ÙˆÙŠØ¨ Ø­Ø¯ÙŠØ«Ø©ØŒ Ø§Ø³ØªØ¬Ø§Ø¨Ø§Øª Ù…ØªØ¯ÙÙ‚Ø©ØŒ ÙˆØªÙ‚Ù†ÙŠØ§Øª Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„Ù…ØªØµÙØ­.

## Ù…Ø§ ÙŠØªØ¶Ù…Ù†Ù‡

- **ðŸš€ ØªØ·Ø¨ÙŠÙ‚ Ø¯Ø±Ø¯Ø´Ø© Chainlit** (`app.py`): ØªØ·Ø¨ÙŠÙ‚ Ø¯Ø±Ø¯Ø´Ø© Ø¬Ø§Ù‡Ø² Ù„Ù„Ø¥Ù†ØªØ§Ø¬ Ù…Ø¹ Ø¯Ø¹Ù… Ø§Ù„ØªØ¯ÙÙ‚
- **ðŸŒ Ø¹Ø±Ø¶ WebGPU** (`webgpu-demo/`): Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¹Ø¨Ø± Ø§Ù„Ù…ØªØµÙØ­ Ù…Ø¹ ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ø£Ø¬Ù‡Ø²Ø©
- **ðŸŽ¨ ØªÙƒØ§Ù…Ù„ ÙˆØ§Ø¬Ù‡Ø© Open WebUI** (`open-webui-guide.md`): ÙˆØ§Ø¬Ù‡Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ù…Ø´Ø§Ø¨Ù‡Ø© Ù„Ù€ ChatGPT
- **ðŸ“š Ø¯ÙØªØ± ØªØ¹Ù„ÙŠÙ…ÙŠ** (`chainlit_app.ipynb`): Ù…ÙˆØ§Ø¯ ØªØ¹Ù„ÙŠÙ…ÙŠØ© ØªÙØ§Ø¹Ù„ÙŠØ©

## Ø§Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ø³Ø±ÙŠØ¹

### 1. ØªØ·Ø¨ÙŠÙ‚ Ø¯Ø±Ø¯Ø´Ø© Chainlit

```cmd
# Navigate to Module08 directory
cd Module08

# Start your model
foundry model run phi-4-mini

# Run Chainlit app (using port 8080 to avoid conflicts)
chainlit run samples\04\app.py -w --port 8080
```

ÙŠÙØªØ­ Ø¹Ù„Ù‰: `http://localhost:8080`

### 2. Ø¹Ø±Ø¶ WebGPU Ø¹Ø¨Ø± Ø§Ù„Ù…ØªØµÙØ­

```cmd
# Navigate to WebGPU demo
cd Module08\samples\04\webgpu-demo

# Serve the demo
python -m http.server 5173
```

ÙŠÙØªØ­ Ø¹Ù„Ù‰: `http://localhost:5173`

### 3. Ø¥Ø¹Ø¯Ø§Ø¯ Open WebUI

```cmd
# Run Open WebUI with Docker
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

ÙŠÙØªØ­ Ø¹Ù„Ù‰: `http://localhost:3000`

## Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ©

### Ù…ØµÙÙˆÙØ© Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø± Ø¨ÙŠÙ† Ø§Ù„Ù…Ø­Ù„ÙŠ ÙˆØ§Ù„Ø³Ø­Ø§Ø¨ÙŠ

| Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ | Ø§Ù„ØªÙˆØµÙŠØ© | Ø§Ù„Ø³Ø¨Ø¨ |
|-----------|---------|-------|
| **Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø© Ù„Ù„Ø®ØµÙˆØµÙŠØ©** | ðŸ  Ù…Ø­Ù„ÙŠ (Foundry) | Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø§ ØªØºØ§Ø¯Ø± Ø§Ù„Ø¬Ù‡Ø§Ø² |
| **Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø§Ù„Ù…Ø¹Ù‚Ø¯** | â˜ï¸ Ø³Ø­Ø§Ø¨ÙŠ (Azure OpenAI) | Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ù†Ù…Ø§Ø°Ø¬ Ø£ÙƒØ¨Ø± |
| **Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ** | ðŸ  Ù…Ø­Ù„ÙŠ (Foundry) | Ø²Ù…Ù† Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø£Ù‚Ù„ØŒ Ø§Ø³ØªØ¬Ø§Ø¨Ø§Øª Ø£Ø³Ø±Ø¹ |
| **ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª** | ðŸ”„ Ù‡Ø¬ÙŠÙ† | Ù…Ø­Ù„ÙŠ Ù„Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ØŒ Ø³Ø­Ø§Ø¨ÙŠ Ù„Ù„ØªØ­Ù„ÙŠÙ„ |
| **ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£ÙƒÙˆØ§Ø¯** | ðŸ  Ù…Ø­Ù„ÙŠ (Foundry) | Ø§Ù„Ø®ØµÙˆØµÙŠØ© + Ù†Ù…Ø§Ø°Ø¬ Ù…ØªØ®ØµØµØ© |
| **Ù…Ù‡Ø§Ù… Ø§Ù„Ø¨Ø­Ø«** | â˜ï¸ Ø³Ø­Ø§Ø¨ÙŠ (Azure OpenAI) | Ù‚Ø§Ø¹Ø¯Ø© Ù…Ø¹Ø±ÙØ© ÙˆØ§Ø³Ø¹Ø© Ù…Ø·Ù„ÙˆØ¨Ø© |

### Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª

| Ø§Ù„ØªÙ‚Ù†ÙŠØ© | Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… | Ø§Ù„Ù…Ø²Ø§ÙŠØ§ | Ø§Ù„Ø¹ÙŠÙˆØ¨ |
|---------|-----------|---------|--------|
| **Chainlit** | Ù…Ø·ÙˆØ±Ùˆ PythonØŒ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø§Ù„Ø³Ø±ÙŠØ¹Ø© | Ø¥Ø¹Ø¯Ø§Ø¯ Ø³Ù‡Ù„ØŒ Ø¯Ø¹Ù… Ø§Ù„ØªØ¯ÙÙ‚ | Python ÙÙ‚Ø· |
| **WebGPU** | Ø£Ù‚ØµÙ‰ Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø®ØµÙˆØµÙŠØ©ØŒ Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª ØºÙŠØ± Ù…ØªØµÙ„Ø© | Ø£ØµÙ„ÙŠ Ù„Ù„Ù…ØªØµÙØ­ØŒ Ù„Ø§ Ø­Ø§Ø¬Ø© Ù„Ù„Ø®Ø§Ø¯Ù… | Ø­Ø¬Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ø¯ÙˆØ¯ |
| **Open WebUI** | Ø§Ù„Ù†Ø´Ø± Ø§Ù„Ø¥Ù†ØªØ§Ø¬ÙŠØŒ Ø§Ù„ÙØ±Ù‚ | ÙˆØ§Ø¬Ù‡Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ©ØŒ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… | ÙŠØªØ·Ù„Ø¨ Docker |

## Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©

- **Foundry Local**: Ù…Ø«Ø¨Øª ÙˆÙŠØ¹Ù…Ù„ ([ØªØ­Ù…ÙŠÙ„](https://aka.ms/foundry-local-installer))
- **Python**: Ø¥ØµØ¯Ø§Ø± 3.10+ Ù…Ø¹ Ø¨ÙŠØ¦Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
- **Ø§Ù„Ù†Ù…ÙˆØ°Ø¬**: ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ø­Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ (`foundry model run phi-4-mini`)
- **Ø§Ù„Ù…ØªØµÙØ­**: Chrome/Edge Ù…Ø¹ Ø¯Ø¹Ù… WebGPU Ù„Ù„Ø¹Ø±ÙˆØ¶
- **Docker**: Ù„Ù€ Open WebUI (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)

## Ø§Ù„ØªØ«Ø¨ÙŠØª ÙˆØ§Ù„Ø¥Ø¹Ø¯Ø§Ø¯

### 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ¦Ø© Python

```cmd
# Navigate to Module08 directory
cd Module08

# Create and activate virtual environment
py -m venv .venv
.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Ø¥Ø¹Ø¯Ø§Ø¯ Foundry Local

```cmd
# Verify Foundry Local installation
foundry --version

# Start the service
foundry service start

# Load a model
foundry model run phi-4-mini

# Verify model is running
foundry service ps
```

## ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ø¹ÙŠÙ†Ø©

### ØªØ·Ø¨ÙŠÙ‚ Ø¯Ø±Ø¯Ø´Ø© Chainlit

**Ø§Ù„Ù…ÙŠØ²Ø§Øª:**
- ðŸš€ **Ø§Ù„ØªØ¯ÙÙ‚ ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ**: Ø¸Ù‡ÙˆØ± Ø§Ù„Ø±Ù…ÙˆØ² Ø£Ø«Ù†Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯Ù‡Ø§
- ðŸ›¡ï¸ **Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù‚ÙˆÙŠØ©**: ØªØ¯Ù‡ÙˆØ± Ø³Ù„Ø³ ÙˆØ§Ø³ØªØ±Ø¯Ø§Ø¯
- ðŸŽ¨ **ÙˆØ§Ø¬Ù‡Ø© Ø­Ø¯ÙŠØ«Ø©**: ÙˆØ§Ø¬Ù‡Ø© Ø¯Ø±Ø¯Ø´Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ø¬Ø§Ù‡Ø²Ø©
- ðŸ”§ **ØªÙƒÙˆÙŠÙ† Ù…Ø±Ù†**: Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© ÙˆØ§Ù„ÙƒØ´Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
- ðŸ“± **ØªØµÙ…ÙŠÙ… Ù…ØªØ¬Ø§ÙˆØ¨**: ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ Ø£Ø¬Ù‡Ø²Ø© Ø³Ø·Ø­ Ø§Ù„Ù…ÙƒØªØ¨ ÙˆØ§Ù„Ù‡ÙˆØ§ØªÙ Ø§Ù„Ù…Ø­Ù…ÙˆÙ„Ø©

**Ø§Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ø³Ø±ÙŠØ¹:**
```cmd
# Run with default settings (recommended)
chainlit run samples\04\app.py -w --port 8080

# Use specific model
set MODEL=qwen2.5-7b-instruct
chainlit run samples\04\app.py -w --port 8080

# Manual endpoint configuration
set BASE_URL=http://localhost:51211
set API_KEY=your-api-key
chainlit run samples\04\app.py -w --port 8080
```

### Ø¹Ø±Ø¶ WebGPU Ø¹Ø¨Ø± Ø§Ù„Ù…ØªØµÙØ­

**Ø§Ù„Ù…ÙŠØ²Ø§Øª:**
- ðŸŒ **Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø£ØµÙ„ÙŠ Ù„Ù„Ù…ØªØµÙØ­**: Ù„Ø§ Ø­Ø§Ø¬Ø© Ù„Ù„Ø®Ø§Ø¯Ù…ØŒ ÙŠØ¹Ù…Ù„ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ ÙÙŠ Ø§Ù„Ù…ØªØµÙØ­
- âš¡ **ØªØ³Ø±ÙŠØ¹ WebGPU**: ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø¹Ù†Ø¯ ØªÙˆÙØ±Ù‡
- ðŸ”’ **Ø£Ù‚ØµÙ‰ Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø®ØµÙˆØµÙŠØ©**: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø§ ØªØºØ§Ø¯Ø± Ø¬Ù‡Ø§Ø²Ùƒ Ø£Ø¨Ø¯Ù‹Ø§
- ðŸŽ¯ **Ø¨Ø¯ÙˆÙ† ØªØ«Ø¨ÙŠØª**: ÙŠØ¹Ù…Ù„ ÙÙŠ Ø£ÙŠ Ù…ØªØµÙØ­ Ù…ØªÙˆØ§ÙÙ‚
- ðŸ”„ **ØªØ¯Ù‡ÙˆØ± Ø³Ù„Ø³**: ÙŠØ¹ÙˆØ¯ Ø¥Ù„Ù‰ ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ© Ø¥Ø°Ø§ ÙƒØ§Ù† WebGPU ØºÙŠØ± Ù…ØªÙˆÙØ±

**Ø§Ù„ØªØ´ØºÙŠÙ„:**
```cmd
cd samples\04\webgpu-demo
python -m http.server 5173
# Open http://localhost:5173
```

### ØªÙƒØ§Ù…Ù„ Open WebUI

**Ø§Ù„Ù…ÙŠØ²Ø§Øª:**
- ðŸŽ¨ **ÙˆØ§Ø¬Ù‡Ø© Ù…Ø´Ø§Ø¨Ù‡Ø© Ù„Ù€ ChatGPT**: ÙˆØ§Ø¬Ù‡Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ© ÙˆÙ…Ø£Ù„ÙˆÙØ©
- ðŸ‘¥ **Ø¯Ø¹Ù… Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†**: Ø­Ø³Ø§Ø¨Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ÙˆØ³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª
- ðŸ“ **Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª**: ØªØ­Ù…ÙŠÙ„ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª
- ðŸ”„ **ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬**: ØªØ¨Ø¯ÙŠÙ„ Ø³Ù‡Ù„ Ø¨ÙŠÙ† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
- ðŸ³ **Ù†Ø´Ø± Docker**: Ø¥Ø¹Ø¯Ø§Ø¯ Ø¬Ø§Ù‡Ø² Ù„Ù„Ø¥Ù†ØªØ§Ø¬ ÙˆÙ…ÙØ­ÙŽÙˆÙ’Ø³ÙŽØ¨

**Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³Ø±ÙŠØ¹:**
```cmd
docker run -d --name open-webui -p 3000:8080 \
  -e OPENAI_API_BASE_URL=http://host.docker.internal:51211/v1 \
  -e OPENAI_API_KEY=foundry-local-key \
  ghcr.io/open-webui/open-webui:main
```

## Ù…Ø±Ø¬Ø¹ Ø§Ù„ØªÙƒÙˆÙŠÙ†

### Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©

| Ø§Ù„Ù…ØªØºÙŠØ± | Ø§Ù„ÙˆØµÙ | Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ | Ø§Ù„Ù…Ø«Ø§Ù„ |
|---------|-------|----------|--------|
| `MODEL` | Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ¹Ø§Ø± Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… | `phi-4-mini` | `qwen2.5-7b-instruct` |
| `BASE_URL` | Ù†Ù‚Ø·Ø© Ù†Ù‡Ø§ÙŠØ© Foundry Local | Ø§Ù„ÙƒØ´Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ | `http://localhost:51211` |
| `API_KEY` | Ù…ÙØªØ§Ø­ API (Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ù„Ù„Ù…Ø­Ù„ÙŠ) | `""` | `your-api-key` |

## Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØ¥ØµÙ„Ø§Ø­Ù‡Ø§

### Ø§Ù„Ù…Ø´ÙƒÙ„Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©

**ØªØ·Ø¨ÙŠÙ‚ Chainlit:**

1. **Ø§Ù„Ø®Ø¯Ù…Ø© ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©:**
   ```cmd
   # Check Foundry Local status
   foundry service status
   foundry service ps
   
   # Validate API endpoint (note: port 51211)
   curl http://localhost:51211/v1/models
   ```

2. **ØªØ¹Ø§Ø±Ø¶ Ø§Ù„Ù…Ù†Ø§ÙØ°:**
   ```cmd
   # Check what's using port 8080
   netstat -ano | findstr :8080
   
   # Use different port if needed
   chainlit run samples\04\app.py -w --port 3000
   ```

3. **Ù…Ø´ÙƒÙ„Ø§Øª Ø¨ÙŠØ¦Ø© Python:**
   ```cmd
   # Verify correct interpreter in VS Code
   # Ctrl+Shift+P â†’ Python: Select Interpreter
   # Choose: Module08/.venv/Scripts/python.exe
   
   # Reinstall dependencies
   pip install -r requirements.txt
   ```

**Ø¹Ø±Ø¶ WebGPU:**

1. **WebGPU ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…:**
   - Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø¥Ù„Ù‰ Chrome/Edge 113+
   - ØªÙ…ÙƒÙŠÙ† WebGPU: `chrome://flags/#enable-unsafe-webgpu`
   - ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø§Ù„Ø© GPU: `chrome://gpu`
   - Ø§Ù„Ø¹Ø±Ø¶ Ø³ÙŠØ¹ÙˆØ¯ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¥Ù„Ù‰ ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ©

2. **Ø£Ø®Ø·Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:**
   - ØªØ£ÙƒØ¯ Ù…Ù† Ø§ØªØµØ§Ù„ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
   - ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ­Ø¯Ø© Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„Ù…ØªØµÙØ­ Ù„Ø£Ø®Ø·Ø§Ø¡ CORS
   - ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ùƒ ØªÙ‚Ø¯Ù… Ø¹Ø¨Ø± HTTP (ÙˆÙ„ÙŠØ³ file://)

**Open WebUI:**

1. **Ø§Ù„Ø§ØªØµØ§Ù„ Ù…Ø±ÙÙˆØ¶:**
   ```cmd
   # Check Docker is running
   docker --version
   
   # Check container status
   docker ps | findstr open-webui
   
   # View container logs
   docker logs open-webui
   ```

2. **Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„Ø§ ØªØ¸Ù‡Ø±:**
   ```cmd
   # Verify Foundry Local endpoint
   curl http://localhost:51211/v1/models
   
   # Restart Open WebUI
   docker restart open-webui
   ```

### Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ­Ù‚Ù‚

```cmd
# âœ… 1. Foundry Local Setup
foundry --version                    # Should show version
foundry service status               # Should show "running"
foundry model list                   # Should show loaded models
curl http://localhost:51211/v1/models  # Should return JSON

# âœ… 2. Python Environment  
python --version                     # Should be 3.10+
pip list | findstr chainlit         # Should show chainlit package
pip list | findstr openai           # Should show openai package

# âœ… 3. Application Testing
chainlit run samples\04\app.py -w --port 8080  # Should open browser
# Test WebGPU demo at localhost:5173
# Test Open WebUI at localhost:3000
```

## Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù…

### ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡

**Chainlit:**
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªØ¯ÙÙ‚ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø¯Ø±Ùƒ
- ØªÙ†ÙÙŠØ° ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ù„ØªØ²Ø§Ù…Ù† Ø¹Ø§Ù„ÙŠ
- ØªØ®Ø²ÙŠÙ† Ø§Ø³ØªØ¬Ø§Ø¨Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©
- Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù…Ø¹ Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©

**WebGPU:**
- Ø§Ø³ØªØ®Ø¯Ù… WebGPU Ù„Ø£Ù‚ØµÙ‰ Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø®ØµÙˆØµÙŠØ© ÙˆØ§Ù„Ø³Ø±Ø¹Ø©
- ØªÙ†ÙÙŠØ° ØªÙ‚Ù„ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø£ØµØºØ±
- Ø§Ø³ØªØ®Ø¯Ø§Ù… Web Workers Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©
- ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¬Ù…Ø¹Ø© ÙÙŠ ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…ØªØµÙØ­

**Open WebUI:**
- Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ­Ø¯Ø§Øª ØªØ®Ø²ÙŠÙ† Ø¯Ø§Ø¦Ù…Ø© Ù„Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª
- ØªÙƒÙˆÙŠÙ† Ø­Ø¯ÙˆØ¯ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ù„Ø­Ø§ÙˆÙŠØ© Docker
- ØªÙ†ÙÙŠØ° Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
- Ø¥Ø¹Ø¯Ø§Ø¯ ÙˆÙƒÙŠÙ„ Ø¹ÙƒØ³ÙŠ Ù„Ø¥Ù†Ù‡Ø§Ø¡ SSL

### Ø£Ù†Ù…Ø§Ø· Ø§Ù„ØªÙƒØ§Ù…Ù„

**Ù‡Ø¬ÙŠÙ† Ù…Ø­Ù„ÙŠ/Ø³Ø­Ø§Ø¨ÙŠ:**
```python
# Route based on complexity and privacy requirements
async def intelligent_routing(prompt: str, metadata: dict):
    if metadata.get("contains_pii"):
        return await foundry_local_completion(prompt)  # Privacy-sensitive
    elif len(prompt.split()) > 200:
        return await azure_openai_completion(prompt)   # Complex reasoning
    else:
        return await foundry_local_completion(prompt)  # Default local
```

**Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙˆØ³Ø§Ø¦Ø·:**
```python
# Combine different AI capabilities
async def analyze_document(file_path: str):
    # 1. OCR with WebGPU (browser-based)
    text = await webgpu_ocr(file_path)
    
    # 2. Analysis with Foundry Local (private)
    summary = await foundry_local_analyze(text)
    
    # 3. Enhancement with cloud (if needed)
    if summary.confidence < 0.8:
        summary = await azure_openai_enhance(summary)
    
    return summary
```

## Ø§Ù„Ù†Ø´Ø± Ø§Ù„Ø¥Ù†ØªØ§Ø¬ÙŠ

### Ø§Ø¹ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù†

- **Ù…ÙØ§ØªÙŠØ­ API**: Ø§Ø³ØªØ®Ø¯Ù… Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©ØŒ Ù„Ø§ ØªÙ‚Ù… Ø¨ØªØ¶Ù…ÙŠÙ†Ù‡Ø§ Ù…Ø¨Ø§Ø´Ø±Ø©
- **Ø§Ù„Ø´Ø¨ÙƒØ©**: Ø§Ø³ØªØ®Ø¯Ù… HTTPS ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ØŒ ÙÙƒØ± ÙÙŠ VPN Ù„Ù„ÙˆØµÙˆÙ„ Ø§Ù„ÙØ±ÙŠÙ‚
- **Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„ÙˆØµÙˆÙ„**: ØªÙ†ÙÙŠØ° Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø© Ù„Ù€ Open WebUI
- **Ø®ØµÙˆØµÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**: ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ ÙŠØ¨Ù‚Ù‰ Ù…Ø­Ù„ÙŠÙ‹Ø§ Ù…Ù‚Ø§Ø¨Ù„ Ù…Ø§ ÙŠØ°Ù‡Ø¨ Ø¥Ù„Ù‰ Ø§Ù„Ø³Ø­Ø§Ø¨Ø©
- **Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª**: Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ ØªØ­Ø¯ÙŠØ« Foundry Local ÙˆØ§Ù„Ø­Ø§ÙˆÙŠØ§Øª

### Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© ÙˆØ§Ù„ØµÙŠØ§Ù†Ø©

- **ÙØ­ÙˆØµØ§Øª Ø§Ù„ØµØ­Ø©**: ØªÙ†ÙÙŠØ° Ù…Ø±Ø§Ù‚Ø¨Ø© Ù†Ù‚Ø§Ø· Ø§Ù„Ù†Ù‡Ø§ÙŠØ©
- **Ø§Ù„ØªØ³Ø¬ÙŠÙ„**: Ù…Ø±ÙƒØ²ÙŠØ© Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª
- **Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³**: ØªØªØ¨Ø¹ Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©ØŒ Ù…Ø¹Ø¯Ù„Ø§Øª Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø±Ø¯
- **Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ**: Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù…Ù†ØªØ¸Ù… Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª ÙˆØ§Ù„ØªÙƒÙˆÙŠÙ†Ø§Øª

## Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ ÙˆØ§Ù„Ù…ÙˆØ§Ø±Ø¯

### Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚
- [ÙˆØ«Ø§Ø¦Ù‚ Chainlit](https://docs.chainlit.io/) - Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„ÙƒØ§Ù…Ù„
- [ÙˆØ«Ø§Ø¦Ù‚ Foundry Local](https://learn.microsoft.com/azure/ai-foundry/foundry-local/) - ÙˆØ«Ø§Ø¦Ù‚ Microsoft Ø§Ù„Ø±Ø³Ù…ÙŠØ©
- [ONNX Runtime Web](https://onnxruntime.ai/docs/get-started/with-javascript/web.html) - ØªÙƒØ§Ù…Ù„ WebGPU
- [ÙˆØ«Ø§Ø¦Ù‚ Open WebUI](https://docs.openwebui.com/) - ØªÙƒÙˆÙŠÙ† Ù…ØªÙ‚Ø¯Ù…

### Ù…Ù„ÙØ§Øª Ø§Ù„Ø¹ÙŠÙ†Ø©
- [`app.py`](../../../../../Module08/samples/04/app.py) - ØªØ·Ø¨ÙŠÙ‚ Chainlit Ø§Ù„Ø¥Ù†ØªØ§Ø¬ÙŠ
- [`chainlit_app.ipynb`](./chainlit_app.ipynb) - Ø¯ÙØªØ± ØªØ¹Ù„ÙŠÙ…ÙŠ
- [`webgpu-demo/`](../../../../../Module08/samples/04/webgpu-demo) - Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¹Ø¨Ø± Ø§Ù„Ù…ØªØµÙØ­
- [`open-webui-guide.md`](./open-webui-guide.md) - Ø¥Ø¹Ø¯Ø§Ø¯ Open WebUI Ø§Ù„ÙƒØ§Ù…Ù„

### Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©
- [ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ø¬Ù„Ø³Ø© 4](../../04.CuttingEdgeModels.md) - Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¬Ù„Ø³Ø© Ø§Ù„ÙƒØ§Ù…Ù„
- [Ø¹ÙŠÙ†Ø§Øª Foundry Local](https://github.com/microsoft/foundry-local/tree/main/samples) - Ø¹ÙŠÙ†Ø§Øª Ø±Ø³Ù…ÙŠØ©

---

